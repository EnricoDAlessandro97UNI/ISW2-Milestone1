{"sha":"037713709672b3b500f7375a1bd81c1649956e3f","node_id":"MDY6Q29tbWl0NDc4NTkyNTI2OjAzNzcxMzcwOTY3MmIzYjUwMGY3Mzc1YTFiZDgxYzE2NDk5NTZlM2Y=","commit":{"author":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-07-29T04:10:33Z"},"committer":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-12-28T00:49:26Z"},"message":"DL-101: Improve session expire handling on fetching log segments for readers\n\nThis change focuses on improving the session expire handling on fetching log segments for readers.\n\nThe log segment management in DL is now done by 3 parts.\n\n- a LogSegmentMetadataStore (one per namespace instance): it is used for fetching the log segments from log segment metadata store (ZooKeeper). it doesn't do any caching.\n- a LogSegmentMetadataCache (one per namespace instance): it is a guava cache based metadata cache. it maintains a mapping between log segment metadata path and the log segment metadata. it manages the cache for the log segments that will be accessed in this namespace instance. it doesn't manage the sequence of the log segments for streams.\n- a PerStreamLogSegmentCache for each BKLogHandler. the log segment cache is per stream. it maintains the sequence of the log segments.\n\nBKLogWriteHandler doesn't watch the log segment changes. It fetches minimal number of log segments when it is created and fetches the full list of log segments for truncations. New log segments will be added to the per stream log segment cache with log segment rolling.\n\nBKLogReadHandler watch the log segments changes and only notify when the list of log segments is changed. the session handling which is specific to the metadata store is hidden to the implementations of LogSegmentMetadataStore.\n\nThe change tries to cleanup bunch of unused methods in BKLog{Read,Write}Handler too.","tree":{"sha":"1355832bb5242813bcacb79d90d5d00adf212620","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/trees/1355832bb5242813bcacb79d90d5d00adf212620"},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/commits/037713709672b3b500f7375a1bd81c1649956e3f","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/037713709672b3b500f7375a1bd81c1649956e3f","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/037713709672b3b500f7375a1bd81c1649956e3f","comments_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/037713709672b3b500f7375a1bd81c1649956e3f/comments","author":null,"committer":null,"parents":[{"sha":"ff21a477e2697daa0759d6a3b7daf5354db156df","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/ff21a477e2697daa0759d6a3b7daf5354db156df","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/ff21a477e2697daa0759d6a3b7daf5354db156df"}],"stats":{"total":2431,"additions":1338,"deletions":1093},"files":[{"sha":"bd71147648f74919784763772b23113e86986824","filename":"src/main/java/com/twitter/distributedlog/AsyncNotification.java","status":"modified","additions":3,"deletions":1,"changes":4,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncNotification.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncNotification.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncNotification.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -20,8 +20,10 @@\n public interface AsyncNotification {\n     /**\n      * Triggered when the background activity encounters an exception\n+     *\n+     * @param reason the exception that encountered.\n      */\n-    void notifyOnError();\n+    void notifyOnError(Throwable reason);\n \n     /**\n      *  Triggered when the background activity completes an operation"},{"sha":"90230aed577091c239238d2efdcc07cbc5eb476c","filename":"src/main/java/com/twitter/distributedlog/BKAsyncLogReaderDLSN.java","status":"modified","additions":14,"deletions":15,"changes":29,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -104,7 +104,7 @@ public LogRecordWithDLSN apply(List<LogRecordWithDLSN> records) {\n \n     private boolean lockStream = false;\n \n-    private boolean disableReadAheadZKNotification = false;\n+    private boolean disableReadAheadLogSegmentsNotification = false;\n \n     private final boolean returnEndOfStreamRecord;\n \n@@ -400,23 +400,17 @@ public void onSuccess(Void value) {\n                         bkLedgerManager.startReadAhead(\n                                 new LedgerReadPosition(getStartDLSN()),\n                                 failureInjector);\n-                        if (disableReadAheadZKNotification) {\n-                            bkLedgerManager.disableReadAheadZKNotification();\n+                        if (disableReadAheadLogSegmentsNotification) {\n+                            bkLedgerManager.disableReadAheadLogSegmentsNotification();\n                         }\n                     } catch (Exception exc) {\n-                        setLastException(new IOException(exc));\n-                        notifyOnError();\n+                        notifyOnError(exc);\n                     }\n                 }\n \n                 @Override\n                 public void onFailure(Throwable cause) {\n-                    if (cause instanceof IOException) {\n-                        setLastException((IOException)cause);\n-                    } else {\n-                        setLastException(new IOException(cause));\n-                    }\n-                    notifyOnError();\n+                    notifyOnError(cause);\n                 }\n             });\n             readAheadStarted = true;\n@@ -643,7 +637,12 @@ private boolean recordPositionsContainsGap(LogRecordWithDLSN record, long lastPo\n      * Triggered when the background activity encounters an exception\n      */\n     @Override\n-    public void notifyOnError() {\n+    public void notifyOnError(Throwable cause) {\n+        if (cause instanceof IOException) {\n+            setLastException((IOException) cause);\n+        } else {\n+            setLastException(new IOException(cause));\n+        }\n         scheduleBackgroundRead();\n     }\n \n@@ -661,9 +660,9 @@ void simulateErrors() {\n     }\n \n     @VisibleForTesting\n-    synchronized void disableReadAheadZKNotification() {\n-        disableReadAheadZKNotification = true;\n-        bkLedgerManager.disableReadAheadZKNotification();\n+    synchronized void disableReadAheadLogSegmentsNotification() {\n+        disableReadAheadLogSegmentsNotification = true;\n+        bkLedgerManager.disableReadAheadLogSegmentsNotification();\n     }\n \n     @VisibleForTesting"},{"sha":"75a5b83ab7d085a5f882d43042afe75d1c666619","filename":"src/main/java/com/twitter/distributedlog/BKDistributedLogManager.java","status":"modified","additions":19,"deletions":8,"changes":27,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -20,6 +20,7 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Optional;\n import com.google.common.base.Preconditions;\n+import com.google.common.base.Ticker;\n import com.twitter.distributedlog.bk.DynamicQuorumConfigProvider;\n import com.twitter.distributedlog.bk.LedgerAllocator;\n import com.twitter.distributedlog.bk.LedgerAllocatorDelegator;\n@@ -32,6 +33,8 @@\n import com.twitter.distributedlog.exceptions.LogEmptyException;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.function.CloseAsyncCloseableFunction;\n+import com.twitter.distributedlog.function.GetVersionedValueFunction;\n import com.twitter.distributedlog.impl.ZKLogSegmentMetadataStore;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForReader;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n@@ -41,6 +44,8 @@\n import com.twitter.distributedlog.lock.SessionLockFactory;\n import com.twitter.distributedlog.lock.ZKDistributedLock;\n import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n+import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.metadata.BKDLConfig;\n import com.twitter.distributedlog.stats.BroadCastStatsLogger;\n@@ -159,6 +164,7 @@ public DLSN apply(LogRecordWithDLSN record) {\n     // log segment metadata stores\n     private final LogSegmentMetadataStore writerMetadataStore;\n     private final LogSegmentMetadataStore readerMetadataStore;\n+    private final LogSegmentMetadataCache logSegmentMetadataCache;\n \n     // bookkeeper clients\n     // NOTE: The actual bookkeeper client is initialized lazily when it is referenced by\n@@ -232,6 +238,7 @@ public DLSN apply(LogRecordWithDLSN record) {\n              null,\n              null,\n              null,\n+             new LogSegmentMetadataCache(conf, Ticker.systemTicker()),\n              OrderedScheduler.newBuilder().name(\"BKDL-\" + name).corePoolSize(1).build(),\n              null,\n              null,\n@@ -293,6 +300,7 @@ public DLSN apply(LogRecordWithDLSN record) {\n                             SessionLockFactory lockFactory,\n                             LogSegmentMetadataStore writerMetadataStore,\n                             LogSegmentMetadataStore readerMetadataStore,\n+                            LogSegmentMetadataCache logSegmentMetadataCache,\n                             OrderedScheduler scheduler,\n                             OrderedScheduler readAheadScheduler,\n                             OrderedScheduler lockStateExecutor,\n@@ -336,6 +344,7 @@ public DLSN apply(LogRecordWithDLSN record) {\n         } else {\n             this.readerMetadataStore = readerMetadataStore;\n         }\n+        this.logSegmentMetadataCache = logSegmentMetadataCache;\n \n         // create the bkc for writers\n         if (null == writerBKCBuilder) {\n@@ -451,7 +460,8 @@ FeatureProvider getFeatureProvider() {\n     private synchronized BKLogReadHandler getReadHandlerForListener(boolean create) {\n         if (null == readHandlerForListener && create) {\n             readHandlerForListener = createReadHandler();\n-            readHandlerForListener.scheduleGetLedgersTask(true, true);\n+            // start fetch the log segments\n+            readHandlerForListener.asyncStartFetchLogSegments();\n         }\n         return readHandlerForListener;\n     }\n@@ -463,13 +473,12 @@ public List<LogSegmentMetadata> getLogSegments() throws IOException {\n \n     protected Future<List<LogSegmentMetadata>> getLogSegmentsAsync() {\n         final BKLogReadHandler readHandler = createReadHandler();\n-        return readHandler.asyncGetFullLedgerList(true, false).ensure(new AbstractFunction0<BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply() {\n-                readHandler.asyncClose();\n-                return BoxedUnit.UNIT;\n-            }\n-        });\n+        return readHandler.readLogSegmentsFromStore(\n+                LogSegmentMetadata.COMPARATOR,\n+                LogSegmentFilter.DEFAULT_FILTER,\n+                null)\n+                .map(GetVersionedValueFunction.GET_LOGSEGMENT_LIST_FUNC)\n+                .ensure(CloseAsyncCloseableFunction.of(readHandler));\n     }\n \n     @Override\n@@ -534,6 +543,7 @@ synchronized BKLogReadHandler createReadHandler(Optional<String> subscriberId,\n                 readerZKCBuilder,\n                 readerBKCBuilder,\n                 readerMetadataStore,\n+                logSegmentMetadataCache,\n                 scheduler,\n                 lockExecutor,\n                 readAheadScheduler,\n@@ -634,6 +644,7 @@ private void createWriteHandler(ZKLogMetadataForWriter logMetadata,\n                 writerZKCBuilder,\n                 writerBKCBuilder,\n                 writerMetadataStore,\n+                logSegmentMetadataCache,\n                 scheduler,\n                 allocator,\n                 statsLogger,"},{"sha":"0f2c2229b77de6273b9037d7ec1286fa39ccc021","filename":"src/main/java/com/twitter/distributedlog/BKDistributedLogNamespace.java","status":"modified","additions":5,"deletions":0,"changes":5,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -20,6 +20,7 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Optional;\n import com.google.common.base.Preconditions;\n+import com.google.common.base.Ticker;\n import com.google.common.collect.Lists;\n import com.google.common.collect.Sets;\n import com.google.common.util.concurrent.ThreadFactoryBuilder;\n@@ -41,6 +42,7 @@\n import com.twitter.distributedlog.impl.federated.FederatedZKLogMetadataStore;\n import com.twitter.distributedlog.lock.SessionLockFactory;\n import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.metadata.BKDLConfig;\n import com.twitter.distributedlog.metadata.LogMetadataStore;\n@@ -301,6 +303,7 @@ private static String getHostIpLockClientId() {\n     // log metadata store\n     private final LogMetadataStore metadataStore;\n     // log segment metadata store\n+    private final LogSegmentMetadataCache logSegmentMetadataCache;\n     private final LogSegmentMetadataStore writerSegmentMetadataStore;\n     private final LogSegmentMetadataStore readerSegmentMetadataStore;\n     // lock factory\n@@ -478,6 +481,7 @@ private BKDistributedLogNamespace(\n                 new ZKLogSegmentMetadataStore(conf, sharedWriterZKCForDL, scheduler);\n         this.readerSegmentMetadataStore =\n                 new ZKLogSegmentMetadataStore(conf, sharedReaderZKCForDL, scheduler);\n+        this.logSegmentMetadataCache = new LogSegmentMetadataCache(conf, Ticker.systemTicker());\n \n         LOG.info(\"Constructed BK DistributedLogNamespace : clientId = {}, regionId = {}, federated = {}.\",\n                 new Object[] { clientId, regionId, bkdlConfig.isFederatedNamespace() });\n@@ -883,6 +887,7 @@ protected DistributedLogManager createDistributedLogManager(\n                 lockFactory,                        /* Lock Factory */\n                 writerSegmentMetadataStore,         /* Log Segment Metadata Store for DL Writers */\n                 readerSegmentMetadataStore,         /* Log Segment Metadata Store for DL Readers */\n+                logSegmentMetadataCache,            /* Log Segment Metadata Cache */\n                 scheduler,                          /* DL scheduler */\n                 readAheadExecutor,                  /* Read Aheader Executor */\n                 lockStateExecutor,                  /* Lock State Executor */"},{"sha":"2a6e85b72c90ae16181cd995b82827f3e587d18c","filename":"src/main/java/com/twitter/distributedlog/BKLogHandler.java","status":"modified","additions":219,"deletions":608,"changes":827,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -19,33 +19,34 @@\n \n import com.google.common.base.Preconditions;\n import com.google.common.base.Stopwatch;\n-import com.twitter.distributedlog.callback.LogSegmentListener;\n+import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n import com.twitter.distributedlog.exceptions.DLInterruptedException;\n import com.twitter.distributedlog.exceptions.LogEmptyException;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n-import com.twitter.distributedlog.exceptions.MetadataException;\n+import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n import com.twitter.distributedlog.exceptions.ZKException;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadata;\n import com.twitter.distributedlog.io.AsyncAbortable;\n import com.twitter.distributedlog.io.AsyncCloseable;\n-import com.twitter.distributedlog.logsegment.LogSegmentCache;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n+import com.twitter.distributedlog.logsegment.PerStreamLogSegmentCache;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.util.Function;\n import com.twitter.util.Future;\n import com.twitter.util.FutureEventListener;\n import com.twitter.util.Promise;\n import org.apache.bookkeeper.stats.AlertStatsLogger;\n-import org.apache.bookkeeper.proto.BookkeeperInternalCallbacks.GenericCallback;\n import org.apache.bookkeeper.stats.OpStatsLogger;\n import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.versioning.Version;\n+import org.apache.bookkeeper.versioning.Versioned;\n import org.apache.commons.lang3.tuple.Pair;\n import org.apache.zookeeper.AsyncCallback;\n import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.WatchedEvent;\n-import org.apache.zookeeper.Watcher;\n import org.apache.zookeeper.ZooKeeper;\n import org.apache.zookeeper.data.Stat;\n import org.slf4j.Logger;\n@@ -63,12 +64,8 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.concurrent.CopyOnWriteArraySet;\n-import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicLong;\n import java.util.concurrent.atomic.AtomicReference;\n \n /**\n@@ -81,11 +78,6 @@\n  * <p>\n  * Those operations are:\n  * <ul>\n- * <li>force_get_list: force to get the list of log segments.\n- * <li>get_list: get the list of the log segments. it might just retrieve from\n- * local log segment cache.\n- * <li>get_filtered_list: get the filtered list of log segments.\n- * <li>get_full_list: get the full list of log segments.\n  * <li>get_inprogress_segment: time between the inprogress log segment created and\n  * the handler read it.\n  * <li>get_completed_segment: time between a log segment is turned to completed and\n@@ -98,146 +90,41 @@\n  * @see BKLogWriteHandler\n  * @see BKLogReadHandler\n  */\n-public abstract class BKLogHandler implements Watcher, AsyncCloseable, AsyncAbortable {\n+public abstract class BKLogHandler implements AsyncCloseable, AsyncAbortable {\n     static final Logger LOG = LoggerFactory.getLogger(BKLogHandler.class);\n \n     protected final ZKLogMetadata logMetadata;\n     protected final DistributedLogConfiguration conf;\n     protected final ZooKeeperClient zooKeeperClient;\n     protected final BookKeeperClient bookKeeperClient;\n     protected final LogSegmentMetadataStore metadataStore;\n+    protected final LogSegmentMetadataCache metadataCache;\n     protected final int firstNumEntriesPerReadLastRecordScan;\n     protected final int maxNumEntriesPerReadLastRecordScan;\n     protected volatile long lastLedgerRollingTimeMillis = -1;\n     protected final OrderedScheduler scheduler;\n     protected final StatsLogger statsLogger;\n     protected final AlertStatsLogger alertStatsLogger;\n-    private final AtomicBoolean ledgerListWatchSet = new AtomicBoolean(false);\n-    private final AtomicBoolean isFullListFetched = new AtomicBoolean(false);\n     protected volatile boolean reportGetSegmentStats = false;\n     private final String lockClientId;\n     protected final AtomicReference<IOException> metadataException = new AtomicReference<IOException>(null);\n \n-    // listener\n-    protected final CopyOnWriteArraySet<LogSegmentListener> listeners =\n-            new CopyOnWriteArraySet<LogSegmentListener>();\n+    // Maintain the list of log segments per stream\n+    protected final PerStreamLogSegmentCache logSegmentCache;\n \n-    // Maintain the list of ledgers\n-    protected final LogSegmentCache logSegmentCache;\n-    protected volatile SyncGetLedgersCallback firstGetLedgersTask = null;\n \n-    protected final AsyncNotification notification;\n-    // log segment filter\n-    protected final LogSegmentFilter filter;\n-\n-    // zookeeper children watcher\n-    private final Watcher getChildrenWatcher;\n \n     // trace\n     protected final long metadataLatencyWarnThresholdMillis;\n \n     // Stats\n-    private final OpStatsLogger forceGetListStat;\n-    private final OpStatsLogger getListStat;\n-    private final OpStatsLogger getFilteredListStat;\n-    private final OpStatsLogger getFullListStat;\n     private final OpStatsLogger getInprogressSegmentStat;\n     private final OpStatsLogger getCompletedSegmentStat;\n     private final OpStatsLogger negativeGetInprogressSegmentStat;\n     private final OpStatsLogger negativeGetCompletedSegmentStat;\n     private final OpStatsLogger recoverLastEntryStats;\n     private final OpStatsLogger recoverScannedEntriesStats;\n \n-    static class SyncGetLedgersCallback implements GenericCallback<List<LogSegmentMetadata>> {\n-\n-        final String path;\n-        final boolean allowEmpty;\n-        final CountDownLatch countDownLatch = new CountDownLatch(1);\n-        final Promise<List<LogSegmentMetadata>> promise =\n-                new Promise<List<LogSegmentMetadata>>();\n-\n-        int rc = KeeperException.Code.APIERROR.intValue();\n-\n-        SyncGetLedgersCallback(String path, boolean allowEmpty) {\n-            this.path = path;\n-            this.allowEmpty = allowEmpty;\n-        }\n-\n-        @Override\n-        public void operationComplete(int rc, List<LogSegmentMetadata> logSegmentMetadatas) {\n-            this.rc = rc;\n-            if (KeeperException.Code.OK.intValue() == rc) {\n-                LOG.debug(\"Updated ledgers list for {} : {}\", path, logSegmentMetadatas);\n-                promise.setValue(logSegmentMetadatas);\n-            } else if (KeeperException.Code.NONODE.intValue() == rc) {\n-                if (allowEmpty) {\n-                    promise.setValue(new ArrayList<LogSegmentMetadata>(0));\n-                } else {\n-                    promise.setException(new LogNotFoundException(\"Log \" + path + \" is not found\"));\n-                }\n-            } else {\n-                promise.setException(new MetadataException(\"Error getting ledgers list for \" + path));\n-            }\n-            countDownLatch.countDown();\n-        }\n-\n-        void waitForFinish() throws IOException {\n-            try {\n-                countDownLatch.await();\n-            } catch (InterruptedException e) {\n-                throw new DLInterruptedException(\"Interrupted on getting ledgers list for \" + path, e);\n-            }\n-            if (KeeperException.Code.OK.intValue() != rc) {\n-                if (KeeperException.Code.NONODE.intValue() == rc) {\n-                    if (!allowEmpty) {\n-                        throw new LogNotFoundException(\"Log \" + path + \" is not found\");\n-                    }\n-                } else {\n-                    throw new MetadataException(\"Error getting ledgers list for \" + path);\n-                }\n-            }\n-        }\n-    }\n-\n-    static class NOPGetLedgersCallback implements GenericCallback<List<LogSegmentMetadata>> {\n-\n-        final String path;\n-\n-        NOPGetLedgersCallback(String path) {\n-            this.path = path;\n-        }\n-\n-        @Override\n-        public void operationComplete(int rc, List<LogSegmentMetadata> logSegmentMetadatas) {\n-            if (KeeperException.Code.OK.intValue() == rc) {\n-                LOG.debug(\"Updated ledgers list : {}\", path, logSegmentMetadatas);\n-            }\n-        }\n-    }\n-\n-    class WatcherGetLedgersCallback implements GenericCallback<List<LogSegmentMetadata>>, Runnable {\n-\n-        final String path;\n-\n-        WatcherGetLedgersCallback(String path) {\n-            this.path = path;\n-        }\n-\n-        @Override\n-        public void operationComplete(int rc, List<LogSegmentMetadata> logSegmentMetadatas) {\n-            if (KeeperException.Code.OK.intValue() == rc) {\n-                LOG.debug(\"Updated ledgers list {} : {}\", path, logSegmentMetadatas);\n-            } else {\n-                scheduler.schedule(this, conf.getZKRetryBackoffMaxMillis(), TimeUnit.MILLISECONDS);\n-            }\n-        }\n-\n-        @Override\n-        public void run() {\n-            asyncGetLedgerListWithRetries(LogSegmentMetadata.COMPARATOR, filter, getChildrenWatcher, this);\n-        }\n-    }\n-\n     /**\n      * Construct a Bookkeeper journal manager.\n      */\n@@ -246,11 +133,10 @@ public void run() {\n                  ZooKeeperClientBuilder zkcBuilder,\n                  BookKeeperClientBuilder bkcBuilder,\n                  LogSegmentMetadataStore metadataStore,\n+                 LogSegmentMetadataCache metadataCache,\n                  OrderedScheduler scheduler,\n                  StatsLogger statsLogger,\n                  AlertStatsLogger alertStatsLogger,\n-                 AsyncNotification notification,\n-                 LogSegmentFilter filter,\n                  String lockClientId) {\n         Preconditions.checkNotNull(zkcBuilder);\n         Preconditions.checkNotNull(bkcBuilder);\n@@ -259,30 +145,24 @@ public void run() {\n         this.scheduler = scheduler;\n         this.statsLogger = statsLogger;\n         this.alertStatsLogger = alertStatsLogger;\n-        this.notification = notification;\n-        this.filter = filter;\n-        this.logSegmentCache = new LogSegmentCache(metadata.getLogName());\n+        this.logSegmentCache = new PerStreamLogSegmentCache(\n+                metadata.getLogName(),\n+                conf.isLogSegmentSequenceNumberValidationEnabled());\n \n         firstNumEntriesPerReadLastRecordScan = conf.getFirstNumEntriesPerReadLastRecordScan();\n         maxNumEntriesPerReadLastRecordScan = conf.getMaxNumEntriesPerReadLastRecordScan();\n         this.zooKeeperClient = zkcBuilder.build();\n         LOG.debug(\"Using ZK Path {}\", logMetadata.getLogRootPath());\n         this.bookKeeperClient = bkcBuilder.build();\n         this.metadataStore = metadataStore;\n+        this.metadataCache = metadataCache;\n         this.lockClientId = lockClientId;\n \n-        this.getChildrenWatcher = this.zooKeeperClient.getWatcherManager()\n-                .registerChildWatcher(logMetadata.getLogSegmentsPath(), this);\n-\n         // Traces\n         this.metadataLatencyWarnThresholdMillis = conf.getMetadataLatencyWarnThresholdMillis();\n \n         // Stats\n         StatsLogger segmentsLogger = statsLogger.scope(\"logsegments\");\n-        forceGetListStat = segmentsLogger.getOpStatsLogger(\"force_get_list\");\n-        getListStat = segmentsLogger.getOpStatsLogger(\"get_list\");\n-        getFilteredListStat = segmentsLogger.getOpStatsLogger(\"get_filtered_list\");\n-        getFullListStat = segmentsLogger.getOpStatsLogger(\"get_full_list\");\n         getInprogressSegmentStat = segmentsLogger.getOpStatsLogger(\"get_inprogress_segment\");\n         getCompletedSegmentStat = segmentsLogger.getOpStatsLogger(\"get_completed_segment\");\n         negativeGetInprogressSegmentStat = segmentsLogger.getOpStatsLogger(\"negative_get_inprogress_segment\");\n@@ -306,67 +186,25 @@ public String getLockClientId() {\n         return lockClientId;\n     }\n \n-    protected void registerListener(LogSegmentListener listener) {\n-        listeners.add(listener);\n-    }\n-\n-    protected void unregisterListener(LogSegmentListener listener) {\n-        listeners.remove(listener);\n-    }\n-\n-    protected void notifyUpdatedLogSegments(List<LogSegmentMetadata> segments) {\n-        for (LogSegmentListener listener : listeners) {\n-            List<LogSegmentMetadata> listToReturn =\n-                    new ArrayList<LogSegmentMetadata>(segments);\n-            Collections.sort(listToReturn, LogSegmentMetadata.DESC_COMPARATOR);\n-            listener.onSegmentsUpdated(listToReturn);\n-        }\n-    }\n-\n-    protected void scheduleGetAllLedgersTaskIfNeeded() {\n-        if (isFullListFetched.get()) {\n-            return;\n-        }\n-        asyncGetLedgerListWithRetries(LogSegmentMetadata.COMPARATOR, LogSegmentFilter.DEFAULT_FILTER,\n-                null, new NOPGetLedgersCallback(getFullyQualifiedName()));\n-    }\n-\n-    protected void scheduleGetLedgersTask(boolean watch, boolean allowEmpty) {\n-        if (!watch) {\n-            ledgerListWatchSet.set(true);\n-        }\n-        LOG.info(\"Scheduling get ledgers task for {}, watch = {}.\", getFullyQualifiedName(), watch);\n-        firstGetLedgersTask = new SyncGetLedgersCallback(getFullyQualifiedName(), allowEmpty);\n-        asyncGetLedgerListWithRetries(LogSegmentMetadata.COMPARATOR, filter,\n-                watch ? getChildrenWatcher : null, firstGetLedgersTask);\n-        LOG.info(\"Scheduled get ledgers task for {}, watch = {}.\", getFullyQualifiedName(), watch);\n-    }\n-\n-    protected void waitFirstGetLedgersTaskToFinish() throws IOException {\n-        SyncGetLedgersCallback task = firstGetLedgersTask;\n-        if (null != task) {\n-            if (LOG.isTraceEnabled()) {\n-                LOG.trace(\"Wait first getting ledgers task to finish for {}.\", getFullyQualifiedName());\n-            }\n-            task.waitForFinish();\n-        }\n-    }\n-\n     public Future<LogRecordWithDLSN> asyncGetFirstLogRecord() {\n         final Promise<LogRecordWithDLSN> promise = new Promise<LogRecordWithDLSN>();\n         checkLogStreamExistsAsync().addEventListener(new FutureEventListener<Void>() {\n             @Override\n             public void onSuccess(Void value) {\n-                asyncGetFullLedgerList(true, true).addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n+                readLogSegmentsFromStore(\n+                        LogSegmentMetadata.COMPARATOR,\n+                        LogSegmentFilter.DEFAULT_FILTER,\n+                        null\n+                ).addEventListener(new FutureEventListener<Versioned<List<LogSegmentMetadata>>>() {\n \n                     @Override\n-                    public void onSuccess(List<LogSegmentMetadata> ledgerList) {\n-                        if (ledgerList.isEmpty()) {\n+                    public void onSuccess(Versioned<List<LogSegmentMetadata>> ledgerList) {\n+                        if (ledgerList.getValue().isEmpty()) {\n                             promise.setException(new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" has no records\"));\n                             return;\n                         }\n                         Future<LogRecordWithDLSN> firstRecord = null;\n-                        for (LogSegmentMetadata ledger : ledgerList) {\n+                        for (LogSegmentMetadata ledger : ledgerList.getValue()) {\n                             if (!ledger.isTruncated() && (ledger.getRecordCount() > 0 || ledger.isInProgress())) {\n                                 firstRecord = asyncReadFirstUserRecord(ledger, DLSN.InitialDLSN);\n                                 break;\n@@ -399,15 +237,25 @@ public Future<LogRecordWithDLSN> getLastLogRecordAsync(final boolean recover, fi\n         checkLogStreamExistsAsync().addEventListener(new FutureEventListener<Void>() {\n             @Override\n             public void onSuccess(Void value) {\n-                asyncGetFullLedgerListDesc(true, true).addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n+                readLogSegmentsFromStore(\n+                        LogSegmentMetadata.DESC_COMPARATOR,\n+                        LogSegmentFilter.DEFAULT_FILTER,\n+                        null\n+                ).addEventListener(new FutureEventListener<Versioned<List<LogSegmentMetadata>>>() {\n \n                     @Override\n-                    public void onSuccess(List<LogSegmentMetadata> ledgerList) {\n-                        if (ledgerList.isEmpty()) {\n-                            promise.setException(new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" has no records\"));\n+                    public void onSuccess(Versioned<List<LogSegmentMetadata>> ledgerList) {\n+                        if (ledgerList.getValue().isEmpty()) {\n+                            promise.setException(\n+                                    new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" has no records\"));\n                             return;\n                         }\n-                        asyncGetLastLogRecord(ledgerList.iterator(), promise, recover, false, includeEndOfStream);\n+                        asyncGetLastLogRecord(\n+                                ledgerList.getValue().iterator(),\n+                                promise,\n+                                recover,\n+                                false,\n+                                includeEndOfStream);\n                     }\n \n                     @Override\n@@ -537,11 +385,15 @@ public Future<Long> asyncGetLogRecordCount(final DLSN beginDLSN) {\n         return checkLogStreamExistsAsync().flatMap(new Function<Void, Future<Long>>() {\n             public Future<Long> apply(Void done) {\n \n-                return asyncGetFullLedgerList(true, false).flatMap(new Function<List<LogSegmentMetadata>, Future<Long>>() {\n-                    public Future<Long> apply(List<LogSegmentMetadata> ledgerList) {\n+                return readLogSegmentsFromStore(\n+                        LogSegmentMetadata.COMPARATOR,\n+                        LogSegmentFilter.DEFAULT_FILTER,\n+                        null\n+                ).flatMap(new Function<Versioned<List<LogSegmentMetadata>>, Future<Long>>() {\n+                    public Future<Long> apply(Versioned<List<LogSegmentMetadata>> ledgerList) {\n \n-                        List<Future<Long>> futureCounts = new ArrayList<Future<Long>>(ledgerList.size());\n-                        for (LogSegmentMetadata ledger : ledgerList) {\n+                        List<Future<Long>> futureCounts = new ArrayList<Future<Long>>(ledgerList.getValue().size());\n+                        for (LogSegmentMetadata ledger : ledgerList.getValue()) {\n                             if (ledger.getLogSegmentSequenceNumber() >= beginDLSN.getLogSegmentSequenceNo()) {\n                                 futureCounts.add(asyncGetLogRecordCount(ledger, beginDLSN));\n                             }\n@@ -665,11 +517,25 @@ public String getFullyQualifiedName() {\n         return logMetadata.getFullyQualifiedName();\n     }\n \n-    // Ledgers Related Functions\n+    // Log Segments Related Functions\n+    //\n     // ***Note***\n-    // Get ledger list should go through #getCachedLogSegments as we need to assign start sequence id for inprogress log\n-    // segment so the reader could generate the right sequence id.\n+    // Get log segment list should go through #getCachedLogSegments as we need to assign start sequence id\n+    // for inprogress log segment so the reader could generate the right sequence id.\n+    //\n+    // ***PerStreamCache vs LogSegmentMetadataCache **\n+    // The per stream cache maintains the list of segments per stream, while the metadata cache\n+    // maintains log segments. The metadata cache is just to reduce the access to zookeeper, it is\n+    // okay that some of the log segments are not in the cache; however the per stream cache can not\n+    // have any gaps between log segment sequence numbers which it has to be accurate.\n \n+    /**\n+     * Get the cached log segments.\n+     *\n+     * @param comparator the comparator to sort the returned log segments.\n+     * @return list of sorted log segments\n+     * @throws UnexpectedException if unexpected condition detected.\n+     */\n     protected List<LogSegmentMetadata> getCachedLogSegments(Comparator<LogSegmentMetadata> comparator)\n         throws UnexpectedException {\n         try {\n@@ -683,227 +549,6 @@ protected List<LogSegmentMetadata> getCachedLogSegments(Comparator<LogSegmentMet\n         }\n     }\n \n-    protected List<LogSegmentMetadata> getFullLedgerList(boolean forceFetch, boolean throwOnEmpty)\n-            throws IOException {\n-        return getLedgerList(forceFetch, true, LogSegmentMetadata.COMPARATOR, throwOnEmpty);\n-    }\n-\n-    protected List<LogSegmentMetadata> getFullLedgerListDesc(boolean forceFetch, boolean throwOnEmpty)\n-            throws IOException {\n-        return getLedgerList(forceFetch, true, LogSegmentMetadata.DESC_COMPARATOR, throwOnEmpty);\n-    }\n-\n-    protected List<LogSegmentMetadata> getFilteredLedgerList(boolean forceFetch, boolean throwOnEmpty)\n-            throws IOException {\n-        return getLedgerList(forceFetch, false, LogSegmentMetadata.COMPARATOR, throwOnEmpty);\n-    }\n-\n-    protected List<LogSegmentMetadata> getFilteredLedgerListDesc(boolean forceFetch, boolean throwOnEmpty)\n-            throws IOException {\n-        return getLedgerList(forceFetch, false, LogSegmentMetadata.DESC_COMPARATOR, throwOnEmpty);\n-    }\n-\n-    protected List<LogSegmentMetadata> getLedgerList(boolean forceFetch,\n-                                                     boolean fetchFullList,\n-                                                     Comparator<LogSegmentMetadata> comparator,\n-                                                     boolean throwOnEmpty)\n-            throws IOException {\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n-        boolean success = false;\n-        try {\n-            List<LogSegmentMetadata> segments =\n-                    doGetLedgerList(forceFetch, fetchFullList, comparator, throwOnEmpty);\n-            success = true;\n-            return segments;\n-        } finally {\n-            OpStatsLogger statsLogger = fetchFullList ? getFullListStat : getFilteredListStat;\n-            if (success) {\n-                statsLogger.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-            } else {\n-                statsLogger.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-            }\n-        }\n-    }\n-\n-    private List<LogSegmentMetadata> doGetLedgerList(boolean forceFetch, boolean fetchFullList,\n-                                                     Comparator<LogSegmentMetadata> comparator,\n-                                                     boolean throwOnEmpty)\n-        throws IOException {\n-        if (fetchFullList) {\n-            if (forceFetch || !isFullListFetched.get()) {\n-                return forceGetLedgerList(comparator, LogSegmentFilter.DEFAULT_FILTER, throwOnEmpty);\n-            } else {\n-                return getCachedLogSegments(comparator);\n-            }\n-        } else {\n-            if (forceFetch) {\n-                return forceGetLedgerList(comparator, filter, throwOnEmpty);\n-            } else {\n-                if(!ledgerListWatchSet.get()) {\n-                    scheduleGetLedgersTask(true, true);\n-                }\n-                waitFirstGetLedgersTaskToFinish();\n-                return getCachedLogSegments(comparator);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Get a list of all segments in the journal.\n-     */\n-    protected List<LogSegmentMetadata> forceGetLedgerList(final Comparator<LogSegmentMetadata> comparator,\n-                                                                final LogSegmentFilter segmentFilter,\n-                                                                boolean throwOnEmpty) throws IOException {\n-        final List<LogSegmentMetadata> ledgers = new ArrayList<LogSegmentMetadata>();\n-        final AtomicInteger result = new AtomicInteger(-1);\n-        final CountDownLatch latch = new CountDownLatch(1);\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n-        asyncGetLedgerListInternal(comparator, segmentFilter, null, new GenericCallback<List<LogSegmentMetadata>>() {\n-            @Override\n-            public void operationComplete(int rc, List<LogSegmentMetadata> logSegmentMetadatas) {\n-                result.set(rc);\n-                if (KeeperException.Code.OK.intValue() == rc) {\n-                    ledgers.addAll(logSegmentMetadatas);\n-                } else {\n-                    LOG.error(\"Failed to get ledger list for {} : with error {}\", getFullyQualifiedName(), rc);\n-                }\n-                latch.countDown();\n-            }\n-        }, new AtomicInteger(conf.getZKNumRetries()), new AtomicLong(conf.getZKRetryBackoffStartMillis()));\n-        try {\n-            latch.await();\n-        } catch (InterruptedException e) {\n-            forceGetListStat.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-            throw new DLInterruptedException(\"Interrupted on reading ledger list from zkfor \" + getFullyQualifiedName(), e);\n-        }\n-        long elapsedMicros = stopwatch.stop().elapsed(TimeUnit.MICROSECONDS);\n-\n-        KeeperException.Code rc = KeeperException.Code.get(result.get());\n-        if (rc == KeeperException.Code.OK) {\n-            forceGetListStat.registerSuccessfulEvent(elapsedMicros);\n-        } else {\n-            forceGetListStat.registerFailedEvent(elapsedMicros);\n-            if (KeeperException.Code.NONODE == rc) {\n-                throw new LogNotFoundException(\"Log \" + getFullyQualifiedName() + \" is not found\");\n-            } else {\n-                throw new IOException(\"ZK Exception \" + rc + \" reading ledger list for \" + getFullyQualifiedName());\n-            }\n-        }\n-\n-        if (throwOnEmpty && ledgers.isEmpty()) {\n-            throw new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" is empty\");\n-        }\n-        return ledgers;\n-    }\n-\n-    protected Future<List<LogSegmentMetadata>> asyncGetFullLedgerList(boolean forceFetch, boolean throwOnEmpty) {\n-        return asyncGetLedgerList(forceFetch, true, LogSegmentMetadata.COMPARATOR, throwOnEmpty);\n-    }\n-\n-    protected Future<List<LogSegmentMetadata>> asyncGetFullLedgerListDesc(boolean forceFetch, boolean throwOnEmpty) {\n-        return asyncGetLedgerList(forceFetch, true, LogSegmentMetadata.DESC_COMPARATOR, throwOnEmpty);\n-    }\n-\n-    protected Future<List<LogSegmentMetadata>> asyncGetFilteredLedgerList(boolean forceFetch, boolean throwOnEmpty) {\n-        return asyncGetLedgerList(forceFetch, false, LogSegmentMetadata.COMPARATOR, throwOnEmpty);\n-    }\n-\n-    protected Future<List<LogSegmentMetadata>> asyncGetFilteredLedgerListDesc(boolean forceFetch, boolean throwOnEmpty) {\n-        return asyncGetLedgerList(forceFetch, false, LogSegmentMetadata.DESC_COMPARATOR, throwOnEmpty);\n-    }\n-\n-    protected Future<List<LogSegmentMetadata>> asyncGetLedgerList(final boolean forceFetch,\n-                                                                        final boolean fetchFullList,\n-                                                                        final Comparator<LogSegmentMetadata> comparator,\n-                                                                        final boolean throwOnEmpty) {\n-        final Promise<List<LogSegmentMetadata>> promise = new Promise<List<LogSegmentMetadata>>();\n-        final Stopwatch stopwatch = Stopwatch.createStarted();\n-        final OpStatsLogger statsLogger = fetchFullList ? getFullListStat : getFilteredListStat;\n-        asyncDoGetLedgerList(forceFetch, fetchFullList, comparator, throwOnEmpty)\n-                .addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n-                    @Override\n-                    public void onSuccess(List<LogSegmentMetadata> value) {\n-                        statsLogger.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-                        promise.setValue(value);\n-                    }\n-\n-                    @Override\n-                    public void onFailure(Throwable cause) {\n-                        statsLogger.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-                        promise.setException(cause);\n-                    }\n-                });\n-        return promise;\n-    }\n-\n-    private Future<List<LogSegmentMetadata>> asyncDoGetLedgerList(final boolean forceFetch,\n-                                                                  final boolean fetchFullList,\n-                                                                  final Comparator<LogSegmentMetadata> comparator,\n-                                                                  final boolean throwOnEmpty) {\n-        if (fetchFullList) {\n-            if (forceFetch || !isFullListFetched.get()) {\n-                return asyncForceGetLedgerList(comparator, LogSegmentFilter.DEFAULT_FILTER, throwOnEmpty);\n-            } else {\n-                try {\n-                    return Future.value(getCachedLogSegments(comparator));\n-                } catch (UnexpectedException ue) {\n-                    return Future.exception(ue);\n-                }\n-            }\n-        } else {\n-            if (forceFetch) {\n-                return asyncForceGetLedgerList(comparator, filter, throwOnEmpty);\n-            } else {\n-                final Promise<List<LogSegmentMetadata>> promise =\n-                        new Promise<List<LogSegmentMetadata>>();\n-                SyncGetLedgersCallback task = firstGetLedgersTask;\n-                task.promise.addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n-                    @Override\n-                    public void onSuccess(List<LogSegmentMetadata> value) {\n-                        try {\n-                            promise.setValue(getCachedLogSegments(comparator));\n-                        } catch (UnexpectedException e) {\n-                            promise.setException(e);\n-                        }\n-                    }\n-\n-                    @Override\n-                    public void onFailure(Throwable cause) {\n-                        promise.setException(cause);\n-                    }\n-                });\n-                return promise;\n-            }\n-        }\n-    }\n-\n-    protected Future<List<LogSegmentMetadata>> asyncForceGetLedgerList(final Comparator<LogSegmentMetadata> comparator,\n-                                                                       final LogSegmentFilter segmentFilter,\n-                                                                       final boolean throwOnEmpty) {\n-        final Promise<List<LogSegmentMetadata>> promise = new Promise<List<LogSegmentMetadata>>();\n-        final Stopwatch stopwatch = Stopwatch.createStarted();\n-        asyncGetLedgerListWithRetries(comparator, segmentFilter, null)\n-            .addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n-\n-                @Override\n-                public void onSuccess(List<LogSegmentMetadata> ledgers) {\n-                    forceGetListStat.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-                    if (ledgers.isEmpty() && throwOnEmpty) {\n-                        promise.setException(new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" is empty\"));\n-                    } else {\n-                        promise.setValue(ledgers);\n-                    }\n-                }\n-\n-                @Override\n-                public void onFailure(Throwable cause) {\n-                    forceGetListStat.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-                    promise.setException(cause);\n-                }\n-            });\n-        return promise;\n-    }\n-\n     /**\n      * Add the segment <i>metadata</i> for <i>name</i> in the cache.\n      *\n@@ -913,6 +558,7 @@ public void onFailure(Throwable cause) {\n      *          segment metadata.\n      */\n     protected void addLogSegmentToCache(String name, LogSegmentMetadata metadata) {\n+        metadataCache.put(metadata.getZkPath(), metadata);\n         logSegmentCache.add(name, metadata);\n         // update the last ledger rolling time\n         if (!metadata.isInProgress() && (lastLedgerRollingTimeMillis < metadata.getCompletionTime())) {\n@@ -952,224 +598,189 @@ protected void addLogSegmentToCache(String name, LogSegmentMetadata metadata) {\n         }\n     }\n \n+    /**\n+     * Read log segment <i>name</i> from the cache.\n+     *\n+     * @param name name of the log segment\n+     * @return log segment metadata\n+     */\n     protected LogSegmentMetadata readLogSegmentFromCache(String name) {\n         return logSegmentCache.get(name);\n     }\n \n+    /**\n+     * Remove the log segment <i>name</i> from the cache.\n+     *\n+     * @param name name of the log segment.\n+     * @return log segment metadata\n+     */\n     protected LogSegmentMetadata removeLogSegmentFromCache(String name) {\n+        metadataCache.invalidate(name);\n         return logSegmentCache.remove(name);\n     }\n \n-    public void asyncGetLedgerList(final Comparator<LogSegmentMetadata> comparator,\n-                                   Watcher watcher,\n-                                   final GenericCallback<List<LogSegmentMetadata>> callback) {\n-        asyncGetLedgerListWithRetries(comparator, filter, watcher, callback);\n+    /**\n+     * Update the log segment cache with updated mapping\n+     *\n+     * @param logSegmentsRemoved log segments removed\n+     * @param logSegmentsAdded log segments added\n+     */\n+    protected void updateLogSegmentCache(Set<String> logSegmentsRemoved,\n+                                         Map<String, LogSegmentMetadata> logSegmentsAdded) {\n+        for (String segmentName : logSegmentsRemoved) {\n+            metadataCache.invalidate(segmentName);\n+        }\n+        for (Map.Entry<String, LogSegmentMetadata> entry : logSegmentsAdded.entrySet()) {\n+            metadataCache.put(entry.getKey(), entry.getValue());\n+        }\n+        logSegmentCache.update(logSegmentsRemoved, logSegmentsAdded);\n     }\n \n-    protected Future<List<LogSegmentMetadata>> asyncGetLedgerListWithRetries(Comparator<LogSegmentMetadata> comparator,\n-                                                                             LogSegmentFilter segmentFilter,\n-                                                                             Watcher watcher) {\n-        final Promise<List<LogSegmentMetadata>> promise = new Promise<List<LogSegmentMetadata>>();\n-        asyncGetLedgerListWithRetries(comparator, segmentFilter, watcher, new GenericCallback<List<LogSegmentMetadata>>() {\n-            @Override\n-            public void operationComplete(int rc, List<LogSegmentMetadata> segments) {\n-                if (KeeperException.Code.OK.intValue() == rc) {\n-                    promise.setValue(segments);\n-                } else if (KeeperException.Code.NONODE.intValue() == rc) {\n-                    promise.setException(new LogNotFoundException(\"Log \" + getFullyQualifiedName() + \" not found\"));\n-                } else {\n-                    String errMsg = \"ZK Exception \" + rc + \" reading ledger list for \" + getFullyQualifiedName();\n-                    promise.setException(new ZKException(errMsg, KeeperException.Code.get(rc)));\n-                }\n-            }\n-        });\n-        return promise;\n-    }\n+    /**\n+     * Read the log segments from the store and register a listener\n+     * @param comparator\n+     * @param segmentFilter\n+     * @param logSegmentNamesListener\n+     * @return future represents the result of log segments\n+     */\n+    public Future<Versioned<List<LogSegmentMetadata>>> readLogSegmentsFromStore(\n+            final Comparator<LogSegmentMetadata> comparator,\n+            final LogSegmentFilter segmentFilter,\n+            final LogSegmentNamesListener logSegmentNamesListener) {\n+        final Promise<Versioned<List<LogSegmentMetadata>>> readResult =\n+                new Promise<Versioned<List<LogSegmentMetadata>>>();\n+        metadataStore.getLogSegmentNames(logMetadata.getLogSegmentsPath(), logSegmentNamesListener)\n+                .addEventListener(new FutureEventListener<Versioned<List<String>>>() {\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        FutureUtils.setException(readResult, cause);\n+                    }\n \n-    private void asyncGetLedgerListWithRetries(final Comparator<LogSegmentMetadata> comparator,\n-                                               final LogSegmentFilter segmentFilter,\n-                                               final Watcher watcher,\n-                                               final GenericCallback<List<LogSegmentMetadata>> finalCallback) {\n-        asyncGetLedgerListInternal(comparator, segmentFilter, watcher, finalCallback,\n-                new AtomicInteger(conf.getZKNumRetries()), new AtomicLong(conf.getZKRetryBackoffStartMillis()));\n+                    @Override\n+                    public void onSuccess(Versioned<List<String>> logSegmentNames) {\n+                        readLogSegmentsFromStore(logSegmentNames, comparator, segmentFilter, readResult);\n+                    }\n+                });\n+        return readResult;\n     }\n \n-    private void asyncGetLedgerListInternal(final Comparator<LogSegmentMetadata> comparator,\n+    protected void readLogSegmentsFromStore(final Versioned<List<String>> logSegmentNames,\n+                                            final Comparator<LogSegmentMetadata> comparator,\n                                             final LogSegmentFilter segmentFilter,\n-                                            final Watcher watcher,\n-                                            final GenericCallback<List<LogSegmentMetadata>> finalCallback,\n-                                            final AtomicInteger numAttemptsLeft,\n-                                            final AtomicLong backoffMillis) {\n-        final Stopwatch stopwatch = Stopwatch.createStarted();\n-        try {\n+                                            final Promise<Versioned<List<LogSegmentMetadata>>> readResult) {\n+        Set<String> segmentsReceived = new HashSet<String>();\n+        segmentsReceived.addAll(segmentFilter.filter(logSegmentNames.getValue()));\n+        Set<String> segmentsAdded;\n+        final Set<String> removedSegments = Collections.synchronizedSet(new HashSet<String>());\n+        final Map<String, LogSegmentMetadata> addedSegments =\n+                Collections.synchronizedMap(new HashMap<String, LogSegmentMetadata>());\n+        Pair<Set<String>, Set<String>> segmentChanges = logSegmentCache.diff(segmentsReceived);\n+        segmentsAdded = segmentChanges.getLeft();\n+        removedSegments.addAll(segmentChanges.getRight());\n+\n+        if (segmentsAdded.isEmpty()) {\n             if (LOG.isTraceEnabled()) {\n-                LOG.trace(\"Async getting ledger list for {}.\", getFullyQualifiedName());\n+                LOG.trace(\"No segments added for {}.\", getFullyQualifiedName());\n             }\n-            final GenericCallback<List<LogSegmentMetadata>> callback = new GenericCallback<List<LogSegmentMetadata>>() {\n-                @Override\n-                public void operationComplete(int rc, List<LogSegmentMetadata> result) {\n-                    long elapsedMicros = stopwatch.stop().elapsed(TimeUnit.MICROSECONDS);\n-                    if (KeeperException.Code.OK.intValue() != rc) {\n-                        getListStat.registerFailedEvent(elapsedMicros);\n-                    } else {\n-                        if (LogSegmentFilter.DEFAULT_FILTER == segmentFilter) {\n-                            isFullListFetched.set(true);\n-                        }\n-                        getListStat.registerSuccessfulEvent(elapsedMicros);\n-                    }\n-                    finalCallback.operationComplete(rc, result);\n-                }\n-            };\n-            zooKeeperClient.get().getChildren(logMetadata.getLogSegmentsPath(), watcher, new AsyncCallback.Children2Callback() {\n-                @Override\n-                public void processResult(final int rc, final String path, final Object ctx, final List<String> children, final Stat stat) {\n-                    if (KeeperException.Code.OK.intValue() != rc) {\n \n-                        if ((KeeperException.Code.CONNECTIONLOSS.intValue() == rc ||\n-                             KeeperException.Code.SESSIONEXPIRED.intValue() == rc ||\n-                             KeeperException.Code.SESSIONMOVED.intValue() == rc) &&\n-                            numAttemptsLeft.decrementAndGet() > 0) {\n-                            long backoffMs = backoffMillis.get();\n-                            backoffMillis.set(Math.min(conf.getZKRetryBackoffMaxMillis(), 2 * backoffMs));\n-                            scheduler.schedule(new Runnable() {\n-                                @Override\n-                                public void run() {\n-                                    asyncGetLedgerListInternal(comparator, segmentFilter, watcher,\n-                                            finalCallback, numAttemptsLeft, backoffMillis);\n-                                }\n-                            }, backoffMs, TimeUnit.MILLISECONDS);\n-                            return;\n-                        }\n-                        callback.operationComplete(rc, null);\n-                        return;\n-                    }\n-\n-                    if (LOG.isTraceEnabled()) {\n-                        LOG.trace(\"Got ledger list from {} : {}\", logMetadata.getLogSegmentsPath(), children);\n-                    }\n+            // update the cache before #getCachedLogSegments to return\n+            updateLogSegmentCache(removedSegments, addedSegments);\n \n-                    ledgerListWatchSet.set(true);\n-                    Set<String> segmentsReceived = new HashSet<String>();\n-                    segmentsReceived.addAll(segmentFilter.filter(children));\n-                    Set<String> segmentsAdded;\n-                    final Set<String> removedSegments = Collections.synchronizedSet(new HashSet<String>());\n-                    final Map<String, LogSegmentMetadata> addedSegments =\n-                            Collections.synchronizedMap(new HashMap<String, LogSegmentMetadata>());\n-                    Pair<Set<String>, Set<String>> segmentChanges = logSegmentCache.diff(segmentsReceived);\n-                    segmentsAdded = segmentChanges.getLeft();\n-                    removedSegments.addAll(segmentChanges.getRight());\n+            List<LogSegmentMetadata> segmentList;\n+            try {\n+                segmentList = getCachedLogSegments(comparator);\n+            } catch (UnexpectedException e) {\n+                FutureUtils.setException(readResult, e);\n+                return;\n+            }\n \n-                    if (segmentsAdded.isEmpty()) {\n-                        if (LOG.isTraceEnabled()) {\n-                            LOG.trace(\"No segments added for {}.\", getFullyQualifiedName());\n-                        }\n+            FutureUtils.setValue(readResult,\n+                    new Versioned<List<LogSegmentMetadata>>(segmentList, logSegmentNames.getVersion()));\n+            return;\n+        }\n \n-                        // update the cache before fetch\n-                        logSegmentCache.update(removedSegments, addedSegments);\n+        final AtomicInteger numChildren = new AtomicInteger(segmentsAdded.size());\n+        final AtomicInteger numFailures = new AtomicInteger(0);\n+        for (final String segment: segmentsAdded) {\n+            String logSegmentPath = logMetadata.getLogSegmentPath(segment);\n+            LogSegmentMetadata cachedSegment = metadataCache.get(logSegmentPath);\n+            if (null != cachedSegment) {\n+                addedSegments.put(segment, cachedSegment);\n+                completeReadLogSegmentsFromStore(\n+                        removedSegments,\n+                        addedSegments,\n+                        comparator,\n+                        readResult,\n+                        logSegmentNames.getVersion(),\n+                        numChildren,\n+                        numFailures);\n+                continue;\n+            }\n+            metadataStore.getLogSegment(logSegmentPath)\n+                    .addEventListener(new FutureEventListener<LogSegmentMetadata>() {\n \n-                        List<LogSegmentMetadata> segmentList;\n-                        try {\n-                            segmentList = getCachedLogSegments(comparator);\n-                        } catch (UnexpectedException e) {\n-                            callback.operationComplete(KeeperException.Code.DATAINCONSISTENCY.intValue(), null);\n-                            return;\n-                        }\n-                        callback.operationComplete(KeeperException.Code.OK.intValue(), segmentList);\n-                        notifyUpdatedLogSegments(segmentList);\n-                        if (!removedSegments.isEmpty()) {\n-                            notifyOnOperationComplete();\n+                        @Override\n+                        public void onSuccess(LogSegmentMetadata result) {\n+                            addedSegments.put(segment, result);\n+                            complete();\n                         }\n-                        return;\n-                    }\n \n-                    final AtomicInteger numChildren = new AtomicInteger(segmentsAdded.size());\n-                    final AtomicInteger numFailures = new AtomicInteger(0);\n-                    for (final String segment: segmentsAdded) {\n-                        metadataStore.getLogSegment(logMetadata.getLogSegmentPath(segment))\n-                                .addEventListener(new FutureEventListener<LogSegmentMetadata>() {\n-\n-                                    @Override\n-                                    public void onSuccess(LogSegmentMetadata result) {\n-                                        addedSegments.put(segment, result);\n-                                        complete();\n-                                    }\n-\n-                                    @Override\n-                                    public void onFailure(Throwable cause) {\n-                                        // NONODE exception is possible in two cases\n-                                        // 1. A log segment was deleted by truncation between the call to getChildren and read\n-                                        // attempt on the znode corresponding to the segment\n-                                        // 2. In progress segment has been completed => inprogress ZNode does not exist\n-                                        if (cause instanceof KeeperException &&\n-                                                KeeperException.Code.NONODE == ((KeeperException) cause).code()) {\n-                                            removedSegments.add(segment);\n-                                            complete();\n-                                        } else {\n-                                            // fail fast\n-                                            if (1 == numFailures.incrementAndGet()) {\n-                                                int rcToReturn = KeeperException.Code.SYSTEMERROR.intValue();\n-                                                if (cause instanceof KeeperException) {\n-                                                    rcToReturn = ((KeeperException) cause).code().intValue();\n-                                                } else if (cause instanceof ZKException) {\n-                                                    rcToReturn = ((ZKException) cause).getKeeperExceptionCode().intValue();\n-                                                }\n-                                                // :( properly we need dlog related response code.\n-                                                callback.operationComplete(rcToReturn, null);\n-                                                return;\n-                                            }\n-                                        }\n-                                    }\n+                        @Override\n+                        public void onFailure(Throwable cause) {\n+                            // LogSegmentNotFoundException exception is possible in two cases\n+                            // 1. A log segment was deleted by truncation between the call to getChildren and read\n+                            // attempt on the znode corresponding to the segment\n+                            // 2. In progress segment has been completed => inprogress ZNode does not exist\n+                            if (cause instanceof LogSegmentNotFoundException) {\n+                                removedSegments.add(segment);\n+                                complete();\n+                            } else {\n+                                // fail fast\n+                                if (1 == numFailures.incrementAndGet()) {\n+                                    FutureUtils.setException(readResult, cause);\n+                                    return;\n+                                }\n+                            }\n+                        }\n \n-                                    private void complete() {\n-                                        if (0 == numChildren.decrementAndGet() && numFailures.get() == 0) {\n-                                            // update the cache only when fetch completed\n-                                            logSegmentCache.update(removedSegments, addedSegments);\n-                                            List<LogSegmentMetadata> segmentList;\n-                                            try {\n-                                                segmentList = getCachedLogSegments(comparator);\n-                                            } catch (UnexpectedException e) {\n-                                                callback.operationComplete(KeeperException.Code.DATAINCONSISTENCY.intValue(), null);\n-                                                return;\n-                                            }\n-                                            callback.operationComplete(KeeperException.Code.OK.intValue(), segmentList);\n-                                            notifyUpdatedLogSegments(segmentList);\n-                                            notifyOnOperationComplete();\n-                                        }\n-                                    }\n-                                });\n-                    }\n-                }\n-            }, null);\n-        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n-            getListStat.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-            finalCallback.operationComplete(KeeperException.Code.CONNECTIONLOSS.intValue(), null);\n-        } catch (InterruptedException e) {\n-            getListStat.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n-            finalCallback.operationComplete(KeeperException.Code.CONNECTIONLOSS.intValue(), null);\n+                        private void complete() {\n+                            completeReadLogSegmentsFromStore(\n+                                    removedSegments,\n+                                    addedSegments,\n+                                    comparator,\n+                                    readResult,\n+                                    logSegmentNames.getVersion(),\n+                                    numChildren,\n+                                    numFailures);\n+                        }\n+                    });\n         }\n     }\n \n-    @Override\n-    public void process(WatchedEvent event) {\n-        if (Watcher.Event.EventType.None.equals(event.getType())) {\n-            if (event.getState() == Watcher.Event.KeeperState.Expired) {\n-                // if the watcher is expired\n-                scheduler.schedule(new WatcherGetLedgersCallback(getFullyQualifiedName()),\n-                        conf.getZKRetryBackoffStartMillis(), TimeUnit.MILLISECONDS);\n-            }\n-        } else if (Watcher.Event.EventType.NodeChildrenChanged.equals(event.getType())) {\n-            if (LOG.isTraceEnabled()) {\n-                LOG.trace(\"LogSegments Changed under {}.\", getFullyQualifiedName());\n-            }\n-            asyncGetLedgerListWithRetries(LogSegmentMetadata.COMPARATOR, filter,\n-                    getChildrenWatcher, new WatcherGetLedgersCallback(getFullyQualifiedName()));\n+    private void completeReadLogSegmentsFromStore(final Set<String> removedSegments,\n+                                                  final Map<String, LogSegmentMetadata> addedSegments,\n+                                                  final Comparator<LogSegmentMetadata> comparator,\n+                                                  final Promise<Versioned<List<LogSegmentMetadata>>> readResult,\n+                                                  final Version logSegmentNamesVersion,\n+                                                  final AtomicInteger numChildren,\n+                                                  final AtomicInteger numFailures) {\n+        if (0 != numChildren.decrementAndGet()) {\n+            return;\n         }\n-    }\n-\n-    void notifyOnOperationComplete() {\n-        if (null != notification) {\n-            notification.notifyOnOperationComplete();\n+        if (numFailures.get() > 0) {\n+            return;\n+        }\n+        // update the cache only when fetch completed and before #getCachedLogSegments\n+        updateLogSegmentCache(removedSegments, addedSegments);\n+        List<LogSegmentMetadata> segmentList;\n+        try {\n+            segmentList = getCachedLogSegments(comparator);\n+        } catch (UnexpectedException e) {\n+            FutureUtils.setException(readResult, e);\n+            return;\n         }\n+        FutureUtils.setValue(readResult,\n+            new Versioned<List<LogSegmentMetadata>>(segmentList, logSegmentNamesVersion));\n     }\n \n }"},{"sha":"a1e29a2995a5372c826084bd61a431f312382b58","filename":"src/main/java/com/twitter/distributedlog/BKLogReadHandler.java","status":"modified","additions":218,"deletions":35,"changes":253,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -18,23 +18,33 @@\n package com.twitter.distributedlog;\n \n import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CopyOnWriteArraySet;\n+import java.util.concurrent.TimeUnit;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Optional;\n import com.google.common.base.Ticker;\n+import com.twitter.distributedlog.callback.LogSegmentListener;\n+import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n import com.twitter.distributedlog.exceptions.DLInterruptedException;\n import com.twitter.distributedlog.exceptions.LockCancelledException;\n import com.twitter.distributedlog.exceptions.LockingException;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForReader;\n import com.twitter.distributedlog.injector.AsyncFailureInjector;\n import com.twitter.distributedlog.lock.DistributedLock;\n import com.twitter.distributedlog.lock.SessionLockFactory;\n import com.twitter.distributedlog.lock.ZKDistributedLock;\n import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.readahead.ReadAheadWorker;\n import com.twitter.distributedlog.stats.BroadCastStatsLogger;\n@@ -55,6 +65,8 @@\n import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.bookkeeper.stats.StatsLogger;\n import org.apache.bookkeeper.util.SafeRunnable;\n+import org.apache.bookkeeper.versioning.Version;\n+import org.apache.bookkeeper.versioning.Versioned;\n import org.apache.zookeeper.CreateMode;\n import org.apache.zookeeper.KeeperException;\n import org.slf4j.Logger;\n@@ -102,11 +114,9 @@\n  * All read lock related stats are exposed under scope `read_lock`. See {@link ZKDistributedLock}\n  * for detail stats.\n  */\n-class BKLogReadHandler extends BKLogHandler {\n+class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n     static final Logger LOG = LoggerFactory.getLogger(BKLogReadHandler.class);\n \n-    private static final int LAYOUT_VERSION = -1;\n-\n     protected final ZKLogMetadataForReader logMetadataForReader;\n     protected final ReadAheadCache readAheadCache;\n     protected final LedgerHandleCache handleCache;\n@@ -123,6 +133,16 @@ class BKLogReadHandler extends BKLogHandler {\n     private DistributedLock readLock;\n     private Future<Void> lockAcquireFuture;\n \n+    // notify the state change about the read handler\n+    protected final AsyncNotification readerStateNotification;\n+\n+    // log segments listener\n+    protected boolean logSegmentsNotificationDisabled = false;\n+    protected final CopyOnWriteArraySet<LogSegmentListener> listeners =\n+            new CopyOnWriteArraySet<LogSegmentListener>();\n+    protected Versioned<List<LogSegmentMetadata>> lastNotifiedLogSegments =\n+            new Versioned<List<LogSegmentMetadata>>(null, Version.NEW);\n+\n     // stats\n     private final AlertStatsLogger alertStatsLogger;\n     private final StatsLogger handlerStatsLogger;\n@@ -132,26 +152,35 @@ class BKLogReadHandler extends BKLogHandler {\n     /**\n      * Construct a Bookkeeper journal manager.\n      */\n-    public BKLogReadHandler(ZKLogMetadataForReader logMetadata,\n-                            Optional<String> subscriberId,\n-                            DistributedLogConfiguration conf,\n-                            DynamicDistributedLogConfiguration dynConf,\n-                            ZooKeeperClientBuilder zkcBuilder,\n-                            BookKeeperClientBuilder bkcBuilder,\n-                            LogSegmentMetadataStore metadataStore,\n-                            OrderedScheduler scheduler,\n-                            OrderedScheduler lockStateExecutor,\n-                            OrderedScheduler readAheadExecutor,\n-                            AlertStatsLogger alertStatsLogger,\n-                            ReadAheadExceptionsLogger readAheadExceptionsLogger,\n-                            StatsLogger statsLogger,\n-                            StatsLogger perLogStatsLogger,\n-                            String clientId,\n-                            AsyncNotification notification,\n-                            boolean isHandleForReading,\n-                            boolean deserializeRecordSet) {\n-        super(logMetadata, conf, zkcBuilder, bkcBuilder, metadataStore, scheduler,\n-              statsLogger, alertStatsLogger, notification, LogSegmentFilter.DEFAULT_FILTER, clientId);\n+    BKLogReadHandler(ZKLogMetadataForReader logMetadata,\n+                     Optional<String> subscriberId,\n+                     DistributedLogConfiguration conf,\n+                     DynamicDistributedLogConfiguration dynConf,\n+                     ZooKeeperClientBuilder zkcBuilder,\n+                     BookKeeperClientBuilder bkcBuilder,\n+                     LogSegmentMetadataStore metadataStore,\n+                     LogSegmentMetadataCache metadataCache,\n+                     OrderedScheduler scheduler,\n+                     OrderedScheduler lockStateExecutor,\n+                     OrderedScheduler readAheadExecutor,\n+                     AlertStatsLogger alertStatsLogger,\n+                     ReadAheadExceptionsLogger readAheadExceptionsLogger,\n+                     StatsLogger statsLogger,\n+                     StatsLogger perLogStatsLogger,\n+                     String clientId,\n+                     AsyncNotification readerStateNotification,\n+                     boolean isHandleForReading,\n+                     boolean deserializeRecordSet) {\n+        super(logMetadata,\n+                conf,\n+                zkcBuilder,\n+                bkcBuilder,\n+                metadataStore,\n+                metadataCache,\n+                scheduler,\n+                statsLogger,\n+                alertStatsLogger,\n+                clientId);\n         this.logMetadataForReader = logMetadata;\n         this.dynConf = dynConf;\n         this.readAheadExecutor = readAheadExecutor;\n@@ -161,6 +190,7 @@ public BKLogReadHandler(ZKLogMetadataForReader logMetadata,\n         this.handlerStatsLogger =\n                 BroadCastStatsLogger.masterslave(this.perLogStatsLogger, statsLogger);\n         this.readAheadExceptionsLogger = readAheadExceptionsLogger;\n+        this.readerStateNotification = readerStateNotification;\n \n         handleCache = LedgerHandleCache.newBuilder()\n                 .bkc(this.bookKeeperClient)\n@@ -171,7 +201,7 @@ public BKLogReadHandler(ZKLogMetadataForReader logMetadata,\n                 getFullyQualifiedName(),\n                 handlerStatsLogger,\n                 alertStatsLogger,\n-                notification,\n+                readerStateNotification,\n                 dynConf.getReadAheadMaxRecords(),\n                 deserializeRecordSet,\n                 conf.getTraceReadAheadDeliveryLatency(),\n@@ -308,14 +338,14 @@ public Future<Void> apply(Void result) {\n                 if (null != readAheadCache) {\n                     readAheadCache.clear();\n                 }\n+                if (null != readAheadWorker) {\n+                    unregisterListener(readAheadWorker);\n+                }\n                 if (null != handleCache) {\n                     handleCache.clear();\n                 }\n-                // No-op\n-                zooKeeperClient.getWatcherManager().unregisterChildWatcher(\n-                        logMetadata.getLogSegmentsPath(),\n-                        BKLogReadHandler.this,\n-                        true);\n+                // unregister the log segment listener\n+                metadataStore.unregisterLogSegmentListener(logMetadata.getLogSegmentsPath(), BKLogReadHandler.this);\n                 return Future.Void();\n             }\n         });\n@@ -326,6 +356,52 @@ public Future<Void> asyncAbort() {\n         return asyncClose();\n     }\n \n+    /**\n+     * Start fetch the log segments and register the {@link LogSegmentNamesListener}.\n+     * The future is satisfied only on a successful fetch or encountered a fatal failure.\n+     *\n+     * @return future represents the fetch result\n+     */\n+    Future<Versioned<List<LogSegmentMetadata>>> asyncStartFetchLogSegments() {\n+        Promise<Versioned<List<LogSegmentMetadata>>> promise =\n+                new Promise<Versioned<List<LogSegmentMetadata>>>();\n+        asyncStartFetchLogSegments(promise);\n+        return promise;\n+    }\n+\n+    void asyncStartFetchLogSegments(final Promise<Versioned<List<LogSegmentMetadata>>> promise) {\n+        readLogSegmentsFromStore(\n+                LogSegmentMetadata.COMPARATOR,\n+                LogSegmentFilter.DEFAULT_FILTER,\n+                this).addEventListener(new FutureEventListener<Versioned<List<LogSegmentMetadata>>>() {\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                if (cause instanceof LogNotFoundException ||\n+                        cause instanceof LogSegmentNotFoundException ||\n+                        cause instanceof UnexpectedException) {\n+                    // indicate some inconsistent behavior, abort\n+                    metadataException.compareAndSet(null, (IOException) cause);\n+                    // notify the reader that read handler is in error state\n+                    notifyReaderOnError(cause);\n+                    FutureUtils.setException(promise, cause);\n+                    return;\n+                }\n+                scheduler.schedule(new Runnable() {\n+                    @Override\n+                    public void run() {\n+                        asyncStartFetchLogSegments(promise);\n+                    }\n+                }, conf.getZKRetryBackoffMaxMillis(), TimeUnit.MILLISECONDS);\n+            }\n+\n+            @Override\n+            public void onSuccess(Versioned<List<LogSegmentMetadata>> segments) {\n+                // no-op\n+                FutureUtils.setValue(promise, segments);\n+            }\n+        });\n+    }\n+\n     public void startReadAhead(LedgerReadPosition startPosition,\n                                AsyncFailureInjector failureInjector) {\n         if (null == readAheadWorker) {\n@@ -334,7 +410,6 @@ public void startReadAhead(LedgerReadPosition startPosition,\n                     dynConf,\n                     logMetadataForReader,\n                     this,\n-                    zooKeeperClient,\n                     readAheadExecutor,\n                     handleCache,\n                     startPosition,\n@@ -345,8 +420,16 @@ public void startReadAhead(LedgerReadPosition startPosition,\n                     perLogStatsLogger,\n                     alertStatsLogger,\n                     failureInjector,\n-                    notification);\n-            readAheadWorker.start();\n+                    readerStateNotification);\n+            registerListener(readAheadWorker);\n+            // start the readahead worker after the log segments are fetched\n+            asyncStartFetchLogSegments().map(new AbstractFunction1<Versioned<List<LogSegmentMetadata>>, BoxedUnit>() {\n+                @Override\n+                public BoxedUnit apply(Versioned<List<LogSegmentMetadata>> logSegments) {\n+                    readAheadWorker.start(logSegments.getValue());\n+                    return BoxedUnit.UNIT;\n+                }\n+            });\n         }\n     }\n \n@@ -407,10 +490,110 @@ public ReadAheadCache getReadAheadCache() {\n     }\n \n     @VisibleForTesting\n-    void disableReadAheadZKNotification() {\n-        if (null != readAheadWorker) {\n-            readAheadWorker.disableZKNotification();\n+    void disableReadAheadLogSegmentsNotification() {\n+        logSegmentsNotificationDisabled = true;\n+    }\n+\n+    @Override\n+    public void onSegmentsUpdated(final Versioned<List<String>> segments) {\n+        synchronized (this) {\n+            if (lastNotifiedLogSegments.getVersion() != Version.NEW &&\n+                    lastNotifiedLogSegments.getVersion().compare(segments.getVersion()) != Version.Occurred.BEFORE) {\n+                // the log segments has been read, and it is possibly a retry from last segments update\n+                return;\n+            }\n+        }\n+\n+        Promise<Versioned<List<LogSegmentMetadata>>> readLogSegmentsPromise =\n+                new Promise<Versioned<List<LogSegmentMetadata>>>();\n+        readLogSegmentsPromise.addEventListener(new FutureEventListener<Versioned<List<LogSegmentMetadata>>>() {\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                if (cause instanceof LogNotFoundException ||\n+                        cause instanceof LogSegmentNotFoundException ||\n+                        cause instanceof UnexpectedException) {\n+                    // indicate some inconsistent behavior, abort\n+                    metadataException.compareAndSet(null, (IOException) cause);\n+                    // notify the reader that read handler is in error state\n+                    notifyReaderOnError(cause);\n+                    return;\n+                }\n+                scheduler.schedule(new Runnable() {\n+                    @Override\n+                    public void run() {\n+                        onSegmentsUpdated(segments);\n+                    }\n+                }, conf.getZKRetryBackoffMaxMillis(), TimeUnit.MILLISECONDS);\n+            }\n+\n+            @Override\n+            public void onSuccess(Versioned<List<LogSegmentMetadata>> logSegments) {\n+                List<LogSegmentMetadata> segmentsToNotify = null;\n+                synchronized (BKLogReadHandler.this) {\n+                    Versioned<List<LogSegmentMetadata>> lastLogSegments = lastNotifiedLogSegments;\n+                    if (lastLogSegments.getVersion() == Version.NEW ||\n+                            lastLogSegments.getVersion().compare(logSegments.getVersion()) == Version.Occurred.BEFORE) {\n+                        lastNotifiedLogSegments = logSegments;\n+                        segmentsToNotify = logSegments.getValue();\n+                    }\n+                }\n+                if (null != segmentsToNotify) {\n+                    notifyUpdatedLogSegments(segmentsToNotify);\n+                }\n+            }\n+        });\n+        // log segments list is updated, read their metadata\n+        readLogSegmentsFromStore(\n+                segments,\n+                LogSegmentMetadata.COMPARATOR,\n+                LogSegmentFilter.DEFAULT_FILTER,\n+                readLogSegmentsPromise);\n+    }\n+\n+    @Override\n+    public void onLogStreamDeleted() {\n+        notifyLogStreamDeleted();\n+    }\n+\n+    //\n+    // Listener for log segments\n+    //\n+\n+    protected void registerListener(LogSegmentListener listener) {\n+        listeners.add(listener);\n+    }\n+\n+    protected void unregisterListener(LogSegmentListener listener) {\n+        listeners.remove(listener);\n+    }\n+\n+    protected void notifyUpdatedLogSegments(List<LogSegmentMetadata> segments) {\n+        if (logSegmentsNotificationDisabled) {\n+            return;\n+        }\n+\n+        for (LogSegmentListener listener : listeners) {\n+            List<LogSegmentMetadata> listToReturn =\n+                    new ArrayList<LogSegmentMetadata>(segments);\n+            Collections.sort(listToReturn, LogSegmentMetadata.COMPARATOR);\n+            listener.onSegmentsUpdated(listToReturn);\n+        }\n+    }\n+\n+    protected void notifyLogStreamDeleted() {\n+        if (logSegmentsNotificationDisabled) {\n+            return;\n+        }\n+\n+        for (LogSegmentListener listener : listeners) {\n+            listener.onLogStreamDeleted();\n         }\n     }\n \n+    // notify the errors\n+    protected void notifyReaderOnError(Throwable cause) {\n+        if (null != readerStateNotification) {\n+            readerStateNotification.notifyOnError(cause);\n+        }\n+    }\n }"},{"sha":"5d3be7df88bcc213a14d82e1811de6d1a5789a7b","filename":"src/main/java/com/twitter/distributedlog/BKLogWriteHandler.java","status":"modified","additions":140,"deletions":54,"changes":194,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -33,6 +33,8 @@\n import com.twitter.distributedlog.impl.BKLogSegmentEntryWriter;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n import com.twitter.distributedlog.lock.DistributedLock;\n+import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.logsegment.RollingPolicy;\n import com.twitter.distributedlog.logsegment.SizeBasedRollingPolicy;\n@@ -63,6 +65,7 @@\n import org.apache.bookkeeper.stats.OpStatsLogger;\n import org.apache.bookkeeper.stats.StatsLogger;\n import org.apache.bookkeeper.versioning.Version;\n+import org.apache.bookkeeper.versioning.Versioned;\n import org.apache.zookeeper.CreateMode;\n import org.apache.zookeeper.KeeperException;\n import org.apache.zookeeper.Op;\n@@ -76,6 +79,7 @@\n \n import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Comparator;\n import java.util.LinkedList;\n import java.util.List;\n import java.util.concurrent.TimeUnit;\n@@ -99,9 +103,6 @@ class BKLogWriteHandler extends BKLogHandler {\n     static final Logger LOG = LoggerFactory.getLogger(BKLogReadHandler.class);\n \n     protected final DistributedLock lock;\n-    protected final int ensembleSize;\n-    protected final int writeQuorumSize;\n-    protected final int ackQuorumSize;\n     protected final LedgerAllocator ledgerAllocator;\n     protected final MaxTxId maxTxId;\n     protected final MaxLogSegmentSequenceNo maxLogSegmentSequenceNo;\n@@ -117,6 +118,10 @@ class BKLogWriteHandler extends BKLogHandler {\n     // tracking the inprogress log segments\n     protected final LinkedList<Long> inprogressLSSNs;\n \n+    // Fetch LogSegments State: write can continue without full list of log segments while truncation needs\n+    private final Future<Versioned<List<LogSegmentMetadata>>> fetchForWrite;\n+    private Future<Versioned<List<LogSegmentMetadata>>> fetchForTruncation;\n+\n     // Recover Functions\n     private final RecoverLogSegmentFunction recoverLogSegmentFunction =\n             new RecoverLogSegmentFunction();\n@@ -162,6 +167,7 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n                       ZooKeeperClientBuilder zkcBuilder,\n                       BookKeeperClientBuilder bkcBuilder,\n                       LogSegmentMetadataStore metadataStore,\n+                      LogSegmentMetadataCache metadataCache,\n                       OrderedScheduler scheduler,\n                       LedgerAllocator allocator,\n                       StatsLogger statsLogger,\n@@ -173,8 +179,16 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n                       FeatureProvider featureProvider,\n                       DynamicDistributedLogConfiguration dynConf,\n                       DistributedLock lock /** owned by handler **/) {\n-        super(logMetadata, conf, zkcBuilder, bkcBuilder, metadataStore,\n-              scheduler, statsLogger, alertStatsLogger, null, WRITE_HANDLE_FILTER, clientId);\n+        super(logMetadata,\n+                conf,\n+                zkcBuilder,\n+                bkcBuilder,\n+                metadataStore,\n+                metadataCache,\n+                scheduler,\n+                statsLogger,\n+                alertStatsLogger,\n+                clientId);\n         this.perLogStatsLogger = perLogStatsLogger;\n         this.writeLimiter = writeLimiter;\n         this.featureProvider = featureProvider;\n@@ -183,23 +197,6 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n         this.lock = lock;\n         this.metadataUpdater = LogSegmentMetadataStoreUpdater.createMetadataUpdater(conf, metadataStore);\n \n-        ensembleSize = conf.getEnsembleSize();\n-\n-        if (ensembleSize < conf.getWriteQuorumSize()) {\n-            writeQuorumSize = ensembleSize;\n-            LOG.warn(\"Setting write quorum size {} greater than ensemble size {}\",\n-                conf.getWriteQuorumSize(), ensembleSize);\n-        } else {\n-            writeQuorumSize = conf.getWriteQuorumSize();\n-        }\n-        if (writeQuorumSize < conf.getAckQuorumSize()) {\n-            ackQuorumSize = writeQuorumSize;\n-            LOG.warn(\"Setting write ack quorum size {} greater than write quorum size {}\",\n-                conf.getAckQuorumSize(), writeQuorumSize);\n-        } else {\n-            ackQuorumSize = conf.getAckQuorumSize();\n-        }\n-\n         if (conf.getEncodeRegionIDInLogSegmentMetadata()) {\n             this.regionId = regionId;\n         } else {\n@@ -215,9 +212,12 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n         maxTxId = new MaxTxId(zooKeeperClient, logMetadata.getMaxTxIdPath(),\n                 conf.getSanityCheckTxnID(), logMetadata.getMaxTxIdData());\n \n-        // Schedule fetching ledgers list in background before we access it.\n-        // We don't need to watch the ledgers list changes for writer, as it manages ledgers list.\n-        scheduleGetLedgersTask(false, true);\n+        // Schedule fetching log segment list in background before we access it.\n+        // We don't need to watch the log segment list changes for writer, as it manages log segment list.\n+        fetchForWrite = readLogSegmentsFromStore(\n+                LogSegmentMetadata.COMPARATOR,\n+                WRITE_HANDLE_FILTER,\n+                null);\n \n         // Initialize other parameters.\n         setLastLedgerRollingTimeMillis(Utils.nowInMillis());\n@@ -237,6 +237,59 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n         deleteOpStats = segmentsStatsLogger.getOpStatsLogger(\"delete\");\n     }\n \n+    private Future<List<LogSegmentMetadata>> getCachedLogSegmentsAfterFirstFetch(\n+            final Comparator<LogSegmentMetadata> comparator) {\n+        final Promise<List<LogSegmentMetadata>> promise = new Promise<List<LogSegmentMetadata>>();\n+        fetchForWrite.addEventListener(new FutureEventListener<Versioned<List<LogSegmentMetadata>>>() {\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                FutureUtils.setException(promise, cause);\n+            }\n+\n+            @Override\n+            public void onSuccess(Versioned<List<LogSegmentMetadata>> result) {\n+                try {\n+                    FutureUtils.setValue(promise, getCachedLogSegments(comparator));\n+                } catch (UnexpectedException e) {\n+                    FutureUtils.setException(promise, e);\n+                }\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    private Future<List<LogSegmentMetadata>> getCachedLogSegmentsAfterFirstFullFetch(\n+            final Comparator<LogSegmentMetadata> comparator) {\n+        Future<Versioned<List<LogSegmentMetadata>>> result;\n+        synchronized (this) {\n+            if (null == fetchForTruncation) {\n+                fetchForTruncation = readLogSegmentsFromStore(\n+                        LogSegmentMetadata.COMPARATOR,\n+                        LogSegmentFilter.DEFAULT_FILTER,\n+                        null);\n+            }\n+            result = fetchForTruncation;\n+        }\n+\n+        final Promise<List<LogSegmentMetadata>> promise = new Promise<List<LogSegmentMetadata>>();\n+        result.addEventListener(new FutureEventListener<Versioned<List<LogSegmentMetadata>>>() {\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                FutureUtils.setException(promise, cause);\n+            }\n+\n+            @Override\n+            public void onSuccess(Versioned<List<LogSegmentMetadata>> result) {\n+                try {\n+                    FutureUtils.setValue(promise, getCachedLogSegments(comparator));\n+                } catch (UnexpectedException e) {\n+                    FutureUtils.setException(promise, e);\n+                }\n+            }\n+        });\n+        return promise;\n+    }\n+\n     // Transactional operations for MaxLogSegmentSequenceNo\n     void storeMaxSequenceNumber(final Transaction txn,\n                                 final MaxLogSegmentSequenceNo maxSeqNo,\n@@ -413,7 +466,7 @@ protected long assignLogSegmentSequenceNumber() throws IOException {\n         boolean logSegmentsFound = false;\n \n         if (LogSegmentMetadata.supportsLogSegmentSequenceNo(conf.getDLLedgerMetadataLayoutVersion())) {\n-            List<LogSegmentMetadata> ledgerListDesc = getFilteredLedgerListDesc(false, false);\n+            List<LogSegmentMetadata> ledgerListDesc = getCachedLogSegments(LogSegmentMetadata.DESC_COMPARATOR);\n             Long nextLogSegmentSeqNo = DLUtils.nextLogSegmentSequenceNumber(ledgerListDesc);\n \n             if (null == nextLogSegmentSeqNo) {\n@@ -452,17 +505,27 @@ protected BKLogSegmentWriter doStartLogSegment(long txId, boolean bestEffort, bo\n         return FutureUtils.result(asyncStartLogSegment(txId, bestEffort, allowMaxTxID));\n     }\n \n-    protected Future<BKLogSegmentWriter> asyncStartLogSegment(long txId,\n-                                                              boolean bestEffort,\n-                                                              boolean allowMaxTxID) {\n-        Promise<BKLogSegmentWriter> promise = new Promise<BKLogSegmentWriter>();\n+    protected Future<BKLogSegmentWriter> asyncStartLogSegment(final long txId,\n+                                                              final boolean bestEffort,\n+                                                              final boolean allowMaxTxID) {\n+        final Promise<BKLogSegmentWriter> promise = new Promise<BKLogSegmentWriter>();\n         try {\n             lock.checkOwnershipAndReacquire();\n         } catch (LockingException e) {\n             FutureUtils.setException(promise, e);\n             return promise;\n         }\n-        doStartLogSegment(txId, bestEffort, allowMaxTxID, promise);\n+        fetchForWrite.addEventListener(new FutureEventListener<Versioned<List<LogSegmentMetadata>>>() {\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                FutureUtils.setException(promise, cause);\n+            }\n+\n+            @Override\n+            public void onSuccess(Versioned<List<LogSegmentMetadata>> list) {\n+                doStartLogSegment(txId, bestEffort, allowMaxTxID, promise);\n+            }\n+        });\n         return promise;\n     }\n \n@@ -732,7 +795,8 @@ protected long computeStartSequenceId(LogSegmentMetadata segment) throws IOExcep\n         // we only record sequence id when both write version and logsegment's version support sequence id\n         if (LogSegmentMetadata.supportsSequenceId(conf.getDLLedgerMetadataLayoutVersion())\n                 && segment.supportsSequenceId()) {\n-            List<LogSegmentMetadata> logSegmentDescList = getFilteredLedgerListDesc(false, false);\n+            List<LogSegmentMetadata> logSegmentDescList =\n+                    getCachedLogSegments(LogSegmentMetadata.DESC_COMPARATOR);\n             startSequenceId = DLUtils.computeStartSequenceId(logSegmentDescList, segment);\n         }\n \n@@ -776,14 +840,46 @@ protected LogSegmentMetadata doCompleteAndCloseLogSegment(\n     }\n \n     protected void doCompleteAndCloseLogSegment(final String inprogressZnodeName,\n-                                                long logSegmentSeqNo,\n-                                                long ledgerId,\n-                                                long firstTxId,\n-                                                long lastTxId,\n-                                                int recordCount,\n-                                                long lastEntryId,\n-                                                long lastSlotId,\n+                                                final long logSegmentSeqNo,\n+                                                final long ledgerId,\n+                                                final long firstTxId,\n+                                                final long lastTxId,\n+                                                final int recordCount,\n+                                                final long lastEntryId,\n+                                                final long lastSlotId,\n                                                 final Promise<LogSegmentMetadata> promise) {\n+        fetchForWrite.addEventListener(new FutureEventListener<Versioned<List<LogSegmentMetadata>>>() {\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                FutureUtils.setException(promise, cause);\n+            }\n+\n+            @Override\n+            public void onSuccess(Versioned<List<LogSegmentMetadata>> segments) {\n+                doCompleteAndCloseLogSegmentAfterLogSegmentListFetched(\n+                        inprogressZnodeName,\n+                        logSegmentSeqNo,\n+                        ledgerId,\n+                        firstTxId,\n+                        lastTxId,\n+                        recordCount,\n+                        lastEntryId,\n+                        lastSlotId,\n+                        promise);\n+            }\n+        });\n+    }\n+\n+    private void doCompleteAndCloseLogSegmentAfterLogSegmentListFetched(\n+            final String inprogressZnodeName,\n+            long logSegmentSeqNo,\n+            long ledgerId,\n+            long firstTxId,\n+            long lastTxId,\n+            int recordCount,\n+            long lastEntryId,\n+            long lastSlotId,\n+            final Promise<LogSegmentMetadata> promise) {\n         try {\n             lock.checkOwnershipAndReacquire();\n         } catch (IOException ioe) {\n@@ -912,7 +1008,7 @@ public Future<Long> recoverIncompleteLogSegments() {\n         } catch (IOException ioe) {\n             return Future.exception(ioe);\n         }\n-        return asyncGetFilteredLedgerList(false, false).flatMap(recoverLogSegmentsFunction);\n+        return getCachedLogSegmentsAfterFirstFetch(LogSegmentMetadata.COMPARATOR).flatMap(recoverLogSegmentsFunction);\n     }\n \n     class RecoverLogSegmentFunction extends Function<LogSegmentMetadata, Future<LogSegmentMetadata>> {\n@@ -1002,8 +1098,7 @@ Future<List<LogSegmentMetadata>> setLogSegmentsOlderThanDLSNTruncated(final DLSN\n             List<LogSegmentMetadata> emptyList = new ArrayList<LogSegmentMetadata>(0);\n             return Future.value(emptyList);\n         }\n-        scheduleGetAllLedgersTaskIfNeeded();\n-        return asyncGetFullLedgerList(false, false).flatMap(\n+        return getCachedLogSegmentsAfterFirstFullFetch(LogSegmentMetadata.COMPARATOR).flatMap(\n                 new AbstractFunction1<List<LogSegmentMetadata>, Future<List<LogSegmentMetadata>>>() {\n                     @Override\n                     public Future<List<LogSegmentMetadata>> apply(List<LogSegmentMetadata> logSegments) {\n@@ -1068,7 +1163,7 @@ Future<List<LogSegmentMetadata>> purgeLogSegmentsOlderThanTimestamp(final long m\n             return Future.exception(new IllegalArgumentException(\n                     \"Invalid timestamp \" + minTimestampToKeep + \" to purge logs for \" + getFullyQualifiedName()));\n         }\n-        return asyncGetFullLedgerList(false, false).flatMap(\n+        return getCachedLogSegmentsAfterFirstFullFetch(LogSegmentMetadata.COMPARATOR).flatMap(\n                 new Function<List<LogSegmentMetadata>, Future<List<LogSegmentMetadata>>>() {\n             @Override\n             public Future<List<LogSegmentMetadata>> apply(List<LogSegmentMetadata> logSegments) {\n@@ -1097,7 +1192,7 @@ public Future<List<LogSegmentMetadata>> apply(List<LogSegmentMetadata> logSegmen\n     }\n \n     Future<List<LogSegmentMetadata>> purgeLogSegmentsOlderThanTxnId(final long minTxIdToKeep) {\n-        return asyncGetFullLedgerList(true, false).flatMap(\n+        return getCachedLogSegmentsAfterFirstFullFetch(LogSegmentMetadata.COMPARATOR).flatMap(\n             new AbstractFunction1<List<LogSegmentMetadata>, Future<List<LogSegmentMetadata>>>() {\n                 @Override\n                 public Future<List<LogSegmentMetadata>> apply(List<LogSegmentMetadata> logSegments) {\n@@ -1260,16 +1355,7 @@ public Future<Void> asyncClose() {\n         return Utils.closeSequence(scheduler,\n                 lock,\n                 ledgerAllocator\n-        ).flatMap(new AbstractFunction1<Void, Future<Void>>() {\n-            @Override\n-            public Future<Void> apply(Void result) {\n-                zooKeeperClient.getWatcherManager().unregisterChildWatcher(\n-                        logMetadata.getLogSegmentsPath(),\n-                        BKLogWriteHandler.this,\n-                        false);\n-                return Future.Void();\n-            }\n-        });\n+        );\n     }\n \n     @Override"},{"sha":"28e69b2d5711faada0b5c8aebf60a98c4fe0d91d","filename":"src/main/java/com/twitter/distributedlog/BKSyncLogReaderDLSN.java","status":"modified","additions":2,"deletions":2,"changes":4,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -238,8 +238,8 @@ public void close() throws IOException {\n     // Test Methods\n     //\n     @VisibleForTesting\n-    void disableReadAheadZKNotification() {\n-        reader.bkLedgerManager.disableReadAheadZKNotification();\n+    void disableReadAheadLogSegmentsNotification() {\n+        reader.bkLedgerManager.disableReadAheadLogSegmentsNotification();\n     }\n \n     @VisibleForTesting"},{"sha":"1f5427c5d49325f6034310c6886e1204cb47efcb","filename":"src/main/java/com/twitter/distributedlog/DistributedLogConfiguration.java","status":"modified","additions":71,"deletions":0,"changes":71,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -212,6 +212,14 @@ public class DistributedLogConfiguration extends CompositeConfiguration {\n     public static final String BKDL_UNPARTITIONED_STREAM_NAME = \"unpartitionedStreamName\";\n     public static final String BKDL_UNPARTITIONED_STREAM_NAME_DEFAULT = \"<default>\";\n \n+    // Log Segment Cache Parameters\n+    public static final String BKDL_LOGSEGMENT_CACHE_TTL_MS = \"logSegmentCacheTTLMs\";\n+    public static final long BKDL_LOGSEGMENT_CACHE_TTL_MS_DEFAULT = 600000; // 10 mins\n+    public static final String BKDL_LOGSEGMENT_CACHE_MAX_SIZE = \"logSegmentCacheMaxSize\";\n+    public static final long BKDL_LOGSEGMENT_CACHE_MAX_SIZE_DEFAULT = 10000;\n+    public static final String BKDL_LOGSEGMENT_CACHE_ENABLED = \"logSegmentCacheEnabled\";\n+    public static final boolean BKDL_LOGSEGMENT_CACHE_ENABLED_DEFAULT = true;\n+\n     //\n     // DL Writer Settings\n     //\n@@ -1643,6 +1651,69 @@ public DistributedLogConfiguration setUnpartitionedStreamName(String streamName)\n         return this;\n     }\n \n+    //\n+    // LogSegment Cache Settings\n+    //\n+\n+    /**\n+     * Get the log segment cache entry TTL in milliseconds.\n+     *\n+     * @return log segment cache ttl in milliseconds.\n+     */\n+    public long getLogSegmentCacheTTLMs() {\n+        return getLong(BKDL_LOGSEGMENT_CACHE_TTL_MS, BKDL_LOGSEGMENT_CACHE_MAX_SIZE_DEFAULT);\n+    }\n+\n+    /**\n+     * Set the log segment cache entry TTL in milliseconds.\n+     *\n+     * @param ttlMs TTL in milliseconds\n+     * @return distributedlog configuration\n+     */\n+    public DistributedLogConfiguration setLogSegmentCacheTTLMs(long ttlMs) {\n+        setProperty(BKDL_LOGSEGMENT_CACHE_TTL_MS, ttlMs);\n+        return this;\n+    }\n+\n+    /**\n+     * Get the maximum size of the log segment cache.\n+     *\n+     * @return maximum size of the log segment cache.\n+     */\n+    public long getLogSegmentCacheMaxSize() {\n+        return getLong(BKDL_LOGSEGMENT_CACHE_MAX_SIZE, BKDL_LOGSEGMENT_CACHE_MAX_SIZE_DEFAULT);\n+    }\n+\n+    /**\n+     * Set the maximum size of the log segment cache.\n+     *\n+     * @param maxSize maximum size of the log segment cache.\n+     * @return distributedlog configuration\n+     */\n+    public DistributedLogConfiguration setLogSegmentCacheMaxSize(long maxSize) {\n+        setProperty(BKDL_LOGSEGMENT_CACHE_MAX_SIZE, maxSize);\n+        return this;\n+    }\n+\n+    /**\n+     * Is log segment cache enabled?\n+     *\n+     * @return true if log segment cache is enabled; otherwise false\n+     */\n+    public boolean isLogSegmentCacheEnabled() {\n+        return getBoolean(BKDL_LOGSEGMENT_CACHE_ENABLED, BKDL_LOGSEGMENT_CACHE_ENABLED_DEFAULT);\n+    }\n+\n+    /**\n+     * Enable/disable log segment cache.\n+     *\n+     * @return distributedlog configuration\n+     */\n+    public DistributedLogConfiguration setLogSegmentCacheEnabled(boolean enabled) {\n+        setProperty(BKDL_LOGSEGMENT_CACHE_ENABLED, enabled);\n+        return this;\n+    }\n+\n     //\n     // DL Writer General Settings\n     //"},{"sha":"229757918e2aa64ece475ad4ccc3b63efeb1ec4c","filename":"src/main/java/com/twitter/distributedlog/LogSegmentMetadata.java","status":"modified","additions":10,"deletions":2,"changes":12,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogSegmentMetadata.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogSegmentMetadata.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogSegmentMetadata.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -23,6 +23,8 @@\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Objects;\n+import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.Utils;\n import com.twitter.util.Future;\n@@ -600,12 +602,18 @@ public static Future<LogSegmentMetadata> read(ZooKeeperClient zkc, String path,\n                 @Override\n                 public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {\n                     if (KeeperException.Code.OK.intValue() != rc) {\n-                        result.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+                        if (KeeperException.Code.NONODE.intValue() == rc) {\n+                            FutureUtils.setException(result, new LogSegmentNotFoundException(path));\n+                        } else {\n+                            FutureUtils.setException(result,\n+                                    new ZKException(\"Failed to read log segment metadata from \" + path,\n+                                            KeeperException.Code.get(rc)));\n+                        }\n                         return;\n                     }\n                     try {\n                         LogSegmentMetadata metadata = parseData(path, data, skipMinVersionCheck);\n-                        result.setValue(metadata);\n+                        FutureUtils.setValue(result, metadata);\n                     } catch (IOException ie) {\n                         LOG.error(\"Error on parsing log segment metadata from {} : \", path, ie);\n                         result.setException(ie);"},{"sha":"2196245d6fd6073e8a884d51a8e7a285cb0d77c0","filename":"src/main/java/com/twitter/distributedlog/callback/LogSegmentListener.java","status":"modified","additions":6,"deletions":1,"changes":7,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentListener.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -22,7 +22,7 @@\n import java.util.List;\n \n /**\n- * Listener on log segments changes for a given stream.\n+ * Listener on log segments changes for a given stream used by {@link com.twitter.distributedlog.BKLogReadHandler}\n  */\n public interface LogSegmentListener {\n \n@@ -34,4 +34,9 @@ public interface LogSegmentListener {\n      *          updated list of segments.\n      */\n     void onSegmentsUpdated(List<LogSegmentMetadata> segments);\n+\n+    /**\n+     * Notified when the log stream is deleted.\n+     */\n+    void onLogStreamDeleted();\n }"},{"sha":"e38f305a9a56c335ab55cf59ece2f8f0bca0ecf8","filename":"src/main/java/com/twitter/distributedlog/callback/LogSegmentNamesListener.java","status":"modified","additions":10,"deletions":2,"changes":12,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentNamesListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentNamesListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentNamesListener.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -17,10 +17,13 @@\n  */\n package com.twitter.distributedlog.callback;\n \n+import org.apache.bookkeeper.versioning.Versioned;\n+\n import java.util.List;\n \n /**\n- * Listener on list of log segments changes for a given stream.\n+ * Listener on list of log segments changes for a given stream used by\n+ * {@link com.twitter.distributedlog.logsegment.LogSegmentMetadataStore}.\n  */\n public interface LogSegmentNamesListener {\n     /**\n@@ -30,5 +33,10 @@ public interface LogSegmentNamesListener {\n      * @param segments\n      *          updated list of segments.\n      */\n-    void onSegmentsUpdated(List<String> segments);\n+    void onSegmentsUpdated(Versioned<List<String>> segments);\n+\n+    /**\n+     * Notified when the log stream is deleted.\n+     */\n+    void onLogStreamDeleted();\n }"},{"sha":"698a08859f22e5d1748424278f112274db2688d0","filename":"src/main/java/com/twitter/distributedlog/function/CloseAsyncCloseableFunction.java","status":"added","additions":51,"deletions":0,"changes":51,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FCloseAsyncCloseableFunction.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FCloseAsyncCloseableFunction.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FCloseAsyncCloseableFunction.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -0,0 +1,51 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.function;\n+\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+import scala.Function0;\n+import scala.runtime.AbstractFunction0;\n+import scala.runtime.BoxedUnit;\n+\n+/**\n+ * Function to close {@link com.twitter.distributedlog.io.AsyncCloseable}\n+ */\n+public class CloseAsyncCloseableFunction extends AbstractFunction0<BoxedUnit> {\n+\n+    /**\n+     * Return a function to close an {@link AsyncCloseable}.\n+     *\n+     * @param closeable closeable to close\n+     * @return function to close an {@link AsyncCloseable}\n+     */\n+    public static Function0<BoxedUnit> of(AsyncCloseable closeable) {\n+        return new CloseAsyncCloseableFunction(closeable);\n+    }\n+\n+    private final AsyncCloseable closeable;\n+\n+    private CloseAsyncCloseableFunction(AsyncCloseable closeable) {\n+        this.closeable = closeable;\n+    }\n+\n+    @Override\n+    public BoxedUnit apply() {\n+        closeable.asyncClose();\n+        return BoxedUnit.UNIT;\n+    }\n+}"},{"sha":"4e7844c488acf4fd841e97d587ec62c5e912b252","filename":"src/main/java/com/twitter/distributedlog/function/GetVersionedValueFunction.java","status":"added","additions":39,"deletions":0,"changes":39,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FGetVersionedValueFunction.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FGetVersionedValueFunction.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FGetVersionedValueFunction.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.function;\n+\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import org.apache.bookkeeper.versioning.Versioned;\n+import scala.Function1;\n+import scala.runtime.AbstractFunction1;\n+\n+import java.util.List;\n+\n+/**\n+ * Function to get the versioned value from {@link org.apache.bookkeeper.versioning.Versioned}\n+ */\n+public class GetVersionedValueFunction<T> extends AbstractFunction1<Versioned<T>, T> {\n+\n+    public static final Function1<Versioned<List<LogSegmentMetadata>>, List<LogSegmentMetadata>>\n+            GET_LOGSEGMENT_LIST_FUNC = new GetVersionedValueFunction<List<LogSegmentMetadata>>();\n+\n+    @Override\n+    public T apply(Versioned<T> versionedValue) {\n+        return versionedValue.getValue();\n+    }\n+}"},{"sha":"f0d2797cd5550b7a2853ebccd65245643665f7ad","filename":"src/main/java/com/twitter/distributedlog/impl/ZKLogSegmentMetadataStore.java","status":"modified","additions":94,"deletions":64,"changes":158,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -22,6 +22,8 @@\n import com.twitter.distributedlog.LogSegmentMetadata;\n import com.twitter.distributedlog.ZooKeeperClient;\n import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n+import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.util.DLUtils;\n import com.twitter.distributedlog.util.FutureUtils;\n@@ -88,30 +90,21 @@ private static class ReadLogSegmentsTask implements Runnable, FutureEventListene\n         public void onSuccess(final Versioned<List<String>> segments) {\n             // reset the back off after a successful operation\n             currentZKBackOffMs = store.minZKBackoffMs;\n-            final Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> listenerSet =\n-                    store.listeners.get(logSegmentsPath);\n-            if (null != listenerSet) {\n-                store.submitTask(logSegmentsPath, new Runnable() {\n-                    @Override\n-                    public void run() {\n-                        for (VersionedLogSegmentNamesListener listener : listenerSet.values()) {\n-                            listener.onSegmentsUpdated(segments);\n-                        }\n-                    }\n-                });\n-            }\n+            store.notifyLogSegmentsUpdated(\n+                    logSegmentsPath,\n+                    store.listeners.get(logSegmentsPath),\n+                    segments);\n         }\n \n         @Override\n         public void onFailure(Throwable cause) {\n-            int backoffMs = store.minZKBackoffMs;\n-            if ((cause instanceof KeeperException)) {\n-                KeeperException ke = (KeeperException) cause;\n-                if (KeeperException.Code.NONODE == ke.code()) {\n-                    // the log segment has been deleted, remove all the registered listeners\n-                    store.listeners.remove(logSegmentsPath);\n-                    return;\n-                }\n+            int backoffMs;\n+            if (cause instanceof LogNotFoundException) {\n+                // the log segment has been deleted, remove all the registered listeners\n+                store.notifyLogStreamDeleted(logSegmentsPath,\n+                        store.listeners.remove(logSegmentsPath));\n+                return;\n+            } else {\n                 backoffMs = currentZKBackOffMs;\n                 currentZKBackOffMs = Math.min(2 * currentZKBackOffMs, store.maxZKBackoffMs);\n             }\n@@ -121,7 +114,7 @@ public void onFailure(Throwable cause) {\n         @Override\n         public void run() {\n             if (null != store.listeners.get(logSegmentsPath)) {\n-                store.getLogSegmentNames(logSegmentsPath, store).addEventListener(this);\n+                store.zkGetLogSegmentNames(logSegmentsPath, store).addEventListener(this);\n             } else {\n                 logger.debug(\"Log segments listener for {} has been removed.\", logSegmentsPath);\n             }\n@@ -146,7 +139,7 @@ synchronized void onSegmentsUpdated(Versioned<List<String>> logSegments) {\n             if (lastNotifiedLogSegments.getVersion() == Version.NEW ||\n                     lastNotifiedLogSegments.getVersion().compare(logSegments.getVersion()) == Version.Occurred.BEFORE) {\n                 lastNotifiedLogSegments = logSegments;\n-                listener.onSegmentsUpdated(logSegments.getValue());\n+                listener.onSegmentsUpdated(logSegments);\n             }\n         }\n \n@@ -309,7 +302,7 @@ public void process(WatchedEvent event) {\n         }\n         switch (event.getType()) {\n             case NodeDeleted:\n-                listeners.remove(path);\n+                notifyLogStreamDeleted(path, listeners.remove(path));\n                 break;\n             case NodeChildrenChanged:\n                 new ReadLogSegmentsTask(path, this).run();\n@@ -324,17 +317,7 @@ public Future<LogSegmentMetadata> getLogSegment(String logSegmentPath) {\n         return LogSegmentMetadata.read(zkc, logSegmentPath, skipMinVersionCheck);\n     }\n \n-    @Override\n-    public Future<List<String>> getLogSegmentNames(String logSegmentsPath) {\n-        return getLogSegmentNames(logSegmentsPath, null).map(new AbstractFunction1<Versioned<List<String>>, List<String>>() {\n-            @Override\n-            public List<String> apply(Versioned<List<String>> list) {\n-                return list.getValue();\n-            }\n-        });\n-    }\n-\n-    Future<Versioned<List<String>>> getLogSegmentNames(String logSegmentsPath, Watcher watcher) {\n+    Future<Versioned<List<String>>> zkGetLogSegmentNames(String logSegmentsPath, Watcher watcher) {\n         Promise<Versioned<List<String>>> result = new Promise<Versioned<List<String>>>();\n         try {\n             zkc.get().getChildren(logSegmentsPath, watcher, this, result);\n@@ -354,46 +337,59 @@ public void processResult(int rc, String path, Object ctx, List<String> children\n             /** cversion: the number of changes to the children of this znode **/\n             ZkVersion zkVersion = new ZkVersion(stat.getCversion());\n             result.setValue(new Versioned(children, zkVersion));\n+        } else if (KeeperException.Code.NONODE.intValue() == rc) {\n+            result.setException(new LogNotFoundException(\"Log \" + path + \" not found\"));\n         } else {\n-            result.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+            result.setException(new ZKException(\"Failed to get log segments from \" + path,\n+                    KeeperException.Code.get(rc)));\n         }\n     }\n \n     @Override\n-    public void registerLogSegmentListener(String logSegmentsPath,\n-                                           LogSegmentNamesListener listener) {\n+    public Future<Versioned<List<String>>> getLogSegmentNames(String logSegmentsPath,\n+                                                              LogSegmentNamesListener listener) {\n+        Watcher zkWatcher;\n         if (null == listener) {\n-            return;\n-        }\n-        closeLock.readLock().lock();\n-        try {\n-            if (closed) {\n-                return;\n-            }\n-            Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> listenerSet =\n-                    listeners.get(logSegmentsPath);\n-            if (null == listenerSet) {\n-                Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> newListenerSet =\n-                        new HashMap<LogSegmentNamesListener, VersionedLogSegmentNamesListener>();\n-                Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> oldListenerSet =\n-                        listeners.putIfAbsent(logSegmentsPath, newListenerSet);\n-                if (null != oldListenerSet) {\n-                    listenerSet = oldListenerSet;\n+            zkWatcher = null;\n+        } else {\n+            closeLock.readLock().lock();\n+            try {\n+                if (closed) {\n+                    zkWatcher = null;\n                 } else {\n-                    listenerSet = newListenerSet;\n-                }\n-            }\n-            synchronized (listenerSet) {\n-                listenerSet.put(listener, new VersionedLogSegmentNamesListener(listener));\n-                if (!listeners.containsKey(logSegmentsPath)) {\n-                    // listener set has been removed, add it back\n-                    listeners.put(logSegmentsPath, listenerSet);\n+                    Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> listenerSet =\n+                            listeners.get(logSegmentsPath);\n+                    if (null == listenerSet) {\n+                        Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> newListenerSet =\n+                                new HashMap<LogSegmentNamesListener, VersionedLogSegmentNamesListener>();\n+                        Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> oldListenerSet =\n+                                listeners.putIfAbsent(logSegmentsPath, newListenerSet);\n+                        if (null != oldListenerSet) {\n+                            listenerSet = oldListenerSet;\n+                        } else {\n+                            listenerSet = newListenerSet;\n+                        }\n+                    }\n+                    synchronized (listenerSet) {\n+                        listenerSet.put(listener, new VersionedLogSegmentNamesListener(listener));\n+                        if (!listeners.containsKey(logSegmentsPath)) {\n+                            // listener set has been removed, add it back\n+                            if (null != listeners.putIfAbsent(logSegmentsPath, listenerSet)) {\n+                                logger.debug(\"Listener set is already found for log segments path {}\", logSegmentsPath);\n+                            }\n+                        }\n+                    }\n+                    zkWatcher = ZKLogSegmentMetadataStore.this;\n                 }\n+            } finally {\n+                closeLock.readLock().unlock();\n             }\n-            new ReadLogSegmentsTask(logSegmentsPath, this).run();\n-        } finally {\n-            closeLock.readLock().unlock();\n         }\n+        Future<Versioned<List<String>>> getLogSegmentNamesResult = zkGetLogSegmentNames(logSegmentsPath, zkWatcher);\n+        if (null != listener) {\n+            getLogSegmentNamesResult.addEventListener(new ReadLogSegmentsTask(logSegmentsPath, this));\n+        }\n+        return zkGetLogSegmentNames(logSegmentsPath, zkWatcher);\n     }\n \n     @Override\n@@ -433,4 +429,38 @@ public void close() throws IOException {\n         }\n     }\n \n+    // Notifications\n+\n+    void notifyLogStreamDeleted(String logSegmentsPath,\n+                                final Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> listeners) {\n+        if (null == listeners) {\n+            return;\n+        }\n+        this.submitTask(logSegmentsPath, new Runnable() {\n+            @Override\n+            public void run() {\n+                for (LogSegmentNamesListener listener : listeners.keySet()) {\n+                    listener.onLogStreamDeleted();\n+                }\n+            }\n+        });\n+\n+    }\n+\n+    void notifyLogSegmentsUpdated(String logSegmentsPath,\n+                                  final Map<LogSegmentNamesListener, VersionedLogSegmentNamesListener> listeners,\n+                                  final Versioned<List<String>> segments) {\n+        if (null == listeners) {\n+            return;\n+        }\n+        this.submitTask(logSegmentsPath, new Runnable() {\n+            @Override\n+            public void run() {\n+                for (VersionedLogSegmentNamesListener listener : listeners.values()) {\n+                    listener.onSegmentsUpdated(segments);\n+                }\n+            }\n+        });\n+    }\n+\n }"},{"sha":"d4ca3ea99ba98e68de48d92f0ca549ad4a6e0adb","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentMetadataCache.java","status":"added","additions":98,"deletions":0,"changes":98,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataCache.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.logsegment;\n+\n+import com.google.common.base.Ticker;\n+import com.google.common.cache.Cache;\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.RemovalListener;\n+import com.google.common.cache.RemovalNotification;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Cache the log segment metadata\n+ */\n+public class LogSegmentMetadataCache implements RemovalListener<String, LogSegmentMetadata> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LogSegmentMetadataCache.class);\n+\n+    private final Cache<String, LogSegmentMetadata> cache;\n+    private final boolean isCacheEnabled;\n+\n+    public LogSegmentMetadataCache(DistributedLogConfiguration conf,\n+                                   Ticker ticker) {\n+        cache = CacheBuilder.newBuilder()\n+                .concurrencyLevel(conf.getNumWorkerThreads())\n+                .initialCapacity(1024)\n+                .expireAfterAccess(conf.getLogSegmentCacheTTLMs(), TimeUnit.MILLISECONDS)\n+                .maximumSize(conf.getLogSegmentCacheMaxSize())\n+                .removalListener(this)\n+                .ticker(ticker)\n+                .recordStats()\n+                .build();\n+        this.isCacheEnabled = conf.isLogSegmentCacheEnabled();\n+        logger.info(\"Log segment cache is enabled = {}\", this.isCacheEnabled);\n+    }\n+\n+    /**\n+     * Add the log <i>segment</i> of <i>path</i> to the cache.\n+     *\n+     * @param path the path of the log segment\n+     * @param segment log segment metadata\n+     */\n+    public void put(String path, LogSegmentMetadata segment) {\n+        if (isCacheEnabled) {\n+            cache.put(path, segment);\n+        }\n+    }\n+\n+    /**\n+     * Invalid the cache entry associated with <i>path</i>.\n+     *\n+     * @param path the path of the log segment\n+     */\n+    public void invalidate(String path) {\n+        if (isCacheEnabled) {\n+            cache.invalidate(path);\n+        }\n+    }\n+\n+    /**\n+     * Retrieve the log segment of <i>path</i> from the cache.\n+     *\n+     * @param path the path of the log segment.\n+     * @return log segment metadata if exists, otherwise null.\n+     */\n+    public LogSegmentMetadata get(String path) {\n+        return cache.getIfPresent(path);\n+    }\n+\n+    @Override\n+    public void onRemoval(RemovalNotification<String, LogSegmentMetadata> notification) {\n+        if (notification.wasEvicted()) {\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Log segment of {} was evicted.\", notification.getKey());\n+            }\n+        }\n+    }\n+}"},{"sha":"2ea167187f6b0d623a0156f8e6703e847c13b15c","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentMetadataStore.java","status":"modified","additions":5,"deletions":12,"changes":17,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -130,24 +130,17 @@ void storeMaxTxnId(Transaction<Object> txn,\n     Future<LogSegmentMetadata> getLogSegment(String logSegmentPath);\n \n     /**\n-     * Retrieve the list of log segments under <code>logSegmentsPath</code>.\n+     * Retrieve the list of log segments under <code>logSegmentsPath</code> and register a <i>listener</i>\n+     * for subsequent changes for the list of log segments.\n      *\n      * @param logSegmentsPath\n      *          path to store list of log segments\n-     * @return future of the retrieved list of log segment names\n-     */\n-    Future<List<String>> getLogSegmentNames(String logSegmentsPath);\n-\n-    /**\n-     * Register a log segment <code>listener</code> on log segment changes under <code>logSegmentsPath</code>.\n-     *\n-     * @param logSegmentsPath\n-     *          log segments path\n      * @param listener\n      *          log segment listener on log segment changes\n+     * @return future of the retrieved list of log segment names\n      */\n-    void registerLogSegmentListener(String logSegmentsPath,\n-                                    LogSegmentNamesListener listener);\n+    Future<Versioned<List<String>>> getLogSegmentNames(String logSegmentsPath,\n+                                                       LogSegmentNamesListener listener);\n \n     /**\n      * Unregister a log segment <code>listener</code> on log segment changes under <code>logSegmentsPath</code>."},{"sha":"f24294184cda3657b1f7018223408c0ec18d788f","filename":"src/main/java/com/twitter/distributedlog/logsegment/PerStreamLogSegmentCache.java","status":"renamed","additions":34,"deletions":19,"changes":53,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FPerStreamLogSegmentCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FPerStreamLogSegmentCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FPerStreamLogSegmentCache.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -17,6 +17,7 @@\n  */\n package com.twitter.distributedlog.logsegment;\n \n+import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.Sets;\n import com.twitter.distributedlog.DistributedLogConstants;\n import com.twitter.distributedlog.LogSegmentMetadata;\n@@ -45,18 +46,26 @@\n  * to change if we change the behavior\n  * </p>\n  */\n-public class LogSegmentCache {\n+public class PerStreamLogSegmentCache {\n \n-    static final Logger LOG = LoggerFactory.getLogger(LogSegmentCache.class);\n+    static final Logger LOG = LoggerFactory.getLogger(PerStreamLogSegmentCache.class);\n \n     protected final String streamName;\n+    protected final boolean validateLogSegmentSequenceNumber;\n     protected final Map<String, LogSegmentMetadata> logSegments =\n             new HashMap<String, LogSegmentMetadata>();\n     protected final ConcurrentMap<Long, LogSegmentMetadata> lid2LogSegments =\n             new ConcurrentHashMap<Long, LogSegmentMetadata>();\n \n-    public LogSegmentCache(String streamName) {\n+    @VisibleForTesting\n+    PerStreamLogSegmentCache(String streamName) {\n+        this(streamName, true);\n+    }\n+\n+    public PerStreamLogSegmentCache(String streamName,\n+                                    boolean validateLogSegmentSequenceNumber) {\n         this.streamName = streamName;\n+        this.validateLogSegmentSequenceNumber = validateLogSegmentSequenceNumber;\n     }\n \n     /**\n@@ -79,25 +88,30 @@ public List<LogSegmentMetadata> getLogSegments(Comparator<LogSegmentMetadata> co\n             segmentsToReturn.addAll(logSegments.values());\n         }\n         Collections.sort(segmentsToReturn, LogSegmentMetadata.COMPARATOR);\n-        long startSequenceId = DistributedLogConstants.UNASSIGNED_SEQUENCE_ID;\n+\n         LogSegmentMetadata prevSegment = null;\n-        for (int i = 0; i < segmentsToReturn.size(); i++) {\n-            LogSegmentMetadata segment = segmentsToReturn.get(i);\n-\n-            // validation on ledger sequence number\n-            // - we are ok that if there are same log segments exist. it is just same log segment in different\n-            //   states (inprogress vs completed). it could happen during completing log segment without transaction\n-            if (null != prevSegment\n-                    && prevSegment.getVersion() >= LogSegmentMetadata.LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO.value\n-                    && segment.getVersion() >= LogSegmentMetadata.LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO.value\n-                    && prevSegment.getLogSegmentSequenceNumber() != segment.getLogSegmentSequenceNumber()\n-                    && prevSegment.getLogSegmentSequenceNumber() + 1 != segment.getLogSegmentSequenceNumber()) {\n-                LOG.error(\"{} found ledger sequence number gap between log segment {} and {}\",\n-                        new Object[] { streamName, prevSegment, segment });\n-                throw new UnexpectedException(streamName + \" found ledger sequence number gap between log segment \"\n-                        + prevSegment.getLogSegmentSequenceNumber() + \" and \" + segment.getLogSegmentSequenceNumber());\n+        if (validateLogSegmentSequenceNumber) {\n+            // validation ledger sequence number to ensure the log segments are unique.\n+            for (int i = 0; i < segmentsToReturn.size(); i++) {\n+                LogSegmentMetadata segment = segmentsToReturn.get(i);\n+\n+                if (null != prevSegment\n+                        && prevSegment.getVersion() >= LogSegmentMetadata.LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO.value\n+                        && segment.getVersion() >= LogSegmentMetadata.LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO.value\n+                        && prevSegment.getLogSegmentSequenceNumber() + 1 != segment.getLogSegmentSequenceNumber()) {\n+                    LOG.error(\"{} found ledger sequence number gap between log segment {} and {}\",\n+                            new Object[] { streamName, prevSegment, segment });\n+                    throw new UnexpectedException(streamName + \" found ledger sequence number gap between log segment \"\n+                            + prevSegment.getLogSegmentSequenceNumber() + \" and \" + segment.getLogSegmentSequenceNumber());\n+                }\n+                prevSegment = segment;\n             }\n+        }\n \n+        prevSegment = null;\n+        long startSequenceId = DistributedLogConstants.UNASSIGNED_SEQUENCE_ID;\n+        for (int i = 0; i < segmentsToReturn.size(); i++) {\n+                LogSegmentMetadata segment = segmentsToReturn.get(i);\n             // assign sequence id\n             if (!segment.isInProgress()) {\n                 if (segment.supportsSequenceId()) {\n@@ -117,6 +131,7 @@ public List<LogSegmentMetadata> getLogSegments(Comparator<LogSegmentMetadata> co\n                             .build();\n                     segmentsToReturn.set(i, newSegment);\n                 }\n+\n                 break;\n             }\n             prevSegment = segment;","previous_filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentCache.java"},{"sha":"9ba8ca44fbc6fed8fa60cfc96dbb19cb939c98a5","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadWorker.java","status":"modified","additions":84,"deletions":87,"changes":171,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -24,21 +24,23 @@\n import com.twitter.distributedlog.BKLogHandler;\n import com.twitter.distributedlog.DLSN;\n import com.twitter.distributedlog.DistributedLogConfiguration;\n-import com.twitter.distributedlog.DistributedLogConstants;\n import com.twitter.distributedlog.LedgerDescriptor;\n import com.twitter.distributedlog.LedgerHandleCache;\n import com.twitter.distributedlog.LedgerReadPosition;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n import com.twitter.distributedlog.exceptions.LogReadException;\n import com.twitter.distributedlog.LogSegmentMetadata;\n import com.twitter.distributedlog.ReadAheadCache;\n-import com.twitter.distributedlog.ZooKeeperClient;\n+import com.twitter.distributedlog.callback.LogSegmentListener;\n import com.twitter.distributedlog.callback.ReadAheadCallback;\n import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForReader;\n import com.twitter.distributedlog.injector.AsyncFailureInjector;\n import com.twitter.distributedlog.io.AsyncCloseable;\n+import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.OrderedScheduler;\n@@ -55,10 +57,8 @@\n import org.apache.bookkeeper.stats.OpStatsLogger;\n import org.apache.bookkeeper.stats.StatsLogger;\n import org.apache.bookkeeper.util.MathUtils;\n+import org.apache.bookkeeper.versioning.Versioned;\n import org.apache.commons.lang3.tuple.Pair;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.WatchedEvent;\n-import org.apache.zookeeper.Watcher;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import scala.Function1;\n@@ -97,7 +97,7 @@\n  * Exceptions Handling Phase: Handle all the exceptions and properly schedule next readahead request.\n  * </p>\n  */\n-public class ReadAheadWorker implements ReadAheadCallback, Runnable, Watcher, AsyncCloseable {\n+public class ReadAheadWorker implements ReadAheadCallback, Runnable, AsyncCloseable, LogSegmentListener {\n \n     private static final Logger LOG = LoggerFactory.getLogger(ReadAheadWorker.class);\n \n@@ -115,7 +115,6 @@ public class ReadAheadWorker implements ReadAheadCallback, Runnable, Watcher, As\n     protected final AsyncNotification notification;\n \n     // resources\n-    private final ZooKeeperClient zkc;\n     protected final OrderedScheduler scheduler;\n     private final LedgerHandleCache handleCache;\n     private final ReadAheadCache readAheadCache;\n@@ -144,22 +143,20 @@ public class ReadAheadWorker implements ReadAheadCallback, Runnable, Watcher, As\n     // LogSegments & Metadata Notification\n     //\n \n-    // variables related to getting log segments from zookeeper\n-    volatile boolean zkNotificationDisabled = false;\n-    private final Watcher getLedgersWatcher;\n-\n     // variables related to zookeeper watcher notification to interrupt long poll waits\n     final Object notificationLock = new Object();\n     AsyncNotification metadataNotification = null;\n     volatile long metadataNotificationTimeMillis = -1L;\n \n     // variables related to log segments\n     private volatile boolean reInitializeMetadata = true;\n+    private volatile boolean forceReadLogSegments = false;\n     volatile boolean inProgressChanged = false;\n     private LogSegmentMetadata currentMetadata = null;\n     private int currentMetadataIndex;\n     protected LedgerDescriptor currentLH;\n-    private volatile List<LogSegmentMetadata> ledgerList;\n+    private volatile List<LogSegmentMetadata> logSegmentListNotified;\n+    private volatile List<LogSegmentMetadata> logSegmentList;\n \n     //\n     // ReadAhead Phases\n@@ -208,7 +205,6 @@ public ReadAheadWorker(DistributedLogConfiguration conf,\n                            DynamicDistributedLogConfiguration dynConf,\n                            ZKLogMetadataForReader logMetadata,\n                            BKLogHandler ledgerManager,\n-                           ZooKeeperClient zkc,\n                            OrderedScheduler scheduler,\n                            LedgerHandleCache handleCache,\n                            LedgerReadPosition startPosition,\n@@ -229,16 +225,14 @@ public ReadAheadWorker(DistributedLogConfiguration conf,\n         this.isHandleForReading = isHandleForReading;\n         this.notification = notification;\n         // Resources\n-        this.zkc = zkc;\n         this.scheduler = scheduler;\n         this.handleCache = handleCache;\n         this.readAheadCache = readAheadCache;\n         // Readahead status\n         this.startReadPosition = new LedgerReadPosition(startPosition);\n         this.nextReadAheadPosition = new LedgerReadPosition(startPosition);\n         // LogSegments\n-        this.getLedgersWatcher = this.zkc.getWatcherManager()\n-                .registerChildWatcher(logMetadata.getLogSegmentsPath(), this);\n+\n         // Failure Detection\n         this.failureInjector = failureInjector;\n         // Tracing\n@@ -283,12 +277,12 @@ public LedgerDescriptor getCurrentLedgerDescriptor() {\n     // ReadAhead Status\n     //\n \n-    void setReadAheadError(ReadAheadTracker tracker) {\n+    void setReadAheadError(ReadAheadTracker tracker, Throwable cause) {\n         LOG.error(\"Read Ahead for {} is set to error.\", logMetadata.getFullyQualifiedName());\n         readAheadError = true;\n         tracker.enterPhase(ReadAheadPhase.ERROR);\n         if (null != notification) {\n-            notification.notifyOnError();\n+            notification.notifyOnError(cause);\n         }\n         if (null != stopPromise) {\n             FutureUtils.setValue(stopPromise, null);\n@@ -299,7 +293,8 @@ void setReadAheadInterrupted(ReadAheadTracker tracker) {\n         readAheadInterrupted = true;\n         tracker.enterPhase(ReadAheadPhase.INTERRUPTED);\n         if (null != notification) {\n-            notification.notifyOnError();\n+            notification.notifyOnError(new DLInterruptedException(\"ReadAhead worker for \"\n+                    + bkLedgerManager.getFullyQualifiedName() + \" is interrupted.\"));\n         }\n         if (null != stopPromise) {\n             FutureUtils.setValue(stopPromise, null);\n@@ -310,7 +305,9 @@ void setReadingFromTruncated(ReadAheadTracker tracker) {\n         readingFromTruncated = true;\n         tracker.enterPhase(ReadAheadPhase.TRUNCATED);\n         if (null != notification) {\n-            notification.notifyOnError();\n+            notification.notifyOnError(\n+                    new AlreadyTruncatedTransactionException(logMetadata.getFullyQualifiedName()\n+                            + \": Trying to position read ahead to a segment that is marked truncated\"));\n         }\n         if (null != stopPromise) {\n             FutureUtils.setValue(stopPromise, null);\n@@ -347,9 +344,11 @@ public boolean isCaughtUp() {\n         return !isCatchingUp;\n     }\n \n-    public void start() {\n-        LOG.debug(\"Starting ReadAhead Worker for {}\", fullyQualifiedName);\n+    public void start(List<LogSegmentMetadata> segmentList) {\n+        LOG.debug(\"Starting ReadAhead Worker for {} : segments = {}\",\n+                fullyQualifiedName, segmentList);\n         running = true;\n+        logSegmentListNotified = segmentList;\n         schedulePhase.process(BKException.Code.OK);\n     }\n \n@@ -358,9 +357,6 @@ public Future<Void> asyncClose() {\n         LOG.info(\"Stopping Readahead worker for {}\", fullyQualifiedName);\n         running = false;\n \n-        this.zkc.getWatcherManager()\n-                .unregisterChildWatcher(this.logMetadata.getLogSegmentsPath(), this, true);\n-\n         // Aside from unfortunate naming of variables, this allows\n         // the currently active long poll to be interrupted and completed\n         AsyncNotification notification;\n@@ -417,7 +413,7 @@ public void run() {\n                 } catch (RuntimeException rte) {\n                     LOG.error(\"ReadAhead on stream {} encountered runtime exception\",\n                             logMetadata.getFullyQualifiedName(), rte);\n-                    setReadAheadError(tracker);\n+                    setReadAheadError(tracker, rte);\n                     throw rte;\n                 }\n             }\n@@ -455,7 +451,7 @@ void submit(Runnable runnable) {\n         try {\n             scheduler.submit(addRTEHandler(runnable));\n         } catch (RejectedExecutionException ree) {\n-            setReadAheadError(tracker);\n+            setReadAheadError(tracker, ree);\n         }\n     }\n \n@@ -470,7 +466,7 @@ private void schedule(Runnable runnable, long timeInMillis) {\n             scheduler.schedule(addRTEHandler(task), timeInMillis, TimeUnit.MILLISECONDS);\n             readAheadWorkerWaits.inc();\n         } catch (RejectedExecutionException ree) {\n-            setReadAheadError(tracker);\n+            setReadAheadError(tracker, ree);\n         }\n     }\n \n@@ -533,12 +529,14 @@ void process(int rc) {\n                     LOG.error(\"{} : BookKeeper Client used by the ReadAhead Thread has encountered {} zookeeper exceptions : simulate = {}\",\n                               new Object[] { fullyQualifiedName, bkcZkExceptions.get(), injectErrors });\n                     running = false;\n-                    setReadAheadError(tracker);\n+                    setReadAheadError(tracker, new LogReadException(\n+                            \"Encountered too many zookeeper issues on read ahead for \" + bkLedgerManager.getFullyQualifiedName()));\n                 } else if (bkcUnExpectedExceptions.get() > BKC_UNEXPECTED_EXCEPTION_THRESHOLD) {\n                     LOG.error(\"{} : ReadAhead Thread has encountered {} unexpected BK exceptions.\",\n                               fullyQualifiedName, bkcUnExpectedExceptions.get());\n                     running = false;\n-                    setReadAheadError(tracker);\n+                    setReadAheadError(tracker, new LogReadException(\n+                            \"Encountered too many unexpected bookkeeper issues on read ahead for \" + bkLedgerManager.getFullyQualifiedName()));\n                 } else {\n                     // We must always reinitialize metadata if the last attempt to read failed.\n                     reInitializeMetadata = true;\n@@ -629,39 +627,21 @@ void process(int rc) {\n      * Phase on checking in progress changed.\n      */\n     final class CheckInProgressChangedPhase extends Phase\n-        implements BookkeeperInternalCallbacks.GenericCallback<List<LogSegmentMetadata>> {\n+            implements FutureEventListener<Versioned<List<LogSegmentMetadata>>> {\n \n         CheckInProgressChangedPhase(Phase next) {\n             super(next);\n         }\n \n-        @Override\n-        public void operationComplete(final int rc, final List<LogSegmentMetadata> result) {\n+        void processLogSegments(final List<LogSegmentMetadata> segments) {\n             // submit callback execution to dlg executor to avoid deadlock.\n             submit(new Runnable() {\n                 @Override\n                 public void run() {\n-                    if (KeeperException.Code.OK.intValue() != rc) {\n-                        if (KeeperException.Code.NONODE.intValue() == rc) {\n-                            LOG.info(\"Log {} has been deleted. Set ReadAhead to error to stop reading.\",\n-                                    logMetadata.getFullyQualifiedName());\n-                            logDeleted = true;\n-                            setReadAheadError(tracker);\n-                            return;\n-                        }\n-                        LOG.info(\"ZK Exception {} while reading ledger list\", rc);\n-                        reInitializeMetadata = true;\n-                        if (DistributedLogConstants.DL_INTERRUPTED_EXCEPTION_RESULT_CODE == rc) {\n-                            handleException(ReadAheadPhase.GET_LEDGERS, BKException.Code.InterruptedException);\n-                        } else {\n-                            handleException(ReadAheadPhase.GET_LEDGERS, BKException.Code.ZKException);\n-                        }\n-                        return;\n-                    }\n-                    ledgerList = result;\n+                    logSegmentList = segments;\n                     boolean isInitialPositioning = nextReadAheadPosition.definitelyLessThanOrEqualTo(startReadPosition);\n-                    for (int i = 0; i < ledgerList.size(); i++) {\n-                        LogSegmentMetadata l = ledgerList.get(i);\n+                    for (int i = 0; i < logSegmentList.size(); i++) {\n+                        LogSegmentMetadata l = logSegmentList.get(i);\n                         // By default we should skip truncated segments during initial positioning\n                         if (l.isTruncated() &&\n                             isInitialPositioning &&\n@@ -820,11 +800,34 @@ void process(int rc) {\n                             TimeUnit.MILLISECONDS.toMicros(elapsedMillisSinceMetadataChanged));\n                     metadataNotificationTimeMillis = -1L;\n                 }\n-                bkLedgerManager.asyncGetLedgerList(LogSegmentMetadata.COMPARATOR, getLedgersWatcher, this);\n+                if (forceReadLogSegments) {\n+                    forceReadLogSegments = false;\n+                    bkLedgerManager.readLogSegmentsFromStore(\n+                            LogSegmentMetadata.COMPARATOR,\n+                            LogSegmentFilter.DEFAULT_FILTER,\n+                            null\n+                    ).addEventListener(this);\n+                } else {\n+                    processLogSegments(logSegmentListNotified);\n+                }\n             } else {\n                 next.process(BKException.Code.OK);\n             }\n         }\n+\n+        @Override\n+        public void onSuccess(Versioned<List<LogSegmentMetadata>> segments) {\n+            processLogSegments(segments.getValue());\n+        }\n+\n+        @Override\n+        public void onFailure(Throwable cause) {\n+            LOG.info(\"Encountered metadata exception while reading log segments of {} : {}. Retrying ...\",\n+                    bkLedgerManager.getFullyQualifiedName(), cause.getMessage());\n+            reInitializeMetadata = true;\n+            forceReadLogSegments = true;\n+            handleException(ReadAheadPhase.GET_LEDGERS, BKException.Code.ZKException);\n+        }\n     }\n \n     final class OpenLedgerPhase extends Phase\n@@ -922,6 +925,7 @@ public void onFailure(Throwable cause) {\n                                     LOG.info(\"{} Ledger {} for inprogress segment {} closed for idle reader warn threshold\",\n                                         new Object[] { fullyQualifiedName, currentMetadata, currentLH });\n                                     reInitializeMetadata = true;\n+                                    forceReadLogSegments = true;\n                                 }\n                             } else {\n                                 lastLedgerCloseDetected.reset().start();\n@@ -986,7 +990,9 @@ public void onFailure(Throwable cause) {\n                                 }\n \n                                 if (conf.getPositionGapDetectionEnabled() && gapDetected) {\n-                                    setReadAheadError(tracker);\n+                                    setReadAheadError(tracker, new UnexpectedException(\n+                                            \"Unexpected last entry id during read ahead : \" + currentMetadata\n+                                                    + \", lac = \" + lastAddConfirmed));\n                                 } else {\n                                     // This disconnect will only surface during repositioning and\n                                     // will not silently miss records; therefore its safe to not halt\n@@ -1003,14 +1009,16 @@ public void onFailure(Throwable cause) {\n                                     }\n                                     LogSegmentMetadata oldMetadata = currentMetadata;\n                                     currentMetadata = null;\n-                                    if (currentMetadataIndex + 1 < ledgerList.size()) {\n-                                        currentMetadata = ledgerList.get(++currentMetadataIndex);\n+                                    if (currentMetadataIndex + 1 < logSegmentList.size()) {\n+                                        currentMetadata = logSegmentList.get(++currentMetadataIndex);\n                                         if (currentMetadata.getLogSegmentSequenceNumber() != (oldMetadata.getLogSegmentSequenceNumber() + 1)) {\n                                             // We should never get here as we should have exited the loop if\n                                             // pendingRequests were empty\n                                             alertStatsLogger.raise(\"Unexpected condition during read ahead; {} , {}\",\n                                                 currentMetadata, oldMetadata);\n-                                            setReadAheadError(tracker);\n+                                            setReadAheadError(tracker, new UnexpectedException(\n+                                                    \"Unexpected condition during read ahead : current metadata \"\n+                                                            + currentMetadata + \", old metadata \" + oldMetadata));\n                                         } else {\n                                             if (currentMetadata.isTruncated()) {\n                                                 if (conf.getAlertWhenPositioningOnTruncated()) {\n@@ -1345,37 +1353,26 @@ public void run() {\n     }\n \n     @Override\n-    public void process(WatchedEvent event) {\n-        if (zkNotificationDisabled) {\n-            return;\n+    public void onSegmentsUpdated(List<LogSegmentMetadata> segments) {\n+        AsyncNotification notification;\n+        synchronized (notificationLock) {\n+            logSegmentListNotified = segments;\n+            reInitializeMetadata = true;\n+            LOG.debug(\"{} Read ahead node changed\", fullyQualifiedName);\n+            notification = metadataNotification;\n+            metadataNotification = null;\n         }\n-\n-        if ((event.getType() == Watcher.Event.EventType.None)\n-                && (event.getState() == Watcher.Event.KeeperState.SyncConnected)) {\n-            LOG.debug(\"Reconnected ...\");\n-        } else if (((event.getType() == Event.EventType.None) && (event.getState() == Event.KeeperState.Expired)) ||\n-                   ((event.getType() == Event.EventType.NodeChildrenChanged))) {\n-            AsyncNotification notification;\n-            synchronized (notificationLock) {\n-                reInitializeMetadata = true;\n-                LOG.debug(\"{} Read ahead node changed\", fullyQualifiedName);\n-                notification = metadataNotification;\n-                metadataNotification = null;\n-            }\n-            metadataNotificationTimeMillis = System.currentTimeMillis();\n-            if (null != notification) {\n-                notification.notifyOnOperationComplete();\n-            }\n-        } else if (event.getType() == Event.EventType.NodeDeleted) {\n-            logDeleted = true;\n-            setReadAheadError(tracker);\n+        metadataNotificationTimeMillis = System.currentTimeMillis();\n+        if (null != notification) {\n+            notification.notifyOnOperationComplete();\n         }\n     }\n \n-    @VisibleForTesting\n-    public void disableZKNotification() {\n-        LOG.info(\"{} ZK Notification was disabled\", fullyQualifiedName);\n-        zkNotificationDisabled = true;\n+    @Override\n+    public void onLogStreamDeleted() {\n+        logDeleted = true;\n+        setReadAheadError(tracker, new LogNotFoundException(\"Log stream \"\n+                + bkLedgerManager.getFullyQualifiedName() + \" is deleted.\"));\n     }\n \n     /**\n@@ -1424,7 +1421,7 @@ class InterruptibleScheduledRunnable implements AsyncNotification, Runnable {\n         }\n \n         @Override\n-        public void notifyOnError() {\n+        public void notifyOnError(Throwable t) {\n             longPollInterruptionStat.registerFailedEvent(MathUtils.elapsedMicroSec(startNanos));\n             execute();\n         }\n@@ -1477,7 +1474,7 @@ void complete(boolean success) {\n         abstract void doComplete(boolean success);\n \n         @Override\n-        public void notifyOnError() {\n+        public void notifyOnError(Throwable cause) {\n             longPollInterruptionStat.registerFailedEvent(MathUtils.elapsedMicroSec(startNanos));\n             complete(false);\n         }"},{"sha":"6a647a9c46049b58a72262bb0da40443e9606dc6","filename":"src/main/java/com/twitter/distributedlog/util/FutureUtils.java","status":"modified","additions":3,"deletions":2,"changes":5,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFutureUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFutureUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFutureUtils.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -343,9 +343,10 @@ public static <T> T lockResult(Future<T> result, String lockPath) throws Locking\n      */\n     public static Throwable zkException(Throwable throwable, String path) {\n         if (throwable instanceof KeeperException) {\n-            return throwable;\n+            return new ZKException(\"Encountered zookeeper exception on \" + path, (KeeperException) throwable);\n         } else if (throwable instanceof ZooKeeperClient.ZooKeeperConnectionException) {\n-            return KeeperException.create(KeeperException.Code.CONNECTIONLOSS, path);\n+            return new ZKException(\"Encountered zookeeper connection loss on \" + path,\n+                    KeeperException.Code.CONNECTIONLOSS);\n         } else if (throwable instanceof InterruptedException) {\n             return new DLInterruptedException(\"Interrupted on operating \" + path, throwable);\n         } else {"},{"sha":"c588cd72a8749439f7df05cfe3b870b8401b1f22","filename":"src/test/java/com/twitter/distributedlog/DLMTestUtil.java","status":"modified","additions":10,"deletions":2,"changes":12,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -18,6 +18,7 @@\n package com.twitter.distributedlog;\n \n import com.twitter.distributedlog.impl.BKLogSegmentEntryWriter;\n+import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.metadata.BKDLConfig;\n import com.twitter.distributedlog.metadata.DLMetadata;\n import com.twitter.distributedlog.namespace.DistributedLogNamespace;\n@@ -185,7 +186,12 @@ public static void fenceStream(DistributedLogConfiguration conf, URI uri, String\n         BKDistributedLogManager dlm = (BKDistributedLogManager) createNewDLM(name, conf, uri);\n         try {\n             BKLogReadHandler readHandler = dlm.createReadHandler();\n-            List<LogSegmentMetadata> ledgerList = readHandler.getFullLedgerList(true, true);\n+            List<LogSegmentMetadata> ledgerList = FutureUtils.result(\n+                    readHandler.readLogSegmentsFromStore(\n+                            LogSegmentMetadata.COMPARATOR,\n+                            LogSegmentFilter.DEFAULT_FILTER,\n+                            null)\n+            ).getValue();\n             LogSegmentMetadata lastSegment = ledgerList.get(ledgerList.size() - 1);\n             BookKeeperClient bkc = dlm.getWriterBKC();\n             LedgerHandle lh = bkc.get().openLedger(lastSegment.getLedgerId(),\n@@ -415,10 +421,12 @@ public static void injectLogSegmentWithGivenLogSegmentSeqNo(DistributedLogManage\n                 conf.getAckQuorumSize(), BookKeeper.DigestType.CRC32, conf.getBKDigestPW().getBytes());\n         String inprogressZnodeName = writeHandler.inprogressZNodeName(lh.getId(), startTxID, logSegmentSeqNo);\n         String znodePath = writeHandler.inprogressZNode(lh.getId(), startTxID, logSegmentSeqNo);\n+        int logSegmentMetadataVersion = conf.getDLLedgerMetadataLayoutVersion();\n         LogSegmentMetadata l =\n             new LogSegmentMetadata.LogSegmentMetadataBuilder(znodePath,\n-                    conf.getDLLedgerMetadataLayoutVersion(), lh.getId(), startTxID)\n+                    logSegmentMetadataVersion, lh.getId(), startTxID)\n                 .setLogSegmentSequenceNo(logSegmentSeqNo)\n+                .setEnvelopeEntries(LogSegmentMetadata.supportsEnvelopedEntries(logSegmentMetadataVersion))\n                 .build();\n         l.write(dlm.writerZKC);\n         writeHandler.maxTxId.store(startTxID);"},{"sha":"fb69c8d996f233043bac367621b4230af0977c7c","filename":"src/test/java/com/twitter/distributedlog/NonBlockingReadsTestUtil.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FNonBlockingReadsTestUtil.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FNonBlockingReadsTestUtil.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FNonBlockingReadsTestUtil.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -65,7 +65,7 @@ static void readNonBlocking(DistributedLogManager dlm,\n         try {\n             LOG.info(\"Created reader reading from {}\", dlm.getStreamName());\n             if (forceStall) {\n-                reader.disableReadAheadZKNotification();\n+                reader.disableReadAheadLogSegmentsNotification();\n             }\n \n             long numTrans = 0;"},{"sha":"0c7f346b7c7412a5cfe7bd5128d4d170e99cd7e3","filename":"src/test/java/com/twitter/distributedlog/TestAsyncReaderWriter.java","status":"modified","additions":12,"deletions":4,"changes":16,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -86,6 +86,7 @@ public TestAsyncReaderWriter() {\n         this.testConf = new DistributedLogConfiguration();\n         this.testConf.loadConf(conf);\n         this.testConf.setReaderIdleErrorThresholdMillis(1200000);\n+        this.testConf.setReadAheadWaitTimeOnEndOfStream(20);\n     }\n \n     @Rule\n@@ -816,7 +817,8 @@ public void testSimpleAsyncReadWriteStartEmpty() throws Exception {\n     @Ignore\n     @Test(timeout = 120000)\n     public void testSimpleAsyncReadWriteStartEmptyFactory() throws Exception {\n-        int count = 50;\n+        // int count = 50;\n+        int count = 1;\n         String name = runtime.getMethodName();\n         DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n         confLocal.loadConf(testConf);\n@@ -1484,9 +1486,8 @@ public void testReleaseLockAfterFailedToRecover() throws Exception {\n     }\n \n     @DistributedLogAnnotations.FlakyTest\n-    @Ignore\n     @Test(timeout = 60000)\n-    public void testAsyncReadMissingZKNotification() throws Exception {\n+    public void testAsyncReadMissingLogSegmentsNotification() throws Exception {\n         String name = \"distrlog-async-reader-missing-zk-notification\";\n         DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n         confLocal.loadConf(testConf);\n@@ -1501,6 +1502,7 @@ public void testAsyncReadMissingZKNotification() throws Exception {\n         final int segmentSize = 10;\n         final int numSegments = 3;\n         final CountDownLatch latch = new CountDownLatch(1);\n+        final CountDownLatch readLatch = new CountDownLatch(1);\n         final ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(1);\n         executor.schedule(\n                 new Runnable() {\n@@ -1515,6 +1517,9 @@ public void run() {\n                                     writer.write(DLMTestUtil.getLargeLogRecordInstance(txid++));\n                                     if ((i == 0) && (j == 1)) {\n                                         latch.countDown();\n+                                    } else {\n+                                        // wait for reader to start\n+                                        readLatch.await();\n                                     }\n                                 }\n                                 writer.closeAndComplete();\n@@ -1530,13 +1535,16 @@ public void run() {\n \n         latch.await();\n         BKAsyncLogReaderDLSN reader = (BKAsyncLogReaderDLSN)dlm.getAsyncLogReader(DLSN.InitialDLSN);\n-        reader.disableReadAheadZKNotification();\n+        reader.disableReadAheadLogSegmentsNotification();\n         boolean exceptionEncountered = false;\n         int recordCount = 0;\n         try {\n             while (true) {\n                 Future<LogRecordWithDLSN> record = reader.readNext();\n                 Await.result(record);\n+                if (recordCount == 0) {\n+                    readLatch.countDown();\n+                }\n                 recordCount++;\n \n                 if (recordCount >= segmentSize * numSegments) {"},{"sha":"6ad99506f09aa7afbfe6003dac6d867e10785917","filename":"src/test/java/com/twitter/distributedlog/TestBKDistributedLogManager.java","status":"modified","additions":12,"deletions":5,"changes":17,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -979,13 +979,18 @@ public void onSegmentsUpdated(List<LogSegmentMetadata> segments) {\n                     return;\n                 }\n                 if (updates >= 1) {\n-                    if (segments.get(0).getLogSegmentSequenceNumber() != updates) {\n+                    if (segments.get(segments.size() - 1).getLogSegmentSequenceNumber() != updates) {\n                         numFailures.incrementAndGet();\n                     }\n                 }\n                 receivedStreams.set(segments);\n                 latches[updates].countDown();\n             }\n+\n+            @Override\n+            public void onLogStreamDeleted() {\n+                // no-op\n+            }\n         });\n         LOG.info(\"Registered listener for stream {}.\", name);\n         long txid = 1;\n@@ -1006,12 +1011,12 @@ public void onSegmentsUpdated(List<LogSegmentMetadata> segments) {\n         assertEquals(0, numFailures.get());\n         assertNotNull(receivedStreams.get());\n         assertEquals(numSegments, receivedStreams.get().size());\n-        int seqno = numSegments;\n+        int seqno = 1;\n         for (LogSegmentMetadata m : receivedStreams.get()) {\n             assertEquals(seqno, m.getLogSegmentSequenceNumber());\n             assertEquals((seqno - 1) * DEFAULT_SEGMENT_SIZE + 1, m.getFirstTxId());\n             assertEquals(seqno * DEFAULT_SEGMENT_SIZE, m.getLastTxId());\n-            --seqno;\n+            ++seqno;\n         }\n     }\n \n@@ -1122,6 +1127,7 @@ public void testTruncationValidation() throws Exception {\n         confLocal.loadConf(conf);\n         confLocal.setDLLedgerMetadataLayoutVersion(LogSegmentMetadata.LEDGER_METADATA_CURRENT_LAYOUT_VERSION);\n         confLocal.setOutputBufferSize(0);\n+        confLocal.setLogSegmentCacheEnabled(false);\n \n         LogSegmentMetadataStore metadataStore = new ZKLogSegmentMetadataStore(confLocal, zookeeperClient, scheduler);\n \n@@ -1174,7 +1180,8 @@ public void testTruncationValidation() throws Exception {\n         {\n             LogReader reader = dlm.getInputStream(DLSN.InitialDLSN);\n             LogRecordWithDLSN record = reader.readNext(false);\n-            assertTrue((record != null) && (record.getDlsn().compareTo(new DLSN(2, 0, 0)) == 0));\n+            assertTrue(\"Unexpected record : \" + record,\n+                    (record != null) && (record.getDlsn().compareTo(new DLSN(2, 0, 0)) == 0));\n             reader.close();\n         }\n \n@@ -1225,7 +1232,7 @@ public void testTruncationValidation() throws Exception {\n         BKAsyncLogWriter writer = dlm.startAsyncLogSegmentNonPartitioned();\n         Assert.assertTrue(Await.result(writer.truncate(truncDLSN)));\n         BKLogWriteHandler handler = writer.getCachedWriteHandler();\n-        List<LogSegmentMetadata> cachedSegments = handler.getFullLedgerList(false, false);\n+        List<LogSegmentMetadata> cachedSegments = handler.getCachedLogSegments(LogSegmentMetadata.COMPARATOR);\n         for (LogSegmentMetadata segment: cachedSegments) {\n             if (segment.getLastDLSN().compareTo(truncDLSN) < 0) {\n                 Assert.assertTrue(segment.isTruncated());"},{"sha":"4b17500dc75c3b140a53c37f46d9aca6454ee8d6","filename":"src/test/java/com/twitter/distributedlog/TestBKLogReadHandler.java","status":"modified","additions":14,"deletions":75,"changes":89,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogReadHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogReadHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogReadHandler.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -20,6 +20,7 @@\n import com.google.common.base.Optional;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n import com.twitter.distributedlog.exceptions.OwnershipAcquireFailedException;\n+import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.Utils;\n import com.twitter.util.Duration;\n@@ -28,12 +29,9 @@\n \n import java.util.List;\n import java.util.ArrayList;\n-import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.atomic.AtomicReference;\n \n import com.twitter.util.TimeoutException;\n-import org.apache.bookkeeper.proto.BookkeeperInternalCallbacks;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.rules.TestName;\n@@ -88,76 +86,6 @@ private void prepareLogSegmentsNonPartitioned(String name, int numSegments, int\n         dlm.close();\n     }\n \n-    @Test(timeout = 60000)\n-    public void testGetLedgerList() throws Exception {\n-        String dlName = runtime.getMethodName();\n-        prepareLogSegments(dlName, 3, 3);\n-        BKDistributedLogManager dlm = createNewDLM(conf, dlName);\n-        BKLogReadHandler readHandler = dlm.createReadHandler();\n-        List<LogSegmentMetadata> ledgerList = readHandler.getLedgerList(false, false, LogSegmentMetadata.COMPARATOR, false);\n-        List<LogSegmentMetadata> ledgerList2 = readHandler.getFilteredLedgerList(true, false);\n-        List<LogSegmentMetadata> ledgerList3 = readHandler.getLedgerList(false, false, LogSegmentMetadata.COMPARATOR, false);\n-        assertEquals(3, ledgerList.size());\n-        assertEquals(3, ledgerList2.size());\n-        assertEquals(3, ledgerList3.size());\n-        for (int i=0; i<3; i++) {\n-            assertEquals(ledgerList3.get(i), ledgerList2.get(i));\n-        }\n-    }\n-\n-    @Test(timeout = 60000)\n-    public void testForceGetLedgerList() throws Exception {\n-        String dlName = runtime.getMethodName();\n-        prepareLogSegments(dlName, 3, 3);\n-        BKDistributedLogManager dlm = createNewDLM(conf, dlName);\n-        BKLogReadHandler readHandler = dlm.createReadHandler();\n-        List<LogSegmentMetadata> ledgerList = readHandler.getLedgerList(true, false, LogSegmentMetadata.COMPARATOR, false);\n-        final AtomicReference<List<LogSegmentMetadata>> resultHolder =\n-                new AtomicReference<List<LogSegmentMetadata>>(null);\n-        final CountDownLatch latch = new CountDownLatch(1);\n-        readHandler.asyncGetLedgerList(LogSegmentMetadata.COMPARATOR, null, new BookkeeperInternalCallbacks.GenericCallback<List<LogSegmentMetadata>>() {\n-            @Override\n-            public void operationComplete(int rc, List<LogSegmentMetadata> result) {\n-                resultHolder.set(result);\n-                latch.countDown();\n-            }\n-        });\n-        latch.await();\n-        List<LogSegmentMetadata> newLedgerList = resultHolder.get();\n-        assertNotNull(newLedgerList);\n-        LOG.info(\"Force sync get list : {}\", ledgerList);\n-        LOG.info(\"Async get list : {}\", newLedgerList);\n-        assertEquals(3, ledgerList.size());\n-        assertEquals(3, newLedgerList.size());\n-        for (int i=0; i<3; i++) {\n-            assertEquals(ledgerList.get(i), newLedgerList.get(i));\n-        }\n-    }\n-\n-    @Test(timeout = 60000)\n-    public void testGetFilteredLedgerListInWriteHandler() throws Exception {\n-        String dlName = runtime.getMethodName();\n-        prepareLogSegments(dlName, 11, 3);\n-        BKDistributedLogManager dlm = createNewDLM(conf, dlName);\n-\n-        // Get full list.\n-        BKLogWriteHandler writeHandler0 = dlm.createWriteHandler(false);\n-        List<LogSegmentMetadata> cachedFullLedgerList =\n-                writeHandler0.getCachedLogSegments(LogSegmentMetadata.DESC_COMPARATOR);\n-        assertTrue(cachedFullLedgerList.size() <= 1);\n-        List<LogSegmentMetadata> fullLedgerList = writeHandler0.getFullLedgerListDesc(false, false);\n-        assertEquals(11, fullLedgerList.size());\n-\n-        // Get filtered list.\n-        BKLogWriteHandler writeHandler1 = dlm.createWriteHandler(false);\n-        List<LogSegmentMetadata> filteredLedgerListDesc = writeHandler1.getFilteredLedgerListDesc(false, false);\n-        assertEquals(1, filteredLedgerListDesc.size());\n-        assertEquals(fullLedgerList.get(0), filteredLedgerListDesc.get(0));\n-        List<LogSegmentMetadata> filteredLedgerList = writeHandler1.getFilteredLedgerList(false, false);\n-        assertEquals(1, filteredLedgerList.size());\n-        assertEquals(fullLedgerList.get(0), filteredLedgerList.get(0));\n-    }\n-\n     @Test(timeout = 60000)\n     public void testGetFirstDLSNWithOpenLedger() throws Exception {\n         String dlName = runtime.getMethodName();\n@@ -362,7 +290,13 @@ public void testGetLogRecordCountWithSingleInProgressLedger() throws Exception {\n         Await.result(out.write(DLMTestUtil.getLargeLogRecordInstance(txid++, false)));\n \n         BKLogReadHandler readHandler = bkdlm.createReadHandler();\n-        List<LogSegmentMetadata> ledgerList = readHandler.getLedgerList(false, false, LogSegmentMetadata.COMPARATOR, false);\n+        List<LogSegmentMetadata> ledgerList = FutureUtils.result(\n+                readHandler.readLogSegmentsFromStore(\n+                        LogSegmentMetadata.COMPARATOR,\n+                        LogSegmentFilter.DEFAULT_FILTER,\n+                        null\n+                )\n+        ).getValue();\n         assertEquals(1, ledgerList.size());\n         assertTrue(ledgerList.get(0).isInProgress());\n \n@@ -386,7 +320,12 @@ public void testGetLogRecordCountWithCompletedAndInprogressLedgers() throws Exce\n         Await.result(out.write(DLMTestUtil.getLargeLogRecordInstance(txid++, false)));\n \n         BKLogReadHandler readHandler = bkdlm.createReadHandler();\n-        List<LogSegmentMetadata> ledgerList = readHandler.getLedgerList(false, false, LogSegmentMetadata.COMPARATOR, false);\n+        List<LogSegmentMetadata> ledgerList = FutureUtils.result(\n+                readHandler.readLogSegmentsFromStore(\n+                        LogSegmentMetadata.COMPARATOR,\n+                        LogSegmentFilter.DEFAULT_FILTER,\n+                        null)\n+        ).getValue();\n         assertEquals(2, ledgerList.size());\n         assertFalse(ledgerList.get(0).isInProgress());\n         assertTrue(ledgerList.get(1).isInProgress());"},{"sha":"71b6834ab3c7596e1ca3d0f5156a18b74d0104d4","filename":"src/test/java/com/twitter/distributedlog/TestReadAhead.java","status":"modified","additions":0,"deletions":8,"changes":8,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAhead.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAhead.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAhead.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -139,14 +139,6 @@ public void testReadAheadWaitOnEndOfStream() throws Exception {\n         }\n         Thread.sleep(1000);\n \n-        // Expire the session, so the readahead should be awaken from backoff\n-        ZooKeeperClientUtils.expireSession(reader.bkLedgerManager.zooKeeperClient, zkServers, 1000);\n-        AsyncNotification notification2;\n-        do {\n-            Thread.sleep(200);\n-            notification2 = reader.bkLedgerManager.readAheadWorker.getMetadataNotification();\n-        } while (null == notification2 || notification1 == notification2);\n-\n         // write another record\n         BKSyncLogWriter writer =\n                     (BKSyncLogWriter) dlm.startLogSegmentNonPartitioned();"},{"sha":"998c7ba0fe096214005a095427ff3a86d9559f68","filename":"src/test/java/com/twitter/distributedlog/TestReadUtils.java","status":"modified","additions":7,"deletions":1,"changes":8,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -23,6 +23,7 @@\n \n import com.google.common.base.Optional;\n import com.google.common.collect.Lists;\n+import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.Utils;\n import com.twitter.util.Await;\n@@ -91,7 +92,12 @@ public BoxedUnit apply() {\n \n     private Future<LogRecordWithDLSN> getLastUserRecord(BKDistributedLogManager bkdlm, int ledgerNo) throws Exception {\n         BKLogReadHandler readHandler = bkdlm.createReadHandler();\n-        List<LogSegmentMetadata> ledgerList = readHandler.getLedgerList(false, false, LogSegmentMetadata.COMPARATOR, false);\n+        List<LogSegmentMetadata> ledgerList = FutureUtils.result(\n+                readHandler.readLogSegmentsFromStore(\n+                        LogSegmentMetadata.COMPARATOR,\n+                        LogSegmentFilter.DEFAULT_FILTER,\n+                        null)\n+        ).getValue();\n         final LedgerHandleCache handleCache = LedgerHandleCache.newBuilder()\n                 .bkc(bkdlm.getWriterBKC())\n                 .conf(conf)"},{"sha":"a7dead40b84aa93040ab8371b4bb4b81cb02f64e","filename":"src/test/java/com/twitter/distributedlog/admin/TestDLCK.java","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -99,6 +99,7 @@ public void testCheckAndRepairDLNamespace() throws Exception {\n         confLocal.setImmediateFlushEnabled(true);\n         confLocal.setOutputBufferSize(0);\n         confLocal.setLogSegmentSequenceNumberValidationEnabled(false);\n+        confLocal.setLogSegmentCacheEnabled(false);\n         URI uri = createDLMURI(\"/check-and-repair-dl-namespace\");\n         zkc.get().create(uri.getPath(), new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n         com.twitter.distributedlog.DistributedLogManagerFactory factory ="},{"sha":"66d7228de45dbfa12f601f7831b2b280d061754e","filename":"src/test/java/com/twitter/distributedlog/admin/TestDistributedLogAdmin.java","status":"modified","additions":34,"deletions":27,"changes":61,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDistributedLogAdmin.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDistributedLogAdmin.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDistributedLogAdmin.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -23,6 +23,7 @@\n import com.twitter.distributedlog.DistributedLogConfiguration;\n import com.twitter.distributedlog.TestZooKeeperClientBuilder;\n import com.twitter.distributedlog.annotations.DistributedLogAnnotations;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n import com.twitter.distributedlog.util.Utils;\n import org.apache.zookeeper.CreateMode;\n import org.apache.zookeeper.ZooDefs;\n@@ -46,7 +47,6 @@\n import com.twitter.util.Await;\n import com.twitter.util.Duration;\n import com.twitter.util.Future;\n-import com.twitter.util.TimeoutException;\n \n import static org.junit.Assert.*;\n \n@@ -81,11 +81,19 @@ public void testChangeSequenceNumber() throws Exception {\n         DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n         confLocal.addConfiguration(conf);\n         confLocal.setLogSegmentSequenceNumberValidationEnabled(false);\n+        confLocal.setLogSegmentCacheEnabled(false);\n+\n+        DistributedLogConfiguration readConf = new DistributedLogConfiguration();\n+        readConf.addConfiguration(conf);\n+        readConf.setLogSegmentCacheEnabled(false);\n+        readConf.setLogSegmentSequenceNumberValidationEnabled(true);\n \n         URI uri = createDLMURI(\"/change-sequence-number\");\n         zooKeeperClient.get().create(uri.getPath(), new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n         com.twitter.distributedlog.DistributedLogManagerFactory factory =\n                 new com.twitter.distributedlog.DistributedLogManagerFactory(confLocal, uri);\n+        com.twitter.distributedlog.DistributedLogManagerFactory readFactory =\n+                new com.twitter.distributedlog.DistributedLogManagerFactory(readConf, uri);\n \n         String streamName = \"change-sequence-number\";\n \n@@ -96,61 +104,64 @@ public void testChangeSequenceNumber() throws Exception {\n         dlm.close();\n \n         // create a reader\n-        DistributedLogManager readDLM = factory.createDistributedLogManagerWithSharedClients(streamName);\n+        DistributedLogManager readDLM = readFactory.createDistributedLogManagerWithSharedClients(streamName);\n         AsyncLogReader reader = readDLM.getAsyncLogReader(DLSN.InitialDLSN);\n \n         // read the records\n         long expectedTxId = 1L;\n+        DLSN lastDLSN = DLSN.InitialDLSN;\n         for (int i = 0; i < 4 * 10; i++) {\n-            LogRecord record = Await.result(reader.readNext());\n+            LogRecordWithDLSN record = Await.result(reader.readNext());\n             assertNotNull(record);\n             DLMTestUtil.verifyLogRecord(record);\n             assertEquals(expectedTxId, record.getTransactionId());\n             expectedTxId++;\n+            lastDLSN = record.getDlsn();\n         }\n \n+        LOG.info(\"Injecting bad log segment '3'\");\n+\n         dlm = factory.createDistributedLogManagerWithSharedClients(streamName);\n         DLMTestUtil.injectLogSegmentWithGivenLogSegmentSeqNo(dlm, confLocal, 3L, 5 * 10 + 1, true, 10, false);\n \n-        // Wait for reader to be aware of new log segments\n-        TimeUnit.SECONDS.sleep(2);\n+        LOG.info(\"Injected bad log segment '3'\");\n \n-        DLSN dlsn = readDLM.getLastDLSN();\n-        assertTrue(dlsn.compareTo(new DLSN(5, Long.MIN_VALUE, Long.MIN_VALUE)) < 0);\n-        assertTrue(dlsn.compareTo(new DLSN(4, -1, Long.MIN_VALUE)) > 0);\n         // there isn't records should be read\n         Future<LogRecordWithDLSN> readFuture = reader.readNext();\n         try {\n-            Await.result(readFuture, Duration.fromMilliseconds(1000));\n-            fail(\"Should fail reading next when there is a corrupted log segment\");\n-        } catch (TimeoutException te) {\n+            LogRecordWithDLSN record = Await.result(readFuture);\n+            fail(\"Should fail reading next record \"\n+                    + record\n+                    + \" when there is a corrupted log segment\");\n+        } catch (UnexpectedException ue) {\n             // expected\n         }\n \n+        LOG.info(\"Dryrun fix inprogress segment that has lower sequence number\");\n+\n         // Dryrun\n         DistributedLogAdmin.fixInprogressSegmentWithLowerSequenceNumber(factory,\n                 new DryrunLogSegmentMetadataStoreUpdater(confLocal, getLogSegmentMetadataStore(factory)), streamName, false, false);\n \n-        // Wait for reader to be aware of new log segments\n-        TimeUnit.SECONDS.sleep(2);\n-\n-        dlsn = readDLM.getLastDLSN();\n-        assertTrue(dlsn.compareTo(new DLSN(5, Long.MIN_VALUE, Long.MIN_VALUE)) < 0);\n-        assertTrue(dlsn.compareTo(new DLSN(4, -1, Long.MIN_VALUE)) > 0);\n-        // there isn't records should be read\n         try {\n-            Await.result(readFuture, Duration.fromMilliseconds(1000));\n+            reader = readDLM.getAsyncLogReader(lastDLSN);\n+            Await.result(reader.readNext());\n             fail(\"Should fail reading next when there is a corrupted log segment\");\n-        } catch (TimeoutException te) {\n+        } catch (UnexpectedException ue) {\n             // expected\n         }\n \n+        LOG.info(\"Actual run fix inprogress segment that has lower sequence number\");\n+\n         // Actual run\n         DistributedLogAdmin.fixInprogressSegmentWithLowerSequenceNumber(factory,\n                 LogSegmentMetadataStoreUpdater.createMetadataUpdater(confLocal, getLogSegmentMetadataStore(factory)), streamName, false, false);\n \n-        // Wait for reader to be aware of new log segments\n-        TimeUnit.SECONDS.sleep(2);\n+        // be able to read more after fix\n+        reader = readDLM.getAsyncLogReader(lastDLSN);\n+        // skip the first record\n+        Await.result(reader.readNext());\n+        readFuture = reader.readNext();\n \n         expectedTxId = 51L;\n         LogRecord record = Await.result(readFuture);\n@@ -167,15 +178,11 @@ public void testChangeSequenceNumber() throws Exception {\n             expectedTxId++;\n         }\n \n-        dlsn = readDLM.getLastDLSN();\n-        LOG.info(\"LastDLSN after fix inprogress segment : {}\", dlsn);\n-        assertTrue(dlsn.compareTo(new DLSN(7, Long.MIN_VALUE, Long.MIN_VALUE)) < 0);\n-        assertTrue(dlsn.compareTo(new DLSN(6, -1, Long.MIN_VALUE)) > 0);\n-\n         Utils.close(reader);\n         readDLM.close();\n \n         dlm.close();\n         factory.close();\n+        readFactory.close();\n     }\n }"},{"sha":"d874274dd8757d7dfb312edc665ab40e6d3a4837","filename":"src/test/java/com/twitter/distributedlog/impl/TestZKLogSegmentMetadataStore.java","status":"modified","additions":106,"deletions":12,"changes":118,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -52,6 +52,7 @@\n import java.net.URI;\n import java.util.Collections;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n \n@@ -311,7 +312,8 @@ public void testGetLogSegmentNames() throws Exception {\n         Collections.sort(children);\n         assertEquals(\"Should find 10 log segments\",\n                 10, children.size());\n-        List<String> logSegmentNames = FutureUtils.result(lsmStore.getLogSegmentNames(rootPath));\n+        List<String> logSegmentNames =\n+                FutureUtils.result(lsmStore.getLogSegmentNames(rootPath, null)).getValue();\n         Collections.sort(logSegmentNames);\n         assertEquals(\"Should find 10 log segments\",\n                 10, logSegmentNames.size());\n@@ -331,9 +333,13 @@ public void testGetLogSegmentNames() throws Exception {\n     public void testRegisterListenerAfterLSMStoreClosed() throws Exception {\n         lsmStore.close();\n         LogSegmentMetadata segment = createLogSegment(1L);\n-        lsmStore.registerLogSegmentListener(segment.getZkPath(), new LogSegmentNamesListener() {\n+        lsmStore.getLogSegmentNames(segment.getZkPath(), new LogSegmentNamesListener() {\n             @Override\n-            public void onSegmentsUpdated(List<String> segments) {\n+            public void onSegmentsUpdated(Versioned<List<String>> segments) {\n+                // no-op;\n+            }\n+            @Override\n+            public void onLogStreamDeleted() {\n                 // no-op;\n             }\n         });\n@@ -358,13 +364,17 @@ public void testLogSegmentNamesListener() throws Exception {\n         final List<List<String>> segmentLists = Lists.newArrayListWithExpectedSize(2);\n         LogSegmentNamesListener listener = new LogSegmentNamesListener() {\n             @Override\n-            public void onSegmentsUpdated(List<String> segments) {\n+            public void onSegmentsUpdated(Versioned<List<String>> segments) {\n                 logger.info(\"Received segments : {}\", segments);\n-                segmentLists.add(segments);\n+                segmentLists.add(segments.getValue());\n                 numNotifications.incrementAndGet();\n             }\n+            @Override\n+            public void onLogStreamDeleted() {\n+                // no-op;\n+            }\n         };\n-        lsmStore.registerLogSegmentListener(rootPath, listener);\n+        lsmStore.getLogSegmentNames(rootPath, listener);\n         assertEquals(1, lsmStore.listeners.size());\n         assertTrue(\"Should contain listener\", lsmStore.listeners.containsKey(rootPath));\n         assertTrue(\"Should contain listener\", lsmStore.listeners.get(rootPath).containsKey(listener));\n@@ -420,13 +430,18 @@ public void testLogSegmentNamesListenerOnDeletion() throws Exception {\n         final List<List<String>> segmentLists = Lists.newArrayListWithExpectedSize(2);\n         LogSegmentNamesListener listener = new LogSegmentNamesListener() {\n             @Override\n-            public void onSegmentsUpdated(List<String> segments) {\n+            public void onSegmentsUpdated(Versioned<List<String>> segments) {\n                 logger.info(\"Received segments : {}\", segments);\n-                segmentLists.add(segments);\n+                segmentLists.add(segments.getValue());\n                 numNotifications.incrementAndGet();\n             }\n+\n+            @Override\n+            public void onLogStreamDeleted() {\n+                // no-op;\n+            }\n         };\n-        lsmStore.registerLogSegmentListener(rootPath, listener);\n+        lsmStore.getLogSegmentNames(rootPath, listener);\n         assertEquals(1, lsmStore.listeners.size());\n         assertTrue(\"Should contain listener\", lsmStore.listeners.containsKey(rootPath));\n         assertTrue(\"Should contain listener\", lsmStore.listeners.get(rootPath).containsKey(listener));\n@@ -487,13 +502,18 @@ public void testLogSegmentNamesListenerOnSessionExpired() throws Exception {\n         final List<List<String>> segmentLists = Lists.newArrayListWithExpectedSize(2);\n         LogSegmentNamesListener listener = new LogSegmentNamesListener() {\n             @Override\n-            public void onSegmentsUpdated(List<String> segments) {\n+            public void onSegmentsUpdated(Versioned<List<String>> segments) {\n                 logger.info(\"Received segments : {}\", segments);\n-                segmentLists.add(segments);\n+                segmentLists.add(segments.getValue());\n                 numNotifications.incrementAndGet();\n             }\n+\n+            @Override\n+            public void onLogStreamDeleted() {\n+                // no-op;\n+            }\n         };\n-        lsmStore.registerLogSegmentListener(rootPath, listener);\n+        lsmStore.getLogSegmentNames(rootPath, listener);\n         assertEquals(1, lsmStore.listeners.size());\n         assertTrue(\"Should contain listener\", lsmStore.listeners.containsKey(rootPath));\n         assertTrue(\"Should contain listener\", lsmStore.listeners.get(rootPath).containsKey(listener));\n@@ -535,6 +555,80 @@ public void onSegmentsUpdated(List<String> segments) {\n                 newChildren, thirdSegmentList);\n     }\n \n+    @Test(timeout = 60000)\n+    public void testLogSegmentNamesListenerOnDeletingLogStream() throws Exception {\n+        int numSegments = 3;\n+        Transaction<Object> createTxn = lsmStore.transaction();\n+        for (int i = 0; i < numSegments; i++) {\n+            LogSegmentMetadata segment = createLogSegment(i);\n+            lsmStore.createLogSegment(createTxn, segment);\n+        }\n+        FutureUtils.result(createTxn.execute());\n+        String rootPath = \"/\" + runtime.getMethodName();\n+        List<String> children = zkc.get().getChildren(rootPath, false);\n+        Collections.sort(children);\n+\n+        final AtomicInteger numNotifications = new AtomicInteger(0);\n+        final List<List<String>> segmentLists = Lists.newArrayListWithExpectedSize(2);\n+        final CountDownLatch deleteLatch = new CountDownLatch(1);\n+        LogSegmentNamesListener listener = new LogSegmentNamesListener() {\n+            @Override\n+            public void onSegmentsUpdated(Versioned<List<String>> segments) {\n+                logger.info(\"Received segments : {}\", segments);\n+                segmentLists.add(segments.getValue());\n+                numNotifications.incrementAndGet();\n+            }\n+\n+            @Override\n+            public void onLogStreamDeleted() {\n+                deleteLatch.countDown();\n+            }\n+        };\n+        lsmStore.getLogSegmentNames(rootPath, listener);\n+        assertEquals(1, lsmStore.listeners.size());\n+        assertTrue(\"Should contain listener\", lsmStore.listeners.containsKey(rootPath));\n+        assertTrue(\"Should contain listener\", lsmStore.listeners.get(rootPath).containsKey(listener));\n+        while (numNotifications.get() < 1) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+        assertEquals(\"Should receive one segment list update\",\n+                1, numNotifications.get());\n+        List<String> firstSegmentList = segmentLists.get(0);\n+        Collections.sort(firstSegmentList);\n+        assertEquals(\"List of segments should be same\",\n+                children, firstSegmentList);\n+\n+        // delete all log segments, it should trigger segment list updated\n+        Transaction<Object> deleteTxn = lsmStore.transaction();\n+        for (int i = 0; i < numSegments; i++) {\n+            LogSegmentMetadata segment = createLogSegment(i);\n+            lsmStore.deleteLogSegment(deleteTxn, segment);\n+        }\n+        FutureUtils.result(deleteTxn.execute());\n+        List<String> newChildren = zkc.get().getChildren(rootPath, false);\n+        Collections.sort(newChildren);\n+        while (numNotifications.get() < 2) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+        assertEquals(\"Should receive second segment list update\",\n+                2, numNotifications.get());\n+        List<String> secondSegmentList = segmentLists.get(1);\n+        Collections.sort(secondSegmentList);\n+        assertEquals(\"List of segments should be updated\",\n+                0, secondSegmentList.size());\n+        assertEquals(\"List of segments should be updated\",\n+                newChildren, secondSegmentList);\n+\n+        // delete the root path\n+        zkc.get().delete(rootPath, -1);\n+        while (!lsmStore.listeners.isEmpty()) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+        assertTrue(\"listener should be removed after root path is deleted\",\n+                lsmStore.listeners.isEmpty());\n+        deleteLatch.await();\n+    }\n+\n     @Test(timeout = 60000)\n     public void testStoreMaxLogSegmentSequenceNumber() throws Exception {\n         Transaction<Object> updateTxn = lsmStore.transaction();"},{"sha":"456ed6855fce64ca541638ff03495b8989accc4c","filename":"src/test/java/com/twitter/distributedlog/logsegment/TestPerStreamLogSegmentCache.java","status":"renamed","additions":10,"deletions":44,"changes":54,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestPerStreamLogSegmentCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestPerStreamLogSegmentCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestPerStreamLogSegmentCache.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -26,25 +26,24 @@\n import org.apache.commons.lang3.tuple.Pair;\n import org.junit.Test;\n \n-import java.util.Collections;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n \n import static org.junit.Assert.*;\n \n /**\n- * Test Case for Log Segment Cache.\n+ * Test Case for Per Stream Log Segment Cache.\n  */\n-public class TestLogSegmentCache {\n+public class TestPerStreamLogSegmentCache {\n \n     @Test(timeout = 60000)\n     public void testBasicOperations() {\n         LogSegmentMetadata metadata =\n                 DLMTestUtil.completedLogSegment(\"/segment1\", 1L, 1L, 100L, 100, 1L, 99L, 0L);\n         String name = DLMTestUtil.completedLedgerZNodeNameWithLogSegmentSequenceNumber(1L);\n \n-        LogSegmentCache cache = new LogSegmentCache(\"test-basic-operations\");\n+        PerStreamLogSegmentCache cache = new PerStreamLogSegmentCache(\"test-basic-operations\");\n         assertNull(\"No log segment \" + name + \" should be cached\", cache.get(name));\n         cache.add(name, metadata);\n         LogSegmentMetadata metadataRetrieved = cache.get(name);\n@@ -60,7 +59,7 @@ public void testBasicOperations() {\n \n     @Test(timeout = 60000)\n     public void testDiff() {\n-        LogSegmentCache cache = new LogSegmentCache(\"test-diff\");\n+        PerStreamLogSegmentCache cache = new PerStreamLogSegmentCache(\"test-diff\");\n         // add 5 completed log segments\n         for (int i = 1; i <= 5; i++) {\n             LogSegmentMetadata metadata =\n@@ -98,7 +97,7 @@ public void testDiff() {\n \n     @Test(timeout = 60000)\n     public void testUpdate() {\n-        LogSegmentCache cache = new LogSegmentCache(\"test-update\");\n+        PerStreamLogSegmentCache cache = new PerStreamLogSegmentCache(\"test-update\");\n         // add 5 completed log segments\n         for (int i = 1; i <= 5; i++) {\n             LogSegmentMetadata metadata =\n@@ -144,7 +143,7 @@ public void testUpdate() {\n \n     @Test(timeout = 60000, expected = UnexpectedException.class)\n     public void testGapDetection() throws Exception {\n-        LogSegmentCache cache = new LogSegmentCache(\"test-gap-detection\");\n+        PerStreamLogSegmentCache cache = new PerStreamLogSegmentCache(\"test-gap-detection\");\n         cache.add(DLMTestUtil.completedLedgerZNodeNameWithLogSegmentSequenceNumber(1L),\n                 DLMTestUtil.completedLogSegment(\"/segment-1\", 1L, 1L, 100L, 100, 1L, 99L, 0L));\n         cache.add(DLMTestUtil.completedLedgerZNodeNameWithLogSegmentSequenceNumber(3L),\n@@ -154,7 +153,7 @@ public void testGapDetection() throws Exception {\n \n     @Test(timeout = 60000)\n     public void testGapDetectionOnLogSegmentsWithoutLogSegmentSequenceNumber() throws Exception {\n-        LogSegmentCache cache = new LogSegmentCache(\"test-gap-detection\");\n+        PerStreamLogSegmentCache cache = new PerStreamLogSegmentCache(\"test-gap-detection\");\n         LogSegmentMetadata segment1 =\n                 DLMTestUtil.completedLogSegment(\"/segment-1\", 1L, 1L, 100L, 100, 1L, 99L, 0L)\n                         .mutator().setVersion(LogSegmentMetadata.LogSegmentMetadataVersion.VERSION_V1_ORIGINAL).build();\n@@ -168,9 +167,9 @@ public void testGapDetectionOnLogSegmentsWithoutLogSegmentSequenceNumber() throw\n         assertEquals(expectedList, resultList);\n     }\n \n-    @Test(timeout = 60000)\n+    @Test(timeout = 60000, expected = UnexpectedException.class)\n     public void testSameLogSegment() throws Exception {\n-        LogSegmentCache cache = new LogSegmentCache(\"test-same-log-segment\");\n+        PerStreamLogSegmentCache cache = new PerStreamLogSegmentCache(\"test-same-log-segment\");\n         List<LogSegmentMetadata> expectedList = Lists.newArrayListWithExpectedSize(2);\n         LogSegmentMetadata inprogress =\n                 DLMTestUtil.inprogressLogSegment(\"/inprogress-1\", 1L, 1L, 1L);\n@@ -181,40 +180,7 @@ public void testSameLogSegment() throws Exception {\n         expectedList.add(completed);\n         cache.add(DLMTestUtil.completedLedgerZNodeNameWithLogSegmentSequenceNumber(1L), completed);\n \n-        List<LogSegmentMetadata> retrievedList = cache.getLogSegments(LogSegmentMetadata.COMPARATOR);\n-        assertEquals(\"Should get both log segments in ascending order\",\n-                expectedList.size(), retrievedList.size());\n-        for (int i = 0; i < expectedList.size(); i++) {\n-            assertEqualsWithoutSequenceId(expectedList.get(i), retrievedList.get(i));\n-        }\n-        assertEquals(\"inprogress log segment should see start sequence id : 0\",\n-                0L, retrievedList.get(0).getStartSequenceId());\n-        Collections.reverse(expectedList);\n-        retrievedList = cache.getLogSegments(LogSegmentMetadata.DESC_COMPARATOR);\n-        assertEquals(\"Should get both log segments in descending order\",\n-                expectedList.size(), retrievedList.size());\n-        for (int i = 0; i < expectedList.size(); i++) {\n-            assertEqualsWithoutSequenceId(expectedList.get(i), retrievedList.get(i));\n-        }\n-        assertEquals(\"inprogress log segment should see start sequence id : 0\",\n-                0L, retrievedList.get(1).getStartSequenceId());\n-    }\n-\n-    private static void assertEqualsWithoutSequenceId(LogSegmentMetadata m1, LogSegmentMetadata m2) {\n-        assertEquals(\"expected \" + m1 + \" but got \" + m2,\n-                m1.getLogSegmentSequenceNumber(), m2.getLogSegmentSequenceNumber());\n-        assertEquals(\"expected \" + m1 + \" but got \" + m2,\n-                m1.getLedgerId(), m2.getLedgerId());\n-        assertEquals(\"expected \" + m1 + \" but got \" + m2,\n-                m1.getFirstTxId(), m2.getFirstTxId());\n-        assertEquals(\"expected \" + m1 + \" but got \" + m2,\n-                m1.getLastTxId(), m2.getLastTxId());\n-        assertEquals(\"expected \" + m1 + \" but got \" + m2,\n-                m1.getLastDLSN(), m2.getLastDLSN());\n-        assertEquals(\"expected \" + m1 + \" but got \" + m2,\n-                m1.getRecordCount(), m2.getRecordCount());\n-        assertEquals(\"expected \" + m1 + \" but got \" + m2,\n-                m1.isInProgress(), m2.isInProgress());\n+        cache.getLogSegments(LogSegmentMetadata.COMPARATOR);\n     }\n \n }","previous_filename":"src/test/java/com/twitter/distributedlog/logsegment/TestLogSegmentCache.java"},{"sha":"cbabf2a0d35296bea0d0a81730f1e2b25da03c84","filename":"src/test/java/com/twitter/distributedlog/tools/TestDistributedLogTool.java","status":"modified","additions":6,"deletions":2,"changes":8,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTestDistributedLogTool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/037713709672b3b500f7375a1bd81c1649956e3f/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTestDistributedLogTool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTestDistributedLogTool.java?ref=037713709672b3b500f7375a1bd81c1649956e3f","patch":"@@ -21,6 +21,7 @@\n \n import com.twitter.distributedlog.DLMTestUtil;\n import com.twitter.distributedlog.DLSN;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n import com.twitter.distributedlog.DistributedLogManager;\n import com.twitter.distributedlog.TestDistributedLogBase;\n import com.twitter.distributedlog.LocalDLMEmulator;\n@@ -205,8 +206,11 @@ public void testToolReadEntriesCommand() throws Exception {\n \n     @Test(timeout = 60000)\n     public void testToolTruncateStream() throws Exception {\n-        DistributedLogManager dlm = DLMTestUtil.createNewDLM(\"testToolTruncateStream\", conf, defaultUri);\n-        DLMTestUtil.generateCompletedLogSegments(dlm, conf, 3, 1000);\n+        DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n+        confLocal.addConfiguration(conf);\n+        confLocal.setLogSegmentCacheEnabled(false);\n+        DistributedLogManager dlm = DLMTestUtil.createNewDLM(\"testToolTruncateStream\", confLocal, defaultUri);\n+        DLMTestUtil.generateCompletedLogSegments(dlm, confLocal, 3, 1000);\n \n         DLSN dlsn = new DLSN(2,1,0);\n         TruncateStreamCommand cmd = new TruncateStreamCommand();"}]}