{"sha":"5a71ed88116fcdffcccdb99eb79055912c46a85e","node_id":"MDY6Q29tbWl0NDc4NTkyNTI2OjVhNzFlZDg4MTE2ZmNkZmZjY2NkYjk5ZWI3OTA1NTkxMmM0NmE4NWU=","commit":{"author":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-05-09T19:06:08Z"},"committer":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-05-09T19:06:08Z"},"message":"Initial Check-in for distributedlog oss","tree":{"sha":"8d21214bb3b3390deed2244c1a84dabe8c49a98b","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/trees/8d21214bb3b3390deed2244c1a84dabe8c49a98b"},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/commits/5a71ed88116fcdffcccdb99eb79055912c46a85e","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/5a71ed88116fcdffcccdb99eb79055912c46a85e","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/5a71ed88116fcdffcccdb99eb79055912c46a85e","comments_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/5a71ed88116fcdffcccdb99eb79055912c46a85e/comments","author":null,"committer":null,"parents":[],"stats":{"total":66853,"additions":66853,"deletions":0},"files":[{"sha":"6643cb231fe3af2d2c60871d6ac9f6fcdc8d50dc","filename":"bin/dlog","status":"added","additions":153,"deletions":0,"changes":153,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/bin%2Fdlog","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/bin%2Fdlog","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/bin%2Fdlog?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,153 @@\n+#!/usr/bin/env bash\n+\n+# check if net.ipv6.bindv6only is set to 1\n+bindv6only=$(/sbin/sysctl -n net.ipv6.bindv6only 2> /dev/null)\n+if [ -n \"$bindv6only\" ] && [ \"$bindv6only\" -eq \"1\" ]\n+then\n+  echo \"Error: \\\"net.ipv6.bindv6only\\\" is set to 1 - Java networking could be broken\"\n+  echo \"For more info (the following page also applies to dlog): http://wiki.apache.org/hadoop/HadoopIPv6\"\n+  exit 1\n+fi\n+\n+# See the following page for extensive details on setting\n+# up the JVM to accept JMX remote management:\n+# http://java.sun.com/javase/6/docs/technotes/guides/management/agent.html\n+# by default we allow local JMX connections\n+if [ \"x$JMXLOCALONLY\" = \"x\" ]\n+then\n+    JMXLOCALONLY=false\n+fi\n+\n+if [ \"x$JMXDISABLE\" = \"x\" ]\n+then\n+    echo \"JMX enabled by default\" >&2\n+    # for some reason these two options are necessary on jdk6 on Ubuntu\n+    #   accord to the docs they are not necessary, but otw jconsole cannot\n+    #   do a local attach\n+    JMX_ARGS=\"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=$JMXLOCALONLY\"\n+else\n+    echo \"JMX disabled by user request\" >&2\n+fi\n+\n+BINDIR=`dirname \"$0\"`\n+DLOG_HOME=`cd $BINDIR/.. > /dev/null;pwd`\n+\n+DEFAULT_LOG_CONF=$DLOG_HOME/conf/log4j.properties\n+\n+source $DLOG_HOME/conf/dlogenv.sh\n+\n+# exclude tests jar\n+RELEASE_JAR=`ls $DLOG_HOME/distributedlog-*.jar 2> /dev/null | egrep -v 'tests|javadoc|sources' | tail -1`\n+if [ $? == 0 ]; then\n+    DLOG_JAR=$RELEASE_JAR\n+fi\n+\n+# exclude tests jar\n+BUILT_JAR=`ls $DLOG_HOME/target/distributedlog-*.jar 2> /dev/null | egrep -v 'tests|javadoc|sources' | tail -1`\n+if [ $? != 0 ] && [ ! -e \"$DLOG_JAR\" ]; then\n+    echo \"\\nCouldn't find dlog jar.\";\n+    echo \"Make sure you've run 'mvn package'\\n\";\n+    exit 1;\n+elif [ -e \"$BUILT_JAR\" ]; then\n+    DLOG_JAR=$BUILT_JAR\n+fi\n+\n+dlog_help() {\n+    cat <<EOF\n+Usage: dlog <command>\n+where command is one of:\n+    local               Run distributedlog sandbox\n+    example             Run distributedlog example\n+    tool                Run distributedlog tool\n+    proxy_tool          Run distributedlog proxy tool to interact with proxies\n+    balancer            Run distributedlog balancer\n+    admin               Run distributedlog admin tool\n+    help                This help message\n+\n+or command is the full name of a class with a defined main() method.\n+\n+Environment variables:\n+   DLOG_LOG_CONF        Log4j configuration file (default $DEFAULT_LOG_CONF)\n+   DLOG_EXTRA_OPTS      Extra options to be passed to the jvm\n+   DLOG_EXTRA_CLASSPATH Add extra paths to the dlog classpath\n+\n+These variable can also be set in conf/dlogenv.sh\n+EOF\n+}\n+\n+add_maven_deps_to_classpath() {\n+    MVN=\"mvn\"\n+    if [ \"$MAVEN_HOME\" != \"\" ]; then\n+\tMVN=${MAVEN_HOME}/bin/mvn\n+    fi\n+\n+    # Need to generate classpath from maven pom. This is costly so generate it\n+    # and cache it. Save the file into our target dir so a mvn clean will get\n+    # clean it up and force us create a new one.\n+    f=\"${DLOG_HOME}/target/cached_classpath.txt\"\n+    if [ ! -f \"${f}\" ]\n+    then\n+\t${MVN} -f \"${DLOG_HOME}/pom.xml\" dependency:build-classpath -Dmdep.outputFile=\"${f}\" &> /dev/null\n+    fi\n+    DLOG_CLASSPATH=${CLASSPATH}:`cat \"${f}\"`\n+}\n+\n+if [ -d \"$DLOG_HOME/lib\" ]; then\n+    for i in $DLOG_HOME/lib/*.jar; do\n+\tDLOG_CLASSPATH=$DLOG_CLASSPATH:$i\n+    done\n+else\n+    add_maven_deps_to_classpath\n+fi\n+\n+# if no args specified, show usage\n+if [ $# = 0 ]; then\n+    dlog_help;\n+    exit 1;\n+fi\n+\n+# get arguments\n+COMMAND=$1\n+shift\n+\n+if [ -z \"$DLOG_LOG_CONF\" ]; then\n+    DLOG_LOG_CONF=$DEFAULT_LOG_CONF\n+fi\n+\n+DLOG_CLASSPATH=\"$DLOG_JAR:$DLOG_CLASSPATH:$DLOG_EXTRA_CLASSPATH\"\n+if [ \"$DLOG_LOG_CONF\" != \"\" ]; then\n+    DLOG_CLASSPATH=\"`dirname $DLOG_LOG_CONF`:$DLOG_CLASSPATH\"\n+    OPTS=\"$OPTS -Dlog4j.configuration=`basename $DLOG_LOG_CONF`\"\n+fi\n+OPTS=\"-cp $DLOG_CLASSPATH $OPTS $DLOG_EXTRA_OPTS\"\n+\n+OPTS=\"$OPTS $DLOG_EXTRA_OPTS\"\n+\n+# Disable ipv6 as it can cause issues\n+OPTS=\"$OPTS -Djava.net.preferIPv4Stack=true\"\n+\n+# log directory & file\n+DLOG_ROOT_LOGGER=${DLOG_ROOT_LOGGER:-\"INFO,R\"}\n+DLOG_LOG_DIR=${DLOG_LOG_DIR:-\"$DLOG_HOME/logs\"}\n+DLOG_LOG_FILE=${DLOG_LOG_FILE:-\"dlog.log\"}\n+\n+#Configure log configuration system properties\n+OPTS=\"$OPTS -Ddlog.root.logger=$DLOG_ROOT_LOGGER\"\n+OPTS=\"$OPTS -Ddlog.log.dir=$DLOG_LOG_DIR\"\n+OPTS=\"$OPTS -Ddlog.log.file=$DLOG_LOG_FILE\"\n+\n+#Change to DLOG_HOME to support relative paths\n+cd \"$DLOG_HOME\"\n+if [ $COMMAND == \"local\" ]; then\n+    exec java $OPTS $JMX_ARGS com.twitter.distributedlog.LocalDLMEmulator $@\n+elif [ $COMMAND == \"tool\" ]; then\n+    exec java $OPTS com.twitter.distributedlog.tools.Tool com.twitter.distributedlog.tools.DistributedLogTool $@\n+elif [ $COMMAND == \"admin\" ]; then\n+    exec java $OPTS com.twitter.distributedlog.tools.Tool com.twitter.distributedlog.admin.DistributedLogAdmin $@\n+elif [ $COMMAND == \"help\" ]; then\n+    dlog_help;\n+else\n+    exec java $OPTS $COMMAND $@\n+fi\n+\n+"},{"sha":"75a147a9c2c540d7329f5581115cfcf4d7658dfd","filename":"conf/distributedlog.conf","status":"added","additions":107,"deletions":0,"changes":107,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/conf%2Fdistributedlog.conf","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/conf%2Fdistributedlog.conf","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/conf%2Fdistributedlog.conf?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,107 @@\n+########################\n+# ZooKeeper Client Settings\n+########################\n+\n+# zookeeper settings\n+zkSessionTimeoutSeconds=30\n+zkNumRetries=0\n+zkRetryStartBackoffMillis=100\n+zkRetryMaxBackoffMillis=200\n+# bkc zookeeper settings\n+bkcZKSessionTimeoutSeconds=60\n+bkcZKNumRetries=20\n+bkcZKRetryStartBackoffMillis=100\n+bkcZKRetryMaxBackoffMillis=200\n+\n+########################\n+# BookKeeper Client Settings\n+########################\n+\n+# bookkeeper client timeouts\n+bkcWriteTimeoutSeconds=10\n+bkcReadTimeoutSeconds=1\n+bkcNumWorkerThreads=16\n+# bkcNumIOThreads=16\n+bkc.numChannelsPerBookie=1\n+bkc.enableTaskExecutionStats=true\n+bkc.connectTimeoutMillis=1000\n+bkc.enablePerHostStats=true\n+\n+########################\n+# DL Settings\n+########################\n+\n+# lock timeout\n+lockTimeoutSeconds=0\n+# dl worker threads\n+numWorkerThreads=16\n+\n+### Recovery Related Settings\n+\n+# recover log segments in background\n+recoverLogSegmentsInBackground=true\n+# disable max id in proxy\n+maxIdSanityCheck=true\n+# use allocator pool for proxy\n+enableLedgerAllocatorPool=false\n+# ledger allocator pool size\n+ledgerAllocatorPoolCoreSize=20\n+# check stream exists or not\n+createStreamIfNotExists=true\n+# encode dc id in version\n+encodeDCIDInVersion=true\n+# logSegmentNameVersion\n+logSegmentNameVersion=1\n+\n+### Write Performance Related Settings\n+\n+# ensemble size\n+ensemble-size=3\n+write-quorum-size=3\n+ack-quorum-size=2\n+bkc.ensemblePlacementPolicy=org.apache.bookkeeper.client.RackawareEnsemblePlacementPolicy\n+bkc.delayEnsembleChange=true\n+\n+# sync settings\n+# buffer size is large because when we rewrite we perform a very large write to persist\n+# all queue state at once (up to max queue memory size, ex. 16MB). the write will be\n+# throttled if it takes too long, which can hurt performance, so important to optimize\n+# for this case.\n+output-buffer-size=512000\n+enableImmediateFlush=false\n+periodicFlushFrequencyMilliSeconds=6\n+logFlushTimeoutSeconds=120\n+\n+### Ledger Rolling Related Settings\n+\n+# retention policy\n+retention-size=0\n+# rolling ledgers (disable time rolling/enable size rolling)\n+rolling-interval=0\n+\n+# max logsegment bytes=2GB\n+# much larger than max journal size, effectively never roll and let drpc do it\n+maxLogSegmentBytes=2147483648\n+\n+# rolling concurrency\n+logSegmentRollingConcurrency=1\n+# disable sanityCheckDelete\n+sanityCheckDelete=false\n+ledgerAllocatorPoolName=drpc-alloc-pool\n+\n+### Readahead settings\n+\n+enableReadAhead=true\n+ReadAheadBatchSize=10\n+ReadAheadMaxEntries=100\n+ReadAheadWaitTime=10\n+\n+### Rate limit\n+\n+rpsSoftWriteLimit=1\n+rpsHardWriteLimit=5\n+rpsHardServiceLimit=15\n+\n+### Config\n+\n+dynamicConfigReloadIntervalSec=5\n\\ No newline at end of file"},{"sha":"72af987a9dcb62d66038af139bf545fad94b797a","filename":"conf/distributedlog_proxy.conf","status":"added","additions":126,"deletions":0,"changes":126,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/conf%2Fdistributedlog_proxy.conf","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/conf%2Fdistributedlog_proxy.conf","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/conf%2Fdistributedlog_proxy.conf?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,126 @@\n+########################\n+# ZooKeeper Client Settings\n+########################\n+\n+# zookeeper settings\n+zkSessionTimeoutSeconds=1\n+zkNumRetries=0\n+zkRetryStartBackoffMillis=100\n+zkRetryMaxBackoffMillis=200\n+# bkc zookeeper settings\n+bkcZKSessionTimeoutSeconds=60\n+bkcZKNumRetries=20\n+bkcZKRetryStartBackoffMillis=100\n+bkcZKRetryMaxBackoffMillis=200\n+\n+########################\n+# BookKeeper Client Settings\n+########################\n+\n+# bookkeeper client timeouts\n+bkcWriteTimeoutSeconds=2\n+bkcReadTimeoutSeconds=1\n+bkcNumWorkerThreads=32\n+bkc.numChannelsPerBookie=1\n+bkc.enableTaskExecutionStats=true\n+bkc.connectTimeoutMillis=200\n+bkc.enableParallelRecoveryRead=true\n+bkc.recoveryReadBatchSize=5\n+bkc.enablePerHostStats=true\n+\n+########################\n+# DL Settings\n+########################\n+\n+# Metadata Settings\n+\n+# ledger metadata version that supports sequence id\n+ledger-metadata-layout=5\n+\n+# lock timeout\n+lockTimeoutSeconds=0\n+# dl worker threads\n+numWorkerThreads=32\n+\n+### Recovery Related Settings\n+\n+# recover log segments in background\n+recoverLogSegmentsInBackground=false\n+# disable max id in proxy\n+maxIdSanityCheck=false\n+# use allocator pool for proxy\n+enableLedgerAllocatorPool=true\n+# ledger allocator pool path\n+ledgerAllocatorPoolPath=.write_proxy_eventbus_high_throughput_allocation_pool\n+# ledger allocator pool size\n+ledgerAllocatorPoolCoreSize=40\n+# check stream exists or not\n+createStreamIfNotExists=true\n+# encode dc id in version\n+encodeDCIDInVersion=true\n+# logSegmentNameVersion\n+logSegmentNameVersion=1\n+\n+### Write Performance Related Settings\n+\n+# ensemble size\n+ensemble-size=3\n+write-quorum-size=3\n+ack-quorum-size=2\n+bkc.ensemblePlacementPolicy=org.apache.bookkeeper.client.RackawareEnsemblePlacementPolicy\n+bkc.delayEnsembleChange=true\n+bkc.writeRequestToChannelAsync=true\n+\n+# enable immediate flush\n+enableImmediateFlush=true\n+# 0k output buffer\n+output-buffer-size=0\n+# disable periodical flush\n+periodicFlushFrequencyMilliSeconds=0\n+enableTaskExecutionStats=true\n+taskExecutionWarnTimeMicros=100000\n+\n+### Ledger Rolling Related Settings\n+\n+# retention policy\n+retention-size=4\n+# rolling ledgers (enable time rolling): 120 minutes = 2 hours\n+rolling-interval=120\n+# max logsegment bytes : 2GB\n+maxLogSegmentBytes=2147483648\n+# rolling concurrency\n+logSegmentRollingConcurrency=1\n+# disable sanityCheckDelete\n+sanityCheckDelete=false\n+# compression codec\n+compressionType=lz4\n+\n+### Per Stream Stats\n+enablePerStreamStat=true\n+\n+########################\n+# DL Settings\n+########################\n+\n+# proxy server settings\n+server_mode=DURABLE\n+serviceTimeoutMs=60000\n+streamProbationTimeoutMs=120000\n+server_threads=16\n+server_dlsn_version=1\n+server_enable_perstream_stat=true\n+server_graceful_shutdown_period_ms=35000\n+stream_partition_converter_class=com.twitter.distributedlog.service.streamset.EventBusStreamPartitionConverter\n+\n+# write limits\n+perWriterOutstandingWriteLimit=-1\n+globalOutstandingWriteLimit=15000\n+outstandingWriteLimitDarkmode=false\n+\n+# bytes per second limit applied at the host level (50MBps on 1Gib machines)\n+bpsHardServiceLimit=52428800\n+# bytes per second limit after which no new streams may be acquired (65MBps on 1Gib machines)\n+bpsStreamAcquireServiceLimit=47185920\n+\n+# limit the maximum number of streams\n+maxAcquiredPartitionsPerProxy=-1"},{"sha":"11e4024ace74f9982140a335efabe3eb0f83551a","filename":"conf/dlogenv.sh","status":"added","additions":41,"deletions":0,"changes":41,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/conf%2Fdlogenv.sh","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/conf%2Fdlogenv.sh","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/conf%2Fdlogenv.sh?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,41 @@\n+#!/bin/sh\n+#\n+#/**\n+# * Copyright 2007 The Apache Software Foundation\n+# *\n+# * Licensed to the Apache Software Foundation (ASF) under one\n+# * or more contributor license agreements.  See the NOTICE file\n+# * distributed with this work for additional information\n+# * regarding copyright ownership.  The ASF licenses this file\n+# * to you under the Apache License, Version 2.0 (the\n+# * \"License\"); you may not use this file except in compliance\n+# * with the License.  You may obtain a copy of the License at\n+# *\n+# *     http://www.apache.org/licenses/LICENSE-2.0\n+# *\n+# * Unless required by applicable law or agreed to in writing, software\n+# * distributed under the License is distributed on an \"AS IS\" BASIS,\n+# * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# * See the License for the specific language governing permissions and\n+# * limitations under the License.\n+# */\n+\n+# default settings for starting distributedlog sandbox\n+\n+# Log4j configuration file\n+# DLOG_LOG_CONF=\n+\n+# Extra options to be passed to the jvm\n+# DLOG_EXTRA_OPTS=\n+\n+# Add extra paths to the dlog classpath\n+# DLOG_EXTRA_CLASSPATH=\n+\n+# Configure the root logger\n+# DLOG_ROOT_LOGGER=\n+\n+# Configure the log dir\n+# DLOG_LOG_DIR=\n+\n+# Configure the log file\n+# DLOG_LOG_FILE="},{"sha":"605049f5bf8b4d24f03665e55a08f1c3c237e876","filename":"conf/log4j.properties","status":"added","additions":42,"deletions":0,"changes":42,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/conf%2Flog4j.properties","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/conf%2Flog4j.properties","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/conf%2Flog4j.properties?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,42 @@\n+#\n+# DistributedLog Logging Configuration\n+#\n+\n+# Default values\n+dlog.root.logger=INFO, R\n+dlog.log.dir=logs\n+dlog.log.file=dlog.log\n+\n+log4j.rootLogger=${dlog.root.logger}\n+log4j.logger.org.apache.zookeeper=INFO\n+log4j.logger.org.apache.bookkeeper=INFO\n+\n+# redirect executor output to executors.log since slow op warnings can be quite verbose\n+log4j.logger.com.twitter.distributedlog.util.MonitoredFuturePool=INFO, Executors\n+log4j.logger.com.twitter.distributedlog.util.MonitoredScheduledThreadPoolExecutor=INFO, Executors\n+log4j.logger.org.apache.bookkeeper.util.SafeRunnable=INFO, Executors\n+log4j.additivity.com.twitter.distributedlog.util.MonitoredFuturePool=false\n+log4j.additivity.com.twitter.distributedlog.util.MonitoredScheduledThreadPoolExecutor=false\n+log4j.additivity.org.apache.bookkeeper.util.SafeRunnable=false\n+\n+log4j.appender.Executors=org.apache.log4j.RollingFileAppender\n+log4j.appender.Executors.Threshold=INFO\n+log4j.appender.Executors.File=${dlog.log.dir}/executors.log\n+log4j.appender.Executors.MaxFileSize=20MB\n+log4j.appender.Executors.MaxBackupIndex=5\n+log4j.appender.Executors.layout=org.apache.log4j.PatternLayout\n+log4j.appender.Executors.layout.ConversionPattern=%d{ISO8601} - %-5p - [%t:%C{1}@%L] - %m%n\n+\n+log4j.appender.R=org.apache.log4j.RollingFileAppender\n+log4j.appender.R.Threshold=INFO\n+log4j.appender.R.File=${dlog.log.dir}/${dlog.log.file}\n+log4j.appender.R.MaxFileSize=20MB\n+log4j.appender.R.MaxBackupIndex=50\n+log4j.appender.R.layout=org.apache.log4j.PatternLayout\n+log4j.appender.R.layout.ConversionPattern=%d{ISO8601} - %-5p - [%t:%C{1}@%L] - %m%n\n+\n+log4j.appender.stderr=org.apache.log4j.ConsoleAppender\n+log4j.appender.stderr.Target=System.err\n+log4j.appender.stderr.Threshold=INFO\n+log4j.appender.stderr.layout=org.apache.log4j.PatternLayout\n+log4j.appender.stderr.layout.ConversionPattern=%d{ISO8601} - %-5p - [%t:%C{1}@%L] - %m%n"},{"sha":"0e9334afc3feadcaa82b202e0cc665ece414d2e4","filename":"pom.xml","status":"added","additions":216,"deletions":0,"changes":216,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/pom.xml","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/pom.xml","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/pom.xml?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,216 @@\n+<?xml version=\"1.0\"?>\n+<!--\n+   Licensed to the Apache Software Foundation (ASF) under one or more\n+   contributor license agreements.  See the NOTICE file distributed with\n+   this work for additional information regarding copyright ownership.\n+   The ASF licenses this file to You under the Apache License, Version 2.0\n+   (the \"License\"); you may not use this file except in compliance with\n+   the License.  You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <parent>\n+    <groupId>com.twitter</groupId>\n+    <artifactId>distributedlog</artifactId>\n+    <version>0.3.51-SNAPSHOT</version>\n+  </parent>\n+  <artifactId>distributedlog-core</artifactId>\n+  <name>DistributedLog Core Library</name>\n+  <dependencies>\n+    <dependency>\n+      <groupId>org.apache.zookeeper</groupId>\n+      <artifactId>zookeeper</artifactId>\n+      <version>${zookeeper.version}</version>\n+      <exclusions>\n+        <exclusion>\n+          <groupId>com.google.guava</groupId>\n+          <artifactId>guava</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>org.slf4j</groupId>\n+          <artifactId>slf4j-log4j12</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>com.twitter</groupId>\n+          <artifactId>finagle-core_2.11</artifactId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+    <dependency>\n+      <groupId>junit</groupId>\n+      <artifactId>junit</artifactId>\n+      <version>4.8.1</version>\n+      <scope>test</scope>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.slf4j</groupId>\n+      <artifactId>slf4j-log4j12</artifactId>\n+      <version>1.6.4</version>\n+      <scope>test</scope>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.slf4j</groupId>\n+      <artifactId>slf4j-api</artifactId>\n+      <version>1.6.4</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>com.twitter.common</groupId>\n+      <artifactId>stats-util</artifactId>\n+      <version>0.0.58</version>\n+      <exclusions>\n+        <exclusion>\n+          <groupId>org.slf4j</groupId>\n+          <artifactId>slf4j-jdk14</artifactId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+    <dependency>\n+      <groupId>com.twitter</groupId>\n+      <artifactId>util-core_2.11</artifactId>\n+      <version>${birdcage.sha}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.commons</groupId>\n+      <artifactId>commons-lang3</artifactId>\n+      <version>3.3.2</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>jline</groupId>\n+      <artifactId>jline</artifactId>\n+      <version>0.9.94</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.thrift</groupId>\n+      <artifactId>libthrift</artifactId>\n+      <version>0.5.0-1</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>com.twitter</groupId>\n+      <artifactId>scrooge-core_2.11</artifactId>\n+      <version>${scrooge.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.bookkeeper</groupId>\n+      <artifactId>bookkeeper-server</artifactId>\n+      <version>${bookkeeper.version}</version>\n+      <type>jar</type>\n+      <exclusions>\n+        <exclusion>\n+          <groupId>org.jboss.netty</groupId>\n+          <artifactId>netty</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>org.apache.zookeeper</groupId>\n+          <artifactId>zookeeper</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>commons-cli</groupId>\n+          <artifactId>commons-cli</artifactId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+    <dependency>\n+      <groupId>commons-cli</groupId>\n+      <artifactId>commons-cli</artifactId>\n+      <version>1.1</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>com.twitter</groupId>\n+      <artifactId>distributedlog-protocol</artifactId>\n+      <version>${project.parent.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>net.jpountz.lz4</groupId>\n+      <artifactId>lz4</artifactId>\n+      <version>1.2.0</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.mockito</groupId>\n+      <artifactId>mockito-core</artifactId>\n+      <version>1.9.5</version>\n+      <scope>test</scope>\n+    </dependency> \n+  </dependencies>\n+  <build>\n+    <plugins>\n+      <plugin>\n+        <groupId>com.twitter</groupId>\n+        <artifactId>scrooge-maven-plugin</artifactId>\n+        <version>${scrooge-maven-plugin.version}</version>\n+        <configuration>\n+          <language>java</language>\n+        </configuration>\n+        <executions>\n+          <execution>\n+            <id>thrift-sources</id>\n+            <phase>generate-sources</phase>\n+            <goals>\n+              <goal>compile</goal>\n+            </goals>\n+          </execution>\n+        </executions>\n+      </plugin>\n+      <plugin>\n+        <artifactId>maven-compiler-plugin</artifactId>\n+        <version>3.1</version>\n+        <configuration>\n+          <compilerArguments>\n+            <Xlint:deprecation />\n+            <Xlint:unchecked />\n+          </compilerArguments>\n+        </configuration>\n+      </plugin>\n+      <plugin>\n+        <groupId>org.apache.maven.plugins</groupId>\n+        <artifactId>maven-jar-plugin</artifactId>\n+        <version>2.2</version>\n+        <executions>\n+          <execution>\n+            <goals>\n+              <goal>test-jar</goal>\n+            </goals>\n+          </execution>\n+        </executions>\n+      </plugin>\n+      <plugin>\n+        <groupId>org.apache.maven.plugins</groupId>\n+        <artifactId>maven-surefire-plugin</artifactId>\n+        <version>2.9</version>\n+        <configuration>\n+          <redirectTestOutputToFile>true</redirectTestOutputToFile>\n+          <argLine>-Xmx3G -Djava.net.preferIPv4Stack=true -XX:MaxDirectMemorySize=2G</argLine>\n+          <forkMode>always</forkMode>\n+          <forkedProcessTimeoutInSeconds>1800</forkedProcessTimeoutInSeconds>\n+        </configuration>\n+      </plugin>\n+      <plugin>\n+        <groupId>org.codehaus.mojo</groupId>\n+        <artifactId>findbugs-maven-plugin</artifactId>\n+        <configuration>\n+          <excludeFilterFile>${basedir}/src/main/resources/findbugsExclude.xml</excludeFilterFile>\n+        </configuration>\n+      </plugin>\n+    </plugins>\n+  </build>\n+  <profiles>\n+    <profile>\n+      <id>twitter-ostrich-provider</id>\n+      <dependencies>\n+        <dependency>\n+          <groupId>org.apache.bookkeeper.stats</groupId>\n+          <artifactId>twitter-ostrich-provider</artifactId>\n+          <version>${bookkeeper.version}</version>\n+        </dependency>\n+      </dependencies>\n+    </profile>\n+  </profiles>\n+</project>"},{"sha":"235c6eb2c437021091298761780391ace8d3585b","filename":"src/assemble/bin.xml","status":"added","additions":55,"deletions":0,"changes":55,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fassemble%2Fbin.xml","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fassemble%2Fbin.xml","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fassemble%2Fbin.xml?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,55 @@\n+<!--\n+   Licensed to the Apache Software Foundation (ASF) under one or more\n+   contributor license agreements.  See the NOTICE file distributed with\n+   this work for additional information regarding copyright ownership.\n+   The ASF licenses this file to You under the Apache License, Version 2.0\n+   (the \"License\"); you may not use this file except in compliance with\n+   the License.  You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+-->\n+<assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2\"\n+    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+    xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd\">\n+  <id>bin</id>\n+  <formats>\n+    <format>zip</format>\n+  </formats>\n+  <includeBaseDirectory>true</includeBaseDirectory>\n+  <fileSets>\n+    <fileSet>\n+      <directory>target</directory>\n+      <outputDirectory>/</outputDirectory>\n+      <includes>\n+        <include>${project.artifactId}-${project.version}.jar</include>\n+      </includes>\n+    </fileSet>\n+    <fileSet>\n+      <directory>conf</directory>\n+    </fileSet>\n+    <fileSet>\n+      <directory>bin</directory>\n+      <fileMode>755</fileMode>\n+    </fileSet>\n+    <fileSet>\n+      <fileMode>644</fileMode>\n+      <includes>\n+        <include>${basedir}/*.txt</include>\n+      </includes>\n+    </fileSet>\n+  </fileSets>\n+  <dependencySets>\n+    <dependencySet>\n+      <outputDirectory>/lib</outputDirectory>\n+      <unpack>false</unpack>\n+      <scope>runtime</scope>\n+      <useProjectArtifact>false</useProjectArtifact>\n+    </dependencySet>\n+  </dependencySets>\n+</assembly>"},{"sha":"0f93bfe5c5dfb61a896f86b84904cbd6287074f2","filename":"src/main/java/com/twitter/distributedlog/AppendOnlyStreamReader.java","status":"added","additions":198,"deletions":0,"changes":198,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAppendOnlyStreamReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAppendOnlyStreamReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAppendOnlyStreamReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,198 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Preconditions;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class AppendOnlyStreamReader extends InputStream {\n+    static final Logger LOG = LoggerFactory.getLogger(AppendOnlyStreamReader.class);\n+\n+    private LogRecordWithInputStream currentLogRecord = null;\n+    private final DistributedLogManager dlm;\n+    private LogReader reader;\n+    private long currentPosition;\n+    private static final int SKIP_BUFFER_SIZE = 512;\n+\n+    // Cache the input stream for a log record.\n+    private static class LogRecordWithInputStream {\n+        private final InputStream payloadStream;\n+        private final LogRecordWithDLSN logRecord;\n+\n+        LogRecordWithInputStream(LogRecordWithDLSN logRecord) {\n+            Preconditions.checkNotNull(logRecord);\n+\n+            LOG.debug(\"Got record dlsn = {}, txid = {}, len = {}\",\n+                new Object[] {logRecord.getDlsn(), logRecord.getTransactionId(), logRecord.getPayload().length});\n+\n+            this.logRecord = logRecord;\n+            this.payloadStream = logRecord.getPayLoadInputStream();\n+        }\n+\n+        InputStream getPayLoadInputStream() {\n+            return payloadStream;\n+        }\n+\n+        LogRecordWithDLSN getLogRecord() {\n+            return logRecord;\n+        }\n+\n+        // The last txid of the log record is the position of the next byte in the stream.\n+        // Subtract length to get starting offset.\n+        long getOffset() {\n+            return logRecord.getTransactionId() - logRecord.getPayload().length;\n+        }\n+    }\n+\n+    /**\n+     * Construct ledger input stream\n+     *\n+     * @param dlm the Distributed Log Manager to access the stream\n+     */\n+    AppendOnlyStreamReader(DistributedLogManager dlm)\n+        throws IOException {\n+        this.dlm = dlm;\n+        reader = dlm.getInputStream(0);\n+        currentPosition = 0;\n+    }\n+\n+    /**\n+     * Get input stream representing next entry in the\n+     * ledger.\n+     *\n+     * @return input stream, or null if no more entries\n+     */\n+    private LogRecordWithInputStream nextLogRecord() throws IOException {\n+        return nextLogRecord(reader);\n+    }\n+\n+    private static LogRecordWithInputStream nextLogRecord(LogReader reader) throws IOException {\n+        LogRecordWithDLSN record = reader.readNext(false);\n+\n+        if (null != record) {\n+            return new LogRecordWithInputStream(record);\n+        } else {\n+            record = reader.readNext(false);\n+            if (null != record) {\n+                return new LogRecordWithInputStream(record);\n+            } else {\n+                LOG.debug(\"No record\");\n+                return null;\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public int read() throws IOException {\n+        byte[] b = new byte[1];\n+        if (read(b, 0, 1) != 1) {\n+            return -1;\n+        } else {\n+            return b[0];\n+        }\n+    }\n+\n+    @Override\n+    public int read(byte[] b, int off, int len) throws IOException {\n+        int read = 0;\n+        if (currentLogRecord == null) {\n+            currentLogRecord = nextLogRecord();\n+            if (currentLogRecord == null) {\n+                return read;\n+            }\n+        }\n+\n+        while (read < len) {\n+            int thisread = currentLogRecord.getPayLoadInputStream().read(b, off + read, (len - read));\n+            if (thisread == -1) {\n+                currentLogRecord = nextLogRecord();\n+                if (currentLogRecord == null) {\n+                    return read;\n+                }\n+            } else {\n+                LOG.debug(\"Offset saved = {}, persisted = {}\",\n+                    currentPosition, currentLogRecord.getLogRecord().getTransactionId());\n+                currentPosition += thisread;\n+                read += thisread;\n+            }\n+        }\n+        return read;\n+    }\n+\n+    /**\n+     * Position the reader at the given offset. If we fail to skip to the desired position\n+     * and don't hit end of stream, return false.\n+     *\n+     * @throws com.twitter.distributedlog.exceptions.EndOfStreamException if we attempt to\n+     *         skip past the end of the stream.\n+     */\n+    public boolean skipTo(long position) throws IOException {\n+\n+        // No need to skip anywhere.\n+        if (position == position()) {\n+            return true;\n+        }\n+\n+        LogReader skipReader = dlm.getInputStream(position);\n+        LogRecordWithInputStream logRecord = null;\n+        try {\n+            logRecord = nextLogRecord(skipReader);\n+        } catch (IOException ex) {\n+            skipReader.close();\n+            throw ex;\n+        }\n+\n+        if (null == logRecord) {\n+            return false;\n+        }\n+\n+        // We may end up with a reader positioned *before* the requested position if\n+        // we're near the tail and the writer is still active, or if the desired position\n+        // is not at a log record payload boundary.\n+        // Transaction ID gives us the starting position of the log record. Read ahead\n+        // if necessary.\n+        currentPosition = logRecord.getOffset();\n+        currentLogRecord = logRecord;\n+        LogReader oldReader = reader;\n+        reader = skipReader;\n+\n+        // Close the oldreader after swapping AppendOnlyStreamReader state. Close may fail\n+        // and we need to make sure it leaves AppendOnlyStreamReader in a consistent state.\n+        oldReader.close();\n+\n+        byte[] skipBuffer = new byte[SKIP_BUFFER_SIZE];\n+        while (currentPosition < position) {\n+            long bytesToRead = Math.min(position - currentPosition, SKIP_BUFFER_SIZE);\n+            long bytesRead = read(skipBuffer, 0, (int)bytesToRead);\n+            if (bytesRead < bytesToRead) {\n+                return false;\n+            }\n+        }\n+\n+        return true;\n+    }\n+\n+    public long position() {\n+        return currentPosition;\n+    }\n+}"},{"sha":"aa0aef9b0727d17c8c345ebb5745885ab902d28e","filename":"src/main/java/com/twitter/distributedlog/AppendOnlyStreamWriter.java","status":"added","additions":107,"deletions":0,"changes":107,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAppendOnlyStreamWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAppendOnlyStreamWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAppendOnlyStreamWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,107 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.util.Await;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class AppendOnlyStreamWriter implements Closeable {\n+    static final Logger LOG = LoggerFactory.getLogger(AppendOnlyStreamWriter.class);\n+\n+    // Use a 1-length array to satisfy Java's inner class reference rules. Use primitive\n+    // type because synchronized block is needed anyway.\n+    final long[] syncPos = new long[1];\n+    BKAsyncLogWriter logWriter;\n+    long requestPos = 0;\n+\n+    public AppendOnlyStreamWriter(BKAsyncLogWriter logWriter, long pos) {\n+        LOG.debug(\"initialize at position {}\", pos);\n+        this.logWriter = logWriter;\n+        this.syncPos[0] = pos;\n+        this.requestPos = pos;\n+    }\n+\n+    public Future<DLSN> write(byte[] data) {\n+        requestPos += data.length;\n+        Future<DLSN> writeResult = logWriter.write(new LogRecord(requestPos, data));\n+        return writeResult.addEventListener(new WriteCompleteListener(requestPos));\n+    }\n+\n+    public void force(boolean metadata) throws IOException {\n+        long pos = 0;\n+        try {\n+            pos = Await.result(logWriter.flushAndCommit());\n+        } catch (IOException ioe) {\n+            throw ioe;\n+        } catch (Exception ex) {\n+            LOG.error(\"unexpected exception in AppendOnlyStreamWriter.force \", ex);\n+            throw new UnexpectedException(\"unexpected exception in AppendOnlyStreamWriter.force\", ex);\n+        }\n+        synchronized (syncPos) {\n+            syncPos[0] = pos;\n+        }\n+    }\n+\n+    public long position() {\n+        synchronized (syncPos) {\n+            return syncPos[0];\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        logWriter.closeAndComplete();\n+    }\n+\n+    public void markEndOfStream() throws IOException {\n+        try {\n+            Await.result(logWriter.markEndOfStream());\n+        } catch (IOException ioe) {\n+            throw ioe;\n+        } catch (Exception ex) {\n+            throw new UnexpectedException(\"Mark end of stream hit unexpected exception\", ex);\n+        }\n+    }\n+\n+    class WriteCompleteListener implements FutureEventListener<DLSN> {\n+        private final long position;\n+        public WriteCompleteListener(long position) {\n+            this.position = position;\n+        }\n+        @Override\n+        public void onSuccess(DLSN response) {\n+            synchronized (syncPos) {\n+                if (position > syncPos[0]) {\n+                    syncPos[0] = position;\n+                }\n+            }\n+        }\n+        @Override\n+        public void onFailure(Throwable cause) {\n+            // Handled at the layer above\n+        }\n+    }\n+}"},{"sha":"8e077976f6eb0b5ebe1b198bd7163cb527b3eaa2","filename":"src/main/java/com/twitter/distributedlog/AsyncLogReader.java","status":"added","additions":69,"deletions":0,"changes":69,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncLogReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncLogReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncLogReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,69 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+import com.twitter.util.Future;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+public interface AsyncLogReader extends AsyncCloseable {\n+\n+    /**\n+     * Get stream name that the reader reads from.\n+     *\n+     * @return stream name.\n+     */\n+    public String getStreamName();\n+\n+    /**\n+     * Read the next record from the log stream\n+     *\n+     * @return A promise that when satisfied will contain the Log Record with its DLSN.\n+     */\n+    public Future<LogRecordWithDLSN> readNext();\n+\n+    /**\n+     * Read next <i>numEntries</i> entries. The future is only satisfied with non-empty list\n+     * of entries. It doesn't block until returning exact <i>numEntries</i>. It is a best effort\n+     * call.\n+     *\n+     * @param numEntries\n+     *          num entries\n+     * @return A promise that when satisfied will contain a non-empty list of records with their DLSN.\n+     */\n+    public Future<List<LogRecordWithDLSN>> readBulk(int numEntries);\n+\n+    /**\n+     * Read next <i>numEntries</i> entries in a given <i>waitTime</i>.\n+     * <p>\n+     * The future is satisfied when either reads <i>numEntries</i> entries or reaches <i>waitTime</i>.\n+     * The only exception is if there isn't any new entries written within <i>waitTime</i>, it would\n+     * wait until new entries are available.\n+     *\n+     * @param numEntries\n+     *          max entries to return\n+     * @param waitTime\n+     *          maximum wait time if there are entries already for read\n+     * @param timeUnit\n+     *          wait time unit\n+     * @return A promise that when satisfied will contain a non-empty list of records with their DLSN.\n+     */\n+    public Future<List<LogRecordWithDLSN>> readBulk(int numEntries, long waitTime, TimeUnit timeUnit);\n+}"},{"sha":"e83e3431fbc9b7daffad5398c8a5ce1d3fd0d6d0","filename":"src/main/java/com/twitter/distributedlog/AsyncLogWriter.java","status":"added","additions":70,"deletions":0,"changes":70,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncLogWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncLogWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncLogWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,70 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.io.AsyncAbortable;\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+import com.twitter.util.Future;\n+\n+import java.io.Closeable;\n+import java.util.List;\n+\n+public interface AsyncLogWriter extends AsyncCloseable, AsyncAbortable {\n+\n+    /**\n+     * Get the last committed transaction id.\n+     *\n+     * @return last committed transaction id.\n+     */\n+    public long getLastTxId();\n+\n+    /**\n+     * Write a log record to the stream.\n+     *\n+     * @param record single log record\n+     * @return A Future which contains a DLSN if the record was successfully written\n+     * or an exception if the write fails\n+     */\n+    public Future<DLSN> write(LogRecord record);\n+\n+    /**\n+     * Write log records to the stream in bulk. Each future in the list represents the result of\n+     * one write operation. The size of the result list is equal to the size of the input list.\n+     * Buffers are written in order, and the list of result futures has the same order.\n+     *\n+     * @param record set of log records\n+     * @return A Future which contains a list of Future DLSNs if the record was successfully written\n+     * or an exception if the operation fails.\n+     */\n+    public Future<List<Future<DLSN>>> writeBulk(List<LogRecord> record);\n+\n+    /**\n+     * Truncate the log until <i>dlsn</i>.\n+     *\n+     * @param dlsn\n+     *          dlsn to truncate until.\n+     * @return A Future indicates whether the operation succeeds or not, or an exception\n+     * if the truncation fails.\n+     */\n+    public Future<Boolean> truncate(DLSN dlsn);\n+\n+    /**\n+     * Get the name of the stream this writer writes data to\n+     */\n+    public String getStreamName();\n+}"},{"sha":"e7cb601c8c53fb1a1f3b07e7547fe9e2205c42f8","filename":"src/main/java/com/twitter/distributedlog/AsyncNotification.java","status":"added","additions":30,"deletions":0,"changes":30,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncNotification.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncNotification.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FAsyncNotification.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,30 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+public interface AsyncNotification {\n+    /**\n+     * Triggered when the background activity encounters an exception\n+     */\n+    void notifyOnError();\n+\n+    /**\n+     *  Triggered when the background activity completes an operation\n+     */\n+    void notifyOnOperationComplete();\n+}"},{"sha":"83167aba47ad119a353cc97bc45a658ce0d6e7cf","filename":"src/main/java/com/twitter/distributedlog/BKAbstractLogWriter.java","status":"added","additions":553,"deletions":0,"changes":553,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAbstractLogWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAbstractLogWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAbstractLogWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,553 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.exceptions.AlreadyClosedException;\n+import com.twitter.distributedlog.exceptions.LockingException;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.io.Abortable;\n+import com.twitter.distributedlog.io.Abortables;\n+import com.twitter.distributedlog.io.AsyncAbortable;\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.PermitManager;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.util.Function;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.runtime.AbstractFunction0;\n+import scala.runtime.AbstractFunction1;\n+import scala.runtime.BoxedUnit;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+abstract class BKAbstractLogWriter implements Closeable, AsyncCloseable, Abortable, AsyncAbortable {\n+    static final Logger LOG = LoggerFactory.getLogger(BKAbstractLogWriter.class);\n+\n+    protected final DistributedLogConfiguration conf;\n+    private final DynamicDistributedLogConfiguration dynConf;\n+    protected final BKDistributedLogManager bkDistributedLogManager;\n+\n+    // States\n+    private Promise<Void> closePromise = null;\n+    private boolean forceRolling = false;\n+    private boolean forceRecovery = false;\n+\n+    // Truncation Related\n+    private Future<List<LogSegmentMetadata>> lastTruncationAttempt = null;\n+    @VisibleForTesting\n+    private Long minTimestampToKeepOverride = null;\n+\n+    // Log Segment Writers\n+    protected BKLogSegmentWriter segmentWriter = null;\n+    protected Future<BKLogSegmentWriter> segmentWriterFuture = null;\n+    protected BKLogSegmentWriter allocatedSegmentWriter = null;\n+    protected BKLogWriteHandler writeHandler = null;\n+\n+    BKAbstractLogWriter(DistributedLogConfiguration conf,\n+                        DynamicDistributedLogConfiguration dynConf,\n+                        BKDistributedLogManager bkdlm) {\n+        this.conf = conf;\n+        this.dynConf = dynConf;\n+        this.bkDistributedLogManager = bkdlm;\n+        LOG.debug(\"Initial retention period for {} : {}\", bkdlm.getStreamName(),\n+                TimeUnit.MILLISECONDS.convert(dynConf.getRetentionPeriodHours(), TimeUnit.HOURS));\n+    }\n+\n+    // manage write handler\n+\n+    synchronized protected BKLogWriteHandler getCachedWriteHandler() {\n+        return writeHandler;\n+    }\n+\n+    protected BKLogWriteHandler getWriteHandler() throws IOException {\n+        BKLogWriteHandler writeHandler = createAndCacheWriteHandler();\n+        writeHandler.checkMetadataException();\n+        return writeHandler;\n+    }\n+\n+    protected BKLogWriteHandler createAndCacheWriteHandler()\n+            throws IOException {\n+        synchronized (this) {\n+            if (writeHandler != null) {\n+                return writeHandler;\n+            }\n+        }\n+        // This code path will be executed when the handler is not set or has been closed\n+        // due to forceRecovery during testing\n+        BKLogWriteHandler newHandler =\n+                FutureUtils.result(bkDistributedLogManager.asyncCreateWriteHandler(false));\n+        boolean success = false;\n+        try {\n+            synchronized (this) {\n+                if (writeHandler == null) {\n+                    writeHandler = newHandler;\n+                    success = true;\n+                }\n+                return writeHandler;\n+            }\n+        } finally {\n+            if (!success) {\n+                newHandler.asyncAbort();\n+            }\n+        }\n+    }\n+\n+    // manage log segment writers\n+\n+    protected synchronized BKLogSegmentWriter getCachedLogWriter() {\n+        return segmentWriter;\n+    }\n+\n+    protected synchronized Future<BKLogSegmentWriter> getCachedLogWriterFuture() {\n+        return segmentWriterFuture;\n+    }\n+\n+    protected synchronized void cacheLogWriter(BKLogSegmentWriter logWriter) {\n+        this.segmentWriter = logWriter;\n+        this.segmentWriterFuture = Future.value(logWriter);\n+    }\n+\n+    protected synchronized BKLogSegmentWriter removeCachedLogWriter() {\n+        try {\n+            return segmentWriter;\n+        } finally {\n+            segmentWriter = null;\n+            segmentWriterFuture = null;\n+        }\n+    }\n+\n+    protected synchronized BKLogSegmentWriter getAllocatedLogWriter() {\n+        return allocatedSegmentWriter;\n+    }\n+\n+    protected synchronized void cacheAllocatedLogWriter(BKLogSegmentWriter logWriter) {\n+        this.allocatedSegmentWriter = logWriter;\n+    }\n+\n+    protected synchronized BKLogSegmentWriter removeAllocatedLogWriter() {\n+        try {\n+            return allocatedSegmentWriter;\n+        } finally {\n+            allocatedSegmentWriter = null;\n+        }\n+    }\n+\n+    private Future<Void> asyncCloseAndComplete(boolean shouldThrow) {\n+        BKLogSegmentWriter segmentWriter = getCachedLogWriter();\n+        BKLogWriteHandler writeHandler = getCachedWriteHandler();\n+        if (null != segmentWriter && null != writeHandler) {\n+            cancelTruncation();\n+            Promise<Void> completePromise = new Promise<Void>();\n+            asyncCloseAndComplete(segmentWriter, writeHandler, completePromise, shouldThrow);\n+            return completePromise;\n+        } else {\n+            return closeNoThrow();\n+        }\n+    }\n+\n+    private void asyncCloseAndComplete(final BKLogSegmentWriter segmentWriter,\n+                                       final BKLogWriteHandler writeHandler,\n+                                       final Promise<Void> completePromise,\n+                                       final boolean shouldThrow) {\n+        writeHandler.completeAndCloseLogSegment(segmentWriter)\n+                .addEventListener(new FutureEventListener<LogSegmentMetadata>() {\n+                    @Override\n+                    public void onSuccess(LogSegmentMetadata segment) {\n+                        removeCachedLogWriter();\n+                        complete(null);\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        LOG.error(\"Completing Log segments encountered exception\", cause);\n+                        complete(cause);\n+                    }\n+\n+                    private void complete(final Throwable cause) {\n+                        closeNoThrow().ensure(new AbstractFunction0<BoxedUnit>() {\n+                            @Override\n+                            public BoxedUnit apply() {\n+                                if (null != cause && shouldThrow) {\n+                                    FutureUtils.setException(completePromise, cause);\n+                                } else {\n+                                    FutureUtils.setValue(completePromise, null);\n+                                }\n+                                return BoxedUnit.UNIT;\n+                            }\n+                        });\n+                    }\n+                });\n+    }\n+\n+    @VisibleForTesting\n+    void closeAndComplete() throws IOException {\n+        FutureUtils.result(asyncCloseAndComplete(true));\n+    }\n+\n+    protected Future<Void> asyncCloseAndComplete() {\n+        return asyncCloseAndComplete(true);\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        FutureUtils.result(asyncClose());\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        return asyncCloseAndComplete(false);\n+    }\n+\n+    /**\n+     * Close the writer and release all the underlying resources\n+     */\n+    protected Future<Void> closeNoThrow() {\n+        Promise<Void> closeFuture;\n+        synchronized (this) {\n+            if (null != closePromise) {\n+                return closePromise;\n+            }\n+            closeFuture = closePromise = new Promise<Void>();\n+        }\n+        cancelTruncation();\n+        Utils.closeSequence(bkDistributedLogManager.getScheduler(),\n+                true, /** ignore close errors **/\n+                getCachedLogWriter(),\n+                getAllocatedLogWriter(),\n+                getCachedWriteHandler()\n+        ).proxyTo(closeFuture);\n+        return closeFuture;\n+    }\n+\n+    @Override\n+    public void abort() throws IOException {\n+        FutureUtils.result(asyncAbort());\n+    }\n+\n+    @Override\n+    public Future<Void> asyncAbort() {\n+        Promise<Void> closeFuture;\n+        synchronized (this) {\n+            if (null != closePromise) {\n+                return closePromise;\n+            }\n+            closeFuture = closePromise = new Promise<Void>();\n+        }\n+        cancelTruncation();\n+        Abortables.abortSequence(bkDistributedLogManager.getScheduler(),\n+                getCachedLogWriter(),\n+                getAllocatedLogWriter(),\n+                getCachedWriteHandler()).proxyTo(closeFuture);\n+        return closeFuture;\n+    }\n+\n+    // used by sync writer\n+    protected BKLogSegmentWriter getLedgerWriter(final long startTxId,\n+                                                 final boolean allowMaxTxID)\n+            throws IOException {\n+        Future<BKLogSegmentWriter> logSegmentWriterFuture = asyncGetLedgerWriter(true);\n+        BKLogSegmentWriter logSegmentWriter = null;\n+        if (null != logSegmentWriterFuture) {\n+            logSegmentWriter = FutureUtils.result(logSegmentWriterFuture);\n+        }\n+        if (null == logSegmentWriter || (shouldStartNewSegment(logSegmentWriter) || forceRolling)) {\n+            logSegmentWriter = FutureUtils.result(rollLogSegmentIfNecessary(\n+                    logSegmentWriter, startTxId, true /* bestEffort */, allowMaxTxID));\n+        }\n+        return logSegmentWriter;\n+    }\n+\n+    // used by async writer\n+    synchronized protected Future<BKLogSegmentWriter> asyncGetLedgerWriter(boolean resetOnError) {\n+        final BKLogSegmentWriter ledgerWriter = getCachedLogWriter();\n+        Future<BKLogSegmentWriter> ledgerWriterFuture = getCachedLogWriterFuture();\n+        if (null == ledgerWriterFuture || null == ledgerWriter) {\n+            return null;\n+        }\n+\n+        // Handle the case where the last call to write actually caused an error in the log\n+        if ((ledgerWriter.isLogSegmentInError() || forceRecovery) && resetOnError) {\n+            // Close the ledger writer so that we will recover and start a new log segment\n+            Future<Void> closeFuture;\n+            if (ledgerWriter.isLogSegmentInError()) {\n+                closeFuture = ledgerWriter.asyncAbort();\n+            } else {\n+                closeFuture = ledgerWriter.asyncClose();\n+            }\n+            return closeFuture.flatMap(\n+                    new AbstractFunction1<Void, Future<BKLogSegmentWriter>>() {\n+                @Override\n+                public Future<BKLogSegmentWriter> apply(Void result) {\n+                    removeCachedLogWriter();\n+\n+                    if (ledgerWriter.isLogSegmentInError()) {\n+                        return Future.value(null);\n+                    }\n+\n+                    BKLogWriteHandler writeHandler;\n+                    try {\n+                        writeHandler = getWriteHandler();\n+                    } catch (IOException e) {\n+                        return Future.exception(e);\n+                    }\n+                    if (null != writeHandler && forceRecovery) {\n+                        return writeHandler.completeAndCloseLogSegment(ledgerWriter)\n+                                .map(new AbstractFunction1<LogSegmentMetadata, BKLogSegmentWriter>() {\n+                            @Override\n+                            public BKLogSegmentWriter apply(LogSegmentMetadata completedLogSegment) {\n+                                return null;\n+                            }\n+                        });\n+                    } else {\n+                        return Future.value(null);\n+                    }\n+                }\n+            });\n+        } else {\n+            return ledgerWriterFuture;\n+        }\n+    }\n+\n+    boolean shouldStartNewSegment(BKLogSegmentWriter ledgerWriter) throws IOException {\n+        BKLogWriteHandler writeHandler = getWriteHandler();\n+        return null == ledgerWriter || writeHandler.shouldStartNewSegment(ledgerWriter) || forceRolling;\n+    }\n+\n+    private void truncateLogSegmentsIfNecessary(BKLogWriteHandler writeHandler) {\n+        boolean truncationEnabled = false;\n+\n+        long minTimestampToKeep = 0;\n+\n+        long retentionPeriodInMillis = TimeUnit.MILLISECONDS.convert(dynConf.getRetentionPeriodHours(), TimeUnit.HOURS);\n+        if (retentionPeriodInMillis > 0) {\n+            minTimestampToKeep = Utils.nowInMillis() - retentionPeriodInMillis;\n+            truncationEnabled = true;\n+        }\n+\n+        if (null != minTimestampToKeepOverride) {\n+            minTimestampToKeep = minTimestampToKeepOverride;\n+            truncationEnabled = true;\n+        }\n+\n+        // skip scheduling if there is task that's already running\n+        //\n+        if (truncationEnabled && ((lastTruncationAttempt == null) || lastTruncationAttempt.isDefined())) {\n+            lastTruncationAttempt = writeHandler.purgeLogSegmentsOlderThanTimestamp(minTimestampToKeep);\n+        }\n+    }\n+\n+    private Future<BKLogSegmentWriter> asyncStartNewLogSegment(final BKLogWriteHandler writeHandler,\n+                                                               final long startTxId,\n+                                                               final boolean allowMaxTxID) {\n+        return writeHandler.recoverIncompleteLogSegments()\n+                .flatMap(new AbstractFunction1<Long, Future<BKLogSegmentWriter>>() {\n+            @Override\n+            public Future<BKLogSegmentWriter> apply(Long lastTxId) {\n+                return writeHandler.asyncStartLogSegment(startTxId, false, allowMaxTxID)\n+                        .onSuccess(new AbstractFunction1<BKLogSegmentWriter, BoxedUnit>() {\n+                    @Override\n+                    public BoxedUnit apply(BKLogSegmentWriter newSegmentWriter) {\n+                        cacheLogWriter(newSegmentWriter);\n+                        return BoxedUnit.UNIT;\n+                    }\n+                });\n+            }\n+        });\n+    }\n+\n+    private Future<BKLogSegmentWriter> closeOldLogSegmentAndStartNewOneWithPermit(\n+            final BKLogSegmentWriter oldSegmentWriter,\n+            final BKLogWriteHandler writeHandler,\n+            final long startTxId,\n+            final boolean bestEffort,\n+            final boolean allowMaxTxID) {\n+        final PermitManager.Permit switchPermit = bkDistributedLogManager.getLogSegmentRollingPermitManager().acquirePermit();\n+        if (switchPermit.isAllowed()) {\n+            return closeOldLogSegmentAndStartNewOne(\n+                    oldSegmentWriter,\n+                    writeHandler,\n+                    startTxId,\n+                    bestEffort,\n+                    allowMaxTxID\n+            ).rescue(new Function<Throwable, Future<BKLogSegmentWriter>>() {\n+                @Override\n+                public Future<BKLogSegmentWriter> apply(Throwable cause) {\n+                    if (cause instanceof LockingException) {\n+                        LOG.warn(\"We lost lock during completeAndClose log segment for {}. Disable ledger rolling until it is recovered : \",\n+                                writeHandler.getFullyQualifiedName(), cause);\n+                        bkDistributedLogManager.getLogSegmentRollingPermitManager().disallowObtainPermits(switchPermit);\n+                        return Future.value(oldSegmentWriter);\n+                    } else if (cause instanceof ZKException) {\n+                        ZKException zke = (ZKException) cause;\n+                        if (ZKException.isRetryableZKException(zke)) {\n+                            LOG.warn(\"Encountered zookeeper connection issues during completeAndClose log segment for {}.\" +\n+                                    \" Disable ledger rolling until it is recovered : {}\", writeHandler.getFullyQualifiedName(),\n+                                    zke.getKeeperExceptionCode());\n+                            bkDistributedLogManager.getLogSegmentRollingPermitManager().disallowObtainPermits(switchPermit);\n+                            return Future.value(oldSegmentWriter);\n+                        }\n+                    }\n+                    return Future.exception(cause);\n+                }\n+            }).ensure(new AbstractFunction0<BoxedUnit>() {\n+                @Override\n+                public BoxedUnit apply() {\n+                    bkDistributedLogManager.getLogSegmentRollingPermitManager()\n+                            .releasePermit(switchPermit);\n+                    return BoxedUnit.UNIT;\n+                }\n+            });\n+        } else {\n+            bkDistributedLogManager.getLogSegmentRollingPermitManager().releasePermit(switchPermit);\n+            return Future.value(oldSegmentWriter);\n+        }\n+    }\n+\n+    private Future<BKLogSegmentWriter> closeOldLogSegmentAndStartNewOne(\n+            final BKLogSegmentWriter oldSegmentWriter,\n+            final BKLogWriteHandler writeHandler,\n+            final long startTxId,\n+            final boolean bestEffort,\n+            final boolean allowMaxTxID) {\n+        // we switch only when we could allocate a new log segment.\n+        BKLogSegmentWriter newSegmentWriter = getAllocatedLogWriter();\n+        if (null == newSegmentWriter) {\n+            if (LOG.isDebugEnabled()) {\n+                LOG.debug(\"Allocating a new log segment from {} for {}.\", startTxId,\n+                        writeHandler.getFullyQualifiedName());\n+            }\n+            return writeHandler.asyncStartLogSegment(startTxId, bestEffort, allowMaxTxID)\n+                    .flatMap(new AbstractFunction1<BKLogSegmentWriter, Future<BKLogSegmentWriter>>() {\n+                        @Override\n+                        public Future<BKLogSegmentWriter> apply(BKLogSegmentWriter newSegmentWriter) {\n+                            if (null == newSegmentWriter) {\n+                                if (bestEffort) {\n+                                    return Future.value(oldSegmentWriter);\n+                                } else {\n+                                    return Future.exception(\n+                                            new UnexpectedException(\"StartLogSegment returns null for bestEffort rolling\"));\n+                                }\n+                            }\n+                            cacheAllocatedLogWriter(newSegmentWriter);\n+                            if (LOG.isDebugEnabled()) {\n+                                LOG.debug(\"Allocated a new log segment from {} for {}.\", startTxId,\n+                                        writeHandler.getFullyQualifiedName());\n+                            }\n+                            return completeOldSegmentAndCacheNewLogSegmentWriter(oldSegmentWriter, newSegmentWriter);\n+                        }\n+                    });\n+        } else {\n+            return completeOldSegmentAndCacheNewLogSegmentWriter(oldSegmentWriter, newSegmentWriter);\n+        }\n+    }\n+\n+    private Future<BKLogSegmentWriter> completeOldSegmentAndCacheNewLogSegmentWriter(\n+            BKLogSegmentWriter oldSegmentWriter,\n+            final BKLogSegmentWriter newSegmentWriter) {\n+        final Promise<BKLogSegmentWriter> completePromise = new Promise<BKLogSegmentWriter>();\n+        // complete the old log segment\n+        writeHandler.completeAndCloseLogSegment(oldSegmentWriter)\n+                .addEventListener(new FutureEventListener<LogSegmentMetadata>() {\n+\n+                    @Override\n+                    public void onSuccess(LogSegmentMetadata value) {\n+                        cacheLogWriter(newSegmentWriter);\n+                        removeAllocatedLogWriter();\n+                        FutureUtils.setValue(completePromise, newSegmentWriter);\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        FutureUtils.setException(completePromise, cause);\n+                    }\n+                });\n+        return completePromise;\n+    }\n+\n+    synchronized protected Future<BKLogSegmentWriter> rollLogSegmentIfNecessary(\n+            final BKLogSegmentWriter segmentWriter,\n+            long startTxId,\n+            boolean bestEffort,\n+            boolean allowMaxTxID) {\n+        final BKLogWriteHandler writeHandler;\n+        try {\n+            writeHandler = getWriteHandler();\n+        } catch (IOException e) {\n+            return Future.exception(e);\n+        }\n+        Future<BKLogSegmentWriter> rollPromise;\n+        if (null != segmentWriter && (writeHandler.shouldStartNewSegment(segmentWriter) || forceRolling)) {\n+            rollPromise = closeOldLogSegmentAndStartNewOneWithPermit(\n+                    segmentWriter, writeHandler, startTxId, bestEffort, allowMaxTxID);\n+        } else if (null == segmentWriter) {\n+            rollPromise = asyncStartNewLogSegment(writeHandler, startTxId, allowMaxTxID);\n+        } else {\n+            rollPromise = Future.value(segmentWriter);\n+        }\n+        return rollPromise.map(new AbstractFunction1<BKLogSegmentWriter, BKLogSegmentWriter>() {\n+            @Override\n+            public BKLogSegmentWriter apply(BKLogSegmentWriter newSegmentWriter) {\n+                if (segmentWriter == newSegmentWriter) {\n+                    return newSegmentWriter;\n+                }\n+                truncateLogSegmentsIfNecessary(writeHandler);\n+                return newSegmentWriter;\n+            }\n+        });\n+    }\n+\n+    protected synchronized void checkClosedOrInError(String operation) throws AlreadyClosedException {\n+        if (null != closePromise) {\n+            LOG.error(\"Executing \" + operation + \" on already closed Log Writer\");\n+            throw new AlreadyClosedException(\"Executing \" + operation + \" on already closed Log Writer\");\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void setForceRolling(boolean forceRolling) {\n+        this.forceRolling = forceRolling;\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void overRideMinTimeStampToKeep(Long minTimestampToKeepOverride) {\n+        this.minTimestampToKeepOverride = minTimestampToKeepOverride;\n+    }\n+\n+    protected synchronized void cancelTruncation() {\n+        if (null != lastTruncationAttempt) {\n+            FutureUtils.cancel(lastTruncationAttempt);\n+            lastTruncationAttempt = null;\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void setForceRecovery(boolean forceRecovery) {\n+        this.forceRecovery = forceRecovery;\n+    }\n+\n+}"},{"sha":"ef055a0173550956ac5bbaac159238ab87028bc2","filename":"src/main/java/com/twitter/distributedlog/BKAsyncLogReaderDLSN.java","status":"added","additions":686,"deletions":0,"changes":686,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,686 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Optional;\n+import com.google.common.base.Stopwatch;\n+import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.EndOfStreamException;\n+import com.twitter.distributedlog.exceptions.IdleReaderException;\n+import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.exceptions.ReadCancelledException;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.injector.AsyncFailureInjector;\n+import com.twitter.distributedlog.injector.AsyncRandomFailureInjector;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import com.twitter.util.Throw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import org.apache.bookkeeper.stats.Counter;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.zookeeper.Watcher;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.Function1;\n+import scala.runtime.AbstractFunction1;\n+\n+/**\n+ * BookKeeper based {@link AsyncLogReader} implementation.\n+ *\n+ * <h3>Metrics</h3>\n+ * All the metrics are exposed under `async_reader`.\n+ * <ul>\n+ * <li> `async_reader`/future_set: opstats. time spent on satisfying futures of read requests.\n+ * if it is high, it means that the caller takes time on processing the result of read requests.\n+ * The side effect is blocking consequent reads.\n+ * <li> `async_reader`/schedule: opstats. time spent on scheduling next reads.\n+ * <li> `async_reader`/background_read: opstats. time spent on background reads.\n+ * <li> `async_reader`/read_next_exec: opstats. time spent on executing {@link #readNext()}.\n+ * <li> `async_reader`/time_between_read_next: opstats. time spent on between two consequent {@link #readNext()}.\n+ * if it is high, it means that the caller is slowing down on calling {@link #readNext()}.\n+ * <li> `async_reader`/delay_until_promise_satisfied: opstats. total latency for the read requests.\n+ * <li> `async_reader`/idle_reader_error: counter. the number idle reader errors.\n+ * </ul>\n+ */\n+class BKAsyncLogReaderDLSN implements ZooKeeperClient.ZooKeeperSessionExpireNotifier, AsyncLogReader, Runnable, AsyncNotification {\n+    static final Logger LOG = LoggerFactory.getLogger(BKAsyncLogReaderDLSN.class);\n+\n+    private static final Function1<List<LogRecordWithDLSN>, LogRecordWithDLSN> READ_NEXT_MAP_FUNCTION =\n+            new AbstractFunction1<List<LogRecordWithDLSN>, LogRecordWithDLSN>() {\n+                @Override\n+                public LogRecordWithDLSN apply(List<LogRecordWithDLSN> records) {\n+                    return records.get(0);\n+                }\n+            };\n+\n+    protected final BKDistributedLogManager bkDistributedLogManager;\n+    protected final BKLogReadHandler bkLedgerManager;\n+    private Watcher sessionExpireWatcher = null;\n+    private final AtomicReference<Throwable> lastException = new AtomicReference<Throwable>();\n+    private final ScheduledExecutorService executorService;\n+    private final ConcurrentLinkedQueue<PendingReadRequest> pendingRequests = new ConcurrentLinkedQueue<PendingReadRequest>();\n+    private final AtomicLong scheduleCount = new AtomicLong(0);\n+    final private Stopwatch scheduleDelayStopwatch;\n+    final private Stopwatch readNextDelayStopwatch;\n+    private DLSN startDLSN;\n+    private boolean readAheadStarted = false;\n+    private int lastPosition = 0;\n+    private final boolean positionGapDetectionEnabled;\n+    private final int idleErrorThresholdMillis;\n+    private final ScheduledFuture<?> idleReaderTimeoutTask;\n+    private ScheduledFuture<?> backgroundScheduleTask = null;\n+\n+    protected Promise<Void> closeFuture = null;\n+\n+    private boolean lockStream = false;\n+\n+    private boolean disableReadAheadZKNotification = false;\n+\n+    private final boolean returnEndOfStreamRecord;\n+\n+    private final Runnable BACKGROUND_READ_SCHEDULER = new Runnable() {\n+        @Override\n+        public void run() {\n+            synchronized (scheduleCount) {\n+                backgroundScheduleTask = null;\n+            }\n+            scheduleBackgroundRead();\n+        }\n+    };\n+\n+    // Failure Injector\n+    private final AsyncFailureInjector failureInjector;\n+    private boolean disableProcessingReadRequests = false;\n+\n+    // Stats\n+    private final OpStatsLogger readNextExecTime;\n+    private final OpStatsLogger delayUntilPromiseSatisfied;\n+    private final OpStatsLogger timeBetweenReadNexts;\n+    private final OpStatsLogger futureSetLatency;\n+    private final OpStatsLogger scheduleLatency;\n+    private final OpStatsLogger backgroundReaderRunTime;\n+    private final Counter idleReaderCheckCount;\n+    private final Counter idleReaderCheckIdleReadRequestCount;\n+    private final Counter idleReaderCheckIdleReadAheadCount;\n+    private final Counter idleReaderError;\n+\n+    private class PendingReadRequest {\n+        private final Stopwatch enqueueTime;\n+        private final int numEntries;\n+        private final List<LogRecordWithDLSN> records;\n+        private final Promise<List<LogRecordWithDLSN>> promise;\n+        private final long deadlineTime;\n+        private final TimeUnit deadlineTimeUnit;\n+\n+        PendingReadRequest(int numEntries,\n+                           long deadlineTime,\n+                           TimeUnit deadlineTimeUnit) {\n+            this.numEntries = numEntries;\n+            this.enqueueTime = Stopwatch.createStarted();\n+            // optimize the space usage for single read.\n+            if (numEntries == 1) {\n+                this.records = new ArrayList<LogRecordWithDLSN>(1);\n+            } else {\n+                this.records = new ArrayList<LogRecordWithDLSN>();\n+            }\n+            this.promise = new Promise<List<LogRecordWithDLSN>>();\n+            this.deadlineTime = deadlineTime;\n+            this.deadlineTimeUnit = deadlineTimeUnit;\n+        }\n+\n+        Promise<List<LogRecordWithDLSN>> getPromise() {\n+            return promise;\n+        }\n+\n+        long elapsedSinceEnqueue(TimeUnit timeUnit) {\n+            return enqueueTime.elapsed(timeUnit);\n+        }\n+\n+        void setException(Throwable throwable) {\n+            Stopwatch stopwatch = Stopwatch.createStarted();\n+            if (promise.updateIfEmpty(new Throw<List<LogRecordWithDLSN>>(throwable))) {\n+                futureSetLatency.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+                delayUntilPromiseSatisfied.registerFailedEvent(enqueueTime.elapsed(TimeUnit.MICROSECONDS));\n+            }\n+        }\n+\n+        boolean hasReadRecords() {\n+            return records.size() > 0;\n+        }\n+\n+        boolean hasReadEnoughRecords() {\n+            return records.size() >= numEntries;\n+        }\n+\n+        long getRemainingWaitTime() {\n+            if (deadlineTime <= 0L) {\n+                return 0L;\n+            }\n+            return deadlineTime - elapsedSinceEnqueue(deadlineTimeUnit);\n+        }\n+\n+        void addRecord(LogRecordWithDLSN record) {\n+            records.add(record);\n+        }\n+\n+        void complete() {\n+            if (LOG.isTraceEnabled()) {\n+                LOG.trace(\"{} : Satisfied promise with {} records\", bkLedgerManager.getFullyQualifiedName(), records.size());\n+            }\n+            delayUntilPromiseSatisfied.registerSuccessfulEvent(enqueueTime.stop().elapsed(TimeUnit.MICROSECONDS));\n+            Stopwatch stopwatch = Stopwatch.createStarted();\n+            promise.setValue(records);\n+            futureSetLatency.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+        }\n+    }\n+\n+    BKAsyncLogReaderDLSN(BKDistributedLogManager bkdlm,\n+                         ScheduledExecutorService executorService,\n+                         OrderedScheduler lockStateExecutor,\n+                         DLSN startDLSN,\n+                         Optional<String> subscriberId,\n+                         boolean returnEndOfStreamRecord,\n+                         boolean deserializeRecordSet,\n+                         StatsLogger statsLogger) {\n+        this.bkDistributedLogManager = bkdlm;\n+        this.executorService = executorService;\n+        this.bkLedgerManager = bkDistributedLogManager.createReadHandler(subscriberId,\n+                lockStateExecutor, this, deserializeRecordSet, true);\n+        sessionExpireWatcher = this.bkLedgerManager.registerExpirationHandler(this);\n+        LOG.debug(\"Starting async reader at {}\", startDLSN);\n+        this.startDLSN = startDLSN;\n+        this.scheduleDelayStopwatch = Stopwatch.createUnstarted();\n+        this.readNextDelayStopwatch = Stopwatch.createStarted();\n+        this.positionGapDetectionEnabled = bkdlm.getConf().getPositionGapDetectionEnabled();\n+        this.idleErrorThresholdMillis = bkdlm.getConf().getReaderIdleErrorThresholdMillis();\n+        this.returnEndOfStreamRecord = returnEndOfStreamRecord;\n+\n+        // Failure Injection\n+        this.failureInjector = AsyncRandomFailureInjector.newBuilder()\n+                .injectDelays(bkdlm.getConf().getEIInjectReadAheadDelay(),\n+                              bkdlm.getConf().getEIInjectReadAheadDelayPercent(),\n+                              bkdlm.getConf().getEIInjectMaxReadAheadDelayMs())\n+                .injectErrors(false, 10)\n+                .injectStops(bkdlm.getConf().getEIInjectReadAheadStall(), 10)\n+                .injectCorruption(bkdlm.getConf().getEIInjectReadAheadBrokenEntries())\n+                .build();\n+\n+        // Stats\n+        StatsLogger asyncReaderStatsLogger = statsLogger.scope(\"async_reader\");\n+        futureSetLatency = asyncReaderStatsLogger.getOpStatsLogger(\"future_set\");\n+        scheduleLatency = asyncReaderStatsLogger.getOpStatsLogger(\"schedule\");\n+        backgroundReaderRunTime = asyncReaderStatsLogger.getOpStatsLogger(\"background_read\");\n+        readNextExecTime = asyncReaderStatsLogger.getOpStatsLogger(\"read_next_exec\");\n+        timeBetweenReadNexts = asyncReaderStatsLogger.getOpStatsLogger(\"time_between_read_next\");\n+        delayUntilPromiseSatisfied = asyncReaderStatsLogger.getOpStatsLogger(\"delay_until_promise_satisfied\");\n+        idleReaderError = asyncReaderStatsLogger.getCounter(\"idle_reader_error\");\n+        idleReaderCheckCount = asyncReaderStatsLogger.getCounter(\"idle_reader_check_total\");\n+        idleReaderCheckIdleReadRequestCount = asyncReaderStatsLogger.getCounter(\"idle_reader_check_idle_read_requests\");\n+        idleReaderCheckIdleReadAheadCount = asyncReaderStatsLogger.getCounter(\"idle_reader_check_idle_readahead\");\n+\n+        // Lock the stream if requested. The lock will be released when the reader is closed.\n+        this.lockStream = false;\n+        this.idleReaderTimeoutTask = scheduleIdleReaderTaskIfNecessary();\n+    }\n+\n+    @Override\n+    public void notifySessionExpired() {\n+        // ZK Session notification is an indication to check if this has resulted in a fatal error\n+        // of the underlying reader, in itself this reader doesnt error out unless the underlying\n+        // reader has hit an error\n+        scheduleBackgroundRead();\n+    }\n+\n+    private ScheduledFuture<?> scheduleIdleReaderTaskIfNecessary() {\n+        if (idleErrorThresholdMillis < Integer.MAX_VALUE) {\n+            // Dont run the task more than once every seconds (for sanity)\n+            long period = Math.max(idleErrorThresholdMillis / 10, 1000);\n+            // Except when idle reader threshold is less than a second (tests?)\n+            period = Math.min(period, idleErrorThresholdMillis / 5);\n+\n+            return executorService.scheduleAtFixedRate(new Runnable() {\n+                @Override\n+                public void run() {\n+                    PendingReadRequest nextRequest = pendingRequests.peek();\n+\n+                    idleReaderCheckCount.inc();\n+                    if (null == nextRequest) {\n+                        return;\n+                    }\n+\n+                    idleReaderCheckIdleReadRequestCount.inc();\n+                    if (nextRequest.elapsedSinceEnqueue(TimeUnit.MILLISECONDS) < idleErrorThresholdMillis) {\n+                        return;\n+                    }\n+\n+                    ReadAheadCache cache = bkLedgerManager.getReadAheadCache();\n+\n+                    // read request has been idle\n+                    //   - cache has records but read request are idle,\n+                    //     that means notification was missed between readahead and reader.\n+                    //   - cache is empty and readahead is idle (no records added for a long time)\n+                    idleReaderCheckIdleReadAheadCount.inc();\n+                    if (cache.getNumCachedRecords() <= 0\n+                            && !cache.isReadAheadIdle(idleErrorThresholdMillis, TimeUnit.MILLISECONDS)) {\n+                        return;\n+                    }\n+\n+                    idleReaderError.inc();\n+                    IdleReaderException ire = new IdleReaderException(\"Reader on stream \"\n+                            + bkLedgerManager.getFullyQualifiedName()\n+                            + \" is idle for \" + idleErrorThresholdMillis +\" ms\");\n+                    setLastException(ire);\n+                    // cancel all pending reads directly rather than notifying on error\n+                    // because idle reader could happen on idle read requests that usually means something wrong\n+                    // in scheduling reads\n+                    cancelAllPendingReads(ire);\n+                }\n+            }, period, period, TimeUnit.MILLISECONDS);\n+        }\n+\n+        return null;\n+    }\n+\n+    protected synchronized void setStartDLSN(DLSN fromDLSN) throws UnexpectedException {\n+        if (readAheadStarted) {\n+            throw new UnexpectedException(\"Could't reset from dlsn after reader already starts reading.\");\n+        }\n+        startDLSN = fromDLSN;\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized DLSN getStartDLSN() {\n+        return startDLSN;\n+    }\n+\n+    public Future<Void> lockStream() {\n+        this.lockStream = true;\n+        return bkLedgerManager.lockStream();\n+    }\n+\n+    private boolean checkClosedOrInError(String operation) {\n+        if (null == lastException.get()) {\n+            try {\n+                if (null != bkLedgerManager && null != bkLedgerManager.readAheadWorker) {\n+                    bkLedgerManager.readAheadWorker.checkClosedOrInError();\n+                }\n+\n+                bkDistributedLogManager.checkClosedOrInError(operation);\n+            } catch (IOException exc) {\n+                setLastException(exc);\n+            }\n+        }\n+\n+        if (lockStream) {\n+            try {\n+                bkLedgerManager.checkReadLock();\n+            } catch (IOException ex) {\n+                setLastException(ex);\n+            }\n+        }\n+\n+        if (null != lastException.get()) {\n+            LOG.trace(\"Cancelling pending reads\");\n+            cancelAllPendingReads(lastException.get());\n+            return true;\n+        }\n+\n+        return false;\n+    }\n+\n+    private void setLastException(IOException exc) {\n+        lastException.compareAndSet(null, exc);\n+    }\n+\n+    @Override\n+    public String getStreamName() {\n+        return bkDistributedLogManager.getStreamName();\n+    }\n+\n+    /**\n+     * @return A promise that when satisfied will contain the Log Record with its DLSN.\n+     */\n+    @Override\n+    public synchronized Future<LogRecordWithDLSN> readNext() {\n+        return readInternal(1, 0, TimeUnit.MILLISECONDS).map(READ_NEXT_MAP_FUNCTION);\n+    }\n+\n+    public synchronized Future<List<LogRecordWithDLSN>> readBulk(int numEntries) {\n+        return readInternal(numEntries, 0, TimeUnit.MILLISECONDS);\n+    }\n+\n+    @Override\n+    public synchronized Future<List<LogRecordWithDLSN>> readBulk(int numEntries,\n+                                                                 long waitTime,\n+                                                                 TimeUnit timeUnit) {\n+        return readInternal(numEntries, waitTime, timeUnit);\n+    }\n+\n+    /**\n+     * Read up to <i>numEntries</i> entries. The future will be satisfied when any number of entries are\n+     * ready (1 to <i>numEntries</i>).\n+     *\n+     * @param numEntries\n+     *          num entries to read\n+     * @return A promise that satisfied with a non-empty list of log records with their DLSN.\n+     */\n+    private synchronized Future<List<LogRecordWithDLSN>> readInternal(int numEntries,\n+                                                                      long deadlineTime,\n+                                                                      TimeUnit deadlineTimeUnit) {\n+        timeBetweenReadNexts.registerSuccessfulEvent(readNextDelayStopwatch.elapsed(TimeUnit.MICROSECONDS));\n+        readNextDelayStopwatch.reset().start();\n+        final PendingReadRequest readRequest = new PendingReadRequest(numEntries, deadlineTime, deadlineTimeUnit);\n+\n+        if (!readAheadStarted) {\n+            bkLedgerManager.checkLogStreamExistsAsync().addEventListener(new FutureEventListener<Void>() {\n+                @Override\n+                public void onSuccess(Void value) {\n+                    try {\n+                        bkLedgerManager.startReadAhead(\n+                                new LedgerReadPosition(getStartDLSN()),\n+                                failureInjector);\n+                        if (disableReadAheadZKNotification) {\n+                            bkLedgerManager.disableReadAheadZKNotification();\n+                        }\n+                    } catch (Exception exc) {\n+                        setLastException(new IOException(exc));\n+                        notifyOnError();\n+                    }\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause) {\n+                    if (cause instanceof IOException) {\n+                        setLastException((IOException)cause);\n+                    } else {\n+                        setLastException(new IOException(cause));\n+                    }\n+                    notifyOnError();\n+                }\n+            });\n+            readAheadStarted = true;\n+        }\n+\n+        if (checkClosedOrInError(\"readNext\")) {\n+            readRequest.setException(lastException.get());\n+        } else {\n+            boolean queueEmpty = pendingRequests.isEmpty();\n+            pendingRequests.add(readRequest);\n+\n+            if (queueEmpty) {\n+                scheduleBackgroundRead();\n+            }\n+        }\n+\n+        readNextExecTime.registerSuccessfulEvent(readNextDelayStopwatch.elapsed(TimeUnit.MICROSECONDS));\n+        readNextDelayStopwatch.reset().start();\n+\n+        return readRequest.getPromise();\n+    }\n+\n+    public synchronized void scheduleBackgroundRead() {\n+        // if the reader is already closed, we don't need to schedule background read again.\n+        if (null != closeFuture) {\n+            return;\n+        }\n+\n+        long prevCount = scheduleCount.getAndIncrement();\n+        if (0 == prevCount) {\n+            scheduleDelayStopwatch.reset().start();\n+            executorService.submit(this);\n+        }\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        // Cancel the idle reader timeout task, interrupting if necessary\n+        ReadCancelledException exception;\n+        Promise<Void> closePromise;\n+        synchronized (this) {\n+            if (null != closeFuture) {\n+                return closeFuture;\n+            }\n+            closePromise = closeFuture = new Promise<Void>();\n+            exception = new ReadCancelledException(bkLedgerManager.getFullyQualifiedName(), \"Reader was closed\");\n+            setLastException(exception);\n+        }\n+\n+        // Do this after we have checked that the reader was not previously closed\n+        try {\n+            if (null != idleReaderTimeoutTask) {\n+                idleReaderTimeoutTask.cancel(true);\n+            }\n+        } catch (Exception exc) {\n+            LOG.info(\"{}: Failed to cancel the background idle reader timeout task\", bkLedgerManager.getFullyQualifiedName());\n+        }\n+\n+        synchronized (scheduleCount) {\n+            if (null != backgroundScheduleTask) {\n+                backgroundScheduleTask.cancel(true);\n+            }\n+        }\n+\n+        cancelAllPendingReads(exception);\n+\n+        bkLedgerManager.unregister(sessionExpireWatcher);\n+\n+        FutureUtils.ignore(bkLedgerManager.asyncClose()).proxyTo(closePromise);\n+        return closePromise;\n+    }\n+\n+    private void cancelAllPendingReads(Throwable throwExc) {\n+        for (PendingReadRequest promise : pendingRequests) {\n+            promise.setException(throwExc);\n+        }\n+        pendingRequests.clear();\n+    }\n+\n+    @Override\n+    public void run() {\n+        synchronized(scheduleCount) {\n+            if (scheduleDelayStopwatch.isRunning()) {\n+                scheduleLatency.registerSuccessfulEvent(scheduleDelayStopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            }\n+\n+            Stopwatch runTime = Stopwatch.createStarted();\n+            int iterations = 0;\n+            long scheduleCountLocal = scheduleCount.get();\n+            LOG.debug(\"{}: Scheduled Background Reader\", bkLedgerManager.getFullyQualifiedName());\n+            while(true) {\n+                if (LOG.isTraceEnabled()) {\n+                    LOG.trace(\"{}: Executing Iteration: {}\", bkLedgerManager.getFullyQualifiedName(), iterations++);\n+                }\n+\n+                PendingReadRequest nextRequest = null;\n+                synchronized(this) {\n+                    nextRequest = pendingRequests.peek();\n+\n+                    // Queue is empty, nothing to read, return\n+                    if (null == nextRequest) {\n+                        LOG.trace(\"{}: Queue Empty waiting for Input\", bkLedgerManager.getFullyQualifiedName());\n+                        scheduleCount.set(0);\n+                        backgroundReaderRunTime.registerSuccessfulEvent(runTime.stop().elapsed(TimeUnit.MICROSECONDS));\n+                        return;\n+                    }\n+                }\n+\n+                if (disableProcessingReadRequests) {\n+                    LOG.info(\"Reader of {} is forced to stop processing read requests\", bkLedgerManager.getFullyQualifiedName());\n+                    return;\n+                }\n+\n+                // If the oldest pending promise is interrupted then we must mark\n+                // the reader in error and abort all pending reads since we dont\n+                // know the last consumed read\n+                if (null == lastException.get()) {\n+                    if (nextRequest.getPromise().isInterrupted().isDefined()) {\n+                        setLastException(new DLInterruptedException(\"Interrupted on reading \" + bkLedgerManager.getFullyQualifiedName() + \" : \",\n+                                nextRequest.getPromise().isInterrupted().get()));\n+                    }\n+                }\n+\n+                if (checkClosedOrInError(\"readNext\")) {\n+                    if (!(lastException.get().getCause() instanceof LogNotFoundException)) {\n+                        LOG.warn(\"{}: Exception\", bkLedgerManager.getFullyQualifiedName(), lastException.get());\n+                    }\n+                    backgroundReaderRunTime.registerFailedEvent(runTime.stop().elapsed(TimeUnit.MICROSECONDS));\n+                    return;\n+                }\n+\n+                try {\n+                    // Fail 10% of the requests when asked to simulate errors\n+                    if (failureInjector.shouldInjectErrors()) {\n+                        throw new IOException(\"Reader Simulated Exception\");\n+                    }\n+                    LogRecordWithDLSN record;\n+                    while (!nextRequest.hasReadEnoughRecords()) {\n+                        // read single record\n+                        do {\n+                            record = bkLedgerManager.getNextReadAheadRecord();\n+                        } while (null != record && (record.isControl() || (record.getDlsn().compareTo(getStartDLSN()) < 0)));\n+                        if (null == record) {\n+                            break;\n+                        } else {\n+                            if (record.isEndOfStream() && !returnEndOfStreamRecord) {\n+                                setLastException(new EndOfStreamException(\"End of Stream Reached for \"\n+                                        + bkLedgerManager.getFullyQualifiedName()));\n+                                break;\n+                            }\n+\n+                            // gap detection\n+                            if (recordPositionsContainsGap(record, lastPosition)) {\n+                                bkDistributedLogManager.raiseAlert(\"Gap detected between records at dlsn = {}\", record.getDlsn());\n+                                if (positionGapDetectionEnabled) {\n+                                    throw new DLIllegalStateException(\"Gap detected between records at dlsn = \" + record.getDlsn());\n+                                }\n+                            }\n+                            lastPosition = record.getLastPositionWithinLogSegment();\n+\n+                            nextRequest.addRecord(record);\n+                        }\n+                    };\n+                } catch (IOException exc) {\n+                    setLastException(exc);\n+                    if (!(exc instanceof LogNotFoundException)) {\n+                        LOG.warn(\"{} : read with skip Exception\", bkLedgerManager.getFullyQualifiedName(), lastException.get());\n+                    }\n+                    continue;\n+                }\n+\n+                if (nextRequest.hasReadRecords()) {\n+                    long remainingWaitTime = nextRequest.getRemainingWaitTime();\n+                    if (remainingWaitTime > 0 && !nextRequest.hasReadEnoughRecords()) {\n+                        backgroundReaderRunTime.registerSuccessfulEvent(runTime.stop().elapsed(TimeUnit.MICROSECONDS));\n+                        scheduleDelayStopwatch.reset().start();\n+                        scheduleCount.set(0);\n+                        // the request could still wait for more records\n+                        backgroundScheduleTask = executorService.schedule(BACKGROUND_READ_SCHEDULER, remainingWaitTime, nextRequest.deadlineTimeUnit);\n+                        return;\n+                    }\n+\n+                    PendingReadRequest request = pendingRequests.poll();\n+                    if (null != request && nextRequest == request) {\n+                        request.complete();\n+                        if (null != backgroundScheduleTask) {\n+                            backgroundScheduleTask.cancel(true);\n+                            backgroundScheduleTask = null;\n+                        }\n+                    } else {\n+                        DLIllegalStateException ise = new DLIllegalStateException(\"Unexpected condition at dlsn = \"\n+                                + nextRequest.records.get(0).getDlsn());\n+                        nextRequest.setException(ise);\n+                        if (null != request) {\n+                            request.setException(ise);\n+                        }\n+                        // We should never get here as we should have exited the loop if\n+                        // pendingRequests were empty\n+                        bkDistributedLogManager.raiseAlert(\"Unexpected condition at dlsn = {}\",\n+                                nextRequest.records.get(0).getDlsn());\n+                        setLastException(ise);\n+                    }\n+                } else {\n+                    if (0 == scheduleCountLocal) {\n+                        LOG.trace(\"Schedule count dropping to zero\", lastException.get());\n+                        backgroundReaderRunTime.registerSuccessfulEvent(runTime.stop().elapsed(TimeUnit.MICROSECONDS));\n+                        return;\n+                    }\n+                    scheduleCountLocal = scheduleCount.decrementAndGet();\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean recordPositionsContainsGap(LogRecordWithDLSN record, long lastPosition) {\n+        final boolean firstLogRecord = (1 == record.getPositionWithinLogSegment());\n+        final boolean endOfStreamRecord = record.isEndOfStream();\n+        final boolean emptyLogSegment = (0 == lastPosition);\n+        final boolean positionIncreasedByOne = (record.getPositionWithinLogSegment() == (lastPosition + 1));\n+\n+        return !firstLogRecord && !endOfStreamRecord && !emptyLogSegment &&\n+               !positionIncreasedByOne;\n+    }\n+\n+    /**\n+     * Triggered when the background activity encounters an exception\n+     */\n+    @Override\n+    public void notifyOnError() {\n+        scheduleBackgroundRead();\n+    }\n+\n+    /**\n+     * Triggered when the background activity completes an operation\n+     */\n+    @Override\n+    public void notifyOnOperationComplete() {\n+        scheduleBackgroundRead();\n+    }\n+\n+    @VisibleForTesting\n+    void simulateErrors() {\n+        failureInjector.injectErrors(true);\n+    }\n+\n+    @VisibleForTesting\n+    synchronized void disableReadAheadZKNotification() {\n+        disableReadAheadZKNotification = true;\n+        bkLedgerManager.disableReadAheadZKNotification();\n+    }\n+\n+    @VisibleForTesting\n+    synchronized void disableProcessingReadRequests() {\n+        disableProcessingReadRequests = true;\n+    }\n+}\n+"},{"sha":"ffa478aade8f44933bf856dd983243aecde96ffe","filename":"src/main/java/com/twitter/distributedlog/BKAsyncLogWriter.java","status":"added","additions":526,"deletions":0,"changes":526,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,526 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Stopwatch;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.exceptions.StreamNotReadyException;\n+import com.twitter.distributedlog.exceptions.WriteCancelledException;\n+import com.twitter.distributedlog.exceptions.WriteException;\n+import com.twitter.distributedlog.feature.CoreFeatureKeys;\n+import com.twitter.distributedlog.stats.OpStatsListener;\n+import com.twitter.distributedlog.util.FailpointUtils;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import com.twitter.util.Try;\n+import org.apache.bookkeeper.feature.Feature;\n+import org.apache.bookkeeper.feature.FeatureProvider;\n+import org.apache.bookkeeper.stats.Counter;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.Function1;\n+import scala.Option;\n+import scala.runtime.AbstractFunction1;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * BookKeeper based {@link AsyncLogWriter} implementation.\n+ *\n+ * <h3>Metrics</h3>\n+ * All the metrics are exposed under `log_writer`.\n+ * <ul>\n+ * <li> `log_writer/write`: opstats. latency characteristics about the time that write operations spent.\n+ * <li> `log_writer/bulk_write`: opstats. latency characteristics about the time that bulk_write\n+ * operations spent.\n+ * are pending in the queue for long time due to log segment rolling.\n+ * <li> `log_writer/get_writer`: opstats. the time spent on getting the writer. it could spike when there\n+ * is log segment rolling happened during getting the writer. it is a good stat to look into when the latency\n+ * is caused by queuing time.\n+ * <li> `log_writer/pending_request_dispatch`: counter. the number of queued operations that are dispatched\n+ * after log segment is rolled. it is an metric on measuring how many operations has been queued because of\n+ * log segment rolling.\n+ * </ul>\n+ * See {@link BKLogSegmentWriter} for segment writer stats.\n+ */\n+public class BKAsyncLogWriter extends BKAbstractLogWriter implements AsyncLogWriter {\n+\n+    static final Logger LOG = LoggerFactory.getLogger(BKAsyncLogWriter.class);\n+\n+    static Function1<List<LogSegmentMetadata>, Boolean> TruncationResultConverter =\n+            new AbstractFunction1<List<LogSegmentMetadata>, Boolean>() {\n+                @Override\n+                public Boolean apply(List<LogSegmentMetadata> segments) {\n+                    return true;\n+                }\n+            };\n+\n+    // Records pending for roll log segment.\n+    class PendingLogRecord implements FutureEventListener<DLSN> {\n+\n+        final LogRecord record;\n+        final Promise<DLSN> promise;\n+        final boolean flush;\n+\n+        PendingLogRecord(LogRecord record, boolean flush) {\n+            this.record = record;\n+            this.promise = new Promise<DLSN>();\n+            this.flush = flush;\n+        }\n+\n+        @Override\n+        public void onSuccess(DLSN value) {\n+            promise.setValue(value);\n+        }\n+\n+        @Override\n+        public void onFailure(Throwable cause) {\n+            promise.setException(cause);\n+            encounteredError = true;\n+        }\n+    }\n+\n+    /**\n+     * Last pending record in current log segment. After it is satisified, it would\n+     * roll log segment.\n+     *\n+     * This implementation is based on the assumption that all future satisified in same\n+     * order future pool.\n+     */\n+    class LastPendingLogRecord extends PendingLogRecord {\n+\n+        LastPendingLogRecord(LogRecord record, boolean flush) {\n+            super(record, flush);\n+        }\n+\n+        @Override\n+        public void onSuccess(DLSN value) {\n+            super.onSuccess(value);\n+            // roll log segment and issue all pending requests.\n+            rollLogSegmentAndIssuePendingRequests(record);\n+        }\n+\n+        @Override\n+        public void onFailure(Throwable cause) {\n+            super.onFailure(cause);\n+            // error out pending requests.\n+            errorOutPendingRequestsAndWriter(cause);\n+        }\n+    }\n+\n+    private final boolean streamFailFast;\n+    private final boolean disableRollOnSegmentError;\n+    private LinkedList<PendingLogRecord> pendingRequests = null;\n+    private volatile boolean encounteredError = false;\n+    private Promise<BKLogSegmentWriter> rollingFuture = null;\n+    private long lastTxId = DistributedLogConstants.INVALID_TXID;\n+\n+    private final StatsLogger statsLogger;\n+    private final OpStatsLogger writeOpStatsLogger;\n+    private final OpStatsLogger markEndOfStreamOpStatsLogger;\n+    private final OpStatsLogger bulkWriteOpStatsLogger;\n+    private final OpStatsLogger getWriterOpStatsLogger;\n+    private final Counter pendingRequestDispatch;\n+\n+    private final Feature disableLogSegmentRollingFeature;\n+\n+    BKAsyncLogWriter(DistributedLogConfiguration conf,\n+                     DynamicDistributedLogConfiguration dynConf,\n+                     BKDistributedLogManager bkdlm,\n+                     BKLogWriteHandler writeHandler, /** log writer owns the handler **/\n+                     FeatureProvider featureProvider,\n+                     StatsLogger dlmStatsLogger) {\n+        super(conf, dynConf, bkdlm);\n+        this.writeHandler = writeHandler;\n+        this.streamFailFast = conf.getFailFastOnStreamNotReady();\n+        this.disableRollOnSegmentError = conf.getDisableRollingOnLogSegmentError();\n+\n+        // features\n+        disableLogSegmentRollingFeature = featureProvider.getFeature(CoreFeatureKeys.DISABLE_LOGSEGMENT_ROLLING.name().toLowerCase());\n+        // stats\n+        this.statsLogger = dlmStatsLogger.scope(\"log_writer\");\n+        this.writeOpStatsLogger = statsLogger.getOpStatsLogger(\"write\");\n+        this.markEndOfStreamOpStatsLogger = statsLogger.getOpStatsLogger(\"mark_end_of_stream\");\n+        this.bulkWriteOpStatsLogger = statsLogger.getOpStatsLogger(\"bulk_write\");\n+        this.getWriterOpStatsLogger = statsLogger.getOpStatsLogger(\"get_writer\");\n+        this.pendingRequestDispatch = statsLogger.getCounter(\"pending_request_dispatch\");\n+    }\n+\n+    @VisibleForTesting\n+    synchronized void setLastTxId(long txId) {\n+        lastTxId = Math.max(lastTxId, txId);\n+    }\n+\n+    @Override\n+    public synchronized long getLastTxId() {\n+        return lastTxId;\n+    }\n+\n+    /**\n+     * Write a log record as control record. The method will be used by Monitor Service to enforce a new inprogress segment.\n+     *\n+     * @param record\n+     *          log record\n+     * @return future of the write\n+     */\n+    public Future<DLSN> writeControlRecord(final LogRecord record) {\n+        record.setControl();\n+        return write(record);\n+    }\n+\n+    private BKLogSegmentWriter getCachedLogSegmentWriter() throws WriteException {\n+        if (encounteredError) {\n+            throw new WriteException(bkDistributedLogManager.getStreamName(),\n+                    \"writer has been closed due to error.\");\n+        }\n+        BKLogSegmentWriter segmentWriter = getCachedLogWriter();\n+        if (null != segmentWriter\n+                && segmentWriter.isLogSegmentInError()\n+                && !disableRollOnSegmentError) {\n+            return null;\n+        } else {\n+            return segmentWriter;\n+        }\n+    }\n+\n+    private Future<BKLogSegmentWriter> getLogSegmentWriter(long firstTxid,\n+                                                           boolean bestEffort,\n+                                                           boolean rollLog,\n+                                                           boolean allowMaxTxID) {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        return doGetLogSegmentWriter(firstTxid, bestEffort, rollLog, allowMaxTxID)\n+                .addEventListener(new OpStatsListener<BKLogSegmentWriter>(getWriterOpStatsLogger, stopwatch));\n+    }\n+\n+    private Future<BKLogSegmentWriter> doGetLogSegmentWriter(final long firstTxid,\n+                                                             final boolean bestEffort,\n+                                                             final boolean rollLog,\n+                                                             final boolean allowMaxTxID) {\n+        if (encounteredError) {\n+            return Future.exception(new WriteException(bkDistributedLogManager.getStreamName(),\n+                    \"writer has been closed due to error.\"));\n+        }\n+        Future<BKLogSegmentWriter> writerFuture = asyncGetLedgerWriter(!disableRollOnSegmentError);\n+        if (null == writerFuture) {\n+            return rollLogSegmentIfNecessary(null, firstTxid, bestEffort, allowMaxTxID);\n+        } else if (rollLog) {\n+            return writerFuture.flatMap(new AbstractFunction1<BKLogSegmentWriter, Future<BKLogSegmentWriter>>() {\n+                @Override\n+                public Future<BKLogSegmentWriter> apply(BKLogSegmentWriter writer) {\n+                    return rollLogSegmentIfNecessary(writer, firstTxid, bestEffort, allowMaxTxID);\n+                }\n+            });\n+        } else {\n+            return writerFuture;\n+        }\n+    }\n+\n+    /**\n+     * We write end of stream marker by writing a record with MAX_TXID, so we need to allow using\n+     * max txid when rolling for this case only.\n+     */\n+    private Future<BKLogSegmentWriter> getLogSegmentWriterForEndOfStream() {\n+        return getLogSegmentWriter(DistributedLogConstants.MAX_TXID,\n+                                     false /* bestEffort */,\n+                                     false /* roll log */,\n+                                     true /* allow max txid */);\n+    }\n+\n+    private Future<BKLogSegmentWriter> getLogSegmentWriter(long firstTxid,\n+                                                           boolean bestEffort,\n+                                                           boolean rollLog) {\n+        return getLogSegmentWriter(firstTxid, bestEffort, rollLog, false /* allow max txid */);\n+    }\n+\n+    Future<DLSN> queueRequest(LogRecord record, boolean flush) {\n+        PendingLogRecord pendingLogRecord = new PendingLogRecord(record, flush);\n+        pendingRequests.add(pendingLogRecord);\n+        return pendingLogRecord.promise;\n+    }\n+\n+    boolean shouldRollLog(BKLogSegmentWriter w) {\n+        try {\n+            return null == w ||\n+                    (!disableLogSegmentRollingFeature.isAvailable() &&\n+                    shouldStartNewSegment(w));\n+        } catch (IOException ioe) {\n+            return false;\n+        }\n+    }\n+\n+    void startQueueingRequests() {\n+        assert(null == pendingRequests && null == rollingFuture);\n+        pendingRequests = new LinkedList<PendingLogRecord>();\n+        rollingFuture = new Promise<BKLogSegmentWriter>();\n+    }\n+\n+    // for ordering guarantee, we shouldn't send requests to next log segments until\n+    // previous log segment is done.\n+    private synchronized Future<DLSN> asyncWrite(final LogRecord record,\n+                                                 boolean flush) {\n+        // The passed in writer may be stale since we acquire the writer outside of sync\n+        // lock. If we recently rolled and the new writer is cached, use that instead.\n+        Future<DLSN> result = null;\n+        BKLogSegmentWriter w;\n+        try {\n+            w = getCachedLogSegmentWriter();\n+        } catch (WriteException we) {\n+            return Future.exception(we);\n+        }\n+        if (null != rollingFuture) {\n+            if (streamFailFast) {\n+                result = Future.exception(new StreamNotReadyException(\"Rolling log segment\"));\n+            } else {\n+                result = queueRequest(record, flush);\n+            }\n+        } else if (shouldRollLog(w)) {\n+            // insert a last record, so when it called back, we will trigger a log segment rolling\n+            startQueueingRequests();\n+            if (null != w) {\n+                LastPendingLogRecord lastLogRecordInCurrentSegment = new LastPendingLogRecord(record, flush);\n+                w.asyncWrite(record, true).addEventListener(lastLogRecordInCurrentSegment);\n+                result = lastLogRecordInCurrentSegment.promise;\n+            } else { // no log segment yet. roll the log segment and issue pending requests.\n+                result = queueRequest(record, flush);\n+                rollLogSegmentAndIssuePendingRequests(record);\n+            }\n+        } else {\n+            result = w.asyncWrite(record, flush);\n+        }\n+        // use map here rather than onSuccess because we want lastTxId to be updated before\n+        // satisfying the future\n+        return result.map(new AbstractFunction1<DLSN, DLSN>() {\n+            @Override\n+            public DLSN apply(DLSN dlsn) {\n+                setLastTxId(record.getTransactionId());\n+                return dlsn;\n+            }\n+        });\n+    }\n+\n+    private List<Future<DLSN>> asyncWriteBulk(List<LogRecord> records) {\n+        final ArrayList<Future<DLSN>> results = new ArrayList<Future<DLSN>>(records.size());\n+        Iterator<LogRecord> iterator = records.iterator();\n+        while (iterator.hasNext()) {\n+            LogRecord record = iterator.next();\n+            Future<DLSN> future = asyncWrite(record, !iterator.hasNext());\n+            results.add(future);\n+\n+            // Abort early if an individual write has already failed.\n+            Option<Try<DLSN>> result = future.poll();\n+            if (result.isDefined() && result.get().isThrow()) {\n+                break;\n+            }\n+        }\n+        if (records.size() > results.size()) {\n+            appendCancelledFutures(results, records.size() - results.size());\n+        }\n+        return results;\n+    }\n+\n+    private void appendCancelledFutures(List<Future<DLSN>> futures, int numToAdd) {\n+        final WriteCancelledException cre =\n+            new WriteCancelledException(getStreamName());\n+        for (int i = 0; i < numToAdd; i++) {\n+            Future<DLSN> cancelledFuture = Future.exception(cre);\n+            futures.add(cancelledFuture);\n+        }\n+    }\n+\n+    private void rollLogSegmentAndIssuePendingRequests(LogRecord record) {\n+        getLogSegmentWriter(record.getTransactionId(), true, true)\n+                .addEventListener(new FutureEventListener<BKLogSegmentWriter>() {\n+            @Override\n+            public void onSuccess(BKLogSegmentWriter writer) {\n+                try {\n+                    synchronized (BKAsyncLogWriter.this) {\n+                        for (PendingLogRecord pendingLogRecord : pendingRequests) {\n+                            FailpointUtils.checkFailPoint(FailpointUtils.FailPointName.FP_LogWriterIssuePending);\n+                            writer.asyncWrite(pendingLogRecord.record, pendingLogRecord.flush)\n+                                    .addEventListener(pendingLogRecord);\n+                        }\n+                        if (null != rollingFuture) {\n+                            FutureUtils.setValue(rollingFuture, writer);\n+                        }\n+                        rollingFuture = null;\n+                        pendingRequestDispatch.add(pendingRequests.size());\n+                        pendingRequests = null;\n+                    }\n+                } catch (IOException ioe) {\n+                    errorOutPendingRequestsAndWriter(ioe);\n+                }\n+            }\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                errorOutPendingRequestsAndWriter(cause);\n+            }\n+        });\n+    }\n+\n+    @VisibleForTesting\n+    void errorOutPendingRequests(Throwable cause, boolean errorOutWriter) {\n+        final List<PendingLogRecord> pendingRequestsSnapshot;\n+        synchronized (this) {\n+            pendingRequestsSnapshot = pendingRequests;\n+            encounteredError = errorOutWriter;\n+            pendingRequests = null;\n+            if (null != rollingFuture) {\n+                FutureUtils.setException(rollingFuture, cause);\n+            }\n+            rollingFuture = null;\n+        }\n+\n+        pendingRequestDispatch.add(pendingRequestsSnapshot.size());\n+\n+        // After erroring out the writer above, no more requests\n+        // will be enqueued to pendingRequests\n+        for (PendingLogRecord pendingLogRecord : pendingRequestsSnapshot) {\n+            pendingLogRecord.promise.setException(cause);\n+        }\n+    }\n+\n+    void errorOutPendingRequestsAndWriter(Throwable cause) {\n+        errorOutPendingRequests(cause, true /* error out writer */);\n+    }\n+\n+    /**\n+     * Write a log record to the stream.\n+     *\n+     * @param record single log record\n+     */\n+    @Override\n+    public Future<DLSN> write(final LogRecord record) {\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        return asyncWrite(record, true)\n+                .addEventListener(new OpStatsListener<DLSN>(writeOpStatsLogger, stopwatch));\n+    }\n+\n+    /**\n+     * Write many log records to the stream. The return type here is unfortunate but its a direct result\n+     * of having to combine FuturePool and the asyncWriteBulk method which returns a future as well. The\n+     * problem is the List that asyncWriteBulk returns can't be materialized until getLogSegmentWriter\n+     * completes, so it has to be wrapped in a future itself.\n+     *\n+     * @param records list of records\n+     */\n+    @Override\n+    public Future<List<Future<DLSN>>> writeBulk(final List<LogRecord> records) {\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        return Future.value(asyncWriteBulk(records))\n+                .addEventListener(new OpStatsListener<List<Future<DLSN>>>(bulkWriteOpStatsLogger, stopwatch));\n+    }\n+\n+    @Override\n+    public Future<Boolean> truncate(final DLSN dlsn) {\n+        if (DLSN.InvalidDLSN == dlsn) {\n+            return Future.value(false);\n+        }\n+        BKLogWriteHandler writeHandler;\n+        try {\n+            writeHandler = getWriteHandler();\n+        } catch (IOException e) {\n+            return Future.exception(e);\n+        }\n+        return writeHandler.setLogSegmentsOlderThanDLSNTruncated(dlsn).map(TruncationResultConverter);\n+    }\n+\n+    Future<Long> flushAndCommit() {\n+        Future<BKLogSegmentWriter> writerFuture;\n+        synchronized (this) {\n+            if (null != this.rollingFuture) {\n+                writerFuture = this.rollingFuture;\n+            } else {\n+                writerFuture = getCachedLogWriterFuture();\n+            }\n+        }\n+        if (null == writerFuture) {\n+            return Future.value(lastTxId);\n+        }\n+        return writerFuture.flatMap(new AbstractFunction1<BKLogSegmentWriter, Future<Long>>() {\n+            @Override\n+            public Future<Long> apply(BKLogSegmentWriter writer) {\n+                return writer.flushAndCommit();\n+            }\n+        });\n+    }\n+\n+    Future<Long> markEndOfStream() {\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        Future<BKLogSegmentWriter> logSegmentWriterFuture;\n+        synchronized (this) {\n+            logSegmentWriterFuture = this.rollingFuture;\n+        }\n+        if (null == logSegmentWriterFuture) {\n+            logSegmentWriterFuture = getLogSegmentWriterForEndOfStream();\n+        }\n+\n+        return logSegmentWriterFuture.flatMap(new AbstractFunction1<BKLogSegmentWriter, Future<Long>>() {\n+            @Override\n+            public Future<Long> apply(BKLogSegmentWriter w) {\n+                return w.markEndOfStream();\n+            }\n+        }).addEventListener(new OpStatsListener<Long>(markEndOfStreamOpStatsLogger, stopwatch));\n+    }\n+\n+    @Override\n+    protected Future<Void> asyncCloseAndComplete() {\n+        Future<BKLogSegmentWriter> logSegmentWriterFuture;\n+        synchronized (this) {\n+            logSegmentWriterFuture = this.rollingFuture;\n+        }\n+\n+        if (null == logSegmentWriterFuture) {\n+            return super.asyncCloseAndComplete();\n+        } else {\n+            return logSegmentWriterFuture.flatMap(new AbstractFunction1<BKLogSegmentWriter, Future<Void>>() {\n+                @Override\n+                public Future<Void> apply(BKLogSegmentWriter segmentWriter) {\n+                    return BKAsyncLogWriter.super.asyncCloseAndComplete();\n+                }\n+            });\n+        }\n+    }\n+\n+    @Override\n+    void closeAndComplete() throws IOException {\n+        FutureUtils.result(asyncCloseAndComplete());\n+    }\n+\n+    /**\n+     * *TEMP HACK*\n+     * Get the name of the stream this writer writes data to\n+     */\n+    @Override\n+    public String getStreamName() {\n+        return bkDistributedLogManager.getStreamName();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"AsyncLogWriter:%s\", getStreamName());\n+    }\n+}"},{"sha":"fd8ec2dee277a5e8543a41371e3ed5c882ecdcce","filename":"src/main/java/com/twitter/distributedlog/BKDistributedLogManager.java","status":"added","additions":1473,"deletions":0,"changes":1473,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,1473 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Optional;\n+import com.google.common.base.Preconditions;\n+import com.twitter.distributedlog.bk.DynamicQuorumConfigProvider;\n+import com.twitter.distributedlog.bk.LedgerAllocator;\n+import com.twitter.distributedlog.bk.LedgerAllocatorDelegator;\n+import com.twitter.distributedlog.bk.QuorumConfigProvider;\n+import com.twitter.distributedlog.bk.SimpleLedgerAllocator;\n+import com.twitter.distributedlog.callback.LogSegmentListener;\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.exceptions.AlreadyClosedException;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.LogEmptyException;\n+import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.impl.ZKLogSegmentMetadataStore;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForReader;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+import com.twitter.distributedlog.lock.SessionLockFactory;\n+import com.twitter.distributedlog.lock.DistributedLock;\n+import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.metadata.BKDLConfig;\n+import com.twitter.distributedlog.stats.BroadCastStatsLogger;\n+import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n+import com.twitter.distributedlog.subscription.SubscriptionStateStore;\n+import com.twitter.distributedlog.subscription.SubscriptionsStore;\n+import com.twitter.distributedlog.subscription.ZKSubscriptionStateStore;\n+import com.twitter.distributedlog.subscription.ZKSubscriptionsStore;\n+import com.twitter.distributedlog.util.ConfUtils;\n+import com.twitter.distributedlog.util.DLUtils;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.MonitoredFuturePool;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.distributedlog.util.PermitLimiter;\n+import com.twitter.distributedlog.util.PermitManager;\n+import com.twitter.distributedlog.util.SchedulerUtils;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.util.ExceptionalFunction;\n+import com.twitter.util.ExceptionalFunction0;\n+import com.twitter.util.ExecutorServiceFuturePool;\n+import com.twitter.util.Function;\n+import com.twitter.util.Future;\n+import com.twitter.util.FuturePool;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.stats.AlertStatsLogger;\n+import org.apache.bookkeeper.feature.FeatureProvider;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.Watcher;\n+import org.apache.zookeeper.ZKUtil;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n+import org.jboss.netty.util.HashedWheelTimer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.runtime.AbstractFunction0;\n+import scala.runtime.AbstractFunction1;\n+import scala.runtime.BoxedUnit;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.RejectedExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * <h3>Metrics</h3>\n+ * <ul>\n+ * <li> `log_writer/*`: all asynchronous writer related metrics are exposed under scope `log_writer`.\n+ * See {@link BKAsyncLogWriter} for detail stats.\n+ * <li> `async_reader/*`: all asyncrhonous reader related metrics are exposed under scope `async_reader`.\n+ * See {@link BKAsyncLogReaderDLSN} for detail stats.\n+ * <li> `writer_future_pool/*`: metrics about the future pools that used by writers are exposed under\n+ * scope `writer_future_pool`. See {@link MonitoredFuturePool} for detail stats.\n+ * <li> `reader_future_pool/*`: metrics about the future pools that used by readers are exposed under\n+ * scope `reader_future_pool`. See {@link MonitoredFuturePool} for detail stats.\n+ * <li> `lock/*`: metrics about the locks used by writers. See {@link DistributedLock} for detail\n+ * stats.\n+ * <li> `read_lock/*`: metrics about the locks used by readers. See {@link DistributedLock} for\n+ * detail stats.\n+ * <li> `logsegments/*`: metrics about basic operations on log segments. See {@link BKLogHandler} for details.\n+ * <li> `segments/*`: metrics about write operations on log segments. See {@link BKLogWriteHandler} for details.\n+ * <li> `readahead_worker/*`: metrics about readahead workers used by readers. See {@link BKLogReadHandler}\n+ * for details.\n+ * </ul>\n+ */\n+class BKDistributedLogManager extends ZKMetadataAccessor implements DistributedLogManager {\n+    static final Logger LOG = LoggerFactory.getLogger(BKDistributedLogManager.class);\n+\n+    static void createLog(DistributedLogConfiguration conf, ZooKeeperClient zkc, URI uri, String streamName)\n+            throws IOException, InterruptedException {\n+        Future<ZKLogMetadataForWriter> createFuture = ZKLogMetadataForWriter.of(\n+                        uri, streamName, conf.getUnpartitionedStreamName(), zkc.get(), zkc.getDefaultACL(), true, true);\n+        FutureUtils.result(createFuture);\n+    }\n+\n+    static final Function<LogRecordWithDLSN, Long> RECORD_2_TXID_FUNCTION =\n+            new Function<LogRecordWithDLSN, Long>() {\n+                @Override\n+                public Long apply(LogRecordWithDLSN record) {\n+                    return record.getTransactionId();\n+                }\n+            };\n+\n+    static final Function<LogRecordWithDLSN, DLSN> RECORD_2_DLSN_FUNCTION =\n+            new Function<LogRecordWithDLSN, DLSN>() {\n+                @Override\n+                public DLSN apply(LogRecordWithDLSN record) {\n+                    return record.getDlsn();\n+                }\n+            };\n+\n+\n+    private final String clientId;\n+    private final int regionId;\n+    private final String streamIdentifier;\n+    private final DistributedLogConfiguration conf;\n+    private final DynamicDistributedLogConfiguration dynConf;\n+    private Promise<Void> closePromise;\n+    private final OrderedScheduler scheduler;\n+    private final OrderedScheduler readAheadScheduler;\n+    private boolean ownExecutor;\n+    private final FeatureProvider featureProvider;\n+    private final StatsLogger statsLogger;\n+    private final StatsLogger perLogStatsLogger;\n+    private final AlertStatsLogger alertStatsLogger;\n+\n+    // lock factory\n+    private SessionLockFactory lockFactory = null;\n+\n+    // log segment metadata stores\n+    private final LogSegmentMetadataStore writerMetadataStore;\n+    private final LogSegmentMetadataStore readerMetadataStore;\n+\n+    // bookkeeper clients\n+    // NOTE: The actual bookkeeper client is initialized lazily when it is referenced by\n+    //       {@link com.twitter.distributedlog.BookKeeperClient#get()}. So it is safe to\n+    //       keep builders and their client wrappers here, as they will be used when\n+    //       instantiating readers or writers.\n+    private final BookKeeperClientBuilder writerBKCBuilder;\n+    private final BookKeeperClient writerBKC;\n+    private final boolean ownWriterBKC;\n+    private final BookKeeperClientBuilder readerBKCBuilder;\n+    private final BookKeeperClient readerBKC;\n+    private final boolean ownReaderBKC;\n+\n+    //\n+    // Writer Related Variables\n+    //\n+    private final LedgerAllocator ledgerAllocator;\n+    private final PermitLimiter writeLimiter;\n+    // Log Segment Rolling Manager to control rolling speed\n+    private final PermitManager logSegmentRollingPermitManager;\n+    private OrderedScheduler lockStateExecutor = null;\n+\n+    //\n+    // Reader Related Variables\n+    ///\n+    // read handler for listener.\n+    private BKLogReadHandler readHandlerForListener = null;\n+    private FuturePool readerFuturePool = null;\n+    private final PendingReaders pendingReaders;\n+    private final ReadAheadExceptionsLogger readAheadExceptionsLogger;\n+\n+    /**\n+     * Create a DLM for testing.\n+     *\n+     * @param name log name\n+     * @param conf distributedlog configuration\n+     * @param uri uri location for the log\n+     * @param writerZKCBuilder zookeeper builder for writers\n+     * @param readerZKCBuilder zookeeper builder for readers\n+     * @param zkcForWriterBKC zookeeper builder for bookkeeper shared by writers\n+     * @param zkcForReaderBKC zookeeper builder for bookkeeper shared by readers\n+     * @param writerBKCBuilder bookkeeper builder for writers\n+     * @param readerBKCBuilder bookkeeper builder for readers\n+     * @param featureProvider provider to offer features\n+     * @param writeLimiter write limiter\n+     * @param statsLogger stats logger to receive stats\n+     * @throws IOException\n+     */\n+    BKDistributedLogManager(String name,\n+                            DistributedLogConfiguration conf,\n+                            URI uri,\n+                            ZooKeeperClientBuilder writerZKCBuilder,\n+                            ZooKeeperClientBuilder readerZKCBuilder,\n+                            ZooKeeperClient zkcForWriterBKC,\n+                            ZooKeeperClient zkcForReaderBKC,\n+                            BookKeeperClientBuilder writerBKCBuilder,\n+                            BookKeeperClientBuilder readerBKCBuilder,\n+                            FeatureProvider featureProvider,\n+                            PermitLimiter writeLimiter,\n+                            StatsLogger statsLogger) throws IOException {\n+        this(name,\n+             conf,\n+             ConfUtils.getConstDynConf(conf),\n+             uri,\n+             writerZKCBuilder,\n+             readerZKCBuilder,\n+             zkcForWriterBKC,\n+             zkcForReaderBKC,\n+             writerBKCBuilder,\n+             readerBKCBuilder,\n+             null,\n+             null,\n+             null,\n+             OrderedScheduler.newBuilder().name(\"BKDL-\" + name).corePoolSize(1).build(),\n+             null,\n+             null,\n+             null,\n+             null,\n+             new ReadAheadExceptionsLogger(statsLogger),\n+             DistributedLogConstants.UNKNOWN_CLIENT_ID,\n+             DistributedLogConstants.LOCAL_REGION_ID,\n+             null,\n+             writeLimiter,\n+             PermitManager.UNLIMITED_PERMIT_MANAGER,\n+             featureProvider,\n+             statsLogger,\n+             NullStatsLogger.INSTANCE);\n+        this.ownExecutor = true;\n+    }\n+\n+    /**\n+     * Create a {@link DistributedLogManager} with supplied resources.\n+     *\n+     * @param name log name\n+     * @param conf distributedlog configuration\n+     * @param uri uri location for the log\n+     * @param writerZKCBuilder zookeeper builder for writers\n+     * @param readerZKCBuilder zookeeper builder for readers\n+     * @param zkcForWriterBKC zookeeper builder for bookkeeper shared by writers\n+     * @param zkcForReaderBKC zookeeper builder for bookkeeper shared by readers\n+     * @param writerBKCBuilder bookkeeper builder for writers\n+     * @param readerBKCBuilder bookkeeper builder for readers\n+     * @param lockFactory distributed lock factory\n+     * @param writerMetadataStore writer metadata store\n+     * @param readerMetadataStore reader metadata store\n+     * @param scheduler ordered scheduled used by readers and writers\n+     * @param readAheadScheduler readAhead scheduler used by readers\n+     * @param lockStateExecutor ordered scheduled used by locks to execute lock actions\n+     * @param channelFactory client socket channel factory to build bookkeeper clients\n+     * @param requestTimer request timer to build bookkeeper clients\n+     * @param readAheadExceptionsLogger stats logger to record readahead exceptions\n+     * @param clientId client id that used to initiate the locks\n+     * @param regionId region id that would be encrypted as part of log segment metadata\n+     *                 to indicate which region that the log segment will be created\n+     * @param ledgerAllocator ledger allocator to allocate ledgers\n+     * @param featureProvider provider to offer features\n+     * @param writeLimiter write limiter\n+     * @param statsLogger stats logger to receive stats\n+     * @param perLogStatsLogger stats logger to receive per log stats\n+     * @throws IOException\n+     */\n+    BKDistributedLogManager(String name,\n+                            DistributedLogConfiguration conf,\n+                            DynamicDistributedLogConfiguration dynConf,\n+                            URI uri,\n+                            ZooKeeperClientBuilder writerZKCBuilder,\n+                            ZooKeeperClientBuilder readerZKCBuilder,\n+                            ZooKeeperClient zkcForWriterBKC,\n+                            ZooKeeperClient zkcForReaderBKC,\n+                            BookKeeperClientBuilder writerBKCBuilder,\n+                            BookKeeperClientBuilder readerBKCBuilder,\n+                            SessionLockFactory lockFactory,\n+                            LogSegmentMetadataStore writerMetadataStore,\n+                            LogSegmentMetadataStore readerMetadataStore,\n+                            OrderedScheduler scheduler,\n+                            OrderedScheduler readAheadScheduler,\n+                            OrderedScheduler lockStateExecutor,\n+                            ClientSocketChannelFactory channelFactory,\n+                            HashedWheelTimer requestTimer,\n+                            ReadAheadExceptionsLogger readAheadExceptionsLogger,\n+                            String clientId,\n+                            Integer regionId,\n+                            LedgerAllocator ledgerAllocator,\n+                            PermitLimiter writeLimiter,\n+                            PermitManager logSegmentRollingPermitManager,\n+                            FeatureProvider featureProvider,\n+                            StatsLogger statsLogger,\n+                            StatsLogger perLogStatsLogger) throws IOException {\n+        super(name, conf, uri, writerZKCBuilder, readerZKCBuilder, statsLogger);\n+        Preconditions.checkNotNull(readAheadExceptionsLogger, \"No ReadAhead Stats Logger Provided.\");\n+        this.conf = conf;\n+        this.dynConf = dynConf;\n+        this.scheduler = scheduler;\n+        this.lockFactory = lockFactory;\n+        this.lockStateExecutor = lockStateExecutor;\n+        this.readAheadScheduler = null == readAheadScheduler ? scheduler : readAheadScheduler;\n+        this.statsLogger = statsLogger;\n+        this.perLogStatsLogger = BroadCastStatsLogger.masterslave(perLogStatsLogger, statsLogger);\n+        this.ownExecutor = false;\n+        this.pendingReaders = new PendingReaders(scheduler);\n+        this.regionId = regionId;\n+        this.clientId = clientId;\n+        this.streamIdentifier = conf.getUnpartitionedStreamName();\n+        this.ledgerAllocator = ledgerAllocator;\n+        this.writeLimiter = writeLimiter;\n+        this.logSegmentRollingPermitManager = logSegmentRollingPermitManager;\n+\n+        if (null == writerMetadataStore) {\n+            this.writerMetadataStore = new ZKLogSegmentMetadataStore(conf, writerZKC, scheduler);\n+        } else {\n+            this.writerMetadataStore = writerMetadataStore;\n+        }\n+        if (null == readerMetadataStore) {\n+            this.readerMetadataStore = new ZKLogSegmentMetadataStore(conf, readerZKC, scheduler);\n+        } else {\n+            this.readerMetadataStore = readerMetadataStore;\n+        }\n+\n+        // create the bkc for writers\n+        if (null == writerBKCBuilder) {\n+            // resolve uri\n+            BKDLConfig bkdlConfig = BKDLConfig.resolveDLConfig(writerZKC, uri);\n+            BKDLConfig.propagateConfiguration(bkdlConfig, conf);\n+            this.writerBKCBuilder = BookKeeperClientBuilder.newBuilder()\n+                    .dlConfig(conf)\n+                    .name(String.format(\"bk:%s:dlm_writer_shared\", name))\n+                    .ledgersPath(bkdlConfig.getBkLedgersPath())\n+                    .channelFactory(channelFactory)\n+                    .requestTimer(requestTimer)\n+                    .statsLogger(statsLogger);\n+            if (null == zkcForWriterBKC) {\n+                this.writerBKCBuilder.zkServers(bkdlConfig.getBkZkServersForWriter());\n+            } else {\n+                this.writerBKCBuilder.zkc(zkcForWriterBKC);\n+            }\n+            this.ownWriterBKC = true;\n+        } else {\n+            this.writerBKCBuilder = writerBKCBuilder;\n+            this.ownWriterBKC = false;\n+        }\n+        this.writerBKC = this.writerBKCBuilder.build();\n+\n+        // create the bkc for readers\n+        if (null == readerBKCBuilder) {\n+            // resolve uri\n+            BKDLConfig bkdlConfig = BKDLConfig.resolveDLConfig(writerZKC, uri);\n+            BKDLConfig.propagateConfiguration(bkdlConfig, conf);\n+            if (bkdlConfig.getBkZkServersForWriter().equals(bkdlConfig.getBkZkServersForReader())) {\n+                this.readerBKCBuilder = this.writerBKCBuilder;\n+                this.ownReaderBKC = false;\n+            } else {\n+                this.readerBKCBuilder = BookKeeperClientBuilder.newBuilder()\n+                        .dlConfig(conf)\n+                        .name(String.format(\"bk:%s:dlm_reader_shared\", name))\n+                        .ledgersPath(bkdlConfig.getBkLedgersPath())\n+                        .channelFactory(channelFactory)\n+                        .requestTimer(requestTimer)\n+                        .statsLogger(statsLogger);\n+                if (null == zkcForReaderBKC) {\n+                    this.readerBKCBuilder.zkServers(bkdlConfig.getBkZkServersForReader());\n+                } else {\n+                    this.readerBKCBuilder.zkc(zkcForReaderBKC);\n+                }\n+                this.ownReaderBKC = true;\n+            }\n+        } else {\n+            this.readerBKCBuilder = readerBKCBuilder;\n+            this.ownReaderBKC = false;\n+        }\n+        this.readerBKC = this.readerBKCBuilder.build();\n+\n+        // Feature Provider\n+        this.featureProvider = featureProvider;\n+\n+        // Stats\n+        this.alertStatsLogger = new AlertStatsLogger(this.perLogStatsLogger, \"dl_alert\");\n+        this.readAheadExceptionsLogger = readAheadExceptionsLogger;\n+    }\n+\n+    private synchronized OrderedScheduler getLockStateExecutor(boolean createIfNull) {\n+        if (createIfNull && null == lockStateExecutor && ownExecutor) {\n+            lockStateExecutor = OrderedScheduler.newBuilder()\n+                    .corePoolSize(1).name(\"BKDL-LockState\").build();\n+        }\n+        return lockStateExecutor;\n+    }\n+\n+    private synchronized SessionLockFactory getLockFactory(boolean createIfNull) {\n+        if (createIfNull && null == lockFactory) {\n+            lockFactory = new ZKSessionLockFactory(\n+                    writerZKC,\n+                    clientId,\n+                    getLockStateExecutor(createIfNull),\n+                    conf.getZKNumRetries(),\n+                    conf.getLockTimeoutMilliSeconds(),\n+                    conf.getZKRetryBackoffStartMillis(),\n+                    statsLogger);\n+        }\n+        return lockFactory;\n+    }\n+\n+    DistributedLogConfiguration getConf() {\n+        return conf;\n+    }\n+\n+    OrderedScheduler getScheduler() {\n+        return scheduler;\n+    }\n+\n+    @VisibleForTesting\n+    BookKeeperClient getWriterBKC() {\n+        return this.writerBKC;\n+    }\n+\n+    @VisibleForTesting\n+    BookKeeperClient getReaderBKC() {\n+        return this.readerBKC;\n+    }\n+\n+    @VisibleForTesting\n+    FuturePool getReaderFuturePool() {\n+        return this.readerFuturePool;\n+    }\n+\n+    @VisibleForTesting\n+    FeatureProvider getFeatureProvider() {\n+        return this.featureProvider;\n+    }\n+\n+    private synchronized BKLogReadHandler getReadHandlerForListener(boolean create) {\n+        if (null == readHandlerForListener && create) {\n+            readHandlerForListener = createReadHandler();\n+            readHandlerForListener.scheduleGetLedgersTask(true, true);\n+        }\n+        return readHandlerForListener;\n+    }\n+\n+    @Override\n+    public List<LogSegmentMetadata> getLogSegments() throws IOException {\n+        return FutureUtils.result(getLogSegmentsAsync());\n+    }\n+\n+    protected Future<List<LogSegmentMetadata>> getLogSegmentsAsync() {\n+        final BKLogReadHandler readHandler = createReadHandler();\n+        return readHandler.asyncGetFullLedgerList(true, false).ensure(new AbstractFunction0<BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply() {\n+                readHandler.asyncClose();\n+                return BoxedUnit.UNIT;\n+            }\n+        });\n+    }\n+\n+    @Override\n+    public void registerListener(LogSegmentListener listener) throws IOException {\n+        BKLogReadHandler readHandler = getReadHandlerForListener(true);\n+        readHandler.registerListener(listener);\n+    }\n+\n+    @Override\n+    public synchronized void unregisterListener(LogSegmentListener listener) {\n+        if (null != readHandlerForListener) {\n+            readHandlerForListener.unregisterListener(listener);\n+        }\n+    }\n+\n+    public void checkClosedOrInError(String operation) throws AlreadyClosedException {\n+        if (null != closePromise) {\n+            throw new AlreadyClosedException(\"Executing \" + operation + \" on already closed DistributedLogManager\");\n+        }\n+\n+        if (null != writerBKC) {\n+            writerBKC.checkClosedOrInError();\n+        }\n+        if (null != readerBKC) {\n+            readerBKC.checkClosedOrInError();\n+        }\n+    }\n+\n+    // Create Read Handler\n+\n+    synchronized BKLogReadHandler createReadHandler() {\n+        Optional<String> subscriberId = Optional.absent();\n+        return createReadHandler(subscriberId, false);\n+    }\n+\n+    synchronized BKLogReadHandler createReadHandler(Optional<String> subscriberId) {\n+        return createReadHandler(subscriberId, false);\n+    }\n+\n+    synchronized BKLogReadHandler createReadHandler(Optional<String> subscriberId,\n+                                                    boolean isHandleForReading) {\n+        return createReadHandler(\n+                subscriberId,\n+                getLockStateExecutor(true),\n+                null,\n+                true, /* deserialize record set */\n+                isHandleForReading);\n+    }\n+\n+    synchronized BKLogReadHandler createReadHandler(Optional<String> subscriberId,\n+                                                    OrderedScheduler lockExecutor,\n+                                                    AsyncNotification notification,\n+                                                    boolean deserializeRecordSet,\n+                                                    boolean isHandleForReading) {\n+        ZKLogMetadataForReader logMetadata = ZKLogMetadataForReader.of(uri, name, streamIdentifier);\n+        return new BKLogReadHandler(\n+                logMetadata,\n+                subscriberId,\n+                conf,\n+                dynConf,\n+                readerZKCBuilder,\n+                readerBKCBuilder,\n+                readerMetadataStore,\n+                scheduler,\n+                lockExecutor,\n+                readAheadScheduler,\n+                alertStatsLogger,\n+                readAheadExceptionsLogger,\n+                statsLogger,\n+                perLogStatsLogger,\n+                clientId,\n+                notification,\n+                isHandleForReading,\n+                deserializeRecordSet);\n+    }\n+\n+    // Create Ledger Allocator\n+\n+    LedgerAllocator createLedgerAllocator(ZKLogMetadataForWriter logMetadata) throws IOException {\n+        LedgerAllocator ledgerAllocatorDelegator;\n+        if (!dynConf.getEnableLedgerAllocatorPool()) {\n+            QuorumConfigProvider quorumConfigProvider =\n+                    new DynamicQuorumConfigProvider(dynConf);\n+            LedgerAllocator allocator = new SimpleLedgerAllocator(\n+                    logMetadata.getAllocationPath(),\n+                    logMetadata.getAllocationData(),\n+                    quorumConfigProvider,\n+                    writerZKC,\n+                    writerBKC);\n+            ledgerAllocatorDelegator = new LedgerAllocatorDelegator(allocator, true);\n+        } else {\n+            ledgerAllocatorDelegator = ledgerAllocator;\n+        }\n+        return ledgerAllocatorDelegator;\n+    }\n+\n+    // Create Write Handler\n+\n+    public BKLogWriteHandler createWriteHandler(boolean lockHandler)\n+            throws IOException {\n+        return FutureUtils.result(asyncCreateWriteHandler(lockHandler));\n+    }\n+\n+    Future<BKLogWriteHandler> asyncCreateWriteHandler(final boolean lockHandler) {\n+        final ZooKeeper zk;\n+        try {\n+            zk = writerZKC.get();\n+        } catch (InterruptedException e) {\n+            LOG.error(\"Failed to initialize zookeeper client : \", e);\n+            return Future.exception(new DLInterruptedException(\"Failed to initialize zookeeper client\", e));\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            return Future.exception(FutureUtils.zkException(e, uri.getPath()));\n+        }\n+\n+        boolean ownAllocator = null == ledgerAllocator;\n+\n+        // Fetching Log Metadata\n+        Future<ZKLogMetadataForWriter> metadataFuture =\n+                ZKLogMetadataForWriter.of(uri, name, streamIdentifier,\n+                        zk, writerZKC.getDefaultACL(),\n+                        ownAllocator, conf.getCreateStreamIfNotExists() || ownAllocator);\n+        return metadataFuture.flatMap(new AbstractFunction1<ZKLogMetadataForWriter, Future<BKLogWriteHandler>>() {\n+            @Override\n+            public Future<BKLogWriteHandler> apply(ZKLogMetadataForWriter logMetadata) {\n+                Promise<BKLogWriteHandler> createPromise = new Promise<BKLogWriteHandler>();\n+                createWriteHandler(logMetadata, lockHandler, createPromise);\n+                return createPromise;\n+            }\n+        });\n+    }\n+\n+    private void createWriteHandler(ZKLogMetadataForWriter logMetadata,\n+                                    boolean lockHandler,\n+                                    final Promise<BKLogWriteHandler> createPromise) {\n+        OrderedScheduler lockStateExecutor = getLockStateExecutor(true);\n+        // Build the locks\n+        DistributedLock lock = new DistributedLock(\n+                lockStateExecutor,\n+                getLockFactory(true),\n+                logMetadata.getLockPath(),\n+                conf.getLockTimeoutMilliSeconds(),\n+                statsLogger);\n+        // Build the ledger allocator\n+        LedgerAllocator allocator;\n+        try {\n+            allocator = createLedgerAllocator(logMetadata);\n+        } catch (IOException e) {\n+            FutureUtils.setException(createPromise, e);\n+            return;\n+        }\n+\n+        // Make sure writer handler created before resources are initialized\n+        final BKLogWriteHandler writeHandler = new BKLogWriteHandler(\n+                logMetadata,\n+                conf,\n+                writerZKCBuilder,\n+                writerBKCBuilder,\n+                writerMetadataStore,\n+                scheduler,\n+                allocator,\n+                statsLogger,\n+                perLogStatsLogger,\n+                alertStatsLogger,\n+                clientId,\n+                regionId,\n+                writeLimiter,\n+                featureProvider,\n+                dynConf,\n+                lock);\n+        PermitManager manager = getLogSegmentRollingPermitManager();\n+        if (manager instanceof Watcher) {\n+            writeHandler.register((Watcher) manager);\n+        }\n+        if (lockHandler) {\n+            writeHandler.lockHandler().addEventListener(new FutureEventListener<DistributedLock>() {\n+                @Override\n+                public void onSuccess(DistributedLock lock) {\n+                    FutureUtils.setValue(createPromise, writeHandler);\n+                }\n+\n+                @Override\n+                public void onFailure(final Throwable cause) {\n+                    writeHandler.asyncClose().ensure(new AbstractFunction0<BoxedUnit>() {\n+                        @Override\n+                        public BoxedUnit apply() {\n+                            FutureUtils.setException(createPromise, cause);\n+                            return BoxedUnit.UNIT;\n+                        }\n+                    });\n+                }\n+            });\n+        } else {\n+            FutureUtils.setValue(createPromise, writeHandler);\n+        }\n+    }\n+\n+    PermitManager getLogSegmentRollingPermitManager() {\n+        return logSegmentRollingPermitManager;\n+    }\n+\n+    <T> Future<T> processReaderOperation(final Function<BKLogReadHandler, Future<T>> func) {\n+        initializeFuturePool(false);\n+        return readerFuturePool.apply(new ExceptionalFunction0<BKLogReadHandler>() {\n+            @Override\n+            public BKLogReadHandler applyE() throws Throwable {\n+                return getReadHandlerForListener(true);\n+            }\n+        }).flatMap(new ExceptionalFunction<BKLogReadHandler, Future<T>>() {\n+            @Override\n+            public Future<T> applyE(final BKLogReadHandler readHandler) throws Throwable {\n+                return func.apply(readHandler);\n+            }\n+        });\n+    }\n+\n+    /**\n+     * Check if an end of stream marker was added to the stream\n+     * A stream with an end of stream marker cannot be appended to\n+     *\n+     * @return true if the marker was added to the stream, false otherwise\n+     */\n+    @Override\n+    public boolean isEndOfStreamMarked() throws IOException {\n+        checkClosedOrInError(\"isEndOfStreamMarked\");\n+        long lastTxId = FutureUtils.result(getLastLogRecordAsyncInternal(false, true)).getTransactionId();\n+        return lastTxId == DistributedLogConstants.MAX_TXID;\n+    }\n+\n+    /**\n+     * Begin appending to the end of the log stream which is being treated as a sequence of bytes\n+     *\n+     * @return the writer interface to generate log records\n+     */\n+    public AppendOnlyStreamWriter getAppendOnlyStreamWriter() throws IOException {\n+        long position;\n+        try {\n+            position = FutureUtils.result(getLastLogRecordAsyncInternal(true, false)).getTransactionId();\n+            if (DistributedLogConstants.INVALID_TXID == position ||\n+                DistributedLogConstants.EMPTY_LOGSEGMENT_TX_ID == position) {\n+                position = 0;\n+            }\n+        } catch (LogEmptyException ex) {\n+            position = 0;\n+        } catch (LogNotFoundException ex) {\n+            position = 0;\n+        }\n+        return new AppendOnlyStreamWriter(startAsyncLogSegmentNonPartitioned(), position);\n+    }\n+\n+    /**\n+     * Get a reader to read a log stream as a sequence of bytes\n+     *\n+     * @return the writer interface to generate log records\n+     */\n+    public AppendOnlyStreamReader getAppendOnlyStreamReader() throws IOException {\n+        return new AppendOnlyStreamReader(this);\n+    }\n+\n+    /**\n+     * Begin writing to the log stream identified by the name\n+     *\n+     * @return the writer interface to generate log records\n+     */\n+    @Override\n+    public BKSyncLogWriter startLogSegmentNonPartitioned() throws IOException {\n+        checkClosedOrInError(\"startLogSegmentNonPartitioned\");\n+        BKSyncLogWriter writer = new BKSyncLogWriter(conf, dynConf, this);\n+        boolean success = false;\n+        try {\n+            writer.createAndCacheWriteHandler();\n+            BKLogWriteHandler writeHandler = writer.getWriteHandler();\n+            FutureUtils.result(writeHandler.lockHandler());\n+            success = true;\n+            return writer;\n+        } finally {\n+            if (!success) {\n+                writer.abort();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Begin writing to the log stream identified by the name\n+     *\n+     * @return the writer interface to generate log records\n+     */\n+    @Override\n+    public BKAsyncLogWriter startAsyncLogSegmentNonPartitioned() throws IOException {\n+        return (BKAsyncLogWriter) FutureUtils.result(openAsyncLogWriter());\n+    }\n+\n+    @Override\n+    public Future<AsyncLogWriter> openAsyncLogWriter() {\n+        try {\n+            checkClosedOrInError(\"startLogSegmentNonPartitioned\");\n+        } catch (AlreadyClosedException e) {\n+            return Future.exception(e);\n+        }\n+\n+        Future<BKLogWriteHandler> createWriteHandleFuture;\n+        synchronized (this) {\n+            // 1. create the locked write handler\n+            createWriteHandleFuture = asyncCreateWriteHandler(true);\n+        }\n+        return createWriteHandleFuture.flatMap(new AbstractFunction1<BKLogWriteHandler, Future<AsyncLogWriter>>() {\n+            @Override\n+            public Future<AsyncLogWriter> apply(final BKLogWriteHandler writeHandler) {\n+                final BKAsyncLogWriter writer;\n+                synchronized (BKDistributedLogManager.this) {\n+                    // 2. create the writer with the handler\n+                    writer = new BKAsyncLogWriter(\n+                            conf,\n+                            dynConf,\n+                            BKDistributedLogManager.this,\n+                            writeHandler,\n+                            featureProvider,\n+                            statsLogger);\n+                }\n+                // 3. recover the incomplete log segments\n+                return writeHandler.recoverIncompleteLogSegments()\n+                        .map(new AbstractFunction1<Long, AsyncLogWriter>() {\n+                            @Override\n+                            public AsyncLogWriter apply(Long lastTxId) {\n+                                // 4. update last tx id if successfully recovered\n+                                writer.setLastTxId(lastTxId);\n+                                return writer;\n+                            }\n+                        }).onFailure(new AbstractFunction1<Throwable, BoxedUnit>() {\n+                            @Override\n+                            public BoxedUnit apply(Throwable cause) {\n+                                // 5. close the writer if recovery failed\n+                                writer.asyncAbort();\n+                                return BoxedUnit.UNIT;\n+                            }\n+                        });\n+            }\n+        });\n+    }\n+\n+    @Override\n+    public Future<DLSN> getDLSNNotLessThanTxId(final long fromTxnId) {\n+        return getLogSegmentsAsync().flatMap(new AbstractFunction1<List<LogSegmentMetadata>, Future<DLSN>>() {\n+            @Override\n+            public Future<DLSN> apply(List<LogSegmentMetadata> segments) {\n+                return getDLSNNotLessThanTxId(fromTxnId, segments);\n+            }\n+        });\n+    }\n+\n+    private Future<DLSN> getDLSNNotLessThanTxId(long fromTxnId,\n+                                                final List<LogSegmentMetadata> segments) {\n+        if (segments.isEmpty()) {\n+            return getLastDLSNAsync();\n+        }\n+        final int segmentIdx = DLUtils.findLogSegmentNotLessThanTxnId(segments, fromTxnId);\n+        if (segmentIdx < 0) {\n+            return Future.value(new DLSN(segments.get(0).getLogSegmentSequenceNumber(), 0L, 0L));\n+        }\n+        final LedgerHandleCache handleCache =\n+                LedgerHandleCache.newBuilder().bkc(readerBKC).conf(conf).build();\n+        return getDLSNNotLessThanTxIdInSegment(\n+                fromTxnId,\n+                segmentIdx,\n+                segments,\n+                handleCache\n+        ).ensure(new AbstractFunction0<BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply() {\n+                handleCache.clear();\n+                return BoxedUnit.UNIT;\n+            }\n+        });\n+    }\n+\n+    private Future<DLSN> getDLSNNotLessThanTxIdInSegment(final long fromTxnId,\n+                                                         final int segmentIdx,\n+                                                         final List<LogSegmentMetadata> segments,\n+                                                         final LedgerHandleCache handleCache) {\n+        final LogSegmentMetadata segment = segments.get(segmentIdx);\n+        return ReadUtils.getLogRecordNotLessThanTxId(\n+                name,\n+                segment,\n+                fromTxnId,\n+                scheduler,\n+                handleCache,\n+                Math.max(2, dynConf.getReadAheadBatchSize())\n+        ).flatMap(new AbstractFunction1<Optional<LogRecordWithDLSN>, Future<DLSN>>() {\n+            @Override\n+            public Future<DLSN> apply(Optional<LogRecordWithDLSN> foundRecord) {\n+                if (foundRecord.isPresent()) {\n+                    return Future.value(foundRecord.get().getDlsn());\n+                }\n+                if ((segments.size() - 1) == segmentIdx) {\n+                    return getLastLogRecordAsync().map(new AbstractFunction1<LogRecordWithDLSN, DLSN>() {\n+                        @Override\n+                        public DLSN apply(LogRecordWithDLSN record) {\n+                            if (record.getTransactionId() >= fromTxnId) {\n+                                return record.getDlsn();\n+                            }\n+                            return record.getDlsn().getNextDLSN();\n+                        }\n+                    });\n+                } else {\n+                    return getDLSNNotLessThanTxIdInSegment(\n+                            fromTxnId,\n+                            segmentIdx + 1,\n+                            segments,\n+                            handleCache);\n+                }\n+            }\n+        });\n+    }\n+\n+    /**\n+     * Get the input stream starting with fromTxnId for the specified log\n+     *\n+     * @param fromTxnId - the first transaction id we want to read\n+     * @return the stream starting with transaction fromTxnId\n+     * @throws IOException if a stream cannot be found.\n+     */\n+    @Override\n+    public LogReader getInputStream(long fromTxnId)\n+        throws IOException {\n+        return getInputStreamInternal(fromTxnId);\n+    }\n+\n+    @Override\n+    public LogReader getInputStream(DLSN fromDLSN) throws IOException {\n+        return getInputStreamInternal(fromDLSN, Optional.<Long>absent());\n+    }\n+\n+    @Override\n+    public AsyncLogReader getAsyncLogReader(long fromTxnId) throws IOException {\n+        return FutureUtils.result(openAsyncLogReader(fromTxnId));\n+    }\n+\n+    /**\n+     * Opening a log reader positioning by transaction id <code>fromTxnId</code>.\n+     *\n+     * <p>\n+     * - retrieve log segments for the stream\n+     * - if the log segment list is empty, positioning by the last dlsn\n+     * - otherwise, find the first log segment that contains the records whose transaction ids are not less than\n+     *   the provided transaction id <code>fromTxnId</code>\n+     *   - if all log segments' records' transaction ids are more than <code>fromTxnId</code>, positioning\n+     *     on the first record.\n+     *   - otherwise, search the log segment to find the log record\n+     *     - if the log record is found, positioning the reader by that found record's dlsn\n+     *     - otherwise, positioning by the last dlsn\n+     * </p>\n+     *\n+     * @see DLUtils#findLogSegmentNotLessThanTxnId(List, long)\n+     * @see ReadUtils#getLogRecordNotLessThanTxId(String, LogSegmentMetadata, long, ExecutorService, LedgerHandleCache, int)\n+     * @param fromTxnId\n+     *          transaction id to start reading from\n+     * @return future representing the open result.\n+     */\n+    @Override\n+    public Future<AsyncLogReader> openAsyncLogReader(long fromTxnId) {\n+        final Promise<DLSN> dlsnPromise = new Promise<DLSN>();\n+        getDLSNNotLessThanTxId(fromTxnId).addEventListener(new FutureEventListener<DLSN>() {\n+\n+            @Override\n+            public void onSuccess(DLSN dlsn) {\n+                dlsnPromise.setValue(dlsn);\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                if (cause instanceof LogEmptyException) {\n+                    dlsnPromise.setValue(DLSN.InitialDLSN);\n+                } else {\n+                    dlsnPromise.setException(cause);\n+                }\n+            }\n+        });\n+        return dlsnPromise.flatMap(new AbstractFunction1<DLSN, Future<AsyncLogReader>>() {\n+            @Override\n+            public Future<AsyncLogReader> apply(DLSN dlsn) {\n+                return openAsyncLogReader(dlsn);\n+            }\n+        });\n+    }\n+\n+    @Override\n+    public AsyncLogReader getAsyncLogReader(DLSN fromDLSN) throws IOException {\n+        return FutureUtils.result(openAsyncLogReader(fromDLSN));\n+    }\n+\n+    @Override\n+    public Future<AsyncLogReader> openAsyncLogReader(DLSN fromDLSN) {\n+        Optional<String> subscriberId = Optional.absent();\n+        AsyncLogReader reader = new BKAsyncLogReaderDLSN(\n+                this,\n+                scheduler,\n+                getLockStateExecutor(true),\n+                fromDLSN,\n+                subscriberId,\n+                false,\n+                dynConf.getDeserializeRecordSetOnReads(),\n+                statsLogger);\n+        return Future.value(reader);\n+    }\n+\n+    /**\n+     * Note the lock here is a sort of elective exclusive lock. I.e. acquiring this lock will only prevent other\n+     * people who try to acquire the lock from reading from the stream. Normal readers (and writers) will not be\n+     * blocked.\n+     */\n+    @Override\n+    public Future<AsyncLogReader> getAsyncLogReaderWithLock(final DLSN fromDLSN) {\n+        Optional<String> subscriberId = Optional.absent();\n+        return getAsyncLogReaderWithLock(Optional.of(fromDLSN), subscriberId);\n+    }\n+\n+    @Override\n+    public Future<AsyncLogReader> getAsyncLogReaderWithLock(final DLSN fromDLSN, final String subscriberId) {\n+        return getAsyncLogReaderWithLock(Optional.of(fromDLSN), Optional.of(subscriberId));\n+    }\n+\n+    @Override\n+    public Future<AsyncLogReader> getAsyncLogReaderWithLock(String subscriberId) {\n+        Optional<DLSN> fromDLSN = Optional.absent();\n+        return getAsyncLogReaderWithLock(fromDLSN, Optional.of(subscriberId));\n+    }\n+\n+    protected Future<AsyncLogReader> getAsyncLogReaderWithLock(final Optional<DLSN> fromDLSN,\n+                                                               final Optional<String> subscriberId) {\n+        if (!fromDLSN.isPresent() && !subscriberId.isPresent()) {\n+            return Future.exception(new UnexpectedException(\"Neither from dlsn nor subscriber id is provided.\"));\n+        }\n+        final BKAsyncLogReaderDLSN reader = new BKAsyncLogReaderDLSN(\n+                BKDistributedLogManager.this,\n+                scheduler,\n+                getLockStateExecutor(true),\n+                fromDLSN.isPresent() ? fromDLSN.get() : DLSN.InitialDLSN,\n+                subscriberId,\n+                false,\n+                dynConf.getDeserializeRecordSetOnReads(),\n+                statsLogger);\n+        pendingReaders.add(reader);\n+        final Future<Void> lockFuture = reader.lockStream();\n+        final Promise<AsyncLogReader> createPromise = new Promise<AsyncLogReader>(\n+                new Function<Throwable, BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply(Throwable cause) {\n+                // cancel the lock when the creation future is cancelled\n+                lockFuture.cancel();\n+                return BoxedUnit.UNIT;\n+            }\n+        });\n+        // lock the stream - fetch the last commit position on success\n+        lockFuture.flatMap(new Function<Void, Future<AsyncLogReader>>() {\n+            @Override\n+            public Future<AsyncLogReader> apply(Void complete) {\n+                if (fromDLSN.isPresent()) {\n+                    return Future.value((AsyncLogReader) reader);\n+                }\n+                LOG.info(\"Reader {} @ {} reading last commit position from subscription store after acquired lock.\",\n+                        subscriberId.get(), name);\n+                // we acquired lock\n+                final SubscriptionStateStore stateStore = getSubscriptionStateStore(subscriberId.get());\n+                return stateStore.getLastCommitPosition().map(new ExceptionalFunction<DLSN, AsyncLogReader>() {\n+                    @Override\n+                    public AsyncLogReader applyE(DLSN lastCommitPosition) throws UnexpectedException {\n+                        LOG.info(\"Reader {} @ {} positioned to last commit position {}.\",\n+                                new Object[] { subscriberId.get(), name, lastCommitPosition });\n+                        reader.setStartDLSN(lastCommitPosition);\n+                        return reader;\n+                    }\n+                });\n+            }\n+        }).addEventListener(new FutureEventListener<AsyncLogReader>() {\n+            @Override\n+            public void onSuccess(AsyncLogReader r) {\n+                pendingReaders.remove(reader);\n+                FutureUtils.setValue(createPromise, r);\n+            }\n+\n+            @Override\n+            public void onFailure(final Throwable cause) {\n+                pendingReaders.remove(reader);\n+                reader.asyncClose().ensure(new AbstractFunction0<BoxedUnit>() {\n+                    @Override\n+                    public BoxedUnit apply() {\n+                        FutureUtils.setException(createPromise, cause);\n+                        return BoxedUnit.UNIT;\n+                    }\n+                });\n+            }\n+        });\n+        return createPromise;\n+    }\n+\n+    /**\n+     * Get the input stream starting with fromTxnId for the specified log\n+     *\n+     * @param fromTxnId\n+     *          transaction id to start reading from\n+     * @return log reader\n+     * @throws IOException\n+     */\n+    LogReader getInputStreamInternal(long fromTxnId)\n+        throws IOException {\n+        DLSN fromDLSN;\n+        try {\n+            fromDLSN = FutureUtils.result(getDLSNNotLessThanTxId(fromTxnId));\n+        } catch (LogEmptyException lee) {\n+            fromDLSN = DLSN.InitialDLSN;\n+        }\n+        return getInputStreamInternal(fromDLSN, Optional.of(fromTxnId));\n+    }\n+\n+    LogReader getInputStreamInternal(DLSN fromDLSN, Optional<Long> fromTxnId)\n+            throws IOException {\n+        LOG.info(\"Create async reader starting from {}\", fromDLSN);\n+        checkClosedOrInError(\"getInputStream\");\n+        Optional<String> subscriberId = Optional.absent();\n+        BKAsyncLogReaderDLSN asyncReader = new BKAsyncLogReaderDLSN(\n+                this,\n+                scheduler,\n+                getLockStateExecutor(true),\n+                fromDLSN,\n+                subscriberId,\n+                true,\n+                dynConf.getDeserializeRecordSetOnReads(),\n+                statsLogger);\n+        return new BKSyncLogReaderDLSN(conf, asyncReader, scheduler, fromTxnId);\n+    }\n+\n+    /**\n+     * Get the last log record in the stream\n+     *\n+     * @return the last log record in the stream\n+     * @throws java.io.IOException if a stream cannot be found.\n+     */\n+    @Override\n+    public LogRecordWithDLSN getLastLogRecord() throws IOException {\n+        checkClosedOrInError(\"getLastLogRecord\");\n+        return FutureUtils.result(getLastLogRecordAsync());\n+    }\n+\n+    @Override\n+    public long getFirstTxId() throws IOException {\n+        checkClosedOrInError(\"getFirstTxId\");\n+        return FutureUtils.result(getFirstRecordAsyncInternal()).getTransactionId();\n+    }\n+\n+    @Override\n+    public long getLastTxId() throws IOException {\n+        checkClosedOrInError(\"getLastTxId\");\n+        return FutureUtils.result(getLastTxIdAsync());\n+    }\n+\n+    @Override\n+    public DLSN getLastDLSN() throws IOException {\n+        checkClosedOrInError(\"getLastDLSN\");\n+        return FutureUtils.result(getLastLogRecordAsyncInternal(false, false)).getDlsn();\n+    }\n+\n+    /**\n+     * Get Latest log record in the log\n+     *\n+     * @return latest log record\n+     */\n+    @Override\n+    public Future<LogRecordWithDLSN> getLastLogRecordAsync() {\n+        return getLastLogRecordAsyncInternal(false, false);\n+    }\n+\n+    private Future<LogRecordWithDLSN> getLastLogRecordAsyncInternal(final boolean recover,\n+                                                                    final boolean includeEndOfStream) {\n+        return processReaderOperation(new Function<BKLogReadHandler, Future<LogRecordWithDLSN>>() {\n+            @Override\n+            public Future<LogRecordWithDLSN> apply(final BKLogReadHandler ledgerHandler) {\n+                return ledgerHandler.getLastLogRecordAsync(recover, includeEndOfStream);\n+            }\n+        });\n+    }\n+\n+    /**\n+     * Get Latest Transaction Id in the log\n+     *\n+     * @return latest transaction id\n+     */\n+    @Override\n+    public Future<Long> getLastTxIdAsync() {\n+        return getLastLogRecordAsyncInternal(false, false)\n+                .map(RECORD_2_TXID_FUNCTION);\n+    }\n+\n+    /**\n+     * Get first DLSN in the log.\n+     *\n+     * @return first dlsn in the stream\n+     */\n+    @Override\n+    public Future<DLSN> getFirstDLSNAsync() {\n+        return getFirstRecordAsyncInternal().map(RECORD_2_DLSN_FUNCTION);\n+    }\n+\n+    private Future<LogRecordWithDLSN> getFirstRecordAsyncInternal() {\n+        return processReaderOperation(new Function<BKLogReadHandler, Future<LogRecordWithDLSN>>() {\n+            @Override\n+            public Future<LogRecordWithDLSN> apply(final BKLogReadHandler ledgerHandler) {\n+                return ledgerHandler.asyncGetFirstLogRecord();\n+            }\n+        });\n+    }\n+\n+    /**\n+     * Get Latest DLSN in the log.\n+     *\n+     * @return latest transaction id\n+     */\n+    @Override\n+    public Future<DLSN> getLastDLSNAsync() {\n+        return getLastLogRecordAsyncInternal(false, false)\n+                .map(RECORD_2_DLSN_FUNCTION);\n+    }\n+\n+    /**\n+     * Get the number of log records in the active portion of the log\n+     * Any log segments that have already been truncated will not be included\n+     *\n+     * @return number of log records\n+     * @throws IOException\n+     */\n+    @Override\n+    public long getLogRecordCount() throws IOException {\n+        checkClosedOrInError(\"getLogRecordCount\");\n+        return FutureUtils.result(getLogRecordCountAsync(DLSN.InitialDLSN));\n+    }\n+\n+    /**\n+     * Get the number of log records in the active portion of the log asynchronously.\n+     * Any log segments that have already been truncated will not be included\n+     *\n+     * @return future number of log records\n+     * @throws IOException\n+     */\n+    @Override\n+    public Future<Long> getLogRecordCountAsync(final DLSN beginDLSN) {\n+        return processReaderOperation(new Function<BKLogReadHandler, Future<Long>>() {\n+                    @Override\n+                    public Future<Long> apply(BKLogReadHandler ledgerHandler) {\n+                        return ledgerHandler.asyncGetLogRecordCount(beginDLSN);\n+                    }\n+                });\n+    }\n+\n+    @Override\n+    public void recover() throws IOException {\n+        recoverInternal(conf.getUnpartitionedStreamName());\n+    }\n+\n+    /**\n+     * Recover a specified stream within the log container\n+     * The writer implicitly recovers a topic when it resumes writing.\n+     * This allows applications to recover a container explicitly so\n+     * that application may read a fully recovered log before resuming\n+     * the writes\n+     *\n+     * @throws IOException if the recovery fails\n+     */\n+    private void recoverInternal(String streamIdentifier) throws IOException {\n+        checkClosedOrInError(\"recoverInternal\");\n+        BKLogWriteHandler ledgerHandler = createWriteHandler(true);\n+        try {\n+            FutureUtils.result(ledgerHandler.recoverIncompleteLogSegments());\n+        } finally {\n+            Utils.closeQuietly(ledgerHandler);\n+        }\n+    }\n+\n+    /**\n+     * Delete all the partitions of the specified log\n+     *\n+     * @throws IOException if the deletion fails\n+     */\n+    @Override\n+    public void delete() throws IOException {\n+        BKLogWriteHandler ledgerHandler = createWriteHandler(true);\n+        try {\n+            ledgerHandler.deleteLog();\n+        } finally {\n+            Utils.closeQuietly(ledgerHandler);\n+        }\n+\n+        // Delete the ZK path associated with the log stream\n+        String zkPath = getZKPath();\n+        // Safety check when we are using the shared zookeeper\n+        if (zkPath.toLowerCase().contains(\"distributedlog\")) {\n+            try {\n+                LOG.info(\"Delete the path associated with the log {}, ZK Path {}\", name, zkPath);\n+                ZKUtil.deleteRecursive(writerZKC.get(), zkPath);\n+            } catch (InterruptedException ie) {\n+                LOG.error(\"Interrupted while accessing ZK\", ie);\n+                throw new DLInterruptedException(\"Error initializing zk\", ie);\n+            } catch (KeeperException ke) {\n+                LOG.error(\"Error accessing entry in zookeeper\", ke);\n+                throw new IOException(\"Error initializing zk\", ke);\n+            }\n+        } else {\n+            LOG.warn(\"Skip deletion of unrecognized ZK Path {}\", zkPath);\n+        }\n+    }\n+\n+\n+    /**\n+     * The DistributedLogManager may archive/purge any logs for transactionId\n+     * less than or equal to minImageTxId.\n+     * This is to be used only when the client explicitly manages deletion. If\n+     * the cleanup policy is based on sliding time window, then this method need\n+     * not be called.\n+     *\n+     * @param minTxIdToKeep the earliest txid that must be retained\n+     * @throws IOException if purging fails\n+     */\n+    @Override\n+    public void purgeLogsOlderThan(long minTxIdToKeep) throws IOException {\n+        Preconditions.checkArgument(minTxIdToKeep > 0, \"Invalid transaction id \" + minTxIdToKeep);\n+        checkClosedOrInError(\"purgeLogSegmentsOlderThan\");\n+        BKLogWriteHandler ledgerHandler = createWriteHandler(true);\n+        try {\n+            LOG.info(\"Purging logs for {} older than {}\", ledgerHandler.getFullyQualifiedName(), minTxIdToKeep);\n+            FutureUtils.result(ledgerHandler.purgeLogSegmentsOlderThanTxnId(minTxIdToKeep));\n+        } finally {\n+            Utils.closeQuietly(ledgerHandler);\n+        }\n+    }\n+\n+    static class PendingReaders implements AsyncCloseable {\n+\n+        final ExecutorService executorService;\n+        final Set<AsyncLogReader> readers = new HashSet<AsyncLogReader>();\n+\n+        PendingReaders(ExecutorService executorService) {\n+            this.executorService = executorService;\n+        }\n+\n+        public synchronized void remove(AsyncLogReader reader) {\n+            readers.remove(reader);\n+        }\n+\n+        public synchronized void add(AsyncLogReader reader) {\n+            readers.add(reader);\n+        }\n+\n+        @Override\n+        public Future<Void> asyncClose() {\n+            return Utils.closeSequence(executorService, true, readers.toArray(new AsyncLogReader[readers.size()]))\n+                    .onSuccess(new AbstractFunction1<Void, BoxedUnit>() {\n+                        @Override\n+                        public BoxedUnit apply(Void value) {\n+                            readers.clear();\n+                            return BoxedUnit.UNIT;\n+                        }\n+                    });\n+        }\n+    };\n+\n+    /**\n+     * Close the distributed log manager, freeing any resources it may hold.\n+     */\n+    @Override\n+    public Future<Void> asyncClose() {\n+        Promise<Void> closeFuture;\n+        BKLogReadHandler readHandlerToClose;\n+        synchronized (this) {\n+            if (null != closePromise) {\n+                return closePromise;\n+            }\n+            closeFuture = closePromise = new Promise<Void>();\n+            readHandlerToClose = readHandlerForListener;\n+        }\n+\n+        // NOTE: the resources {scheduler, writerBKC, readerBKC} are mostly from namespace instance.\n+        //       so they are not blocking call except tests.\n+        AsyncCloseable resourcesCloseable = new AsyncCloseable() {\n+            @Override\n+            public Future<Void> asyncClose() {\n+                int schedTimeout = conf.getSchedulerShutdownTimeoutMs();\n+\n+                // Clean up executor state.\n+                if (ownExecutor) {\n+                    SchedulerUtils.shutdownScheduler(scheduler, schedTimeout, TimeUnit.MILLISECONDS);\n+                    LOG.info(\"Stopped BKDL executor service for {}.\", name);\n+\n+                    if (scheduler != readAheadScheduler) {\n+                        SchedulerUtils.shutdownScheduler(readAheadScheduler, schedTimeout, TimeUnit.MILLISECONDS);\n+                        LOG.info(\"Stopped BKDL ReadAhead Executor Service for {}.\", name);\n+                    }\n+\n+                    SchedulerUtils.shutdownScheduler(getLockStateExecutor(false), schedTimeout, TimeUnit.MILLISECONDS);\n+                    LOG.info(\"Stopped BKDL Lock State Executor for {}.\", name);\n+                }\n+                if (ownWriterBKC) {\n+                    writerBKC.close();\n+                }\n+                if (ownReaderBKC) {\n+                    readerBKC.close();\n+                }\n+                return Future.Void();\n+            }\n+        };\n+\n+        Future<Void> closeResult = Utils.closeSequence(null, true,\n+                readHandlerToClose,\n+                pendingReaders,\n+                resourcesCloseable,\n+                new AsyncCloseable() {\n+                    @Override\n+                    public Future<Void> asyncClose() {\n+                        return BKDistributedLogManager.super.asyncClose();\n+                    }\n+                });\n+        closeResult.proxyTo(closeFuture);\n+        return closeFuture;\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        FutureUtils.result(asyncClose());\n+    }\n+\n+    public boolean scheduleTask(Runnable task) {\n+        try {\n+            scheduler.submit(task);\n+            return true;\n+        } catch (RejectedExecutionException ree) {\n+            LOG.error(\"Task {} is rejected : \", task, ree);\n+            return false;\n+        }\n+    }\n+\n+    private FuturePool buildFuturePool(ExecutorService executorService,\n+                                       StatsLogger statsLogger) {\n+        FuturePool futurePool = new ExecutorServiceFuturePool(executorService);\n+        return new MonitoredFuturePool(\n+                futurePool,\n+                statsLogger,\n+                conf.getEnableTaskExecutionStats(),\n+                conf.getTaskExecutionWarnTimeMicros());\n+    }\n+\n+    private void initializeFuturePool(boolean ordered) {\n+        // ownExecutor is a single threaded thread pool\n+        if (null == readerFuturePool) {\n+            readerFuturePool = buildFuturePool(\n+                    scheduler, statsLogger.scope(\"reader_future_pool\"));\n+        }\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"DLM:%s:%s\", getZKPath(), getStreamName());\n+    }\n+\n+    public void raiseAlert(String msg, Object... args) {\n+        alertStatsLogger.raise(msg, args);\n+    }\n+\n+    /**\n+     * Get the subscription state storage provided by the distributed log manager\n+     *\n+     * @param subscriberId - Application specific Id associated with the subscriber\n+     * @return Subscription state store\n+     */\n+    @Override\n+    @Deprecated\n+    public SubscriptionStateStore getSubscriptionStateStore(String subscriberId) {\n+        return getSubscriptionStateStoreInternal(conf.getUnpartitionedStreamName(), subscriberId);\n+    }\n+\n+    /**\n+     * Get the subscription state storage provided by the distributed log manager\n+     *\n+     * @param streamIdentifier - Identifier associated with the stream\n+     * @param subscriberId - Application specific Id associated with the subscriber\n+     * @return Subscription state store\n+     */\n+    private SubscriptionStateStore getSubscriptionStateStoreInternal(String streamIdentifier, String subscriberId) {\n+        return new ZKSubscriptionStateStore(writerZKC,\n+                ZKLogMetadataForReader.getSubscriberPath(uri, name, streamIdentifier, subscriberId));\n+    }\n+\n+    @Override\n+    public SubscriptionsStore getSubscriptionsStore() {\n+        return getSubscriptionsStoreInternal(conf.getUnpartitionedStreamName());\n+    }\n+\n+    /**\n+     * Get the subscription state storage provided by the distributed log manager\n+     *\n+     * @param streamIdentifier - Identifier associated with the stream\n+     * @return Subscriptions store\n+     */\n+    private SubscriptionsStore getSubscriptionsStoreInternal(String streamIdentifier) {\n+        return new ZKSubscriptionsStore(writerZKC,\n+                ZKLogMetadataForReader.getSubscribersPath(uri, name, streamIdentifier));\n+    }\n+}"},{"sha":"0b522d048c865319078ae680ddab09bbf6fbe983","filename":"src/main/java/com/twitter/distributedlog/BKDistributedLogNamespace.java","status":"added","additions":1077,"deletions":0,"changes":1077,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,1077 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Optional;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Sets;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import com.twitter.distributedlog.DistributedLogManagerFactory.ClientSharingOption;\n+import com.twitter.distributedlog.acl.AccessControlManager;\n+import com.twitter.distributedlog.acl.DefaultAccessControlManager;\n+import com.twitter.distributedlog.acl.ZKAccessControlManager;\n+import com.twitter.distributedlog.bk.LedgerAllocator;\n+import com.twitter.distributedlog.bk.LedgerAllocatorUtils;\n+import com.twitter.distributedlog.callback.NamespaceListener;\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.InvalidStreamNameException;\n+import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.feature.CoreFeatureKeys;\n+import com.twitter.distributedlog.impl.ZKLogMetadataStore;\n+import com.twitter.distributedlog.impl.ZKLogSegmentMetadataStore;\n+import com.twitter.distributedlog.impl.federated.FederatedZKLogMetadataStore;\n+import com.twitter.distributedlog.lock.SessionLockFactory;\n+import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.metadata.BKDLConfig;\n+import com.twitter.distributedlog.metadata.LogMetadataStore;\n+import com.twitter.distributedlog.namespace.DistributedLogNamespace;\n+import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n+import com.twitter.distributedlog.util.ConfUtils;\n+import com.twitter.distributedlog.util.DLUtils;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.LimitedPermitManager;\n+import com.twitter.distributedlog.util.MonitoredScheduledThreadPoolExecutor;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.distributedlog.util.PermitLimiter;\n+import com.twitter.distributedlog.util.PermitManager;\n+import com.twitter.distributedlog.util.SchedulerUtils;\n+import com.twitter.distributedlog.util.SimplePermitLimiter;\n+import com.twitter.distributedlog.util.Utils;\n+import org.apache.bookkeeper.feature.FeatureProvider;\n+import org.apache.bookkeeper.feature.Feature;\n+import org.apache.bookkeeper.feature.SettableFeatureProvider;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.zookeeper.BoundExponentialBackoffRetryPolicy;\n+import org.apache.bookkeeper.zookeeper.RetryPolicy;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.apache.zookeeper.common.PathUtils;\n+import org.apache.zookeeper.data.Stat;\n+import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n+import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory;\n+import org.jboss.netty.util.HashedWheelTimer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.twitter.distributedlog.impl.BKDLUtils.*;\n+\n+/**\n+ * BKDistributedLogNamespace is the default implementation of {@link DistributedLogNamespace}. It uses\n+ * zookeeper for metadata storage and bookkeeper for data storage.\n+ * <h3>Metrics</h3>\n+ *\n+ * <h4>ZooKeeper Client</h4>\n+ * See {@link ZooKeeperClient} for detail sub-stats.\n+ * <ul>\n+ * <li> `scope`/dlzk_factory_writer_shared/* : stats about the zookeeper client shared by all DL writers.\n+ * <li> `scope`/dlzk_factory_reader_shared/* : stats about the zookeeper client shared by all DL readers.\n+ * <li> `scope`/bkzk_factory_writer_shared/* : stats about the zookeeper client used by bookkeeper client\n+ * shared by all DL writers.\n+ * <li> `scope`/bkzk_factory_reader_shared/* : stats about the zookeeper client used by bookkeeper client\n+ * shared by all DL readers.\n+ * </ul>\n+ *\n+ * <h4>BookKeeper Client</h4>\n+ * BookKeeper client stats are exposed directly to current scope. See {@link BookKeeperClient} for detail stats.\n+ *\n+ * <h4>Utils</h4>\n+ * <ul>\n+ * <li> `scope`/factory/thread_pool/* : stats about the ordered scheduler used by this namespace.\n+ * See {@link OrderedScheduler}.\n+ * <li> `scope`/factory/readahead_thread_pool/* : stats about the readahead thread pool executor\n+ * used by this namespace. See {@link MonitoredScheduledThreadPoolExecutor}.\n+ * <li> `scope`/writeLimiter/* : stats about the global write limiter used by this namespace.\n+ * See {@link PermitLimiter}.\n+ * </ul>\n+ *\n+ * <h4>ReadAhead Exceptions</h4>\n+ * Stats about exceptions that encountered in ReadAhead are exposed under <code>`scope`/exceptions</code>.\n+ * See {@link ReadAheadExceptionsLogger}.\n+ *\n+ * <h4>DistributedLogManager</h4>\n+ *\n+ * All the core stats about reader and writer are exposed under current scope via {@link BKDistributedLogManager}.\n+ */\n+public class BKDistributedLogNamespace implements DistributedLogNamespace {\n+    static final Logger LOG = LoggerFactory.getLogger(BKDistributedLogNamespace.class);\n+\n+    public static Builder newBuilder() {\n+        return new Builder();\n+    }\n+\n+    public static class Builder {\n+        private DistributedLogConfiguration _conf = null;\n+        private URI _uri = null;\n+        private StatsLogger _statsLogger = NullStatsLogger.INSTANCE;\n+        private StatsLogger _perLogStatsLogger = NullStatsLogger.INSTANCE;\n+        private FeatureProvider _featureProvider = new SettableFeatureProvider(\"\", 0);\n+        private String _clientId = DistributedLogConstants.UNKNOWN_CLIENT_ID;\n+        private int _regionId = DistributedLogConstants.LOCAL_REGION_ID;\n+\n+        private Builder() {}\n+\n+        public Builder conf(DistributedLogConfiguration conf) {\n+            this._conf = conf;\n+            return this;\n+        }\n+\n+        public Builder uri(URI uri) {\n+            this._uri = uri;\n+            return this;\n+        }\n+\n+        public Builder statsLogger(StatsLogger statsLogger) {\n+            this._statsLogger = statsLogger;\n+            return this;\n+        }\n+\n+        public Builder perLogStatsLogger(StatsLogger perLogStatsLogger) {\n+            this._perLogStatsLogger = perLogStatsLogger;\n+            return this;\n+        }\n+\n+        public Builder featureProvider(FeatureProvider featureProvider) {\n+            this._featureProvider = featureProvider;\n+            return this;\n+        }\n+\n+        public Builder clientId(String clientId) {\n+            this._clientId = clientId;\n+            return this;\n+        }\n+\n+        public Builder regionId(int regionId) {\n+            this._regionId = regionId;\n+            return this;\n+        }\n+\n+        @SuppressWarnings(\"deprecation\")\n+        public BKDistributedLogNamespace build()\n+                throws IOException, NullPointerException, IllegalArgumentException {\n+            Preconditions.checkNotNull(_conf, \"No DistributedLog Configuration\");\n+            Preconditions.checkNotNull(_uri, \"No DistributedLog URI\");\n+            Preconditions.checkNotNull(_featureProvider, \"No Feature Provider\");\n+            Preconditions.checkNotNull(_statsLogger, \"No Stats Logger\");\n+            Preconditions.checkNotNull(_featureProvider, \"No Feature Provider\");\n+            Preconditions.checkNotNull(_clientId, \"No Client ID\");\n+            // validate conf and uri\n+            validateConfAndURI(_conf, _uri);\n+\n+            // Build the namespace zookeeper client\n+            ZooKeeperClientBuilder nsZkcBuilder = createDLZKClientBuilder(\n+                    String.format(\"dlzk:%s:factory_writer_shared\", _uri),\n+                    _conf,\n+                    DLUtils.getZKServersFromDLUri(_uri),\n+                    _statsLogger.scope(\"dlzk_factory_writer_shared\"));\n+            ZooKeeperClient nsZkc = nsZkcBuilder.build();\n+\n+            // Resolve namespace binding\n+            BKDLConfig bkdlConfig = BKDLConfig.resolveDLConfig(nsZkc, _uri);\n+\n+            // Backward Compatible to enable per log stats by configuration settings\n+            StatsLogger perLogStatsLogger = _perLogStatsLogger;\n+            if (perLogStatsLogger == NullStatsLogger.INSTANCE &&\n+                    _conf.getEnablePerStreamStat()) {\n+                perLogStatsLogger = _statsLogger.scope(\"stream\");\n+            }\n+\n+            return new BKDistributedLogNamespace(\n+                    _conf,\n+                    _uri,\n+                    _featureProvider,\n+                    _statsLogger,\n+                    perLogStatsLogger,\n+                    _clientId,\n+                    _regionId,\n+                    nsZkcBuilder,\n+                    nsZkc,\n+                    bkdlConfig);\n+        }\n+    }\n+\n+    static interface ZooKeeperClientHandler<T> {\n+        T handle(ZooKeeperClient zkc) throws IOException;\n+    }\n+\n+    /**\n+     * Run given <i>handler</i> by providing an available new zookeeper client\n+     *\n+     * @param handler\n+     *          Handler to process with provided zookeeper client.\n+     * @param conf\n+     *          Distributedlog Configuration.\n+     * @param namespace\n+     *          Distributedlog Namespace.\n+     */\n+    private static <T> T withZooKeeperClient(ZooKeeperClientHandler<T> handler,\n+                                             DistributedLogConfiguration conf,\n+                                             URI namespace) throws IOException {\n+        ZooKeeperClient zkc = ZooKeeperClientBuilder.newBuilder()\n+                .name(String.format(\"dlzk:%s:factory_static\", namespace))\n+                .sessionTimeoutMs(conf.getZKSessionTimeoutMilliseconds())\n+                .uri(namespace)\n+                .retryThreadCount(conf.getZKClientNumberRetryThreads())\n+                .requestRateLimit(conf.getZKRequestRateLimit())\n+                .zkAclId(conf.getZkAclId())\n+                .build();\n+        try {\n+            return handler.handle(zkc);\n+        } finally {\n+            zkc.close();\n+        }\n+    }\n+\n+    private final String clientId;\n+    private final int regionId;\n+    private final DistributedLogConfiguration conf;\n+    private final URI namespace;\n+    private final BKDLConfig bkdlConfig;\n+    private final OrderedScheduler scheduler;\n+    private final OrderedScheduler readAheadExecutor;\n+    private final OrderedScheduler lockStateExecutor;\n+    private final ClientSocketChannelFactory channelFactory;\n+    private final HashedWheelTimer requestTimer;\n+    // zookeeper clients\n+    // NOTE: The actual zookeeper client is initialized lazily when it is referenced by\n+    //       {@link com.twitter.distributedlog.ZooKeeperClient#get()}. So it is safe to\n+    //       keep builders and their client wrappers here, as they will be used when\n+    //       instantiating readers or writers.\n+    private final ZooKeeperClientBuilder sharedWriterZKCBuilderForDL;\n+    private final ZooKeeperClient sharedWriterZKCForDL;\n+    private final ZooKeeperClientBuilder sharedReaderZKCBuilderForDL;\n+    private final ZooKeeperClient sharedReaderZKCForDL;\n+    private ZooKeeperClientBuilder sharedWriterZKCBuilderForBK = null;\n+    private ZooKeeperClient sharedWriterZKCForBK = null;\n+    private ZooKeeperClientBuilder sharedReaderZKCBuilderForBK = null;\n+    private ZooKeeperClient sharedReaderZKCForBK = null;\n+    // NOTE: The actual bookkeeper client is initialized lazily when it is referenced by\n+    //       {@link com.twitter.distributedlog.BookKeeperClient#get()}. So it is safe to\n+    //       keep builders and their client wrappers here, as they will be used when\n+    //       instantiating readers or writers.\n+    private final BookKeeperClientBuilder sharedWriterBKCBuilder;\n+    private final BookKeeperClient writerBKC;\n+    private final BookKeeperClientBuilder sharedReaderBKCBuilder;\n+    private final BookKeeperClient readerBKC;\n+    // ledger allocator\n+    private final LedgerAllocator allocator;\n+    // access control manager\n+    private AccessControlManager accessControlManager;\n+    // log segment rolling permit manager\n+    private final PermitManager logSegmentRollingPermitManager;\n+    // log metadata store\n+    private final LogMetadataStore metadataStore;\n+    // log segment metadata store\n+    private final LogSegmentMetadataStore writerSegmentMetadataStore;\n+    private final LogSegmentMetadataStore readerSegmentMetadataStore;\n+    // lock factory\n+    private final SessionLockFactory lockFactory;\n+\n+    // feature provider\n+    private final FeatureProvider featureProvider;\n+\n+    // Stats Loggers\n+    private final StatsLogger statsLogger;\n+    private final StatsLogger perLogStatsLogger;\n+    private final ReadAheadExceptionsLogger readAheadExceptionsLogger;\n+\n+    protected boolean closed = false;\n+\n+    private final PermitLimiter writeLimiter;\n+\n+    private BKDistributedLogNamespace(\n+            DistributedLogConfiguration conf,\n+            URI uri,\n+            FeatureProvider featureProvider,\n+            StatsLogger statsLogger,\n+            StatsLogger perLogStatsLogger,\n+            String clientId,\n+            int regionId,\n+            ZooKeeperClientBuilder nsZkcBuilder,\n+            ZooKeeperClient nsZkc,\n+            BKDLConfig bkdlConfig)\n+            throws IOException, IllegalArgumentException {\n+        this.conf = conf;\n+        this.namespace = uri;\n+        this.featureProvider = featureProvider;\n+        this.statsLogger = statsLogger;\n+        this.perLogStatsLogger = perLogStatsLogger;\n+        this.clientId = clientId;\n+        this.regionId = regionId;\n+        this.bkdlConfig = bkdlConfig;\n+\n+        // Build resources\n+        StatsLogger schedulerStatsLogger = statsLogger.scope(\"factory\").scope(\"thread_pool\");\n+        this.scheduler = OrderedScheduler.newBuilder()\n+                .name(\"DLM-\" + uri.getPath())\n+                .corePoolSize(conf.getNumWorkerThreads())\n+                .statsLogger(schedulerStatsLogger)\n+                .perExecutorStatsLogger(schedulerStatsLogger)\n+                .traceTaskExecution(conf.getEnableTaskExecutionStats())\n+                .traceTaskExecutionWarnTimeUs(conf.getTaskExecutionWarnTimeMicros())\n+                .build();\n+        if (conf.getNumReadAheadWorkerThreads() > 0) {\n+            this.readAheadExecutor = OrderedScheduler.newBuilder()\n+                    .name(\"DLM-\" + uri.getPath() + \"-readahead-executor\")\n+                    .corePoolSize(conf.getNumReadAheadWorkerThreads())\n+                    .statsLogger(statsLogger.scope(\"factory\").scope(\"readahead_thread_pool\"))\n+                    .traceTaskExecution(conf.getTraceReadAheadDeliveryLatency())\n+                    .traceTaskExecutionWarnTimeUs(conf.getTaskExecutionWarnTimeMicros())\n+                    .build();\n+            LOG.info(\"Created dedicated readahead executor : threads = {}\", conf.getNumReadAheadWorkerThreads());\n+        } else {\n+            this.readAheadExecutor = this.scheduler;\n+            LOG.info(\"Used shared executor for readahead.\");\n+        }\n+        StatsLogger lockStateStatsLogger = statsLogger.scope(\"factory\").scope(\"lock_scheduler\");\n+        this.lockStateExecutor = OrderedScheduler.newBuilder()\n+                .name(\"DLM-LockState\")\n+                .corePoolSize(conf.getNumLockStateThreads())\n+                .statsLogger(lockStateStatsLogger)\n+                .perExecutorStatsLogger(lockStateStatsLogger)\n+                .traceTaskExecution(conf.getEnableTaskExecutionStats())\n+                .traceTaskExecutionWarnTimeUs(conf.getTaskExecutionWarnTimeMicros())\n+                .build();\n+        this.channelFactory = new NioClientSocketChannelFactory(\n+            Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat(\"DL-netty-boss-%d\").build()),\n+            Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat(\"DL-netty-worker-%d\").build()),\n+            conf.getBKClientNumberIOThreads());\n+        this.requestTimer = new HashedWheelTimer(\n+            new ThreadFactoryBuilder().setNameFormat(\"DLFactoryTimer-%d\").build(),\n+            conf.getTimeoutTimerTickDurationMs(), TimeUnit.MILLISECONDS,\n+            conf.getTimeoutTimerNumTicks());\n+\n+        // Build zookeeper client for writers\n+        this.sharedWriterZKCBuilderForDL = nsZkcBuilder;\n+        this.sharedWriterZKCForDL = nsZkc;\n+\n+        // Build zookeeper client for readers\n+        if (bkdlConfig.getDlZkServersForWriter().equals(bkdlConfig.getDlZkServersForReader())) {\n+            this.sharedReaderZKCBuilderForDL = this.sharedWriterZKCBuilderForDL;\n+        } else {\n+            this.sharedReaderZKCBuilderForDL = createDLZKClientBuilder(\n+                    String.format(\"dlzk:%s:factory_reader_shared\", namespace),\n+                    conf,\n+                    bkdlConfig.getDlZkServersForReader(),\n+                    statsLogger.scope(\"dlzk_factory_reader_shared\"));\n+        }\n+        this.sharedReaderZKCForDL = this.sharedReaderZKCBuilderForDL.build();\n+\n+        // Build bookkeeper client for writers\n+        this.sharedWriterBKCBuilder = createBKCBuilder(\n+                String.format(\"bk:%s:factory_writer_shared\", namespace),\n+                conf,\n+                bkdlConfig.getBkZkServersForWriter(),\n+                bkdlConfig.getBkLedgersPath(),\n+                Optional.of(featureProvider.scope(\"bkc\")));\n+        this.writerBKC = this.sharedWriterBKCBuilder.build();\n+\n+        // Build bookkeeper client for readers\n+        if (bkdlConfig.getBkZkServersForWriter().equals(bkdlConfig.getBkZkServersForReader())) {\n+            this.sharedReaderBKCBuilder = this.sharedWriterBKCBuilder;\n+        } else {\n+            this.sharedReaderBKCBuilder = createBKCBuilder(\n+                String.format(\"bk:%s:factory_reader_shared\", namespace),\n+                conf,\n+                bkdlConfig.getBkZkServersForReader(),\n+                bkdlConfig.getBkLedgersPath(),\n+                Optional.<FeatureProvider>absent());\n+        }\n+        this.readerBKC = this.sharedReaderBKCBuilder.build();\n+\n+        this.logSegmentRollingPermitManager = new LimitedPermitManager(\n+                conf.getLogSegmentRollingConcurrency(), 1, TimeUnit.MINUTES, scheduler);\n+\n+        if (conf.getGlobalOutstandingWriteLimit() < 0) {\n+            this.writeLimiter = PermitLimiter.NULL_PERMIT_LIMITER;\n+        } else {\n+            Feature disableWriteLimitFeature = featureProvider.getFeature(\n+                CoreFeatureKeys.DISABLE_WRITE_LIMIT.name().toLowerCase());\n+            this.writeLimiter = new SimplePermitLimiter(\n+                conf.getOutstandingWriteLimitDarkmode(),\n+                conf.getGlobalOutstandingWriteLimit(),\n+                statsLogger.scope(\"writeLimiter\"),\n+                true /* singleton */,\n+                disableWriteLimitFeature);\n+        }\n+\n+        // propagate bkdlConfig to configuration\n+        BKDLConfig.propagateConfiguration(bkdlConfig, conf);\n+\n+        // Build the allocator\n+        if (conf.getEnableLedgerAllocatorPool()) {\n+            String allocatorPoolPath = validateAndGetFullLedgerAllocatorPoolPath(conf, uri);\n+            allocator = LedgerAllocatorUtils.createLedgerAllocatorPool(allocatorPoolPath, conf.getLedgerAllocatorPoolCoreSize(),\n+                    conf, sharedWriterZKCForDL, writerBKC, scheduler);\n+            if (null != allocator) {\n+                allocator.start();\n+            }\n+            LOG.info(\"Created ledger allocator pool under {} with size {}.\", allocatorPoolPath, conf.getLedgerAllocatorPoolCoreSize());\n+        } else {\n+            allocator = null;\n+        }\n+        // Build the lock factory\n+        this.lockFactory = new ZKSessionLockFactory(\n+                sharedWriterZKCForDL,\n+                clientId,\n+                lockStateExecutor,\n+                conf.getZKNumRetries(),\n+                conf.getLockTimeoutMilliSeconds(),\n+                conf.getZKRetryBackoffStartMillis(),\n+                statsLogger);\n+\n+        // Stats Loggers\n+        this.readAheadExceptionsLogger = new ReadAheadExceptionsLogger(statsLogger);\n+\n+        // log metadata store\n+        if (bkdlConfig.isFederatedNamespace() || conf.isFederatedNamespaceEnabled()) {\n+            this.metadataStore = new FederatedZKLogMetadataStore(conf, namespace, sharedReaderZKCForDL, scheduler);\n+        } else {\n+            this.metadataStore = new ZKLogMetadataStore(conf, namespace, sharedReaderZKCForDL, scheduler);\n+        }\n+\n+        // create log segment metadata store\n+        this.writerSegmentMetadataStore =\n+                new ZKLogSegmentMetadataStore(conf, sharedWriterZKCForDL, scheduler);\n+        this.readerSegmentMetadataStore =\n+                new ZKLogSegmentMetadataStore(conf, sharedReaderZKCForDL, scheduler);\n+\n+        LOG.info(\"Constructed BK DistributedLogNamespace : clientId = {}, regionId = {}, federated = {}.\",\n+                new Object[] { clientId, regionId, bkdlConfig.isFederatedNamespace() });\n+    }\n+\n+    //\n+    // Namespace Methods\n+    //\n+\n+    @Override\n+    public void createLog(String logName)\n+            throws InvalidStreamNameException, IOException {\n+        validateName(logName);\n+        URI uri = FutureUtils.result(metadataStore.createLog(logName));\n+        createUnpartitionedStreams(conf, uri, Lists.newArrayList(logName));\n+    }\n+\n+    @Override\n+    public void deleteLog(String logName)\n+            throws InvalidStreamNameException, LogNotFoundException, IOException {\n+        validateName(logName);\n+        Optional<URI> uri = FutureUtils.result(metadataStore.getLogLocation(logName));\n+        if (!uri.isPresent()) {\n+            throw new LogNotFoundException(\"Log \" + logName + \" isn't found.\");\n+        }\n+        DistributedLogManager dlm = createDistributedLogManager(\n+                uri.get(),\n+                logName,\n+                ClientSharingOption.SharedClients,\n+                Optional.<DistributedLogConfiguration>absent(),\n+                Optional.<DynamicDistributedLogConfiguration>absent());\n+        dlm.delete();\n+    }\n+\n+    @Override\n+    public DistributedLogManager openLog(String logName)\n+            throws InvalidStreamNameException, IOException {\n+        return openLog(logName,\n+                Optional.<DistributedLogConfiguration>absent(),\n+                Optional.<DynamicDistributedLogConfiguration>absent());\n+    }\n+\n+    @Override\n+    public DistributedLogManager openLog(String logName,\n+                                         Optional<DistributedLogConfiguration> logConf,\n+                                         Optional<DynamicDistributedLogConfiguration> dynamicLogConf)\n+            throws InvalidStreamNameException, IOException {\n+        validateName(logName);\n+        Optional<URI> uri = FutureUtils.result(metadataStore.getLogLocation(logName));\n+        if (!uri.isPresent()) {\n+            throw new LogNotFoundException(\"Log \" + logName + \" isn't found.\");\n+        }\n+        return createDistributedLogManager(\n+                uri.get(),\n+                logName,\n+                ClientSharingOption.SharedClients,\n+                logConf,\n+                dynamicLogConf);\n+    }\n+\n+    @Override\n+    public boolean logExists(String logName)\n+        throws IOException, IllegalArgumentException {\n+        Optional<URI> uri = FutureUtils.result(metadataStore.getLogLocation(logName));\n+        return uri.isPresent() && checkIfLogExists(conf, uri.get(), logName);\n+    }\n+\n+    @Override\n+    public Iterator<String> getLogs() throws IOException {\n+        return FutureUtils.result(metadataStore.getLogs());\n+    }\n+\n+    @Override\n+    public void registerNamespaceListener(NamespaceListener listener) {\n+        metadataStore.registerNamespaceListener(listener);\n+    }\n+\n+    @Override\n+    public synchronized AccessControlManager createAccessControlManager() throws IOException {\n+        if (null == accessControlManager) {\n+            String aclRootPath = bkdlConfig.getACLRootPath();\n+            // Build the access control manager\n+            if (aclRootPath == null) {\n+                accessControlManager = DefaultAccessControlManager.INSTANCE;\n+                LOG.info(\"Created default access control manager for {}\", namespace);\n+            } else {\n+                if (!isReservedStreamName(aclRootPath)) {\n+                    throw new IOException(\"Invalid Access Control List Root Path : \" + aclRootPath);\n+                }\n+                String zkRootPath = namespace.getPath() + \"/\" + aclRootPath;\n+                LOG.info(\"Creating zk based access control manager @ {} for {}\",\n+                        zkRootPath, namespace);\n+                accessControlManager = new ZKAccessControlManager(conf, sharedReaderZKCForDL,\n+                        zkRootPath, scheduler);\n+                LOG.info(\"Created zk based access control manager @ {} for {}\",\n+                        zkRootPath, namespace);\n+            }\n+        }\n+        return accessControlManager;\n+    }\n+\n+    //\n+    // Legacy methods\n+    //\n+\n+    static String validateAndGetFullLedgerAllocatorPoolPath(DistributedLogConfiguration conf, URI uri) throws IOException {\n+        String poolPath = conf.getLedgerAllocatorPoolPath();\n+        LOG.info(\"PoolPath is {}\", poolPath);\n+        if (null == poolPath || !poolPath.startsWith(\".\") || poolPath.endsWith(\"/\")) {\n+            LOG.error(\"Invalid ledger allocator pool path specified when enabling ledger allocator pool : {}\", poolPath);\n+            throw new IOException(\"Invalid ledger allocator pool path specified : \" + poolPath);\n+        }\n+        String poolName = conf.getLedgerAllocatorPoolName();\n+        if (null == poolName) {\n+            LOG.error(\"No ledger allocator pool name specified when enabling ledger allocator pool.\");\n+            throw new IOException(\"No ledger allocator name specified when enabling ledger allocator pool.\");\n+        }\n+        String rootPath = uri.getPath() + \"/\" + poolPath + \"/\" + poolName;\n+        try {\n+            PathUtils.validatePath(rootPath);\n+        } catch (IllegalArgumentException iae) {\n+            LOG.error(\"Invalid ledger allocator pool path specified when enabling ledger allocator pool : {}\", poolPath);\n+            throw new IOException(\"Invalid ledger allocator pool path specified : \" + poolPath);\n+        }\n+        return rootPath;\n+    }\n+\n+    private static ZooKeeperClientBuilder createDLZKClientBuilder(String zkcName,\n+                                                                DistributedLogConfiguration conf,\n+                                                                String zkServers,\n+                                                                StatsLogger statsLogger) {\n+        RetryPolicy retryPolicy = null;\n+        if (conf.getZKNumRetries() > 0) {\n+            retryPolicy = new BoundExponentialBackoffRetryPolicy(\n+                conf.getZKRetryBackoffStartMillis(),\n+                conf.getZKRetryBackoffMaxMillis(), conf.getZKNumRetries());\n+        }\n+        ZooKeeperClientBuilder builder = ZooKeeperClientBuilder.newBuilder()\n+            .name(zkcName)\n+            .sessionTimeoutMs(conf.getZKSessionTimeoutMilliseconds())\n+            .retryThreadCount(conf.getZKClientNumberRetryThreads())\n+            .requestRateLimit(conf.getZKRequestRateLimit())\n+            .zkServers(zkServers)\n+            .retryPolicy(retryPolicy)\n+            .statsLogger(statsLogger)\n+            .zkAclId(conf.getZkAclId());\n+        LOG.info(\"Created shared zooKeeper client builder {}: zkServers = {}, numRetries = {}, sessionTimeout = {}, retryBackoff = {},\"\n+                 + \" maxRetryBackoff = {}, zkAclId = {}.\", new Object[] { zkcName, zkServers, conf.getZKNumRetries(),\n+                conf.getZKSessionTimeoutMilliseconds(), conf.getZKRetryBackoffStartMillis(),\n+                conf.getZKRetryBackoffMaxMillis(), conf.getZkAclId() });\n+        return builder;\n+    }\n+\n+    private static ZooKeeperClientBuilder createBKZKClientBuilder(String zkcName,\n+                                                                  DistributedLogConfiguration conf,\n+                                                                  String zkServers,\n+                                                                  StatsLogger statsLogger) {\n+        RetryPolicy retryPolicy = null;\n+        if (conf.getZKNumRetries() > 0) {\n+            retryPolicy = new BoundExponentialBackoffRetryPolicy(\n+                    conf.getBKClientZKRetryBackoffStartMillis(),\n+                    conf.getBKClientZKRetryBackoffMaxMillis(),\n+                    conf.getBKClientZKNumRetries());\n+        }\n+        ZooKeeperClientBuilder builder = ZooKeeperClientBuilder.newBuilder()\n+                .name(zkcName)\n+                .sessionTimeoutMs(conf.getBKClientZKSessionTimeoutMilliSeconds())\n+                .retryThreadCount(conf.getZKClientNumberRetryThreads())\n+                .requestRateLimit(conf.getBKClientZKRequestRateLimit())\n+                .zkServers(zkServers)\n+                .retryPolicy(retryPolicy)\n+                .statsLogger(statsLogger)\n+                .zkAclId(conf.getZkAclId());\n+        LOG.info(\"Created shared zooKeeper client builder {}: zkServers = {}, numRetries = {}, sessionTimeout = {}, retryBackoff = {},\"\n+                + \" maxRetryBackoff = {}, zkAclId = {}.\", new Object[] { zkcName, zkServers, conf.getBKClientZKNumRetries(),\n+                conf.getBKClientZKSessionTimeoutMilliSeconds(), conf.getBKClientZKRetryBackoffStartMillis(),\n+                conf.getBKClientZKRetryBackoffMaxMillis(), conf.getZkAclId() });\n+        return builder;\n+    }\n+\n+    private BookKeeperClientBuilder createBKCBuilder(String bkcName,\n+                                                     DistributedLogConfiguration conf,\n+                                                     String zkServers,\n+                                                     String ledgersPath,\n+                                                     Optional<FeatureProvider> featureProviderOptional) {\n+        BookKeeperClientBuilder builder = BookKeeperClientBuilder.newBuilder()\n+                .name(bkcName)\n+                .dlConfig(conf)\n+                .zkServers(zkServers)\n+                .ledgersPath(ledgersPath)\n+                .channelFactory(channelFactory)\n+                .requestTimer(requestTimer)\n+                .featureProvider(featureProviderOptional)\n+                .statsLogger(statsLogger);\n+        LOG.info(\"Created shared client builder {} : zkServers = {}, ledgersPath = {}, numIOThreads = {}\",\n+                 new Object[] { bkcName, zkServers, ledgersPath, conf.getBKClientNumberIOThreads() });\n+        return builder;\n+    }\n+\n+    @VisibleForTesting\n+    public ZooKeeperClient getSharedWriterZKCForDL() {\n+        return sharedWriterZKCForDL;\n+    }\n+\n+    @VisibleForTesting\n+    public BookKeeperClient getReaderBKC() {\n+        return readerBKC;\n+    }\n+\n+    @VisibleForTesting\n+    public LogSegmentMetadataStore getWriterSegmentMetadataStore() {\n+        return writerSegmentMetadataStore;\n+    }\n+\n+    @VisibleForTesting\n+    public LedgerAllocator getLedgerAllocator() {\n+        return allocator;\n+    }\n+\n+    /**\n+     * Run given <i>handler</i> by providing an available zookeeper client.\n+     *\n+     * @param handler\n+     *          Handler to process with provided zookeeper client.\n+     * @return result processed by handler.\n+     * @throws IOException\n+     */\n+    private <T> T withZooKeeperClient(ZooKeeperClientHandler<T> handler) throws IOException {\n+        return handler.handle(sharedWriterZKCForDL);\n+    }\n+\n+    /**\n+     * Create a DistributedLogManager for <i>nameOfLogStream</i>, with default shared clients.\n+     *\n+     * @param nameOfLogStream\n+     *          name of log stream\n+     * @return distributedlog manager\n+     * @throws com.twitter.distributedlog.exceptions.InvalidStreamNameException if stream name is invalid\n+     * @throws IOException\n+     */\n+    public DistributedLogManager createDistributedLogManagerWithSharedClients(String nameOfLogStream)\n+        throws InvalidStreamNameException, IOException {\n+        return createDistributedLogManager(nameOfLogStream, ClientSharingOption.SharedClients);\n+    }\n+\n+    /**\n+     * Create a DistributedLogManager for <i>nameOfLogStream</i>, with specified client sharing options.\n+     *\n+     * @param nameOfLogStream\n+     *          name of log stream.\n+     * @param clientSharingOption\n+     *          specifies if the ZK/BK clients are shared\n+     * @return distributedlog manager instance.\n+     * @throws com.twitter.distributedlog.exceptions.InvalidStreamNameException if stream name is invalid\n+     * @throws IOException\n+     */\n+    public DistributedLogManager createDistributedLogManager(\n+            String nameOfLogStream,\n+            ClientSharingOption clientSharingOption)\n+        throws InvalidStreamNameException, IOException {\n+        Optional<DistributedLogConfiguration> logConfiguration = Optional.absent();\n+        Optional<DynamicDistributedLogConfiguration> dynamicLogConfiguration = Optional.absent();\n+        return createDistributedLogManager(\n+                nameOfLogStream,\n+                clientSharingOption,\n+                logConfiguration,\n+                dynamicLogConfiguration);\n+    }\n+\n+    /**\n+     * Create a DistributedLogManager for <i>nameOfLogStream</i>, with specified client sharing options.\n+     * Override whitelisted stream-level configuration settings with settings found in\n+     * <i>logConfiguration</i>.\n+     *\n+     *\n+     * @param nameOfLogStream\n+     *          name of log stream.\n+     * @param clientSharingOption\n+     *          specifies if the ZK/BK clients are shared\n+     * @param logConfiguration\n+     *          stream configuration overrides.\n+     * @param dynamicLogConfiguration\n+     *          dynamic stream configuration overrides.\n+     * @return distributedlog manager instance.\n+     * @throws com.twitter.distributedlog.exceptions.InvalidStreamNameException if stream name is invalid\n+     * @throws IOException\n+     */\n+    public DistributedLogManager createDistributedLogManager(\n+            String nameOfLogStream,\n+            ClientSharingOption clientSharingOption,\n+            Optional<DistributedLogConfiguration> logConfiguration,\n+            Optional<DynamicDistributedLogConfiguration> dynamicLogConfiguration)\n+        throws InvalidStreamNameException, IOException {\n+        if (bkdlConfig.isFederatedNamespace()) {\n+            throw new UnsupportedOperationException(\"Use DistributedLogNamespace methods for federated namespace\");\n+        }\n+        return createDistributedLogManager(\n+                namespace,\n+                nameOfLogStream,\n+                clientSharingOption,\n+                logConfiguration,\n+                dynamicLogConfiguration\n+        );\n+    }\n+\n+    /**\n+     * Open the log in location <i>uri</i>.\n+     *\n+     * @param uri\n+     *          location to store the log\n+     * @param nameOfLogStream\n+     *          name of the log\n+     * @param clientSharingOption\n+     *          client sharing option\n+     * @param logConfiguration\n+     *          optional stream configuration\n+     * @param dynamicLogConfiguration\n+     *          dynamic stream configuration overrides.\n+     * @return distributedlog manager instance.\n+     * @throws InvalidStreamNameException if the stream name is invalid\n+     * @throws IOException\n+     */\n+    protected DistributedLogManager createDistributedLogManager(\n+            URI uri,\n+            String nameOfLogStream,\n+            ClientSharingOption clientSharingOption,\n+            Optional<DistributedLogConfiguration> logConfiguration,\n+            Optional<DynamicDistributedLogConfiguration> dynamicLogConfiguration)\n+        throws InvalidStreamNameException, IOException {\n+        // Make sure the name is well formed\n+        validateName(nameOfLogStream);\n+\n+        DistributedLogConfiguration mergedConfiguration = new DistributedLogConfiguration();\n+        mergedConfiguration.addConfiguration(conf);\n+        mergedConfiguration.loadStreamConf(logConfiguration);\n+        // If dynamic config was not provided, default to a static view of the global configuration.\n+        DynamicDistributedLogConfiguration dynConf = null;\n+        if (dynamicLogConfiguration.isPresent()) {\n+            dynConf = dynamicLogConfiguration.get();\n+        } else {\n+            dynConf = ConfUtils.getConstDynConf(mergedConfiguration);\n+        }\n+\n+        ZooKeeperClientBuilder writerZKCBuilderForDL = null;\n+        ZooKeeperClientBuilder readerZKCBuilderForDL = null;\n+        ZooKeeperClient writerZKCForBK = null;\n+        ZooKeeperClient readerZKCForBK = null;\n+        BookKeeperClientBuilder writerBKCBuilder = null;\n+        BookKeeperClientBuilder readerBKCBuilder = null;\n+\n+        switch(clientSharingOption) {\n+            case SharedClients:\n+                writerZKCBuilderForDL = sharedWriterZKCBuilderForDL;\n+                readerZKCBuilderForDL = sharedReaderZKCBuilderForDL;\n+                writerBKCBuilder = sharedWriterBKCBuilder;\n+                readerBKCBuilder = sharedReaderBKCBuilder;\n+                break;\n+            case SharedZKClientPerStreamBKClient:\n+                writerZKCBuilderForDL = sharedWriterZKCBuilderForDL;\n+                readerZKCBuilderForDL = sharedReaderZKCBuilderForDL;\n+                synchronized (this) {\n+                    if (null == this.sharedWriterZKCForBK) {\n+                        this.sharedWriterZKCBuilderForBK = createBKZKClientBuilder(\n+                            String.format(\"bkzk:%s:factory_writer_shared\", uri),\n+                            mergedConfiguration,\n+                            bkdlConfig.getBkZkServersForWriter(),\n+                            statsLogger.scope(\"bkzk_factory_writer_shared\"));\n+                        this.sharedWriterZKCForBK = this.sharedWriterZKCBuilderForBK.build();\n+                    }\n+                    if (null == this.sharedReaderZKCForBK) {\n+                        if (bkdlConfig.getBkZkServersForWriter().equals(bkdlConfig.getBkZkServersForReader())) {\n+                            this.sharedReaderZKCBuilderForBK = this.sharedWriterZKCBuilderForBK;\n+                        } else {\n+                            this.sharedReaderZKCBuilderForBK = createBKZKClientBuilder(\n+                                String.format(\"bkzk:%s:factory_reader_shared\", uri),\n+                                mergedConfiguration,\n+                                bkdlConfig.getBkZkServersForReader(),\n+                                statsLogger.scope(\"bkzk_factory_reader_shared\"));\n+                        }\n+                        this.sharedReaderZKCForBK = this.sharedReaderZKCBuilderForBK.build();\n+                    }\n+                    writerZKCForBK = this.sharedWriterZKCForBK;\n+                    readerZKCForBK = this.sharedReaderZKCForBK;\n+                }\n+                break;\n+        }\n+\n+        LedgerAllocator dlmLedgerAlloctor = null;\n+        PermitManager dlmLogSegmentRollingPermitManager = PermitManager.UNLIMITED_PERMIT_MANAGER;\n+        if (ClientSharingOption.SharedClients == clientSharingOption) {\n+            dlmLedgerAlloctor = this.allocator;\n+            dlmLogSegmentRollingPermitManager = this.logSegmentRollingPermitManager;\n+        }\n+\n+        return new BKDistributedLogManager(\n+                nameOfLogStream,                    /* Log Name */\n+                mergedConfiguration,                /* Configuration */\n+                dynConf,                            /* Dynamic Configuration */\n+                uri,                                /* Namespace */\n+                writerZKCBuilderForDL,              /* ZKC Builder for DL Writer */\n+                readerZKCBuilderForDL,              /* ZKC Builder for DL Reader */\n+                writerZKCForBK,                     /* ZKC for BookKeeper for DL Writers */\n+                readerZKCForBK,                     /* ZKC for BookKeeper for DL Readers */\n+                writerBKCBuilder,                   /* BookKeeper Builder for DL Writers */\n+                readerBKCBuilder,                   /* BookKeeper Builder for DL Readers */\n+                lockFactory,                        /* Lock Factory */\n+                writerSegmentMetadataStore,         /* Log Segment Metadata Store for DL Writers */\n+                readerSegmentMetadataStore,         /* Log Segment Metadata Store for DL Readers */\n+                scheduler,                          /* DL scheduler */\n+                readAheadExecutor,                  /* Read Aheader Executor */\n+                lockStateExecutor,                  /* Lock State Executor */\n+                channelFactory,                     /* Netty Channel Factory */\n+                requestTimer,                       /* Request Timer */\n+                readAheadExceptionsLogger,          /* ReadAhead Exceptions Logger */\n+                clientId,                           /* Client Id */\n+                regionId,                           /* Region Id */\n+                dlmLedgerAlloctor,                  /* Ledger Allocator */\n+                writeLimiter,                       /* Write Limiter */\n+                dlmLogSegmentRollingPermitManager,  /* Log segment rolling limiter */\n+                featureProvider.scope(\"dl\"),        /* Feature Provider */\n+                statsLogger,                        /* Stats Logger */\n+                perLogStatsLogger                   /* Per Log Stats Logger */\n+        );\n+    }\n+\n+    public MetadataAccessor createMetadataAccessor(String nameOfMetadataNode)\n+            throws InvalidStreamNameException, IOException {\n+        if (bkdlConfig.isFederatedNamespace()) {\n+            throw new UnsupportedOperationException(\"Use DistributedLogNamespace methods for federated namespace\");\n+        }\n+        validateName(nameOfMetadataNode);\n+        return new ZKMetadataAccessor(nameOfMetadataNode, conf, namespace,\n+                sharedWriterZKCBuilderForDL, sharedReaderZKCBuilderForDL, statsLogger);\n+    }\n+\n+    public Collection<String> enumerateAllLogsInNamespace()\n+        throws IOException, IllegalArgumentException {\n+        if (bkdlConfig.isFederatedNamespace()) {\n+            throw new UnsupportedOperationException(\"Use DistributedLogNamespace methods for federated namespace\");\n+        }\n+        return Sets.newHashSet(getLogs());\n+    }\n+\n+    public Map<String, byte[]> enumerateLogsWithMetadataInNamespace()\n+        throws IOException, IllegalArgumentException {\n+        if (bkdlConfig.isFederatedNamespace()) {\n+            throw new UnsupportedOperationException(\"Use DistributedLogNamespace methods for federated namespace\");\n+        }\n+        return withZooKeeperClient(new ZooKeeperClientHandler<Map<String, byte[]>>() {\n+            @Override\n+            public Map<String, byte[]> handle(ZooKeeperClient zkc) throws IOException {\n+                return enumerateLogsWithMetadataInternal(zkc, conf, namespace);\n+            }\n+        });\n+    }\n+\n+    private static void validateInput(DistributedLogConfiguration conf, URI uri, String nameOfStream)\n+        throws IllegalArgumentException, InvalidStreamNameException {\n+        validateConfAndURI(conf, uri);\n+        validateName(nameOfStream);\n+    }\n+\n+    private static boolean checkIfLogExists(DistributedLogConfiguration conf, URI uri, String name)\n+        throws IOException, IllegalArgumentException {\n+        validateInput(conf, uri, name);\n+        final String logRootPath = uri.getPath() + String.format(\"/%s\", name);\n+        return withZooKeeperClient(new ZooKeeperClientHandler<Boolean>() {\n+            @Override\n+            public Boolean handle(ZooKeeperClient zkc) throws IOException {\n+                // check existence after syncing\n+                try {\n+                    return null != Utils.sync(zkc, logRootPath).exists(logRootPath, false);\n+                } catch (KeeperException e) {\n+                    throw new ZKException(\"Error on checking if log \" + logRootPath + \" exists\", e.code());\n+                } catch (InterruptedException e) {\n+                    throw new DLInterruptedException(\"Interrupted on checking if log \" + logRootPath + \" exists\", e);\n+                }\n+            }\n+        }, conf, uri);\n+    }\n+\n+    public static Map<String, byte[]> enumerateLogsWithMetadataInNamespace(final DistributedLogConfiguration conf, final URI uri)\n+        throws IOException, IllegalArgumentException {\n+        return withZooKeeperClient(new ZooKeeperClientHandler<Map<String, byte[]>>() {\n+            @Override\n+            public Map<String, byte[]> handle(ZooKeeperClient zkc) throws IOException {\n+                return enumerateLogsWithMetadataInternal(zkc, conf, uri);\n+            }\n+        }, conf, uri);\n+    }\n+\n+    private static Map<String, byte[]> enumerateLogsWithMetadataInternal(ZooKeeperClient zkc,\n+                                                                         DistributedLogConfiguration conf, URI uri)\n+        throws IOException, IllegalArgumentException {\n+        validateConfAndURI(conf, uri);\n+        String namespaceRootPath = uri.getPath();\n+        HashMap<String, byte[]> result = new HashMap<String, byte[]>();\n+        try {\n+            ZooKeeper zk = Utils.sync(zkc, namespaceRootPath);\n+            Stat currentStat = zk.exists(namespaceRootPath, false);\n+            if (currentStat == null) {\n+                return result;\n+            }\n+            List<String> children = zk.getChildren(namespaceRootPath, false);\n+            for(String child: children) {\n+                if (isReservedStreamName(child)) {\n+                    continue;\n+                }\n+                String zkPath = String.format(\"%s/%s\", namespaceRootPath, child);\n+                currentStat = zk.exists(zkPath, false);\n+                if (currentStat == null) {\n+                    result.put(child, new byte[0]);\n+                } else {\n+                    result.put(child, zk.getData(zkPath, false, currentStat));\n+                }\n+            }\n+        } catch (InterruptedException ie) {\n+            LOG.error(\"Interrupted while deleting \" + namespaceRootPath, ie);\n+            throw new IOException(\"Interrupted while reading \" + namespaceRootPath, ie);\n+        } catch (KeeperException ke) {\n+            LOG.error(\"Error reading\" + namespaceRootPath + \"entry in zookeeper\", ke);\n+            throw new IOException(\"Error reading\" + namespaceRootPath + \"entry in zookeeper\", ke);\n+        }\n+        return result;\n+    }\n+\n+    private static void createUnpartitionedStreams(\n+            final DistributedLogConfiguration conf,\n+            final URI uri,\n+            final List<String> streamNames)\n+        throws IOException, IllegalArgumentException {\n+        withZooKeeperClient(new ZooKeeperClientHandler<Void>() {\n+            @Override\n+            public Void handle(ZooKeeperClient zkc) throws IOException {\n+                for (String s : streamNames) {\n+                    try {\n+                        BKDistributedLogManager.createLog(conf, zkc, uri, s);\n+                    } catch (InterruptedException e) {\n+                        LOG.error(\"Interrupted on creating unpartitioned stream {} : \", s, e);\n+                        return null;\n+                    }\n+                }\n+                return null;\n+            }\n+        }, conf, uri);\n+    }\n+\n+    /**\n+     * Close the distributed log manager factory, freeing any resources it may hold.\n+     */\n+    @Override\n+    public void close() {\n+        ZooKeeperClient writerZKC;\n+        ZooKeeperClient readerZKC;\n+        AccessControlManager acm;\n+        synchronized (this) {\n+            if (closed) {\n+                return;\n+            }\n+            closed = true;\n+            writerZKC = sharedWriterZKCForBK;\n+            readerZKC = sharedReaderZKCForBK;\n+            acm = accessControlManager;\n+        }\n+\n+        if (null != acm) {\n+            acm.close();\n+            LOG.info(\"Access Control Manager Stopped.\");\n+        }\n+\n+        // Close the allocator\n+        if (null != allocator) {\n+            Utils.closeQuietly(allocator);\n+            LOG.info(\"Ledger Allocator stopped.\");\n+        }\n+\n+        // Shutdown log segment metadata stores\n+        Utils.close(writerSegmentMetadataStore);\n+        Utils.close(readerSegmentMetadataStore);\n+\n+        // Shutdown the schedulers\n+        SchedulerUtils.shutdownScheduler(scheduler, conf.getSchedulerShutdownTimeoutMs(),\n+                TimeUnit.MILLISECONDS);\n+        LOG.info(\"Executor Service Stopped.\");\n+        if (scheduler != readAheadExecutor) {\n+            SchedulerUtils.shutdownScheduler(readAheadExecutor, conf.getSchedulerShutdownTimeoutMs(),\n+                    TimeUnit.MILLISECONDS);\n+            LOG.info(\"ReadAhead Executor Service Stopped.\");\n+        }\n+\n+        writerBKC.close();\n+        readerBKC.close();\n+        sharedWriterZKCForDL.close();\n+        sharedReaderZKCForDL.close();\n+\n+        // Close shared zookeeper clients for bk\n+        if (null != writerZKC) {\n+            writerZKC.close();\n+        }\n+        if (null != readerZKC) {\n+            readerZKC.close();\n+        }\n+        channelFactory.releaseExternalResources();\n+        LOG.info(\"Release external resources used by channel factory.\");\n+        requestTimer.stop();\n+        LOG.info(\"Stopped request timer\");\n+        SchedulerUtils.shutdownScheduler(lockStateExecutor, 5000, TimeUnit.MILLISECONDS);\n+        LOG.info(\"Stopped lock state executor\");\n+    }\n+}"},{"sha":"9aa3465ba74c276419e6822ab9ee4c62fa178348","filename":"src/main/java/com/twitter/distributedlog/BKLogHandler.java","status":"added","additions":1320,"deletions":0,"changes":1320,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,1320 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Stopwatch;\n+import com.twitter.distributedlog.callback.LogSegmentListener;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.LogEmptyException;\n+import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.exceptions.MetadataException;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadata;\n+import com.twitter.distributedlog.io.AsyncAbortable;\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+import com.twitter.distributedlog.logsegment.LogSegmentCache;\n+import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.util.Function;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.stats.AlertStatsLogger;\n+import org.apache.bookkeeper.proto.BookkeeperInternalCallbacks.GenericCallback;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.apache.zookeeper.AsyncCallback;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.WatchedEvent;\n+import org.apache.zookeeper.Watcher;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.apache.zookeeper.data.Stat;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.runtime.AbstractFunction0;\n+import scala.runtime.BoxedUnit;\n+\n+import java.io.IOException;\n+import java.net.InetAddress;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CopyOnWriteArraySet;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * The base class about log handler on managing log segments.\n+ *\n+ * <h3>Metrics</h3>\n+ * The log handler is a base class on managing log segments. so all the metrics\n+ * here are related to log segments retrieval and exposed under `logsegments`.\n+ * These metrics are all OpStats, in the format of <code>`scope`/logsegments/`op`</code>.\n+ * <p>\n+ * Those operations are:\n+ * <ul>\n+ * <li>force_get_list: force to get the list of log segments.\n+ * <li>get_list: get the list of the log segments. it might just retrieve from\n+ * local log segment cache.\n+ * <li>get_filtered_list: get the filtered list of log segments.\n+ * <li>get_full_list: get the full list of log segments.\n+ * <li>get_inprogress_segment: time between the inprogress log segment created and\n+ * the handler read it.\n+ * <li>get_completed_segment: time between a log segment is turned to completed and\n+ * the handler read it.\n+ * <li>negative_get_inprogress_segment: record the negative values for `get_inprogress_segment`.\n+ * <li>negative_get_completed_segment: record the negative values for `get_completed_segment`.\n+ * <li>recover_last_entry: recovering last entry from a log segment\n+ * <li>recover_scanned_entries: the number of entries that are scanned during recovering.\n+ * </ul>\n+ * @see BKLogWriteHandler\n+ * @see BKLogReadHandler\n+ */\n+public abstract class BKLogHandler implements Watcher, AsyncCloseable, AsyncAbortable {\n+    static final Logger LOG = LoggerFactory.getLogger(BKLogHandler.class);\n+\n+    private static final int LAYOUT_VERSION = -1;\n+\n+    protected final ZKLogMetadata logMetadata;\n+    protected final DistributedLogConfiguration conf;\n+    protected final ZooKeeperClient zooKeeperClient;\n+    protected final BookKeeperClient bookKeeperClient;\n+    protected final LogSegmentMetadataStore metadataStore;\n+    protected final int firstNumEntriesPerReadLastRecordScan;\n+    protected final int maxNumEntriesPerReadLastRecordScan;\n+    protected volatile long lastLedgerRollingTimeMillis = -1;\n+    protected final OrderedScheduler scheduler;\n+    protected final StatsLogger statsLogger;\n+    protected final AlertStatsLogger alertStatsLogger;\n+    private final AtomicBoolean ledgerListWatchSet = new AtomicBoolean(false);\n+    private final AtomicBoolean isFullListFetched = new AtomicBoolean(false);\n+    protected volatile boolean reportGetSegmentStats = false;\n+    private final String lockClientId;\n+    protected final AtomicReference<IOException> metadataException = new AtomicReference<IOException>(null);\n+\n+    // listener\n+    protected final CopyOnWriteArraySet<LogSegmentListener> listeners =\n+            new CopyOnWriteArraySet<LogSegmentListener>();\n+\n+    // Maintain the list of ledgers\n+    protected final LogSegmentCache logSegmentCache;\n+    protected volatile SyncGetLedgersCallback firstGetLedgersTask = null;\n+\n+    protected final AsyncNotification notification;\n+    // log segment filter\n+    protected final LogSegmentFilter filter;\n+\n+    // zookeeper children watcher\n+    private final Watcher getChildrenWatcher;\n+\n+    // trace\n+    protected final long metadataLatencyWarnThresholdMillis;\n+\n+    // Stats\n+    private final OpStatsLogger forceGetListStat;\n+    private final OpStatsLogger getListStat;\n+    private final OpStatsLogger getFilteredListStat;\n+    private final OpStatsLogger getFullListStat;\n+    private final OpStatsLogger getInprogressSegmentStat;\n+    private final OpStatsLogger getCompletedSegmentStat;\n+    private final OpStatsLogger negativeGetInprogressSegmentStat;\n+    private final OpStatsLogger negativeGetCompletedSegmentStat;\n+    private final OpStatsLogger recoverLastEntryStats;\n+    private final OpStatsLogger recoverScannedEntriesStats;\n+\n+    static class SyncGetLedgersCallback implements GenericCallback<List<LogSegmentMetadata>> {\n+\n+        final String path;\n+        final boolean allowEmpty;\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        final Promise<List<LogSegmentMetadata>> promise =\n+                new Promise<List<LogSegmentMetadata>>();\n+\n+        int rc = KeeperException.Code.APIERROR.intValue();\n+\n+        SyncGetLedgersCallback(String path, boolean allowEmpty) {\n+            this.path = path;\n+            this.allowEmpty = allowEmpty;\n+        }\n+\n+        @Override\n+        public void operationComplete(int rc, List<LogSegmentMetadata> logSegmentMetadatas) {\n+            this.rc = rc;\n+            if (KeeperException.Code.OK.intValue() == rc) {\n+                LOG.debug(\"Updated ledgers list for {} : {}\", path, logSegmentMetadatas);\n+                promise.setValue(logSegmentMetadatas);\n+            } else if (KeeperException.Code.NONODE.intValue() == rc) {\n+                if (allowEmpty) {\n+                    promise.setValue(new ArrayList<LogSegmentMetadata>(0));\n+                } else {\n+                    promise.setException(new LogNotFoundException(\"Log \" + path + \" is not found\"));\n+                }\n+            } else {\n+                promise.setException(new MetadataException(\"Error getting ledgers list for \" + path));\n+            }\n+            countDownLatch.countDown();\n+        }\n+\n+        void waitForFinish() throws IOException {\n+            try {\n+                countDownLatch.await();\n+            } catch (InterruptedException e) {\n+                throw new DLInterruptedException(\"Interrupted on getting ledgers list for \" + path, e);\n+            }\n+            if (KeeperException.Code.OK.intValue() != rc) {\n+                if (KeeperException.Code.NONODE.intValue() == rc) {\n+                    if (!allowEmpty) {\n+                        throw new LogNotFoundException(\"Log \" + path + \" is not found\");\n+                    }\n+                } else {\n+                    throw new MetadataException(\"Error getting ledgers list for \" + path);\n+                }\n+            }\n+        }\n+    }\n+\n+    static class NOPGetLedgersCallback implements GenericCallback<List<LogSegmentMetadata>> {\n+\n+        final String path;\n+\n+        NOPGetLedgersCallback(String path) {\n+            this.path = path;\n+        }\n+\n+        @Override\n+        public void operationComplete(int rc, List<LogSegmentMetadata> logSegmentMetadatas) {\n+            if (KeeperException.Code.OK.intValue() == rc) {\n+                LOG.debug(\"Updated ledgers list : {}\", path, logSegmentMetadatas);\n+            }\n+        }\n+    }\n+\n+    class WatcherGetLedgersCallback implements GenericCallback<List<LogSegmentMetadata>>, Runnable {\n+\n+        final String path;\n+\n+        WatcherGetLedgersCallback(String path) {\n+            this.path = path;\n+        }\n+\n+        @Override\n+        public void operationComplete(int rc, List<LogSegmentMetadata> logSegmentMetadatas) {\n+            if (KeeperException.Code.OK.intValue() == rc) {\n+                LOG.debug(\"Updated ledgers list {} : {}\", path, logSegmentMetadatas);\n+            } else {\n+                scheduler.schedule(this, conf.getZKRetryBackoffMaxMillis(), TimeUnit.MILLISECONDS);\n+            }\n+        }\n+\n+        @Override\n+        public void run() {\n+            asyncGetLedgerListWithRetries(LogSegmentMetadata.COMPARATOR, filter, getChildrenWatcher, this);\n+        }\n+    }\n+\n+    /**\n+     * Construct a Bookkeeper journal manager.\n+     */\n+    BKLogHandler(ZKLogMetadata metadata,\n+                 DistributedLogConfiguration conf,\n+                 ZooKeeperClientBuilder zkcBuilder,\n+                 BookKeeperClientBuilder bkcBuilder,\n+                 LogSegmentMetadataStore metadataStore,\n+                 OrderedScheduler scheduler,\n+                 StatsLogger statsLogger,\n+                 AlertStatsLogger alertStatsLogger,\n+                 AsyncNotification notification,\n+                 LogSegmentFilter filter,\n+                 String lockClientId) {\n+        Preconditions.checkNotNull(zkcBuilder);\n+        Preconditions.checkNotNull(bkcBuilder);\n+        this.logMetadata = metadata;\n+        this.conf = conf;\n+        this.scheduler = scheduler;\n+        this.statsLogger = statsLogger;\n+        this.alertStatsLogger = alertStatsLogger;\n+        this.notification = notification;\n+        this.filter = filter;\n+        this.logSegmentCache = new LogSegmentCache(metadata.getLogName());\n+\n+        firstNumEntriesPerReadLastRecordScan = conf.getFirstNumEntriesPerReadLastRecordScan();\n+        maxNumEntriesPerReadLastRecordScan = conf.getMaxNumEntriesPerReadLastRecordScan();\n+        this.zooKeeperClient = zkcBuilder.build();\n+        LOG.debug(\"Using ZK Path {}\", logMetadata.getLogRootPath());\n+        this.bookKeeperClient = bkcBuilder.build();\n+        this.metadataStore = metadataStore;\n+\n+        if (lockClientId.equals(DistributedLogConstants.UNKNOWN_CLIENT_ID)) {\n+            this.lockClientId = getHostIpLockClientId();\n+        } else {\n+            this.lockClientId = lockClientId;\n+        }\n+\n+        this.getChildrenWatcher = this.zooKeeperClient.getWatcherManager()\n+                .registerChildWatcher(logMetadata.getLogSegmentsPath(), this);\n+\n+        // Traces\n+        this.metadataLatencyWarnThresholdMillis = conf.getMetadataLatencyWarnThresholdMillis();\n+\n+        // Stats\n+        StatsLogger segmentsLogger = statsLogger.scope(\"logsegments\");\n+        forceGetListStat = segmentsLogger.getOpStatsLogger(\"force_get_list\");\n+        getListStat = segmentsLogger.getOpStatsLogger(\"get_list\");\n+        getFilteredListStat = segmentsLogger.getOpStatsLogger(\"get_filtered_list\");\n+        getFullListStat = segmentsLogger.getOpStatsLogger(\"get_full_list\");\n+        getInprogressSegmentStat = segmentsLogger.getOpStatsLogger(\"get_inprogress_segment\");\n+        getCompletedSegmentStat = segmentsLogger.getOpStatsLogger(\"get_completed_segment\");\n+        negativeGetInprogressSegmentStat = segmentsLogger.getOpStatsLogger(\"negative_get_inprogress_segment\");\n+        negativeGetCompletedSegmentStat = segmentsLogger.getOpStatsLogger(\"negative_get_completed_segment\");\n+        recoverLastEntryStats = segmentsLogger.getOpStatsLogger(\"recover_last_entry\");\n+        recoverScannedEntriesStats = segmentsLogger.getOpStatsLogger(\"recover_scanned_entries\");\n+    }\n+\n+    BKLogHandler checkMetadataException() throws IOException {\n+        if (null != metadataException.get()) {\n+            throw metadataException.get();\n+        }\n+        return this;\n+    }\n+\n+    public void reportGetSegmentStats(boolean enabled) {\n+        this.reportGetSegmentStats = enabled;\n+    }\n+\n+    public String getLockClientId() {\n+        return lockClientId;\n+    }\n+\n+    private String getHostIpLockClientId() {\n+        try {\n+            return InetAddress.getLocalHost().toString();\n+        } catch(Exception ex) {\n+            return DistributedLogConstants.UNKNOWN_CLIENT_ID;\n+        }\n+    }\n+\n+    protected void registerListener(LogSegmentListener listener) {\n+        listeners.add(listener);\n+    }\n+\n+    protected void unregisterListener(LogSegmentListener listener) {\n+        listeners.remove(listener);\n+    }\n+\n+    protected void notifyUpdatedLogSegments(List<LogSegmentMetadata> segments) {\n+        for (LogSegmentListener listener : listeners) {\n+            List<LogSegmentMetadata> listToReturn =\n+                    new ArrayList<LogSegmentMetadata>(segments);\n+            Collections.sort(listToReturn, LogSegmentMetadata.DESC_COMPARATOR);\n+            listener.onSegmentsUpdated(listToReturn);\n+        }\n+    }\n+\n+    protected void scheduleGetAllLedgersTaskIfNeeded() {\n+        if (isFullListFetched.get()) {\n+            return;\n+        }\n+        asyncGetLedgerListWithRetries(LogSegmentMetadata.COMPARATOR, LogSegmentFilter.DEFAULT_FILTER,\n+                null, new NOPGetLedgersCallback(getFullyQualifiedName()));\n+    }\n+\n+    protected void scheduleGetLedgersTask(boolean watch, boolean allowEmpty) {\n+        if (!watch) {\n+            ledgerListWatchSet.set(true);\n+        }\n+        LOG.info(\"Scheduling get ledgers task for {}, watch = {}.\", getFullyQualifiedName(), watch);\n+        firstGetLedgersTask = new SyncGetLedgersCallback(getFullyQualifiedName(), allowEmpty);\n+        asyncGetLedgerListWithRetries(LogSegmentMetadata.COMPARATOR, filter,\n+                watch ? getChildrenWatcher : null, firstGetLedgersTask);\n+        LOG.info(\"Scheduled get ledgers task for {}, watch = {}.\", getFullyQualifiedName(), watch);\n+    }\n+\n+    protected void waitFirstGetLedgersTaskToFinish() throws IOException {\n+        SyncGetLedgersCallback task = firstGetLedgersTask;\n+        if (null != task) {\n+            if (LOG.isTraceEnabled()) {\n+                LOG.trace(\"Wait first getting ledgers task to finish for {}.\", getFullyQualifiedName());\n+            }\n+            task.waitForFinish();\n+        }\n+    }\n+\n+    public Future<LogRecordWithDLSN> asyncGetFirstLogRecord() {\n+        final Promise<LogRecordWithDLSN> promise = new Promise<LogRecordWithDLSN>();\n+        checkLogStreamExistsAsync().addEventListener(new FutureEventListener<Void>() {\n+            @Override\n+            public void onSuccess(Void value) {\n+                asyncGetFullLedgerList(true, true).addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n+\n+                    @Override\n+                    public void onSuccess(List<LogSegmentMetadata> ledgerList) {\n+                        if (ledgerList.isEmpty()) {\n+                            promise.setException(new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" has no records\"));\n+                            return;\n+                        }\n+                        Future<LogRecordWithDLSN> firstRecord = null;\n+                        for (LogSegmentMetadata ledger : ledgerList) {\n+                            if (!ledger.isTruncated() && (ledger.getRecordCount() > 0 || ledger.isInProgress())) {\n+                                firstRecord = asyncReadFirstUserRecord(ledger, DLSN.InitialDLSN);\n+                                break;\n+                            }\n+                        }\n+                        if (null != firstRecord) {\n+                            promise.become(firstRecord);\n+                        } else {\n+                            promise.setException(new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" has no records\"));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        promise.setException(cause);\n+                    }\n+                });\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                promise.setException(cause);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    public Future<LogRecordWithDLSN> getLastLogRecordAsync(final boolean recover, final boolean includeEndOfStream) {\n+        final Promise<LogRecordWithDLSN> promise = new Promise<LogRecordWithDLSN>();\n+        checkLogStreamExistsAsync().addEventListener(new FutureEventListener<Void>() {\n+            @Override\n+            public void onSuccess(Void value) {\n+                asyncGetFullLedgerListDesc(true, true).addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n+\n+                    @Override\n+                    public void onSuccess(List<LogSegmentMetadata> ledgerList) {\n+                        if (ledgerList.isEmpty()) {\n+                            promise.setException(new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" has no records\"));\n+                            return;\n+                        }\n+                        asyncGetLastLogRecord(ledgerList.iterator(), promise, recover, false, includeEndOfStream);\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        promise.setException(cause);\n+                    }\n+                });\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                promise.setException(cause);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    private void asyncGetLastLogRecord(final Iterator<LogSegmentMetadata> ledgerIter,\n+                                       final Promise<LogRecordWithDLSN> promise,\n+                                       final boolean fence,\n+                                       final boolean includeControlRecord,\n+                                       final boolean includeEndOfStream) {\n+        if (ledgerIter.hasNext()) {\n+            LogSegmentMetadata metadata = ledgerIter.next();\n+            asyncReadLastRecord(metadata, fence, includeControlRecord, includeEndOfStream).addEventListener(\n+                    new FutureEventListener<LogRecordWithDLSN>() {\n+                        @Override\n+                        public void onSuccess(LogRecordWithDLSN record) {\n+                            if (null == record) {\n+                                asyncGetLastLogRecord(ledgerIter, promise, fence, includeControlRecord, includeEndOfStream);\n+                            } else {\n+                                promise.setValue(record);\n+                            }\n+                        }\n+\n+                        @Override\n+                        public void onFailure(Throwable cause) {\n+                            promise.setException(cause);\n+                        }\n+                    }\n+            );\n+        } else {\n+            promise.setException(new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" has no records\"));\n+        }\n+    }\n+\n+    public LogRecordWithDLSN getLastLogRecord(boolean recover, boolean includeEndOfStream) throws IOException {\n+        checkLogStreamExists();\n+        List<LogSegmentMetadata> ledgerList = getFullLedgerListDesc(true, true);\n+\n+        for (LogSegmentMetadata metadata: ledgerList) {\n+            LogRecordWithDLSN record = recoverLastRecordInLedger(metadata, recover, false, includeEndOfStream);\n+\n+            if (null != record) {\n+                assert(!record.isControl());\n+                LOG.debug(\"{} getLastLogRecord Returned {}\", getFullyQualifiedName(), record);\n+                return record;\n+            }\n+        }\n+\n+        throw new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" has no records\");\n+    }\n+\n+    public long getLastTxId(boolean recover,\n+                            boolean includeEndOfStream) throws IOException {\n+        checkLogStreamExists();\n+        return getLastLogRecord(recover, includeEndOfStream).getTransactionId();\n+    }\n+\n+    public DLSN getLastDLSN(boolean recover,\n+                            boolean includeEndOfStream) throws IOException {\n+        checkLogStreamExists();\n+        return getLastLogRecord(recover, includeEndOfStream).getDlsn();\n+    }\n+\n+    public long getLogRecordCount() throws IOException {\n+        try {\n+            checkLogStreamExists();\n+        } catch (LogNotFoundException exc) {\n+            return 0;\n+        }\n+\n+        List<LogSegmentMetadata> ledgerList = getFullLedgerList(true, false);\n+        long count = 0;\n+        for (LogSegmentMetadata l : ledgerList) {\n+            if (l.isInProgress()) {\n+                LogRecord record = recoverLastRecordInLedger(l, false, false, false);\n+                if (null != record) {\n+                    count += record.getLastPositionWithinLogSegment();\n+                }\n+            } else {\n+                count += l.getRecordCount();\n+            }\n+        }\n+        return count;\n+    }\n+\n+    private Future<LogRecordWithDLSN> asyncReadFirstUserRecord(LogSegmentMetadata ledger, DLSN beginDLSN) {\n+        final LedgerHandleCache handleCache =\n+                LedgerHandleCache.newBuilder().bkc(bookKeeperClient).conf(conf).build();\n+        return ReadUtils.asyncReadFirstUserRecord(\n+                getFullyQualifiedName(),\n+                ledger,\n+                firstNumEntriesPerReadLastRecordScan,\n+                maxNumEntriesPerReadLastRecordScan,\n+                new AtomicInteger(0),\n+                scheduler,\n+                handleCache,\n+                beginDLSN\n+        ).ensure(new AbstractFunction0<BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply() {\n+                handleCache.clear();\n+                return BoxedUnit.UNIT;\n+            }\n+        });\n+    }\n+\n+    /**\n+     * This is a helper method to compactly return the record count between two records, the first denoted by\n+     * beginDLSN and the second denoted by endPosition. Its up to the caller to ensure that endPosition refers to\n+     * position in the same ledger as beginDLSN.\n+     */\n+    private Future<Long> asyncGetLogRecordCount(LogSegmentMetadata ledger, final DLSN beginDLSN, final long endPosition) {\n+        return asyncReadFirstUserRecord(ledger, beginDLSN).map(new Function<LogRecordWithDLSN, Long>() {\n+            public Long apply(final LogRecordWithDLSN beginRecord) {\n+                long recordCount = 0;\n+                if (null != beginRecord) {\n+                    recordCount = endPosition + 1 - beginRecord.getLastPositionWithinLogSegment();\n+                }\n+                return recordCount;\n+            }\n+        });\n+    }\n+\n+    /**\n+     * Ledger metadata tells us how many records are in each completed segment, but for the first and last segments\n+     * we may have to crack open the entry and count. For the first entry, we need to do so because beginDLSN may be\n+     * an interior entry. For the last entry, if it is inprogress, we need to recover it and find the last user\n+     * entry.\n+     */\n+    private Future<Long> asyncGetLogRecordCount(final LogSegmentMetadata ledger, final DLSN beginDLSN) {\n+        if (ledger.isInProgress() && ledger.isDLSNinThisSegment(beginDLSN)) {\n+            return asyncReadLastUserRecord(ledger).flatMap(new Function<LogRecordWithDLSN, Future<Long>>() {\n+                public Future<Long> apply(final LogRecordWithDLSN endRecord) {\n+                    if (null != endRecord) {\n+                        return asyncGetLogRecordCount(ledger, beginDLSN, endRecord.getLastPositionWithinLogSegment() /* end position */);\n+                    } else {\n+                        return Future.value((long) 0);\n+                    }\n+                }\n+            });\n+        } else if (ledger.isInProgress()) {\n+            return asyncReadLastUserRecord(ledger).map(new Function<LogRecordWithDLSN, Long>() {\n+                public Long apply(final LogRecordWithDLSN endRecord) {\n+                    if (null != endRecord) {\n+                        return (long) endRecord.getLastPositionWithinLogSegment();\n+                    } else {\n+                        return (long) 0;\n+                    }\n+                }\n+            });\n+        } else if (ledger.isDLSNinThisSegment(beginDLSN)) {\n+            return asyncGetLogRecordCount(ledger, beginDLSN, ledger.getRecordCount() /* end position */);\n+        } else {\n+            return Future.value((long) ledger.getRecordCount());\n+        }\n+    }\n+\n+    /**\n+     * Get a count of records between beginDLSN and the end of the stream.\n+     *\n+     * @param beginDLSN dlsn marking the start of the range\n+     * @return the count of records present in the range\n+     */\n+    public Future<Long> asyncGetLogRecordCount(final DLSN beginDLSN) {\n+\n+        return checkLogStreamExistsAsync().flatMap(new Function<Void, Future<Long>>() {\n+            public Future<Long> apply(Void done) {\n+\n+                return asyncGetFullLedgerList(true, false).flatMap(new Function<List<LogSegmentMetadata>, Future<Long>>() {\n+                    public Future<Long> apply(List<LogSegmentMetadata> ledgerList) {\n+\n+                        List<Future<Long>> futureCounts = new ArrayList<Future<Long>>(ledgerList.size());\n+                        for (LogSegmentMetadata ledger : ledgerList) {\n+                            if (ledger.getLogSegmentSequenceNumber() >= beginDLSN.getLogSegmentSequenceNo()) {\n+                                futureCounts.add(asyncGetLogRecordCount(ledger, beginDLSN));\n+                            }\n+                        }\n+                        return Future.collect(futureCounts).map(new Function<List<Long>, Long>() {\n+                            public Long apply(List<Long> counts) {\n+                                return sum(counts);\n+                            }\n+                        });\n+                    }\n+                });\n+            }\n+        });\n+    }\n+\n+    private Long sum(List<Long> values) {\n+        long sum = 0;\n+        for (Long value : values) {\n+            sum += value;\n+        }\n+        return sum;\n+    }\n+\n+    public long getFirstTxId() throws IOException {\n+        checkLogStreamExists();\n+        List<LogSegmentMetadata> ledgerList = getFullLedgerList(true, true);\n+\n+        // The ledger list should at least have one element\n+        // First TxId is populated even for in progress ledgers\n+        return ledgerList.get(0).getFirstTxId();\n+    }\n+\n+    Future<Void> checkLogStreamExistsAsync() {\n+        final Promise<Void> promise = new Promise<Void>();\n+        try {\n+            final ZooKeeper zk = zooKeeperClient.get();\n+            zk.sync(logMetadata.getLogSegmentsPath(), new AsyncCallback.VoidCallback() {\n+                @Override\n+                public void processResult(int syncRc, String path, Object syncCtx) {\n+                    if (KeeperException.Code.NONODE.intValue() == syncRc) {\n+                        promise.setException(new LogNotFoundException(\n+                                String.format(\"Log %s does not exist or has been deleted\", getFullyQualifiedName())));\n+                        return;\n+                    } else if (KeeperException.Code.OK.intValue() != syncRc){\n+                        promise.setException(new ZKException(\"Error on checking log existence for \" + getFullyQualifiedName(),\n+                                KeeperException.create(KeeperException.Code.get(syncRc))));\n+                        return;\n+                    }\n+                    zk.exists(logMetadata.getLogSegmentsPath(), false, new AsyncCallback.StatCallback() {\n+                        @Override\n+                        public void processResult(int rc, String path, Object ctx, Stat stat) {\n+                            if (KeeperException.Code.OK.intValue() == rc) {\n+                                promise.setValue(null);\n+                            } else if (KeeperException.Code.NONODE.intValue() == rc) {\n+                                promise.setException(new LogNotFoundException(String.format(\"Log %s does not exist or has been deleted\", getFullyQualifiedName())));\n+                            } else {\n+                                promise.setException(new ZKException(\"Error on checking log existence for \" + getFullyQualifiedName(),\n+                                        KeeperException.create(KeeperException.Code.get(rc))));\n+                            }\n+                        }\n+                    }, null);\n+                }\n+            }, null);\n+\n+        } catch (InterruptedException ie) {\n+            LOG.error(\"Interrupted while reading {}\", logMetadata.getLogSegmentsPath(), ie);\n+            promise.setException(new DLInterruptedException(\"Interrupted while checking \"\n+                    + logMetadata.getLogSegmentsPath(), ie));\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            promise.setException(e);\n+        }\n+        return promise;\n+    }\n+\n+    private void checkLogStreamExists() throws IOException {\n+        try {\n+            if (null == Utils.sync(zooKeeperClient, logMetadata.getLogSegmentsPath())\n+                    .exists(logMetadata.getLogSegmentsPath(), false)) {\n+                throw new LogNotFoundException(\"Log \" + getFullyQualifiedName() + \" doesn't exist\");\n+            }\n+        } catch (InterruptedException ie) {\n+            LOG.error(\"Interrupted while reading {}\", logMetadata.getLogSegmentsPath(), ie);\n+            throw new DLInterruptedException(\"Interrupted while checking \"\n+                    + logMetadata.getLogSegmentsPath(), ie);\n+        } catch (KeeperException ke) {\n+            LOG.error(\"Error checking existence for {} : \", logMetadata.getLogSegmentsPath(), ke);\n+            throw new ZKException(\"Error checking existence for \" + getFullyQualifiedName() + \" : \", ke);\n+        }\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        // No-op\n+        this.zooKeeperClient.getWatcherManager().unregisterChildWatcher(logMetadata.getLogSegmentsPath(), this);\n+        return Future.Void();\n+    }\n+\n+    @Override\n+    public Future<Void> asyncAbort() {\n+        return asyncClose();\n+    }\n+\n+    /**\n+     * Find the id of the last edit log transaction written to a edit log\n+     * ledger.\n+     */\n+    protected Pair<Long, DLSN> readLastTxIdInLedger(LogSegmentMetadata l) throws IOException {\n+        LogRecordWithDLSN record = recoverLastRecordInLedger(l, false, false, true);\n+\n+        if (null == record) {\n+            return Pair.of(DistributedLogConstants.EMPTY_LOGSEGMENT_TX_ID, DLSN.InvalidDLSN);\n+        }\n+        else {\n+            return Pair.of(record.getTransactionId(), record.getDlsn());\n+        }\n+    }\n+\n+    /**\n+     * Find the id of the last edit log transaction written to a edit log\n+     * ledger.\n+     */\n+    protected LogRecordWithDLSN recoverLastRecordInLedger(LogSegmentMetadata l,\n+                                                          boolean fence,\n+                                                          boolean includeControl,\n+                                                          boolean includeEndOfStream)\n+        throws IOException {\n+        return FutureUtils.result(asyncReadLastRecord(l, fence, includeControl, includeEndOfStream));\n+    }\n+\n+    public Future<LogRecordWithDLSN> asyncReadLastUserRecord(final LogSegmentMetadata l) {\n+        return asyncReadLastRecord(l, false, false, false);\n+    }\n+\n+    public Future<LogRecordWithDLSN> asyncReadLastRecord(final LogSegmentMetadata l,\n+                                                         final boolean fence,\n+                                                         final boolean includeControl,\n+                                                         final boolean includeEndOfStream) {\n+        final AtomicInteger numRecordsScanned = new AtomicInteger(0);\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        final LedgerHandleCache handleCache =\n+                LedgerHandleCache.newBuilder().bkc(bookKeeperClient).conf(conf).build();\n+        return ReadUtils.asyncReadLastRecord(\n+                getFullyQualifiedName(),\n+                l,\n+                fence,\n+                includeControl,\n+                includeEndOfStream,\n+                firstNumEntriesPerReadLastRecordScan,\n+                maxNumEntriesPerReadLastRecordScan,\n+                numRecordsScanned,\n+                scheduler,\n+                handleCache\n+        ).addEventListener(new FutureEventListener<LogRecordWithDLSN>() {\n+            @Override\n+            public void onSuccess(LogRecordWithDLSN value) {\n+                recoverLastEntryStats.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+                recoverScannedEntriesStats.registerSuccessfulEvent(numRecordsScanned.get());\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                recoverLastEntryStats.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            }\n+        }).ensure(new AbstractFunction0<BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply() {\n+                handleCache.clear();\n+                return BoxedUnit.UNIT;\n+            }\n+        });\n+    }\n+\n+    protected void setLastLedgerRollingTimeMillis(long rollingTimeMillis) {\n+        if (lastLedgerRollingTimeMillis < rollingTimeMillis) {\n+            lastLedgerRollingTimeMillis = rollingTimeMillis;\n+        }\n+    }\n+\n+    public String getFullyQualifiedName() {\n+        return logMetadata.getFullyQualifiedName();\n+    }\n+\n+    // Ledgers Related Functions\n+    // ***Note***\n+    // Get ledger list should go through #getCachedLogSegments as we need to assign start sequence id for inprogress log\n+    // segment so the reader could generate the right sequence id.\n+\n+    protected List<LogSegmentMetadata> getCachedLogSegments(Comparator<LogSegmentMetadata> comparator)\n+        throws UnexpectedException {\n+        try {\n+            return logSegmentCache.getLogSegments(comparator);\n+        } catch (UnexpectedException ue) {\n+            // the log segments cache went wrong\n+            LOG.error(\"Unexpected exception on getting log segments from the cache for stream {}\",\n+                    getFullyQualifiedName(), ue);\n+            metadataException.compareAndSet(null, ue);\n+            throw ue;\n+        }\n+    }\n+\n+    protected List<LogSegmentMetadata> getFullLedgerList(boolean forceFetch, boolean throwOnEmpty)\n+            throws IOException {\n+        return getLedgerList(forceFetch, true, LogSegmentMetadata.COMPARATOR, throwOnEmpty);\n+    }\n+\n+    protected List<LogSegmentMetadata> getFullLedgerListDesc(boolean forceFetch, boolean throwOnEmpty)\n+            throws IOException {\n+        return getLedgerList(forceFetch, true, LogSegmentMetadata.DESC_COMPARATOR, throwOnEmpty);\n+    }\n+\n+    protected List<LogSegmentMetadata> getFilteredLedgerList(boolean forceFetch, boolean throwOnEmpty)\n+            throws IOException {\n+        return getLedgerList(forceFetch, false, LogSegmentMetadata.COMPARATOR, throwOnEmpty);\n+    }\n+\n+    protected List<LogSegmentMetadata> getFilteredLedgerListDesc(boolean forceFetch, boolean throwOnEmpty)\n+            throws IOException {\n+        return getLedgerList(forceFetch, false, LogSegmentMetadata.DESC_COMPARATOR, throwOnEmpty);\n+    }\n+\n+    protected List<LogSegmentMetadata> getLedgerList(boolean forceFetch,\n+                                                     boolean fetchFullList,\n+                                                     Comparator<LogSegmentMetadata> comparator,\n+                                                     boolean throwOnEmpty)\n+            throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        boolean success = false;\n+        try {\n+            List<LogSegmentMetadata> segments =\n+                    doGetLedgerList(forceFetch, fetchFullList, comparator, throwOnEmpty);\n+            success = true;\n+            return segments;\n+        } finally {\n+            OpStatsLogger statsLogger = fetchFullList ? getFullListStat : getFilteredListStat;\n+            if (success) {\n+                statsLogger.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            } else {\n+                statsLogger.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            }\n+        }\n+    }\n+\n+    private List<LogSegmentMetadata> doGetLedgerList(boolean forceFetch, boolean fetchFullList,\n+                                                     Comparator<LogSegmentMetadata> comparator,\n+                                                     boolean throwOnEmpty)\n+        throws IOException {\n+        if (fetchFullList) {\n+            if (forceFetch || !isFullListFetched.get()) {\n+                return forceGetLedgerList(comparator, LogSegmentFilter.DEFAULT_FILTER, throwOnEmpty);\n+            } else {\n+                return getCachedLogSegments(comparator);\n+            }\n+        } else {\n+            if (forceFetch) {\n+                return forceGetLedgerList(comparator, filter, throwOnEmpty);\n+            } else {\n+                if(!ledgerListWatchSet.get()) {\n+                    scheduleGetLedgersTask(true, true);\n+                }\n+                waitFirstGetLedgersTaskToFinish();\n+                return getCachedLogSegments(comparator);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Get a list of all segments in the journal.\n+     */\n+    protected List<LogSegmentMetadata> forceGetLedgerList(final Comparator<LogSegmentMetadata> comparator,\n+                                                                final LogSegmentFilter segmentFilter,\n+                                                                boolean throwOnEmpty) throws IOException {\n+        final List<LogSegmentMetadata> ledgers = new ArrayList<LogSegmentMetadata>();\n+        final AtomicInteger result = new AtomicInteger(-1);\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        asyncGetLedgerListInternal(comparator, segmentFilter, null, new GenericCallback<List<LogSegmentMetadata>>() {\n+            @Override\n+            public void operationComplete(int rc, List<LogSegmentMetadata> logSegmentMetadatas) {\n+                result.set(rc);\n+                if (KeeperException.Code.OK.intValue() == rc) {\n+                    ledgers.addAll(logSegmentMetadatas);\n+                } else {\n+                    LOG.error(\"Failed to get ledger list for {} : with error {}\", getFullyQualifiedName(), rc);\n+                }\n+                latch.countDown();\n+            }\n+        }, new AtomicInteger(conf.getZKNumRetries()), new AtomicLong(conf.getZKRetryBackoffStartMillis()));\n+        try {\n+            latch.await();\n+        } catch (InterruptedException e) {\n+            forceGetListStat.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            throw new DLInterruptedException(\"Interrupted on reading ledger list from zkfor \" + getFullyQualifiedName(), e);\n+        }\n+        long elapsedMicros = stopwatch.stop().elapsed(TimeUnit.MICROSECONDS);\n+\n+        KeeperException.Code rc = KeeperException.Code.get(result.get());\n+        if (rc == KeeperException.Code.OK) {\n+            forceGetListStat.registerSuccessfulEvent(elapsedMicros);\n+        } else {\n+            forceGetListStat.registerFailedEvent(elapsedMicros);\n+            if (KeeperException.Code.NONODE == rc) {\n+                throw new LogNotFoundException(\"Log \" + getFullyQualifiedName() + \" is not found\");\n+            } else {\n+                throw new IOException(\"ZK Exception \" + rc + \" reading ledger list for \" + getFullyQualifiedName());\n+            }\n+        }\n+\n+        if (throwOnEmpty && ledgers.isEmpty()) {\n+            throw new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" is empty\");\n+        }\n+        return ledgers;\n+    }\n+\n+    protected Future<List<LogSegmentMetadata>> asyncGetFullLedgerList(boolean forceFetch, boolean throwOnEmpty) {\n+        return asyncGetLedgerList(forceFetch, true, LogSegmentMetadata.COMPARATOR, throwOnEmpty);\n+    }\n+\n+    protected Future<List<LogSegmentMetadata>> asyncGetFullLedgerListDesc(boolean forceFetch, boolean throwOnEmpty) {\n+        return asyncGetLedgerList(forceFetch, true, LogSegmentMetadata.DESC_COMPARATOR, throwOnEmpty);\n+    }\n+\n+    protected Future<List<LogSegmentMetadata>> asyncGetFilteredLedgerList(boolean forceFetch, boolean throwOnEmpty) {\n+        return asyncGetLedgerList(forceFetch, false, LogSegmentMetadata.COMPARATOR, throwOnEmpty);\n+    }\n+\n+    protected Future<List<LogSegmentMetadata>> asyncGetFilteredLedgerListDesc(boolean forceFetch, boolean throwOnEmpty) {\n+        return asyncGetLedgerList(forceFetch, false, LogSegmentMetadata.DESC_COMPARATOR, throwOnEmpty);\n+    }\n+\n+    protected Future<List<LogSegmentMetadata>> asyncGetLedgerList(final boolean forceFetch,\n+                                                                        final boolean fetchFullList,\n+                                                                        final Comparator<LogSegmentMetadata> comparator,\n+                                                                        final boolean throwOnEmpty) {\n+        final Promise<List<LogSegmentMetadata>> promise = new Promise<List<LogSegmentMetadata>>();\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        final OpStatsLogger statsLogger = fetchFullList ? getFullListStat : getFilteredListStat;\n+        asyncDoGetLedgerList(forceFetch, fetchFullList, comparator, throwOnEmpty)\n+                .addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n+                    @Override\n+                    public void onSuccess(List<LogSegmentMetadata> value) {\n+                        statsLogger.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+                        promise.setValue(value);\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        statsLogger.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+                        promise.setException(cause);\n+                    }\n+                });\n+        return promise;\n+    }\n+\n+    private Future<List<LogSegmentMetadata>> asyncDoGetLedgerList(final boolean forceFetch,\n+                                                                  final boolean fetchFullList,\n+                                                                  final Comparator<LogSegmentMetadata> comparator,\n+                                                                  final boolean throwOnEmpty) {\n+        if (fetchFullList) {\n+            if (forceFetch || !isFullListFetched.get()) {\n+                return asyncForceGetLedgerList(comparator, LogSegmentFilter.DEFAULT_FILTER, throwOnEmpty);\n+            } else {\n+                try {\n+                    return Future.value(getCachedLogSegments(comparator));\n+                } catch (UnexpectedException ue) {\n+                    return Future.exception(ue);\n+                }\n+            }\n+        } else {\n+            if (forceFetch) {\n+                return asyncForceGetLedgerList(comparator, filter, throwOnEmpty);\n+            } else {\n+                final Promise<List<LogSegmentMetadata>> promise =\n+                        new Promise<List<LogSegmentMetadata>>();\n+                SyncGetLedgersCallback task = firstGetLedgersTask;\n+                task.promise.addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n+                    @Override\n+                    public void onSuccess(List<LogSegmentMetadata> value) {\n+                        try {\n+                            promise.setValue(getCachedLogSegments(comparator));\n+                        } catch (UnexpectedException e) {\n+                            promise.setException(e);\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        promise.setException(cause);\n+                    }\n+                });\n+                return promise;\n+            }\n+        }\n+    }\n+\n+    protected Future<List<LogSegmentMetadata>> asyncForceGetLedgerList(final Comparator<LogSegmentMetadata> comparator,\n+                                                                       final LogSegmentFilter segmentFilter,\n+                                                                       final boolean throwOnEmpty) {\n+        final Promise<List<LogSegmentMetadata>> promise = new Promise<List<LogSegmentMetadata>>();\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        asyncGetLedgerListWithRetries(comparator, segmentFilter, null)\n+            .addEventListener(new FutureEventListener<List<LogSegmentMetadata>>() {\n+\n+                @Override\n+                public void onSuccess(List<LogSegmentMetadata> ledgers) {\n+                    forceGetListStat.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+                    if (ledgers.isEmpty() && throwOnEmpty) {\n+                        promise.setException(new LogEmptyException(\"Log \" + getFullyQualifiedName() + \" is empty\"));\n+                    } else {\n+                        promise.setValue(ledgers);\n+                    }\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause) {\n+                    forceGetListStat.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+                    promise.setException(cause);\n+                }\n+            });\n+        return promise;\n+    }\n+\n+    /**\n+     * Add the segment <i>metadata</i> for <i>name</i> in the cache.\n+     *\n+     * @param name\n+     *          segment znode name.\n+     * @param metadata\n+     *          segment metadata.\n+     */\n+    protected void addLogSegmentToCache(String name, LogSegmentMetadata metadata) {\n+        logSegmentCache.add(name, metadata);\n+        // update the last ledger rolling time\n+        if (!metadata.isInProgress() && (lastLedgerRollingTimeMillis < metadata.getCompletionTime())) {\n+            lastLedgerRollingTimeMillis = metadata.getCompletionTime();\n+        }\n+\n+        if (reportGetSegmentStats) {\n+            // update stats\n+            long ts = System.currentTimeMillis();\n+            if (metadata.isInProgress()) {\n+                // as we used timestamp as start tx id we could take it as start time\n+                // NOTE: it is a hack here.\n+                long elapsedMillis = ts - metadata.getFirstTxId();\n+                long elapsedMicroSec = TimeUnit.MILLISECONDS.toMicros(elapsedMillis);\n+                if (elapsedMicroSec > 0) {\n+                    if (elapsedMillis > metadataLatencyWarnThresholdMillis) {\n+                        LOG.warn(\"{} received inprogress log segment in {} millis: {}\",\n+                                 new Object[] { getFullyQualifiedName(), elapsedMillis, metadata });\n+                    }\n+                    getInprogressSegmentStat.registerSuccessfulEvent(elapsedMicroSec);\n+                } else {\n+                    negativeGetInprogressSegmentStat.registerSuccessfulEvent(-elapsedMicroSec);\n+                }\n+            } else {\n+                long elapsedMillis = ts - metadata.getCompletionTime();\n+                long elapsedMicroSec = TimeUnit.MILLISECONDS.toMicros(elapsedMillis);\n+                if (elapsedMicroSec > 0) {\n+                    if (elapsedMillis > metadataLatencyWarnThresholdMillis) {\n+                        LOG.warn(\"{} received completed log segment in {} millis : {}\",\n+                                 new Object[] { getFullyQualifiedName(), elapsedMillis, metadata });\n+                    }\n+                    getCompletedSegmentStat.registerSuccessfulEvent(elapsedMicroSec);\n+                } else {\n+                    negativeGetCompletedSegmentStat.registerSuccessfulEvent(-elapsedMicroSec);\n+                }\n+            }\n+        }\n+    }\n+\n+    protected LogSegmentMetadata readLogSegmentFromCache(String name) {\n+        return logSegmentCache.get(name);\n+    }\n+\n+    protected LogSegmentMetadata removeLogSegmentFromCache(String name) {\n+        return logSegmentCache.remove(name);\n+    }\n+\n+    public void asyncGetLedgerList(final Comparator<LogSegmentMetadata> comparator,\n+                                   Watcher watcher,\n+                                   final GenericCallback<List<LogSegmentMetadata>> callback) {\n+        asyncGetLedgerListWithRetries(comparator, filter, watcher, callback);\n+    }\n+\n+    protected Future<List<LogSegmentMetadata>> asyncGetLedgerListWithRetries(Comparator<LogSegmentMetadata> comparator,\n+                                                                             LogSegmentFilter segmentFilter,\n+                                                                             Watcher watcher) {\n+        final Promise<List<LogSegmentMetadata>> promise = new Promise<List<LogSegmentMetadata>>();\n+        asyncGetLedgerListWithRetries(comparator, segmentFilter, watcher, new GenericCallback<List<LogSegmentMetadata>>() {\n+            @Override\n+            public void operationComplete(int rc, List<LogSegmentMetadata> segments) {\n+                if (KeeperException.Code.OK.intValue() == rc) {\n+                    promise.setValue(segments);\n+                } else if (KeeperException.Code.NONODE.intValue() == rc) {\n+                    promise.setException(new LogNotFoundException(\"Log \" + getFullyQualifiedName() + \" not found\"));\n+                } else {\n+                    String errMsg = \"ZK Exception \" + rc + \" reading ledger list for \" + getFullyQualifiedName();\n+                    promise.setException(new ZKException(errMsg, KeeperException.Code.get(rc)));\n+                }\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    private void asyncGetLedgerListWithRetries(final Comparator<LogSegmentMetadata> comparator,\n+                                               final LogSegmentFilter segmentFilter,\n+                                               final Watcher watcher,\n+                                               final GenericCallback<List<LogSegmentMetadata>> finalCallback) {\n+        asyncGetLedgerListInternal(comparator, segmentFilter, watcher, finalCallback,\n+                new AtomicInteger(conf.getZKNumRetries()), new AtomicLong(conf.getZKRetryBackoffStartMillis()));\n+    }\n+\n+    private void asyncGetLedgerListInternal(final Comparator<LogSegmentMetadata> comparator,\n+                                            final LogSegmentFilter segmentFilter,\n+                                            final Watcher watcher,\n+                                            final GenericCallback<List<LogSegmentMetadata>> finalCallback,\n+                                            final AtomicInteger numAttemptsLeft,\n+                                            final AtomicLong backoffMillis) {\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        try {\n+            if (LOG.isTraceEnabled()) {\n+                LOG.trace(\"Async getting ledger list for {}.\", getFullyQualifiedName());\n+            }\n+            final GenericCallback<List<LogSegmentMetadata>> callback = new GenericCallback<List<LogSegmentMetadata>>() {\n+                @Override\n+                public void operationComplete(int rc, List<LogSegmentMetadata> result) {\n+                    long elapsedMicros = stopwatch.stop().elapsed(TimeUnit.MICROSECONDS);\n+                    if (KeeperException.Code.OK.intValue() != rc) {\n+                        getListStat.registerFailedEvent(elapsedMicros);\n+                    } else {\n+                        if (LogSegmentFilter.DEFAULT_FILTER == segmentFilter) {\n+                            isFullListFetched.set(true);\n+                        }\n+                        getListStat.registerSuccessfulEvent(elapsedMicros);\n+                    }\n+                    finalCallback.operationComplete(rc, result);\n+                }\n+            };\n+            zooKeeperClient.get().getChildren(logMetadata.getLogSegmentsPath(), watcher, new AsyncCallback.Children2Callback() {\n+                @Override\n+                public void processResult(final int rc, final String path, final Object ctx, final List<String> children, final Stat stat) {\n+                    if (KeeperException.Code.OK.intValue() != rc) {\n+\n+                        if ((KeeperException.Code.CONNECTIONLOSS.intValue() == rc ||\n+                             KeeperException.Code.SESSIONEXPIRED.intValue() == rc ||\n+                             KeeperException.Code.SESSIONMOVED.intValue() == rc) &&\n+                            numAttemptsLeft.decrementAndGet() > 0) {\n+                            long backoffMs = backoffMillis.get();\n+                            backoffMillis.set(Math.min(conf.getZKRetryBackoffMaxMillis(), 2 * backoffMs));\n+                            scheduler.schedule(new Runnable() {\n+                                @Override\n+                                public void run() {\n+                                    asyncGetLedgerListInternal(comparator, segmentFilter, watcher,\n+                                            finalCallback, numAttemptsLeft, backoffMillis);\n+                                }\n+                            }, backoffMs, TimeUnit.MILLISECONDS);\n+                            return;\n+                        }\n+                        callback.operationComplete(rc, null);\n+                        return;\n+                    }\n+\n+                    if (LOG.isTraceEnabled()) {\n+                        LOG.trace(\"Got ledger list from {} : {}\", logMetadata.getLogSegmentsPath(), children);\n+                    }\n+\n+                    ledgerListWatchSet.set(true);\n+                    Set<String> segmentsReceived = new HashSet<String>();\n+                    segmentsReceived.addAll(segmentFilter.filter(children));\n+                    Set<String> segmentsAdded;\n+                    final Set<String> removedSegments = Collections.synchronizedSet(new HashSet<String>());\n+                    final Map<String, LogSegmentMetadata> addedSegments =\n+                            Collections.synchronizedMap(new HashMap<String, LogSegmentMetadata>());\n+                    Pair<Set<String>, Set<String>> segmentChanges = logSegmentCache.diff(segmentsReceived);\n+                    segmentsAdded = segmentChanges.getLeft();\n+                    removedSegments.addAll(segmentChanges.getRight());\n+\n+                    if (segmentsAdded.isEmpty()) {\n+                        if (LOG.isTraceEnabled()) {\n+                            LOG.trace(\"No segments added for {}.\", getFullyQualifiedName());\n+                        }\n+\n+                        // update the cache before fetch\n+                        logSegmentCache.update(removedSegments, addedSegments);\n+\n+                        List<LogSegmentMetadata> segmentList;\n+                        try {\n+                            segmentList = getCachedLogSegments(comparator);\n+                        } catch (UnexpectedException e) {\n+                            callback.operationComplete(KeeperException.Code.DATAINCONSISTENCY.intValue(), null);\n+                            return;\n+                        }\n+                        callback.operationComplete(KeeperException.Code.OK.intValue(), segmentList);\n+                        notifyUpdatedLogSegments(segmentList);\n+                        if (!removedSegments.isEmpty()) {\n+                            notifyOnOperationComplete();\n+                        }\n+                        return;\n+                    }\n+\n+                    final AtomicInteger numChildren = new AtomicInteger(segmentsAdded.size());\n+                    final AtomicInteger numFailures = new AtomicInteger(0);\n+                    for (final String segment: segmentsAdded) {\n+                        metadataStore.getLogSegment(logMetadata.getLogSegmentPath(segment))\n+                                .addEventListener(new FutureEventListener<LogSegmentMetadata>() {\n+\n+                                    @Override\n+                                    public void onSuccess(LogSegmentMetadata result) {\n+                                        addedSegments.put(segment, result);\n+                                        complete();\n+                                    }\n+\n+                                    @Override\n+                                    public void onFailure(Throwable cause) {\n+                                        // NONODE exception is possible in two cases\n+                                        // 1. A log segment was deleted by truncation between the call to getChildren and read\n+                                        // attempt on the znode corresponding to the segment\n+                                        // 2. In progress segment has been completed => inprogress ZNode does not exist\n+                                        if (cause instanceof KeeperException &&\n+                                                KeeperException.Code.NONODE == ((KeeperException) cause).code()) {\n+                                            removedSegments.add(segment);\n+                                            complete();\n+                                        } else {\n+                                            // fail fast\n+                                            if (1 == numFailures.incrementAndGet()) {\n+                                                int rcToReturn = KeeperException.Code.SYSTEMERROR.intValue();\n+                                                if (cause instanceof KeeperException) {\n+                                                    rcToReturn = ((KeeperException) cause).code().intValue();\n+                                                } else if (cause instanceof ZKException) {\n+                                                    rcToReturn = ((ZKException) cause).getKeeperExceptionCode().intValue();\n+                                                }\n+                                                // :( properly we need dlog related response code.\n+                                                callback.operationComplete(rcToReturn, null);\n+                                                return;\n+                                            }\n+                                        }\n+                                    }\n+\n+                                    private void complete() {\n+                                        if (0 == numChildren.decrementAndGet() && numFailures.get() == 0) {\n+                                            // update the cache only when fetch completed\n+                                            logSegmentCache.update(removedSegments, addedSegments);\n+                                            List<LogSegmentMetadata> segmentList;\n+                                            try {\n+                                                segmentList = getCachedLogSegments(comparator);\n+                                            } catch (UnexpectedException e) {\n+                                                callback.operationComplete(KeeperException.Code.DATAINCONSISTENCY.intValue(), null);\n+                                                return;\n+                                            }\n+                                            callback.operationComplete(KeeperException.Code.OK.intValue(), segmentList);\n+                                            notifyUpdatedLogSegments(segmentList);\n+                                            notifyOnOperationComplete();\n+                                        }\n+                                    }\n+                                });\n+                    }\n+                }\n+            }, null);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            getListStat.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            finalCallback.operationComplete(KeeperException.Code.CONNECTIONLOSS.intValue(), null);\n+        } catch (InterruptedException e) {\n+            getListStat.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            finalCallback.operationComplete(KeeperException.Code.CONNECTIONLOSS.intValue(), null);\n+        }\n+    }\n+\n+    @Override\n+    public void process(WatchedEvent event) {\n+        if (Watcher.Event.EventType.None.equals(event.getType())) {\n+            if (event.getState() == Watcher.Event.KeeperState.Expired) {\n+                // if the watcher is expired\n+                scheduler.schedule(new WatcherGetLedgersCallback(getFullyQualifiedName()),\n+                        conf.getZKRetryBackoffStartMillis(), TimeUnit.MILLISECONDS);\n+            }\n+        } else if (Watcher.Event.EventType.NodeChildrenChanged.equals(event.getType())) {\n+            if (LOG.isTraceEnabled()) {\n+                LOG.trace(\"LogSegments Changed under {}.\", getFullyQualifiedName());\n+            }\n+            asyncGetLedgerListWithRetries(LogSegmentMetadata.COMPARATOR, filter,\n+                    getChildrenWatcher, new WatcherGetLedgersCallback(getFullyQualifiedName()));\n+        }\n+    }\n+\n+    void notifyOnOperationComplete() {\n+        if (null != notification) {\n+            notification.notifyOnOperationComplete();\n+        }\n+    }\n+\n+    // ZooKeeper Watchers\n+\n+    Watcher registerExpirationHandler(final ZooKeeperClient.ZooKeeperSessionExpireNotifier onExpired) {\n+        if (conf.getZKNumRetries() > 0) {\n+            return new Watcher() {\n+                @Override\n+                public void process(WatchedEvent event) {\n+                    // nop\n+                }\n+            };\n+        }\n+        return zooKeeperClient.registerExpirationHandler(onExpired);\n+    }\n+\n+    boolean unregister(Watcher watcher) {\n+        return zooKeeperClient.unregister(watcher);\n+    }\n+}"},{"sha":"80f1270d06141e3388f5a6b6b160c840a166a5a6","filename":"src/main/java/com/twitter/distributedlog/BKLogReadHandler.java","status":"added","additions":410,"deletions":0,"changes":410,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,410 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.io.IOException;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Optional;\n+import com.google.common.base.Ticker;\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.LockCancelledException;\n+import com.twitter.distributedlog.exceptions.LockingException;\n+import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForReader;\n+import com.twitter.distributedlog.injector.AsyncFailureInjector;\n+import com.twitter.distributedlog.lock.SessionLockFactory;\n+import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n+import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.readahead.ReadAheadWorker;\n+import com.twitter.distributedlog.stats.BroadCastStatsLogger;\n+import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.distributedlog.lock.DistributedLock;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.util.ExceptionalFunction;\n+import com.twitter.util.ExceptionalFunction0;\n+import com.twitter.util.Function;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import com.twitter.util.Return;\n+import com.twitter.util.Throw;\n+import com.twitter.util.Try;\n+import org.apache.bookkeeper.stats.AlertStatsLogger;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.util.SafeRunnable;\n+import org.apache.zookeeper.CreateMode;\n+import org.apache.zookeeper.KeeperException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.Function0;\n+import scala.runtime.AbstractFunction1;\n+import scala.runtime.BoxedUnit;\n+\n+/**\n+ * Log Handler for Readers.\n+ * <h3>Metrics</h3>\n+ *\n+ * <h4>ReadAhead Worker</h4>\n+ * Most of readahead stats are exposed under scope `readahead_worker`. Only readahead exceptions are exposed\n+ * in parent scope via <code>readAheadExceptionsLogger</code>.\n+ * <ul>\n+ * <li> `readahead_worker`/wait: counter. number of waits that readahead worker is waiting. If this keeps increasing,\n+ * it usually means readahead keep getting full because of reader slows down reading.\n+ * <li> `readahead_worker`/repositions: counter. number of repositions that readhead worker encounters. reposition\n+ * means that a readahead worker finds that it isn't advancing to a new log segment and force re-positioning.\n+ * <li> `readahead_worker`/entry_piggy_back_hits: counter. it increases when the last add confirmed being advanced\n+ * because of the piggy-back lac.\n+ * <li> `readahead_worker`/entry_piggy_back_misses: counter. it increases when the last add confirmed isn't advanced\n+ * by a read entry because it doesn't piggy back a newer lac.\n+ * <li> `readahead_worker`/read_entries: opstats. stats on number of entries read per readahead read batch.\n+ * <li> `readahead_worker`/read_lac_counter: counter. stats on the number of readLastConfirmed operations\n+ * <li> `readahead_worker`/read_lac_and_entry_counter: counter. stats on the number of readLastConfirmedAndEntry\n+ * operations.\n+ * <li> `readahead_worker`/cache_full: counter. it increases each time readahead worker finds cache become full.\n+ * If it keeps increasing, that means reader slows down reading.\n+ * <li> `readahead_worker`/resume: opstats. stats on readahead worker resuming reading from wait state.\n+ * <li> `readahead_worker`/read_lac_lag: opstats. stats on the number of entries diff between the lac reader knew\n+ * last time and the lac that it received. if `lag` between two subsequent lacs is high, that might means delay\n+ * might be high. because reader is only allowed to read entries after lac is advanced.\n+ * <li> `readahead_worker`/long_poll_interruption: opstats. stats on the number of interruptions happened to long\n+ * poll. the interruptions are usually because of receiving zookeeper notifications.\n+ * <li> `readahead_worker`/notification_execution: opstats. stats on executions over the notifications received from\n+ * zookeeper.\n+ * <li> `readahead_worker`/metadata_reinitialization: opstats. stats on metadata reinitialization after receiving\n+ * notifcation from log segments updates.\n+ * <li> `readahead_worker`/idle_reader_warn: counter. it increases each time the readahead worker detects itself\n+ * becoming idle.\n+ * </ul>\n+ * <h4>Read Lock</h4>\n+ * All read lock related stats are exposed under scope `read_lock`. See {@link DistributedLock}\n+ * for detail stats.\n+ */\n+class BKLogReadHandler extends BKLogHandler {\n+    static final Logger LOG = LoggerFactory.getLogger(BKLogReadHandler.class);\n+\n+    private static final int LAYOUT_VERSION = -1;\n+\n+    protected final ZKLogMetadataForReader logMetadataForReader;\n+    protected final ReadAheadCache readAheadCache;\n+    protected final LedgerHandleCache handleCache;\n+\n+    protected final OrderedScheduler readAheadExecutor;\n+    protected final DynamicDistributedLogConfiguration dynConf;\n+    protected ReadAheadWorker readAheadWorker = null;\n+    private final boolean isHandleForReading;\n+\n+    private final SessionLockFactory lockFactory;\n+    private final OrderedScheduler lockStateExecutor;\n+    private final Optional<String> subscriberId;\n+    private final String readLockPath;\n+    private DistributedLock readLock;\n+    private Future<Void> lockAcquireFuture;\n+\n+    // stats\n+    private final AlertStatsLogger alertStatsLogger;\n+    private final StatsLogger handlerStatsLogger;\n+    private final StatsLogger perLogStatsLogger;\n+    private final ReadAheadExceptionsLogger readAheadExceptionsLogger;\n+\n+    /**\n+     * Construct a Bookkeeper journal manager.\n+     */\n+    public BKLogReadHandler(ZKLogMetadataForReader logMetadata,\n+                            Optional<String> subscriberId,\n+                            DistributedLogConfiguration conf,\n+                            DynamicDistributedLogConfiguration dynConf,\n+                            ZooKeeperClientBuilder zkcBuilder,\n+                            BookKeeperClientBuilder bkcBuilder,\n+                            LogSegmentMetadataStore metadataStore,\n+                            OrderedScheduler scheduler,\n+                            OrderedScheduler lockStateExecutor,\n+                            OrderedScheduler readAheadExecutor,\n+                            AlertStatsLogger alertStatsLogger,\n+                            ReadAheadExceptionsLogger readAheadExceptionsLogger,\n+                            StatsLogger statsLogger,\n+                            StatsLogger perLogStatsLogger,\n+                            String clientId,\n+                            AsyncNotification notification,\n+                            boolean isHandleForReading,\n+                            boolean deserializeRecordSet) {\n+        super(logMetadata, conf, zkcBuilder, bkcBuilder, metadataStore, scheduler,\n+              statsLogger, alertStatsLogger, notification, LogSegmentFilter.DEFAULT_FILTER, clientId);\n+        this.logMetadataForReader = logMetadata;\n+        this.dynConf = dynConf;\n+        this.readAheadExecutor = readAheadExecutor;\n+        this.alertStatsLogger = alertStatsLogger;\n+        this.perLogStatsLogger =\n+                isHandleForReading ? perLogStatsLogger : NullStatsLogger.INSTANCE;\n+        this.handlerStatsLogger =\n+                BroadCastStatsLogger.masterslave(this.perLogStatsLogger, statsLogger);\n+        this.readAheadExceptionsLogger = readAheadExceptionsLogger;\n+\n+        handleCache = LedgerHandleCache.newBuilder()\n+                .bkc(this.bookKeeperClient)\n+                .conf(conf)\n+                .statsLogger(statsLogger)\n+                .build();\n+        readAheadCache = new ReadAheadCache(\n+                getFullyQualifiedName(),\n+                handlerStatsLogger,\n+                alertStatsLogger,\n+                notification,\n+                dynConf.getReadAheadMaxRecords(),\n+                deserializeRecordSet,\n+                conf.getTraceReadAheadDeliveryLatency(),\n+                conf.getDataLatencyWarnThresholdMillis(),\n+                Ticker.systemTicker());\n+\n+        this.subscriberId = subscriberId;\n+        this.readLockPath = logMetadata.getReadLockPath(subscriberId);\n+        this.lockStateExecutor = lockStateExecutor;\n+        this.lockFactory = new ZKSessionLockFactory(\n+                zooKeeperClient,\n+                getLockClientId(),\n+                lockStateExecutor,\n+                conf.getZKNumRetries(),\n+                conf.getLockTimeoutMilliSeconds(),\n+                conf.getZKRetryBackoffStartMillis(),\n+                statsLogger.scope(\"read_lock\"));\n+\n+        this.isHandleForReading = isHandleForReading;\n+    }\n+\n+    @VisibleForTesting\n+    String getReadLockPath() {\n+        return readLockPath;\n+    }\n+\n+    <T> void satisfyPromiseAsync(final Promise<T> promise, final Try<T> result) {\n+        scheduler.submit(new SafeRunnable() {\n+            @Override\n+            public void safeRun() {\n+                promise.update(result);\n+            }\n+        });\n+    }\n+\n+    /**\n+     * Elective stream lock--readers are not required to acquire the lock before using the stream.\n+     */\n+    synchronized Future<Void> lockStream() {\n+        if (null == lockAcquireFuture) {\n+            final Function0<DistributedLock> lockFunction =  new ExceptionalFunction0<DistributedLock>() {\n+                @Override\n+                public DistributedLock applyE() throws IOException {\n+                    // Unfortunately this has a blocking call which we should not execute on the\n+                    // ZK completion thread\n+                    BKLogReadHandler.this.readLock = new DistributedLock(\n+                            lockStateExecutor,\n+                            lockFactory,\n+                            readLockPath,\n+                            conf.getLockTimeoutMilliSeconds(),\n+                            statsLogger.scope(\"read_lock\"));\n+\n+                    LOG.info(\"acquiring readlock {} at {}\", getLockClientId(), readLockPath);\n+                    return BKLogReadHandler.this.readLock;\n+                }\n+            };\n+            lockAcquireFuture = ensureReadLockPathExist().flatMap(new ExceptionalFunction<Void, Future<Void>>() {\n+                @Override\n+                public Future<Void> applyE(Void in) throws Throwable {\n+                    return scheduler.apply(lockFunction).flatMap(new ExceptionalFunction<DistributedLock, Future<Void>>() {\n+                        @Override\n+                        public Future<Void> applyE(DistributedLock lock) throws IOException {\n+                            return acquireLockOnExecutorThread(lock);\n+                        }\n+                    });\n+                }\n+            });\n+        }\n+        return lockAcquireFuture;\n+    }\n+\n+    /**\n+     * Begin asynchronous lock acquire, but ensure that the returned future is satisfied on an\n+     * executor service thread.\n+     */\n+    Future<Void> acquireLockOnExecutorThread(DistributedLock lock) throws LockingException {\n+        final Future<DistributedLock> acquireFuture = lock.asyncAcquire();\n+\n+        // The future we return must be satisfied on an executor service thread. If we simply\n+        // return the future returned by asyncAcquire, user callbacks may end up running in\n+        // the lock state executor thread, which will cause deadlocks and introduce latency\n+        // etc.\n+        final Promise<Void> threadAcquirePromise = new Promise<Void>();\n+        threadAcquirePromise.setInterruptHandler(new Function<Throwable, BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply(Throwable t) {\n+                FutureUtils.cancel(acquireFuture);\n+                return null;\n+            }\n+        });\n+        acquireFuture.addEventListener(new FutureEventListener<DistributedLock>() {\n+            @Override\n+            public void onSuccess(DistributedLock lock) {\n+                LOG.info(\"acquired readlock {} at {}\", getLockClientId(), readLockPath);\n+                satisfyPromiseAsync(threadAcquirePromise, new Return<Void>(null));\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                LOG.info(\"failed to acquire readlock {} at {}\",\n+                        new Object[]{getLockClientId(), readLockPath, cause});\n+                satisfyPromiseAsync(threadAcquirePromise, new Throw<Void>(cause));\n+            }\n+        });\n+        return threadAcquirePromise;\n+    }\n+\n+    /**\n+     * Check ownership of elective stream lock.\n+     */\n+    void checkReadLock() throws DLIllegalStateException, LockingException {\n+        synchronized (this) {\n+            if ((null == lockAcquireFuture) ||\n+                (!lockAcquireFuture.isDefined())) {\n+                throw new DLIllegalStateException(\"Attempt to check for lock before it has been acquired successfully\");\n+            }\n+        }\n+\n+        readLock.checkOwnership();\n+    }\n+\n+    public Future<Void> asyncClose() {\n+        DistributedLock lockToClose;\n+        synchronized (this) {\n+            if (null != lockAcquireFuture && !lockAcquireFuture.isDefined()) {\n+                FutureUtils.cancel(lockAcquireFuture);\n+            }\n+            lockToClose = readLock;\n+        }\n+        return Utils.closeSequence(scheduler, readAheadWorker, lockToClose)\n+                .flatMap(new AbstractFunction1<Void, Future<Void>>() {\n+            @Override\n+            public Future<Void> apply(Void result) {\n+                if (null != readAheadCache) {\n+                    readAheadCache.clear();\n+                }\n+                if (null != handleCache) {\n+                    handleCache.clear();\n+                }\n+                return BKLogReadHandler.super.asyncClose();\n+            }\n+        });\n+    }\n+\n+    @Override\n+    public Future<Void> asyncAbort() {\n+        return asyncClose();\n+    }\n+\n+    public void startReadAhead(LedgerReadPosition startPosition,\n+                               AsyncFailureInjector failureInjector) {\n+        if (null == readAheadWorker) {\n+            readAheadWorker = new ReadAheadWorker(\n+                    conf,\n+                    dynConf,\n+                    logMetadataForReader,\n+                    this,\n+                    zooKeeperClient,\n+                    readAheadExecutor,\n+                    handleCache,\n+                    startPosition,\n+                    readAheadCache,\n+                    isHandleForReading,\n+                    readAheadExceptionsLogger,\n+                    handlerStatsLogger,\n+                    perLogStatsLogger,\n+                    alertStatsLogger,\n+                    failureInjector,\n+                    notification);\n+            readAheadWorker.start();\n+        }\n+    }\n+\n+    public boolean isReadAheadCaughtUp() {\n+        return null != readAheadWorker && readAheadWorker.isCaughtUp();\n+    }\n+\n+    public LedgerHandleCache getHandleCache() {\n+        return handleCache;\n+    }\n+\n+    private Future<Void> ensureReadLockPathExist() {\n+        final Promise<Void> promise = new Promise<Void>();\n+        promise.setInterruptHandler(new com.twitter.util.Function<Throwable, BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply(Throwable t) {\n+                FutureUtils.setException(promise, new LockCancelledException(readLockPath, \"Could not ensure read lock path\", t));\n+                return null;\n+            }\n+        });\n+        Optional<String> parentPathShouldNotCreate = Optional.of(logMetadata.getLogRootPath());\n+        Utils.zkAsyncCreateFullPathOptimisticRecursive(zooKeeperClient, readLockPath, parentPathShouldNotCreate,\n+                new byte[0], zooKeeperClient.getDefaultACL(), CreateMode.PERSISTENT,\n+                new org.apache.zookeeper.AsyncCallback.StringCallback() {\n+                    @Override\n+                    public void processResult(final int rc, final String path, Object ctx, String name) {\n+                        scheduler.submit(new Runnable() {\n+                            @Override\n+                            public void run() {\n+                                if (KeeperException.Code.NONODE.intValue() == rc) {\n+                                    FutureUtils.setException(promise, new LogNotFoundException(String.format(\"Log %s does not exist or has been deleted\", getFullyQualifiedName())));\n+                                } else if (KeeperException.Code.OK.intValue() == rc) {\n+                                    FutureUtils.setValue(promise, null);\n+                                    LOG.trace(\"Created path {}.\", path);\n+                                } else if (KeeperException.Code.NODEEXISTS.intValue() == rc) {\n+                                    FutureUtils.setValue(promise, null);\n+                                    LOG.trace(\"Path {} is already existed.\", path);\n+                                } else if (DistributedLogConstants.ZK_CONNECTION_EXCEPTION_RESULT_CODE == rc) {\n+                                    FutureUtils.setException(promise, new ZooKeeperClient.ZooKeeperConnectionException(path));\n+                                } else if (DistributedLogConstants.DL_INTERRUPTED_EXCEPTION_RESULT_CODE == rc) {\n+                                    FutureUtils.setException(promise, new DLInterruptedException(path));\n+                                } else {\n+                                    FutureUtils.setException(promise, KeeperException.create(KeeperException.Code.get(rc)));\n+                                }\n+                            }\n+                        });\n+                    }\n+                }, null);\n+        return promise;\n+    }\n+\n+    public LogRecordWithDLSN getNextReadAheadRecord() throws IOException {\n+        return readAheadCache.getNextReadAheadRecord();\n+    }\n+\n+    public ReadAheadCache getReadAheadCache() {\n+        return readAheadCache;\n+    }\n+\n+    @VisibleForTesting\n+    void disableReadAheadZKNotification() {\n+        if (null != readAheadWorker) {\n+            readAheadWorker.disableZKNotification();\n+        }\n+    }\n+\n+}"},{"sha":"004b2fbf7c4663b934110efc362339e776835fff","filename":"src/main/java/com/twitter/distributedlog/BKLogSegmentWriter.java","status":"added","additions":1296,"deletions":0,"changes":1296,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogSegmentWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogSegmentWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogSegmentWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,1296 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Stopwatch;\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.exceptions.BKTransmitException;\n+import com.twitter.distributedlog.exceptions.EndOfStreamException;\n+import com.twitter.distributedlog.exceptions.FlushException;\n+import com.twitter.distributedlog.exceptions.LockingException;\n+import com.twitter.distributedlog.exceptions.LogRecordTooLongException;\n+import com.twitter.distributedlog.exceptions.TransactionIdOutOfOrderException;\n+import com.twitter.distributedlog.exceptions.WriteCancelledException;\n+import com.twitter.distributedlog.exceptions.WriteException;\n+import com.twitter.distributedlog.exceptions.InvalidEnvelopedEntryException;\n+import com.twitter.distributedlog.feature.CoreFeatureKeys;\n+import com.twitter.distributedlog.injector.FailureInjector;\n+import com.twitter.distributedlog.injector.RandomDelayFailureInjector;\n+import com.twitter.distributedlog.io.Buffer;\n+import com.twitter.distributedlog.io.CompressionCodec;\n+import com.twitter.distributedlog.io.CompressionUtils;\n+import com.twitter.distributedlog.lock.DistributedLock;\n+import com.twitter.distributedlog.logsegment.LogSegmentEntryWriter;\n+import com.twitter.distributedlog.logsegment.LogSegmentWriter;\n+import com.twitter.distributedlog.stats.BroadCastStatsLogger;\n+import com.twitter.distributedlog.stats.OpStatsListener;\n+import com.twitter.distributedlog.util.FailpointUtils;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.distributedlog.util.PermitLimiter;\n+import com.twitter.distributedlog.util.SafeQueueingFuturePool;\n+import com.twitter.distributedlog.util.SimplePermitLimiter;\n+import com.twitter.distributedlog.util.Sizable;\n+import com.twitter.util.Function0;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.FuturePool;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.client.AsyncCallback.AddCallback;\n+import org.apache.bookkeeper.client.AsyncCallback.CloseCallback;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+import org.apache.bookkeeper.feature.Feature;\n+import org.apache.bookkeeper.feature.FeatureProvider;\n+import org.apache.bookkeeper.stats.AlertStatsLogger;\n+import org.apache.bookkeeper.stats.Counter;\n+import org.apache.bookkeeper.stats.Gauge;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.runtime.AbstractFunction1;\n+import scala.runtime.BoxedUnit;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+import static com.twitter.distributedlog.LogRecord.MAX_LOGRECORD_SIZE;\n+import static com.twitter.distributedlog.LogRecord.MAX_LOGRECORDSET_SIZE;\n+\n+/**\n+ * BookKeeper Based Log Segment Writer.\n+ *\n+ * Multiple log records are packed into a single bookkeeper\n+ * entry before sending it over the network. The fact that the log record entries\n+ * are complete in the bookkeeper entries means that each bookkeeper log entry\n+ * can be read as a complete edit log. This is useful for reading, as we don't\n+ * need to read through the entire log segment to get the last written entry.\n+ *\n+ * <h3>Metrics</h3>\n+ *\n+ * <ul>\n+ * <li> flush/periodic/{success,miss}: counters for periodic flushes.\n+ * <li> data/{success,miss}: counters for data transmits.\n+ * <li> transmit/packetsize: opstats. characteristics of packet size for transmits.\n+ * <li> control/success: counter of success transmit of control records\n+ * <li> seg_writer/write: opstats. latency characteristics of write operations in segment writer.\n+ * <li> seg_writer/add_complete/{callback,queued,deferred}: opstats. latency components of add completions.\n+ * <li> seg_writer/pendings: counter. the number of records pending by the segment writers.\n+ * <li> transmit/outstanding/requests: per stream gauge. the number of outstanding transmits each stream.\n+ * </ul>\n+ */\n+class BKLogSegmentWriter implements LogSegmentWriter, AddCallback, Runnable, Sizable {\n+    static final Logger LOG = LoggerFactory.getLogger(BKLogSegmentWriter.class);\n+\n+    private final String fullyQualifiedLogSegment;\n+    private final String streamName;\n+    private final int logSegmentMetadataVersion;\n+    private BKTransmitPacket packetPrevious;\n+    private Entry.Writer recordSetWriter;\n+    private final AtomicInteger outstandingTransmits;\n+    private final int transmissionThreshold;\n+    protected final LogSegmentEntryWriter entryWriter;\n+    private final CompressionCodec.Type compressionType;\n+    private final ReentrantLock transmitLock = new ReentrantLock();\n+    private final AtomicInteger transmitResult\n+        = new AtomicInteger(BKException.Code.OK);\n+    private final DistributedLock lock;\n+    private final boolean isDurableWriteEnabled;\n+    private DLSN lastDLSN = DLSN.InvalidDLSN;\n+    private final long startTxId;\n+    private long lastTxId = DistributedLogConstants.INVALID_TXID;\n+    private long lastTxIdAcknowledged = DistributedLogConstants.INVALID_TXID;\n+    private long outstandingBytes = 0;\n+    private long numFlushesSinceRestart = 0;\n+    private long numBytes = 0;\n+    private long lastEntryId = Long.MIN_VALUE;\n+\n+    // Indicates whether there are writes that have been successfully transmitted that would need\n+    // a control record to be transmitted to make them visible to the readers by updating the last\n+    // add confirmed\n+    volatile private boolean controlFlushNeeded = false;\n+    private boolean immediateFlushEnabled = false;\n+    private int minDelayBetweenImmediateFlushMs = 0;\n+    private Stopwatch lastTransmit;\n+    private boolean streamEnded = false;\n+    private ScheduledFuture<?> periodicFlushSchedule = null;\n+    final private AtomicReference<ScheduledFuture<?>> transmitSchedFutureRef = new AtomicReference<ScheduledFuture<?>>(null);\n+    final private AtomicReference<ScheduledFuture<?>> immFlushSchedFutureRef = new AtomicReference<ScheduledFuture<?>>(null);\n+    final private AtomicReference<Exception> scheduledFlushException = new AtomicReference<Exception>(null);\n+    private boolean enforceLock = true;\n+    private Promise<Void> closeFuture = null;\n+    private final boolean enableRecordCounts;\n+    private int positionWithinLogSegment = 0;\n+    private final long logSegmentSequenceNumber;\n+    // Used only for values that *could* change (e.g. buffer size etc.)\n+    private final DistributedLogConfiguration conf;\n+    private final OrderedScheduler scheduler;\n+\n+    // stats\n+    private final StatsLogger envelopeStatsLogger;\n+    private final Counter transmitDataSuccesses;\n+    private final Counter transmitDataMisses;\n+    private final OpStatsLogger transmitDataPacketSize;\n+    private final Counter transmitControlSuccesses;\n+    private final Counter pFlushSuccesses;\n+    private final Counter pFlushMisses;\n+    private final OpStatsLogger writeTime;\n+    private final OpStatsLogger addCompleteTime;\n+    private final OpStatsLogger addCompleteQueuedTime;\n+    private final OpStatsLogger addCompleteDeferredTime;\n+    private final Counter pendingWrites;\n+\n+    // add complete processing\n+    private final SafeQueueingFuturePool<Void> addCompleteFuturePool;\n+\n+    // Functions\n+    private final AbstractFunction1<Integer, Future<Long>> GET_LAST_TXID_ACKNOWLEDGED_AFTER_TRANSMIT_FUNC =\n+            new AbstractFunction1<Integer, Future<Long>>() {\n+                @Override\n+                public Future<Long> apply(Integer transmitRc) {\n+                    if (BKException.Code.OK == transmitRc) {\n+                        return Future.value(getLastTxIdAcknowledged());\n+                    } else {\n+                        return Future.exception(new BKTransmitException(\"Failed to transmit entry\", transmitRc));\n+                    }\n+                }\n+            };\n+    final AbstractFunction1<Long, Future<Long>> COMMIT_AFTER_FLUSH_FUNC =\n+            new AbstractFunction1<Long, Future<Long>>() {\n+                @Override\n+                public Future<Long> apply(Long lastAckedTxId) {\n+                    return commit();\n+                }\n+            };\n+\n+    private final AlertStatsLogger alertStatsLogger;\n+    private final WriteLimiter writeLimiter;\n+    private final FailureInjector writeDelayInjector;\n+\n+    /**\n+     * Construct an edit log output stream which writes to a ledger.\n+     */\n+    protected BKLogSegmentWriter(String streamName,\n+                                 String logSegmentName,\n+                                 DistributedLogConfiguration conf,\n+                                 int logSegmentMetadataVersion,\n+                                 LogSegmentEntryWriter entryWriter,\n+                                 DistributedLock lock, /** the lock needs to be acquired **/\n+                                 long startTxId,\n+                                 long logSegmentSequenceNumber,\n+                                 OrderedScheduler scheduler,\n+                                 StatsLogger statsLogger,\n+                                 StatsLogger perLogStatsLogger,\n+                                 AlertStatsLogger alertStatsLogger,\n+                                 PermitLimiter globalWriteLimiter,\n+                                 FeatureProvider featureProvider,\n+                                 DynamicDistributedLogConfiguration dynConf)\n+        throws IOException {\n+        super();\n+\n+        // set up a write limiter\n+        PermitLimiter streamWriteLimiter = null;\n+        if (conf.getPerWriterOutstandingWriteLimit() < 0) {\n+            streamWriteLimiter = PermitLimiter.NULL_PERMIT_LIMITER;\n+        } else {\n+            Feature disableWriteLimitFeature = featureProvider.getFeature(\n+                CoreFeatureKeys.DISABLE_WRITE_LIMIT.name().toLowerCase());\n+            streamWriteLimiter = new SimplePermitLimiter(\n+                conf.getOutstandingWriteLimitDarkmode(),\n+                conf.getPerWriterOutstandingWriteLimit(),\n+                statsLogger.scope(\"streamWriteLimiter\"),\n+                false,\n+                disableWriteLimitFeature);\n+        }\n+        this.writeLimiter = new WriteLimiter(streamName, streamWriteLimiter, globalWriteLimiter);\n+        this.alertStatsLogger = alertStatsLogger;\n+        this.envelopeStatsLogger = BroadCastStatsLogger.masterslave(statsLogger, perLogStatsLogger);\n+\n+        StatsLogger flushStatsLogger = statsLogger.scope(\"flush\");\n+        StatsLogger pFlushStatsLogger = flushStatsLogger.scope(\"periodic\");\n+        pFlushSuccesses = pFlushStatsLogger.getCounter(\"success\");\n+        pFlushMisses = pFlushStatsLogger.getCounter(\"miss\");\n+\n+        // transmit\n+        StatsLogger transmitDataStatsLogger = statsLogger.scope(\"data\");\n+        transmitDataSuccesses = transmitDataStatsLogger.getCounter(\"success\");\n+        transmitDataMisses = transmitDataStatsLogger.getCounter(\"miss\");\n+        StatsLogger transmitStatsLogger = statsLogger.scope(\"transmit\");\n+        transmitDataPacketSize =  transmitStatsLogger.getOpStatsLogger(\"packetsize\");\n+        StatsLogger transmitControlStatsLogger = statsLogger.scope(\"control\");\n+        transmitControlSuccesses = transmitControlStatsLogger.getCounter(\"success\");\n+        StatsLogger segWriterStatsLogger = statsLogger.scope(\"seg_writer\");\n+        writeTime = segWriterStatsLogger.getOpStatsLogger(\"write\");\n+        addCompleteTime = segWriterStatsLogger.scope(\"add_complete\").getOpStatsLogger(\"callback\");\n+        addCompleteQueuedTime = segWriterStatsLogger.scope(\"add_complete\").getOpStatsLogger(\"queued\");\n+        addCompleteDeferredTime = segWriterStatsLogger.scope(\"add_complete\").getOpStatsLogger(\"deferred\");\n+        pendingWrites = segWriterStatsLogger.getCounter(\"pending\");\n+\n+        // outstanding transmit requests\n+        StatsLogger transmitOutstandingLogger = perLogStatsLogger.scope(\"transmit\").scope(\"outstanding\");\n+        transmitOutstandingLogger.registerGauge(\"requests\", new Gauge<Number>() {\n+            @Override\n+            public Number getDefaultValue() {\n+                return 0;\n+            }\n+            @Override\n+            public Number getSample() {\n+                return outstandingTransmits.get();\n+            }\n+        });\n+\n+        outstandingTransmits = new AtomicInteger(0);\n+        this.fullyQualifiedLogSegment = streamName + \":\" + logSegmentName;\n+        this.streamName = streamName;\n+        this.logSegmentMetadataVersion = logSegmentMetadataVersion;\n+        this.entryWriter = entryWriter;\n+        this.lock = lock;\n+        this.lock.checkOwnershipAndReacquire();\n+\n+        final int configuredTransmissionThreshold = dynConf.getOutputBufferSize();\n+        if (configuredTransmissionThreshold > MAX_LOGRECORDSET_SIZE) {\n+            LOG.warn(\"Setting output buffer size {} greater than max transmission size {} for log segment {}\",\n+                new Object[] {configuredTransmissionThreshold, MAX_LOGRECORDSET_SIZE, fullyQualifiedLogSegment});\n+            this.transmissionThreshold = MAX_LOGRECORDSET_SIZE;\n+        } else {\n+            this.transmissionThreshold = configuredTransmissionThreshold;\n+        }\n+        this.compressionType = CompressionUtils.stringToType(conf.getCompressionType());\n+\n+        this.logSegmentSequenceNumber = logSegmentSequenceNumber;\n+        this.recordSetWriter = Entry.newEntry(\n+                streamName,\n+                Math.max(transmissionThreshold, 1024),\n+                envelopeBeforeTransmit(),\n+                compressionType,\n+                envelopeStatsLogger);\n+        this.packetPrevious = null;\n+        this.startTxId = startTxId;\n+        this.lastTxId = startTxId;\n+        this.lastTxIdAcknowledged = startTxId;\n+        this.enableRecordCounts = conf.getEnableRecordCounts();\n+        this.immediateFlushEnabled = conf.getImmediateFlushEnabled();\n+        this.isDurableWriteEnabled = dynConf.isDurableWriteEnabled();\n+        this.scheduler = scheduler;\n+\n+        // Failure injection\n+        if (conf.getEIInjectWriteDelay()) {\n+            this.writeDelayInjector = new RandomDelayFailureInjector(dynConf);\n+        } else {\n+            this.writeDelayInjector = FailureInjector.NULL;\n+        }\n+\n+        // If we are transmitting immediately (threshold == 0) and if immediate\n+        // flush is enabled, we don't need the periodic flush task\n+        final int configuredPeriodicFlushFrequency = dynConf.getPeriodicFlushFrequencyMilliSeconds();\n+        if (!immediateFlushEnabled || (0 != this.transmissionThreshold)) {\n+            int periodicFlushFrequency = configuredPeriodicFlushFrequency;\n+            if (periodicFlushFrequency > 0 && scheduler != null) {\n+                periodicFlushSchedule = scheduler.scheduleAtFixedRate(this,\n+                        periodicFlushFrequency/2, periodicFlushFrequency/2, TimeUnit.MILLISECONDS);\n+            }\n+        } else {\n+            // Min delay heuristic applies only when immediate flush is enabled\n+            // and transmission threshold is zero\n+            minDelayBetweenImmediateFlushMs = conf.getMinDelayBetweenImmediateFlushMs();\n+        }\n+\n+        this.conf = conf;\n+        if (null != scheduler) {\n+            this.addCompleteFuturePool = new SafeQueueingFuturePool<Void>(scheduler.getFuturePool(streamName));\n+        } else {\n+            this.addCompleteFuturePool = null;\n+        }\n+        assert(!this.immediateFlushEnabled || (null != this.scheduler));\n+        this.lastTransmit = Stopwatch.createStarted();\n+    }\n+\n+    String getFullyQualifiedLogSegment() {\n+        return fullyQualifiedLogSegment;\n+    }\n+\n+    @VisibleForTesting\n+    DistributedLock getLock() {\n+        return this.lock;\n+    }\n+\n+    @VisibleForTesting\n+    FuturePool getFuturePool() {\n+        if (null == scheduler) {\n+            return null;\n+        }\n+        return scheduler.getFuturePool(streamName);\n+    }\n+\n+    @VisibleForTesting\n+    void setTransmitResult(int rc) {\n+        transmitResult.set(rc);\n+    }\n+\n+    @VisibleForTesting\n+    protected final LogSegmentEntryWriter getEntryWriter() {\n+        return this.entryWriter;\n+    }\n+\n+    @Override\n+    public long getLogSegmentId() {\n+        return this.entryWriter.getLogSegmentId();\n+    }\n+\n+    protected final long getLogSegmentSequenceNumber() {\n+        return logSegmentSequenceNumber;\n+    }\n+\n+    /**\n+     * Get the start tx id of the log segment.\n+     *\n+     * @return start tx id of the log segment.\n+     */\n+    protected final long getStartTxId() {\n+        return startTxId;\n+    }\n+\n+    /**\n+     * Get the last tx id that has been written to the log segment buffer but not committed yet.\n+     *\n+     * @return last tx id that has been written to the log segment buffer but not committed yet.\n+     * @see #getLastTxIdAcknowledged()\n+     */\n+    synchronized long getLastTxId() {\n+        return lastTxId;\n+    }\n+\n+    /**\n+     * Get the last tx id that has been acknowledged.\n+     *\n+     * @return last tx id that has been acknowledged.\n+     * @see #getLastTxId()\n+     */\n+    synchronized long getLastTxIdAcknowledged() {\n+        return lastTxIdAcknowledged;\n+    }\n+\n+    /**\n+     * Get the position-within-logsemgnet of the last written log record.\n+     *\n+     * @return position-within-logsegment of the last written log record.\n+     */\n+    int getPositionWithinLogSegment() {\n+        return positionWithinLogSegment;\n+    }\n+\n+    @VisibleForTesting\n+    long getLastEntryId() {\n+        return lastEntryId;\n+    }\n+\n+    /**\n+     * Get the last dlsn of the last acknowledged record.\n+     *\n+     * @return last dlsn of the last acknowledged record.\n+     */\n+    synchronized DLSN getLastDLSN() {\n+        return lastDLSN;\n+    }\n+\n+    @Override\n+    public long size() {\n+        return entryWriter.size();\n+    }\n+\n+    private synchronized int getAverageTransmitSize() {\n+        if (numFlushesSinceRestart > 0) {\n+            long ret = numBytes/numFlushesSinceRestart;\n+\n+            if (ret < Integer.MIN_VALUE || ret > Integer.MAX_VALUE) {\n+                throw new IllegalArgumentException\n+                    (ret + \" transmit size should never exceed max transmit size\");\n+            }\n+            return (int) ret;\n+        }\n+\n+        return 0;\n+    }\n+\n+    private Entry.Writer newRecordSetWriter() {\n+        return Entry.newEntry(\n+                streamName,\n+                Math.max(transmissionThreshold, getAverageTransmitSize()),\n+                envelopeBeforeTransmit(),\n+                compressionType,\n+                envelopeStatsLogger);\n+    }\n+\n+    private boolean envelopeBeforeTransmit() {\n+        return LogSegmentMetadata.supportsEnvelopedEntries(logSegmentMetadataVersion);\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        return closeInternal(false);\n+    }\n+\n+    @Override\n+    public Future<Void> asyncAbort() {\n+        return closeInternal(true);\n+    }\n+\n+    private void flushAddCompletes() {\n+        if (null != addCompleteFuturePool) {\n+            addCompleteFuturePool.close();\n+        }\n+    }\n+\n+    private synchronized void abortPacket(BKTransmitPacket packet) {\n+        long numRecords = 0;\n+        if (null != packet) {\n+            EntryBuffer recordSet = packet.getRecordSet();\n+            numRecords = recordSet.getNumRecords();\n+            int rc = transmitResult.get();\n+            if (BKException.Code.OK == rc) {\n+                rc = BKException.Code.InterruptedException;\n+            }\n+            Throwable reason = new WriteCancelledException(streamName, FutureUtils.transmitException(rc));\n+            recordSet.abortTransmit(reason);\n+        }\n+        LOG.info(\"Stream {} aborted {} writes\", fullyQualifiedLogSegment, numRecords);\n+    }\n+\n+    private synchronized long getWritesPendingTransmit() {\n+        if (null != recordSetWriter) {\n+            return recordSetWriter.getNumRecords();\n+        } else {\n+            return 0;\n+        }\n+    }\n+\n+    private synchronized long getPendingAddCompleteCount() {\n+        if (null != addCompleteFuturePool) {\n+            return addCompleteFuturePool.size();\n+        } else {\n+            return 0;\n+        }\n+    }\n+\n+    private Future<Void> closeInternal(boolean abort) {\n+        Promise<Void> closePromise;\n+        synchronized (this) {\n+            if (null != closeFuture) {\n+                return closeFuture;\n+            }\n+            closePromise = closeFuture = new Promise<Void>();\n+        }\n+\n+        AtomicReference<Throwable> throwExc = new AtomicReference<Throwable>(null);\n+        closeInternal(abort, throwExc, closePromise);\n+        return closePromise;\n+    }\n+\n+    private void closeInternal(final boolean abort,\n+                               final AtomicReference<Throwable> throwExc,\n+                               final Promise<Void> closePromise) {\n+        // Cancel the periodic flush schedule first\n+        // The task is allowed to exit gracefully\n+        if (null != periodicFlushSchedule) {\n+            // we don't need to care about the cancel result here. if the periodicl flush task couldn't\n+            // be cancelled, it means that it is doing flushing. So following flushes would be synchronized\n+            // to wait until background flush completed.\n+            if (!periodicFlushSchedule.cancel(false)) {\n+                LOG.info(\"Periodic flush for log segment {} isn't cancelled.\", getFullyQualifiedLogSegment());\n+            }\n+        }\n+\n+        // If it is a normal close and the stream isn't in an error state, we attempt to flush any buffered data\n+        if (!abort && !isLogSegmentInError()) {\n+            this.enforceLock = false;\n+            LOG.info(\"Flushing before closing log segment {}\", getFullyQualifiedLogSegment());\n+            flushAndCommit().addEventListener(new FutureEventListener<Long>() {\n+                @Override\n+                public void onSuccess(Long value) {\n+                    abortTransmitPacketOnClose(abort, throwExc, closePromise);\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause) {\n+                    throwExc.set(cause);\n+                    abortTransmitPacketOnClose(abort, throwExc, closePromise);\n+                }\n+            });\n+        } else {\n+            abortTransmitPacketOnClose(abort, throwExc, closePromise);\n+        }\n+\n+    }\n+\n+    private void abortTransmitPacketOnClose(final boolean abort,\n+                                            final AtomicReference<Throwable> throwExc,\n+                                            final Promise<Void> closePromise) {\n+        LOG.info(\"Closing BKPerStreamLogWriter (abort={}) for {} :\" +\n+                        \" lastDLSN = {} outstandingTransmits = {} writesPendingTransmit = {} addCompletesPending = {}\",\n+                new Object[]{abort, fullyQualifiedLogSegment, getLastDLSN(),\n+                        outstandingTransmits.get(), getWritesPendingTransmit(), getPendingAddCompleteCount()});\n+\n+        // Save the current packet to reset, leave a new empty packet to avoid a race with\n+        // addCompleteDeferredProcessing.\n+        final BKTransmitPacket packetPreviousSaved;\n+        final BKTransmitPacket packetCurrentSaved;\n+        synchronized (this) {\n+            packetPreviousSaved = packetPrevious;\n+            packetCurrentSaved = new BKTransmitPacket(recordSetWriter);\n+            recordSetWriter = newRecordSetWriter();\n+        }\n+\n+        // Once the last packet been transmitted, apply any remaining promises asynchronously\n+        // to avoid blocking close if bk client is slow for some reason.\n+        if (null != packetPreviousSaved) {\n+            packetPreviousSaved.addTransmitCompleteListener(new FutureEventListener<Integer>() {\n+                @Override\n+                public void onSuccess(Integer transmitResult) {\n+                    flushAddCompletes();\n+                    abortPacket(packetCurrentSaved);\n+                }\n+                @Override\n+                public void onFailure(Throwable cause) {\n+                    LOG.error(\"Unexpected error on transmit completion \", cause);\n+                }\n+            });\n+        } else {\n+            // In this case there are no pending add completes, but we still need to abort the\n+            // current packet.\n+            abortPacket(packetCurrentSaved);\n+        }\n+        closeLedgerOnClose(abort, throwExc, closePromise);\n+    }\n+\n+    private void closeLedgerOnClose(final boolean abort,\n+                                    final AtomicReference<Throwable> throwExc,\n+                                    final Promise<Void> closePromise) {\n+        // close the log segment if it isn't in error state, so all the outstanding addEntry(s) will callback.\n+        if (null == throwExc.get() && !isLogSegmentInError()) {\n+            // Synchronous closing the ledger handle, if we couldn't close a ledger handle successfully.\n+            // we should throw the exception to #closeToFinalize, so it would fail completing a log segment.\n+            entryWriter.asyncClose(new CloseCallback() {\n+                @Override\n+                public void closeComplete(int rc, LedgerHandle lh, Object ctx) {\n+                    if (BKException.Code.OK != rc && BKException.Code.LedgerClosedException != rc) {\n+                        if (!abort) {\n+                            throwExc.set(new IOException(\"Failed to close ledger for \" + fullyQualifiedLogSegment + \" : \" +\n+                                    BKException.getMessage(rc)));\n+                        }\n+                    }\n+                    completeClosePromise(abort, throwExc, closePromise);\n+                }\n+            }, null);\n+        } else {\n+            completeClosePromise(abort, throwExc, closePromise);\n+        }\n+    }\n+\n+    private void completeClosePromise(final boolean abort,\n+                                      final AtomicReference<Throwable> throwExc,\n+                                      final Promise<Void> closePromise) {\n+        // If add entry failed because of closing ledger above, we don't need to fail the close operation\n+        if (!abort && null == throwExc.get() && shouldFailCompleteLogSegment()) {\n+            throwExc.set(new BKTransmitException(\"Closing an errored stream : \", transmitResult.get()));\n+        }\n+\n+        if (null == throwExc.get()) {\n+            FutureUtils.setValue(closePromise, null);\n+        } else {\n+            FutureUtils.setException(closePromise, throwExc.get());\n+        }\n+    }\n+\n+    @Override\n+    synchronized public void write(LogRecord record) throws IOException {\n+        writeUserRecord(record);\n+        flushIfNeeded();\n+    }\n+\n+    @Override\n+    synchronized public Future<DLSN> asyncWrite(LogRecord record) {\n+        return asyncWrite(record, true);\n+    }\n+\n+    synchronized public Future<DLSN> asyncWrite(LogRecord record, boolean flush) {\n+        Future<DLSN> result = null;\n+        try {\n+            if (record.isControl()) {\n+                // we don't pack control records with user records together\n+                // so transmit current output buffer if possible\n+                try {\n+                    transmit();\n+                } catch (IOException ioe) {\n+                    return Future.exception(new WriteCancelledException(fullyQualifiedLogSegment, ioe));\n+                }\n+                result = writeControlLogRecord(record);\n+                transmit();\n+            } else {\n+                result = writeUserRecord(record);\n+                if (!isDurableWriteEnabled) {\n+                    // we have no idea about the DLSN if durability is turned off.\n+                    result = Future.value(DLSN.InvalidDLSN);\n+                }\n+                if (flush) {\n+                    flushIfNeeded();\n+                }\n+            }\n+        } catch (IOException ioe) {\n+            // We may incorrectly report transmit failure here, but only if we happened to hit\n+            // packet/xmit size limit conditions AND fail flush above, which should happen rarely\n+            if (null != result) {\n+                LOG.error(\"Overriding first result with flush failure {}\", result);\n+            }\n+            result = Future.exception(ioe);\n+\n+            // Flush to ensure any prev. writes with flush=false are flushed despite failure.\n+            flushIfNeededNoThrow();\n+        }\n+        return result;\n+    }\n+\n+    synchronized private Future<DLSN> writeUserRecord(LogRecord record) throws IOException {\n+        if (null != closeFuture) {\n+            throw new WriteException(fullyQualifiedLogSegment, BKException.getMessage(BKException.Code.LedgerClosedException));\n+        }\n+\n+        if (BKException.Code.OK != transmitResult.get()) {\n+            // Failfast if the stream already encountered error with safe retry on the client\n+            throw new WriteException(fullyQualifiedLogSegment, BKException.getMessage(transmitResult.get()));\n+        }\n+\n+        if (streamEnded) {\n+            throw new EndOfStreamException(\"Writing to a stream after it has been marked as completed\");\n+        }\n+\n+        if ((record.getTransactionId() < 0) ||\n+            (record.getTransactionId() == DistributedLogConstants.MAX_TXID)) {\n+            throw new TransactionIdOutOfOrderException(record.getTransactionId());\n+        }\n+\n+        // Inject write delay if configured to do so\n+        writeDelayInjector.inject();\n+\n+        // Will check write rate limits and throw if exceeded.\n+        writeLimiter.acquire();\n+        pendingWrites.inc();\n+\n+        // The count represents the number of user records up to the\n+        // current record\n+        // Increment the record count only when writing a user log record\n+        // Internally generated log records don't increment the count\n+        // writeInternal will always set a count regardless of whether it was\n+        // incremented or not.\n+        Future<DLSN> future = null;\n+        try {\n+            // increment the position for the record to write\n+            // if the record is failed to write, it would be decremented.\n+            positionWithinLogSegment++;\n+            int numRecords = 1;\n+            if (record.isRecordSet()) {\n+                numRecords = LogRecordSet.numRecords(record);\n+            }\n+            future = writeInternal(record);\n+            // after the record (record set) is written, the position should be\n+            // moved for {numRecords}, but since we already moved the record by 1\n+            // so advance the position for other {numRecords - 1}.\n+            positionWithinLogSegment += (numRecords - 1);\n+        } catch (IOException ex) {\n+            writeLimiter.release();\n+            pendingWrites.dec();\n+            positionWithinLogSegment--;\n+            throw ex;\n+        }\n+\n+        // Track outstanding requests and return the future.\n+        return future.ensure(new Function0<BoxedUnit>() {\n+            public BoxedUnit apply() {\n+                pendingWrites.dec();\n+                writeLimiter.release();\n+                return null;\n+            }\n+        });\n+    }\n+\n+    boolean isLogSegmentInError() {\n+        return (transmitResult.get() != BKException.Code.OK);\n+    }\n+\n+    boolean shouldFailCompleteLogSegment() {\n+        return (transmitResult.get() != BKException.Code.OK) &&\n+                (transmitResult.get() != BKException.Code.LedgerClosedException);\n+    }\n+\n+    synchronized public Future<DLSN> writeInternal(LogRecord record)\n+            throws LogRecordTooLongException, LockingException, BKTransmitException,\n+                   WriteException, InvalidEnvelopedEntryException {\n+        int logRecordSize = record.getPersistentSize();\n+\n+        if (logRecordSize > MAX_LOGRECORD_SIZE) {\n+            throw new LogRecordTooLongException(String.format(\n+                    \"Log Record of size %d written when only %d is allowed\",\n+                    logRecordSize, MAX_LOGRECORD_SIZE));\n+        }\n+\n+        // If we will exceed the max number of bytes allowed per entry\n+        // initiate a transmit before accepting the new log record\n+        if ((recordSetWriter.getNumBytes() + logRecordSize) > MAX_LOGRECORDSET_SIZE) {\n+            checkStateAndTransmit();\n+        }\n+\n+        checkWriteLock();\n+\n+        if (enableRecordCounts) {\n+            // Set the count here. The caller would appropriately increment it\n+            // if this log record is to be counted\n+            record.setPositionWithinLogSegment(positionWithinLogSegment);\n+        }\n+\n+        Promise<DLSN> writePromise = new Promise<DLSN>();\n+        writePromise.addEventListener(new OpStatsListener<DLSN>(writeTime));\n+        recordSetWriter.writeRecord(record, writePromise);\n+\n+        if (record.getTransactionId() < lastTxId) {\n+            LOG.info(\"Log Segment {} TxId decreased Last: {} Record: {}\",\n+                    new Object[] {fullyQualifiedLogSegment, lastTxId, record.getTransactionId()});\n+        }\n+        if (!record.isControl()) {\n+            // only update last tx id for user records\n+            lastTxId = record.getTransactionId();\n+            outstandingBytes += (20 + record.getPayload().length);\n+        }\n+        return writePromise;\n+    }\n+\n+    synchronized private Future<DLSN> writeControlLogRecord()\n+            throws BKTransmitException, WriteException, InvalidEnvelopedEntryException,\n+                   LockingException, LogRecordTooLongException {\n+        LogRecord controlRec = new LogRecord(lastTxId, DistributedLogConstants.CONTROL_RECORD_CONTENT);\n+        controlRec.setControl();\n+        return writeControlLogRecord(controlRec);\n+    }\n+\n+    synchronized private Future<DLSN> writeControlLogRecord(LogRecord record)\n+            throws BKTransmitException, WriteException, InvalidEnvelopedEntryException,\n+                   LockingException, LogRecordTooLongException {\n+        return writeInternal(record);\n+    }\n+\n+    /**\n+     * We write a special log record that marks the end of the stream. Since this is the last\n+     * log record in the stream, it is marked with MAX_TXID. MAX_TXID also has the useful\n+     * side-effect of disallowing future startLogSegment calls through the MaxTxID check\n+     *\n+     * @throws IOException\n+     */\n+    synchronized private void writeEndOfStreamMarker() throws IOException {\n+        LogRecord endOfStreamRec = new LogRecord(DistributedLogConstants.MAX_TXID, \"endOfStream\".getBytes(UTF_8));\n+        endOfStreamRec.setEndOfStream();\n+        writeInternal(endOfStreamRec);\n+    }\n+\n+    /**\n+     * Flushes all the data up to this point,\n+     * adds the end of stream marker and marks the stream\n+     * as read-only in the metadata. No appends to the\n+     * stream will be allowed after this point\n+     */\n+    public Future<Long> markEndOfStream() {\n+        synchronized (this) {\n+            try {\n+                writeEndOfStreamMarker();\n+            } catch (IOException e) {\n+                return Future.exception(e);\n+            }\n+            streamEnded = true;\n+        }\n+        return flushAndCommit();\n+    }\n+\n+    /**\n+     * Write bulk of records.\n+     *\n+     * (TODO: moved this method to log writer level)\n+     *\n+     * @param records list of records to write\n+     * @return number of records that has been written\n+     * @throws IOException when there is I/O errors during writing records.\n+     */\n+    synchronized public int writeBulk(List<LogRecord> records) throws IOException {\n+        int numRecords = 0;\n+        for (LogRecord r : records) {\n+            write(r);\n+            numRecords++;\n+        }\n+        return numRecords;\n+    }\n+\n+    private void checkStateBeforeTransmit() throws WriteException {\n+        try {\n+            FailpointUtils.checkFailPoint(FailpointUtils.FailPointName.FP_TransmitBeforeAddEntry);\n+        } catch (IOException e) {\n+            throw new WriteException(streamName, \"Fail transmit before adding entries\");\n+        }\n+    }\n+\n+    /**\n+     * Transmit the output buffer data to the backend.\n+     *\n+     * @return last txn id that already acknowledged\n+     * @throws BKTransmitException if the segment writer is already in error state\n+     * @throws LockingException if the segment writer lost lock before transmit\n+     * @throws WriteException if failed to create the envelope for the data to transmit\n+     * @throws InvalidEnvelopedEntryException when built an invalid enveloped entry\n+     */\n+    synchronized void checkStateAndTransmit()\n+            throws BKTransmitException, WriteException, InvalidEnvelopedEntryException, LockingException {\n+        checkStateBeforeTransmit();\n+        transmit();\n+    }\n+\n+    @Override\n+    public synchronized Future<Long> flush() {\n+        try {\n+            checkStateBeforeTransmit();\n+        } catch (WriteException e) {\n+            return Future.exception(e);\n+        }\n+\n+        Future<Integer> transmitFuture;\n+        try {\n+            transmitFuture = transmit();\n+        } catch (BKTransmitException e) {\n+            return Future.exception(e);\n+        } catch (LockingException e) {\n+            return Future.exception(e);\n+        } catch (WriteException e) {\n+            return Future.exception(e);\n+        } catch (InvalidEnvelopedEntryException e) {\n+            return Future.exception(e);\n+        }\n+\n+        if (null == transmitFuture) {\n+            if (null != packetPrevious) {\n+                transmitFuture = packetPrevious.getTransmitFuture();\n+            }  else {\n+                return Future.value(getLastTxIdAcknowledged());\n+            }\n+        }\n+\n+        return transmitFuture.flatMap(GET_LAST_TXID_ACKNOWLEDGED_AFTER_TRANSMIT_FUNC);\n+    }\n+\n+    @Override\n+    public synchronized Future<Long> commit() {\n+        // we don't pack control records with user records together\n+        // so transmit current output buffer if possible\n+        Future<Integer> transmitFuture;\n+        try {\n+            try {\n+                transmitFuture = transmit();\n+            } catch (IOException ioe) {\n+                return Future.exception(ioe);\n+            }\n+            if (null == transmitFuture) {\n+                writeControlLogRecord();\n+                return flush();\n+            }\n+        } catch (IOException ioe) {\n+            return Future.exception(ioe);\n+        }\n+        return transmitFuture.flatMap(GET_LAST_TXID_ACKNOWLEDGED_AFTER_TRANSMIT_FUNC);\n+    }\n+\n+    Future<Long> flushAndCommit() {\n+        return flush().flatMap(COMMIT_AFTER_FLUSH_FUNC);\n+    }\n+\n+    void flushIfNeededNoThrow() {\n+        try {\n+            flushIfNeeded();\n+        } catch (IOException ioe) {\n+            LOG.error(\"Encountered exception while flushing log records to stream {}\",\n+                fullyQualifiedLogSegment, ioe);\n+        }\n+    }\n+\n+    void scheduleFlushWithDelayIfNeeded(final Callable<?> callable,\n+                                        final AtomicReference<ScheduledFuture<?>> scheduledFutureRef) {\n+        final long delayMs = Math.max(0, minDelayBetweenImmediateFlushMs - lastTransmit.elapsed(TimeUnit.MILLISECONDS));\n+        final ScheduledFuture<?> scheduledFuture = scheduledFutureRef.get();\n+        if ((null == scheduledFuture) || scheduledFuture.isDone()) {\n+            scheduledFutureRef.set(scheduler.schedule(new Runnable() {\n+                @Override\n+                public void run() {\n+                    synchronized(this) {\n+                        scheduledFutureRef.set(null);\n+                        try {\n+                            callable.call();\n+\n+                            // Flush was successful or wasn't needed, the exception should be unset.\n+                            scheduledFlushException.set(null);\n+                        } catch (Exception exc) {\n+                            scheduledFlushException.set(exc);\n+                            LOG.error(\"Delayed flush failed\", exc);\n+                        }\n+                    }\n+                }\n+            }, delayMs, TimeUnit.MILLISECONDS));\n+        }\n+    }\n+\n+    // Based on transmit buffer size, immediate flush, etc., should we flush the current\n+    // packet now.\n+    void flushIfNeeded() throws BKTransmitException, WriteException, InvalidEnvelopedEntryException,\n+            LockingException, FlushException {\n+        if (outstandingBytes > transmissionThreshold) {\n+            // If flush delay is disabled, flush immediately, else schedule appropriately.\n+            if (0 == minDelayBetweenImmediateFlushMs) {\n+                checkStateAndTransmit();\n+            } else {\n+                scheduleFlushWithDelayIfNeeded(new Callable<Void>() {\n+                    @Override\n+                    public Void call() throws Exception {\n+                        checkStateAndTransmit();\n+                        return null;\n+                    }\n+                }, transmitSchedFutureRef);\n+\n+                // Timing here is not very important--the last flush failed and we should\n+                // indicate this to the caller. The next flush may succeed and unset the\n+                // scheduledFlushException in which case the next write will succeed (if the caller\n+                // hasn't already closed the writer).\n+                if (scheduledFlushException.get() != null) {\n+                    throw new FlushException(\"Last flush encountered an error while writing data to the backend\",\n+                        getLastTxId(), getLastTxIdAcknowledged(), scheduledFlushException.get());\n+                }\n+            }\n+        }\n+    }\n+\n+    private void checkWriteLock() throws LockingException {\n+        try {\n+            if (FailpointUtils.checkFailPoint(FailpointUtils.FailPointName.FP_WriteInternalLostLock)) {\n+                throw new LockingException(\"/failpoint/lockpath\", \"failpoint is simulating a lost lock\"\n+                        + getFullyQualifiedLogSegment());\n+            }\n+        } catch (IOException e) {\n+            throw new LockingException(\"/failpoint/lockpath\", \"failpoint is simulating a lost lock for \"\n+                    + getFullyQualifiedLogSegment());\n+        }\n+        if (enforceLock) {\n+            lock.checkOwnershipAndReacquire();\n+        }\n+    }\n+\n+    /**\n+     * Transmit the current buffer to bookkeeper.\n+     * Synchronised at the class. #write() and #setReadyToFlush()\n+     * are never called at the same time.\n+     *\n+     * NOTE: This method should only throw known exceptions so that we don't accidentally\n+     *       add new code that throws in an inappropriate place.\n+     *\n+     * @return a transmit future for caller to wait for transmit result if we transmit successfully,\n+     *         null if no data to transmit\n+     * @throws BKTransmitException if the segment writer is already in error state\n+     * @throws LockingException if the segment writer lost lock before transmit\n+     * @throws WriteException if failed to create the envelope for the data to transmit\n+     * @throws InvalidEnvelopedEntryException when built an invalid enveloped entry\n+     */\n+    private Future<Integer> transmit()\n+        throws BKTransmitException, LockingException, WriteException, InvalidEnvelopedEntryException {\n+        EntryBuffer recordSetToTransmit;\n+        transmitLock.lock();\n+        try {\n+            synchronized (this) {\n+                checkWriteLock();\n+                // If transmitResult is anything other than BKException.Code.OK, it means that the\n+                // stream has encountered an error and cannot be written to.\n+                if (!transmitResult.compareAndSet(BKException.Code.OK,\n+                                                  BKException.Code.OK)) {\n+                    LOG.error(\"Log Segment {} Trying to write to an errored stream; Error is {}\",\n+                              fullyQualifiedLogSegment,\n+                              BKException.getMessage(transmitResult.get()));\n+                    throw new BKTransmitException(\"Trying to write to an errored stream;\"\n+                                                          + \" Error code : (\" + transmitResult.get()\n+                                                          + \") \" + BKException.getMessage(transmitResult.get()), transmitResult.get());\n+                }\n+\n+                if (recordSetWriter.getNumRecords() == 0) {\n+                    // Control flushes always have at least the control record to flush\n+                    transmitDataMisses.inc();\n+                    return null;\n+                }\n+\n+                recordSetToTransmit = recordSetWriter;\n+                recordSetWriter = newRecordSetWriter();\n+                outstandingBytes = 0;\n+\n+                if (recordSetToTransmit.hasUserRecords()) {\n+                    numBytes += recordSetToTransmit.getNumBytes();\n+                    numFlushesSinceRestart++;\n+                }\n+            }\n+\n+            Buffer toSend;\n+            try {\n+                toSend = recordSetToTransmit.getBuffer();\n+                FailpointUtils.checkFailPoint(FailpointUtils.FailPointName.FP_TransmitFailGetBuffer);\n+            } catch (IOException e) {\n+                if (e instanceof InvalidEnvelopedEntryException) {\n+                    alertStatsLogger.raise(\"Invalid enveloped entry for segment {} : \", fullyQualifiedLogSegment, e);\n+                }\n+                LOG.error(\"Exception while enveloping entries for segment: {}\",\n+                          new Object[] {fullyQualifiedLogSegment}, e);\n+                // If a write fails here, we need to set the transmit result to an error so that\n+                // no future writes go through and violate ordering guarantees.\n+                transmitResult.set(BKException.Code.WriteException);\n+                if (e instanceof InvalidEnvelopedEntryException) {\n+                    alertStatsLogger.raise(\"Invalid enveloped entry for segment {} : \", fullyQualifiedLogSegment, e);\n+                    throw (InvalidEnvelopedEntryException) e;\n+                } else {\n+                    throw new WriteException(streamName, \"Envelope Error\");\n+                }\n+            }\n+\n+            synchronized (this) {\n+                BKTransmitPacket packet = new BKTransmitPacket(recordSetToTransmit);\n+                packetPrevious = packet;\n+                entryWriter.asyncAddEntry(toSend.getData(), 0, toSend.size(),\n+                                          this, packet);\n+\n+                if (recordSetToTransmit.hasUserRecords()) {\n+                    transmitDataSuccesses.inc();\n+                } else {\n+                    transmitControlSuccesses.inc();\n+                }\n+\n+                lastTransmit.reset().start();\n+                outstandingTransmits.incrementAndGet();\n+                controlFlushNeeded = false;\n+                return packet.getTransmitFuture();\n+            }\n+        } finally {\n+            transmitLock.unlock();\n+        }\n+    }\n+\n+    /**\n+     *  Checks if there is any data to transmit so that the periodic flush\n+     *  task can determine if there is anything it needs to do\n+     */\n+    synchronized private boolean haveDataToTransmit() {\n+        if (!transmitResult.compareAndSet(BKException.Code.OK, BKException.Code.OK)) {\n+            // Even if there is data it cannot be transmitted, so effectively nothing to send\n+            return false;\n+        }\n+\n+        return (recordSetWriter.getNumRecords() > 0);\n+    }\n+\n+    @Override\n+    public void addComplete(final int rc, LedgerHandle handle,\n+                            final long entryId, final Object ctx) {\n+        final AtomicReference<Integer> effectiveRC = new AtomicReference<Integer>(rc);\n+        try {\n+            if (FailpointUtils.checkFailPoint(FailpointUtils.FailPointName.FP_TransmitComplete)) {\n+                effectiveRC.set(BKException.Code.UnexpectedConditionException);\n+            }\n+        } catch (Exception exc) {\n+            effectiveRC.set(BKException.Code.UnexpectedConditionException);\n+        }\n+\n+        // Sanity check to make sure we're receiving these callbacks in order.\n+        if (entryId > -1 && lastEntryId >= entryId) {\n+            LOG.error(\"Log segment {} saw out of order entry {} lastEntryId {}\",\n+                new Object[] {fullyQualifiedLogSegment, entryId, lastEntryId});\n+        }\n+        lastEntryId = entryId;\n+\n+        assert (ctx instanceof BKTransmitPacket);\n+        final BKTransmitPacket transmitPacket = (BKTransmitPacket) ctx;\n+\n+        // Time from transmit until receipt of addComplete callback\n+        addCompleteTime.registerSuccessfulEvent(TimeUnit.MICROSECONDS.convert(\n+            System.nanoTime() - transmitPacket.getTransmitTime(), TimeUnit.NANOSECONDS));\n+\n+        if (BKException.Code.OK == rc) {\n+            EntryBuffer recordSet = transmitPacket.getRecordSet();\n+            if (recordSet.hasUserRecords()) {\n+                synchronized (this) {\n+                    lastTxIdAcknowledged = Math.max(lastTxIdAcknowledged, recordSet.getMaxTxId());\n+                }\n+            }\n+        }\n+\n+        if (null != addCompleteFuturePool) {\n+            final Stopwatch queuedTime = Stopwatch.createStarted();\n+            addCompleteFuturePool.apply(new Function0<Void>() {\n+                public Void apply() {\n+                    final Stopwatch deferredTime = Stopwatch.createStarted();\n+                    addCompleteQueuedTime.registerSuccessfulEvent(queuedTime.elapsed(TimeUnit.MICROSECONDS));\n+                    addCompleteDeferredProcessing(transmitPacket, entryId, effectiveRC.get());\n+                    addCompleteDeferredTime.registerSuccessfulEvent(deferredTime.elapsed(TimeUnit.MICROSECONDS));\n+                    return null;\n+                }\n+                @Override\n+                public String toString() {\n+                    return String.format(\"AddComplete(Stream=%s, entryId=%d, rc=%d)\",\n+                            fullyQualifiedLogSegment, entryId, rc);\n+                }\n+            }).addEventListener(new FutureEventListener<Void>() {\n+                @Override\n+                public void onSuccess(Void done) {\n+                }\n+                @Override\n+                public void onFailure(Throwable cause) {\n+                    LOG.error(\"addComplete processing failed for {} entry {} lastTxId {} rc {} with error\",\n+                        new Object[] {fullyQualifiedLogSegment, entryId, transmitPacket.getRecordSet().getMaxTxId(), rc, cause});\n+                }\n+            });\n+            // Race condition if we notify before the addComplete is enqueued.\n+            transmitPacket.notifyTransmitComplete(effectiveRC.get());\n+            outstandingTransmits.getAndDecrement();\n+        } else {\n+            // Notify transmit complete must be called before deferred processing in the\n+            // sync case since otherwise callbacks in deferred processing may deadlock.\n+            transmitPacket.notifyTransmitComplete(effectiveRC.get());\n+            outstandingTransmits.getAndDecrement();\n+            addCompleteDeferredProcessing(transmitPacket, entryId, effectiveRC.get());\n+        }\n+    }\n+\n+    private void addCompleteDeferredProcessing(final BKTransmitPacket transmitPacket,\n+                                               final long entryId,\n+                                               final int rc) {\n+        boolean cancelPendingPromises = false;\n+        EntryBuffer recordSet = transmitPacket.getRecordSet();\n+        synchronized (this) {\n+            if (transmitResult.compareAndSet(BKException.Code.OK, rc)) {\n+                // If this is the first time we are setting an error code in the transmitResult then\n+                // we must cancel pending promises; once this error has been set, more records will not\n+                // be enqueued; they will be failed with WriteException\n+                cancelPendingPromises = (BKException.Code.OK != rc);\n+            } else {\n+                LOG.warn(\"Log segment {} entryId {}: Tried to set transmit result to ({}) but is already ({})\",\n+                    new Object[] {fullyQualifiedLogSegment, entryId, rc, transmitResult.get()});\n+            }\n+\n+            if (transmitResult.get() != BKException.Code.OK) {\n+                if (recordSet.hasUserRecords()) {\n+                    transmitDataPacketSize.registerFailedEvent(recordSet.getNumBytes());\n+                }\n+            } else {\n+                // If we had data that we flushed then we need it to make sure that\n+                // background flush in the next pass will make the previous writes\n+                // visible by advancing the lastAck\n+                if (recordSet.hasUserRecords()) {\n+                    transmitDataPacketSize.registerSuccessfulEvent(recordSet.getNumBytes());\n+                    controlFlushNeeded = true;\n+                    if (immediateFlushEnabled) {\n+                        if (0 == minDelayBetweenImmediateFlushMs) {\n+                            backgroundFlush(true);\n+                        } else {\n+                            scheduleFlushWithDelayIfNeeded(new Callable<Void>() {\n+                                @Override\n+                                public Void call() throws Exception {\n+                                    backgroundFlush(true);\n+                                    return null;\n+                                }\n+                            }, immFlushSchedFutureRef);\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // update last dlsn before satisifying future\n+            if (BKException.Code.OK == transmitResult.get()) {\n+                DLSN lastDLSNInPacket = recordSet.finalizeTransmit(\n+                        logSegmentSequenceNumber, entryId);\n+                if (recordSet.hasUserRecords()) {\n+                    if (null != lastDLSNInPacket && lastDLSN.compareTo(lastDLSNInPacket) < 0) {\n+                        lastDLSN = lastDLSNInPacket;\n+                    }\n+                }\n+            }\n+        }\n+\n+        if (BKException.Code.OK == transmitResult.get()) {\n+            recordSet.completeTransmit(logSegmentSequenceNumber, entryId);\n+        } else {\n+            recordSet.abortTransmit(FutureUtils.transmitException(transmitResult.get()));\n+        }\n+\n+        if (cancelPendingPromises) {\n+            // Since the writer is in a bad state no more packets will be tramsitted, and its safe to\n+            // assign a new empty packet. This is to avoid a race with closeInternal which may also\n+            // try to cancel the current packet;\n+            final BKTransmitPacket packetCurrentSaved;\n+            synchronized (this) {\n+                packetCurrentSaved = new BKTransmitPacket(recordSetWriter);\n+                recordSetWriter = newRecordSetWriter();\n+            }\n+            packetCurrentSaved.getRecordSet().abortTransmit(\n+                    new WriteCancelledException(streamName,\n+                            FutureUtils.transmitException(transmitResult.get())));\n+        }\n+    }\n+\n+    @Override\n+    synchronized public void run()  {\n+        backgroundFlush(false);\n+    }\n+\n+    synchronized private void backgroundFlush(boolean controlFlushOnly)  {\n+        if (null != closeFuture) {\n+            // if the log segment is closing, skip any background flushing\n+            LOG.debug(\"Skip background flushing since log segment {} is closing.\", getFullyQualifiedLogSegment());\n+            return;\n+        }\n+        try {\n+            boolean newData = haveDataToTransmit();\n+\n+            if (controlFlushNeeded || (!controlFlushOnly && newData)) {\n+                // If we need this periodic transmit to persist previously written data but\n+                // there is no new data (which would cause the transmit to be skipped) generate\n+                // a control record\n+                if (!newData) {\n+                    writeControlLogRecord();\n+                }\n+\n+                transmit();\n+                pFlushSuccesses.inc();\n+            } else {\n+                pFlushMisses.inc();\n+            }\n+        } catch (IOException exc) {\n+            LOG.error(\"Log Segment {}: Error encountered by the periodic flush\", fullyQualifiedLogSegment, exc);\n+        }\n+    }\n+\n+}"},{"sha":"630d626317be0e2759a623a4156e9de345637458","filename":"src/main/java/com/twitter/distributedlog/BKLogWriteHandler.java","status":"added","additions":1318,"deletions":0,"changes":1318,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,1318 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Stopwatch;\n+import com.google.common.collect.Lists;\n+import com.twitter.distributedlog.bk.LedgerAllocator;\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.EndOfStreamException;\n+import com.twitter.distributedlog.exceptions.LockingException;\n+import com.twitter.distributedlog.exceptions.TransactionIdOutOfOrderException;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.function.GetLastTxIdFunction;\n+import com.twitter.distributedlog.impl.BKLogSegmentEntryWriter;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n+import com.twitter.distributedlog.lock.DistributedLock;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.logsegment.RollingPolicy;\n+import com.twitter.distributedlog.logsegment.SizeBasedRollingPolicy;\n+import com.twitter.distributedlog.logsegment.TimeBasedRollingPolicy;\n+import com.twitter.distributedlog.metadata.MetadataUpdater;\n+import com.twitter.distributedlog.metadata.LogSegmentMetadataStoreUpdater;\n+import com.twitter.distributedlog.util.DLUtils;\n+import com.twitter.distributedlog.util.FailpointUtils;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.FutureUtils.FutureEventListenerRunnable;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.distributedlog.util.Transaction;\n+import com.twitter.distributedlog.util.PermitLimiter;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.distributedlog.zk.ZKOp;\n+import com.twitter.distributedlog.zk.ZKTransaction;\n+import com.twitter.distributedlog.zk.ZKVersionedSetOp;\n+import com.twitter.util.Function;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.client.AsyncCallback;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+import org.apache.bookkeeper.feature.FeatureProvider;\n+import org.apache.bookkeeper.meta.ZkVersion;\n+import org.apache.bookkeeper.stats.AlertStatsLogger;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.versioning.Version;\n+import org.apache.zookeeper.CreateMode;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.Op;\n+import org.apache.zookeeper.OpResult;\n+import org.apache.zookeeper.Watcher;\n+import org.apache.zookeeper.ZKUtil;\n+import org.apache.zookeeper.data.ACL;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.runtime.AbstractFunction1;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+import static com.twitter.distributedlog.impl.ZKLogSegmentFilters.WRITE_HANDLE_FILTER;\n+\n+/**\n+ * Log Handler for Writers.\n+ *\n+ * <h3>Metrics</h3>\n+ * All the metrics about log write handler are exposed under scope `segments`.\n+ * <ul>\n+ * <li> `segments`/open : opstats. latency characteristics on starting a new log segment.\n+ * <li> `segments`/close : opstats. latency characteristics on completing an inprogress log segment.\n+ * <li> `segments`/recover : opstats. latency characteristics on recovering a log segment.\n+ * <li> `segments`/delete : opstats. latency characteristics on deleting a log segment.\n+ * </ul>\n+ */\n+class BKLogWriteHandler extends BKLogHandler {\n+    static final Logger LOG = LoggerFactory.getLogger(BKLogReadHandler.class);\n+\n+    protected final DistributedLock lock;\n+    protected final int ensembleSize;\n+    protected final int writeQuorumSize;\n+    protected final int ackQuorumSize;\n+    protected final LedgerAllocator ledgerAllocator;\n+    protected final MaxTxId maxTxId;\n+    protected final MaxLogSegmentSequenceNo maxLogSegmentSequenceNo;\n+    protected final boolean sanityCheckTxnId;\n+    protected final boolean validateLogSegmentSequenceNumber;\n+    protected final int regionId;\n+    protected volatile boolean closed = false;\n+    protected final RollingPolicy rollingPolicy;\n+    protected Future<DistributedLock> lockFuture = null;\n+    protected final PermitLimiter writeLimiter;\n+    protected final FeatureProvider featureProvider;\n+    protected final DynamicDistributedLogConfiguration dynConf;\n+    protected final MetadataUpdater metadataUpdater;\n+    // tracking the inprogress log segments\n+    protected final LinkedList<Long> inprogressLSSNs;\n+\n+    // Recover Functions\n+    private final RecoverLogSegmentFunction recoverLogSegmentFunction =\n+            new RecoverLogSegmentFunction();\n+    private final AbstractFunction1<List<LogSegmentMetadata>, Future<Long>> recoverLogSegmentsFunction =\n+            new AbstractFunction1<List<LogSegmentMetadata>, Future<Long>>() {\n+                @Override\n+                public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n+                    LOG.info(\"Initiating Recovery For {} : {}\", getFullyQualifiedName(), segmentList);\n+                    // if lastLedgerRollingTimeMillis is not updated, we set it to now.\n+                    synchronized (BKLogWriteHandler.this) {\n+                        if (lastLedgerRollingTimeMillis < 0) {\n+                            lastLedgerRollingTimeMillis = Utils.nowInMillis();\n+                        }\n+                    }\n+\n+                    if (validateLogSegmentSequenceNumber) {\n+                        synchronized (inprogressLSSNs) {\n+                            for (LogSegmentMetadata segment : segmentList) {\n+                                if (segment.isInProgress()) {\n+                                    inprogressLSSNs.addLast(segment.getLogSegmentSequenceNumber());\n+                                }\n+                            }\n+                        }\n+                    }\n+\n+                    return FutureUtils.processList(segmentList, recoverLogSegmentFunction, scheduler).map(\n+                            GetLastTxIdFunction.INSTANCE);\n+                }\n+            };\n+\n+    // Stats\n+    private final StatsLogger perLogStatsLogger;\n+    private final OpStatsLogger closeOpStats;\n+    private final OpStatsLogger openOpStats;\n+    private final OpStatsLogger recoverOpStats;\n+    private final OpStatsLogger deleteOpStats;\n+\n+    /**\n+     * Construct a Bookkeeper journal manager.\n+     */\n+    BKLogWriteHandler(ZKLogMetadataForWriter logMetadata,\n+                      DistributedLogConfiguration conf,\n+                      ZooKeeperClientBuilder zkcBuilder,\n+                      BookKeeperClientBuilder bkcBuilder,\n+                      LogSegmentMetadataStore metadataStore,\n+                      OrderedScheduler scheduler,\n+                      LedgerAllocator allocator,\n+                      StatsLogger statsLogger,\n+                      StatsLogger perLogStatsLogger,\n+                      AlertStatsLogger alertStatsLogger,\n+                      String clientId,\n+                      int regionId,\n+                      PermitLimiter writeLimiter,\n+                      FeatureProvider featureProvider,\n+                      DynamicDistributedLogConfiguration dynConf,\n+                      DistributedLock lock /** owned by handler **/) {\n+        super(logMetadata, conf, zkcBuilder, bkcBuilder, metadataStore,\n+              scheduler, statsLogger, alertStatsLogger, null, WRITE_HANDLE_FILTER, clientId);\n+        this.perLogStatsLogger = perLogStatsLogger;\n+        this.writeLimiter = writeLimiter;\n+        this.featureProvider = featureProvider;\n+        this.dynConf = dynConf;\n+        this.ledgerAllocator = allocator;\n+        this.lock = lock;\n+        this.metadataUpdater = LogSegmentMetadataStoreUpdater.createMetadataUpdater(conf, metadataStore);\n+\n+        ensembleSize = conf.getEnsembleSize();\n+\n+        if (ensembleSize < conf.getWriteQuorumSize()) {\n+            writeQuorumSize = ensembleSize;\n+            LOG.warn(\"Setting write quorum size {} greater than ensemble size {}\",\n+                conf.getWriteQuorumSize(), ensembleSize);\n+        } else {\n+            writeQuorumSize = conf.getWriteQuorumSize();\n+        }\n+        if (writeQuorumSize < conf.getAckQuorumSize()) {\n+            ackQuorumSize = writeQuorumSize;\n+            LOG.warn(\"Setting write ack quorum size {} greater than write quorum size {}\",\n+                conf.getAckQuorumSize(), writeQuorumSize);\n+        } else {\n+            ackQuorumSize = conf.getAckQuorumSize();\n+        }\n+\n+        if (conf.getEncodeRegionIDInLogSegmentMetadata()) {\n+            this.regionId = regionId;\n+        } else {\n+            this.regionId = DistributedLogConstants.LOCAL_REGION_ID;\n+        }\n+        this.sanityCheckTxnId = conf.getSanityCheckTxnID();\n+        this.validateLogSegmentSequenceNumber = conf.isLogSegmentSequenceNumberValidationEnabled();\n+\n+        // Construct the max sequence no\n+        maxLogSegmentSequenceNo = new MaxLogSegmentSequenceNo(logMetadata.getMaxLSSNData());\n+        inprogressLSSNs = new LinkedList<Long>();\n+        // Construct the max txn id.\n+        maxTxId = new MaxTxId(zooKeeperClient, logMetadata.getMaxTxIdPath(),\n+                conf.getSanityCheckTxnID(), logMetadata.getMaxTxIdData());\n+\n+        // Schedule fetching ledgers list in background before we access it.\n+        // We don't need to watch the ledgers list changes for writer, as it manages ledgers list.\n+        scheduleGetLedgersTask(false, true);\n+\n+        // Initialize other parameters.\n+        setLastLedgerRollingTimeMillis(Utils.nowInMillis());\n+\n+        // Rolling Policy\n+        if (conf.getLogSegmentRollingIntervalMinutes() > 0) {\n+            rollingPolicy = new TimeBasedRollingPolicy(conf.getLogSegmentRollingIntervalMinutes() * 60 * 1000);\n+        } else {\n+            rollingPolicy = new SizeBasedRollingPolicy(conf.getMaxLogSegmentBytes());\n+        }\n+\n+        // Stats\n+        StatsLogger segmentsStatsLogger = statsLogger.scope(\"segments\");\n+        openOpStats = segmentsStatsLogger.getOpStatsLogger(\"open\");\n+        closeOpStats = segmentsStatsLogger.getOpStatsLogger(\"close\");\n+        recoverOpStats = segmentsStatsLogger.getOpStatsLogger(\"recover\");\n+        deleteOpStats = segmentsStatsLogger.getOpStatsLogger(\"delete\");\n+    }\n+\n+    // Transactional operations for MaxLogSegmentSequenceNo\n+    void storeMaxSequenceNumber(final Transaction txn,\n+                                final MaxLogSegmentSequenceNo maxSeqNo,\n+                                final long seqNo,\n+                                final boolean isInprogress) {\n+        byte[] data = DLUtils.serializeLogSegmentSequenceNumber(seqNo);\n+        Op zkOp = Op.setData(logMetadata.getLogSegmentsPath(), data, maxSeqNo.getZkVersion());\n+        txn.addOp(new ZKVersionedSetOp(zkOp, new Transaction.OpListener<Version>() {\n+            @Override\n+            public void onCommit(Version version) {\n+                if (validateLogSegmentSequenceNumber) {\n+                    synchronized (inprogressLSSNs) {\n+                        if (isInprogress) {\n+                            inprogressLSSNs.add(seqNo);\n+                        } else {\n+                            inprogressLSSNs.removeFirst();\n+                        }\n+                    }\n+                }\n+                maxSeqNo.update((ZkVersion) version, seqNo);\n+            }\n+\n+            @Override\n+            public void onAbort(Throwable t) {\n+                // no-op\n+            }\n+        }));\n+    }\n+\n+    // Transactional operations for MaxTxId\n+    void storeMaxTxId(final ZKTransaction txn,\n+                      final MaxTxId maxTxId,\n+                      final long txId) {\n+        byte[] data = maxTxId.couldStore(txId);\n+        if (null != data) {\n+            Op zkOp = Op.setData(maxTxId.getZkPath(), data, -1);\n+            txn.addOp(new ZKVersionedSetOp(zkOp, new Transaction.OpListener<Version>() {\n+                @Override\n+                public void onCommit(Version version) {\n+                    maxTxId.setMaxTxId(txId);\n+                }\n+\n+                @Override\n+                public void onAbort(Throwable t) {\n+\n+                }\n+            }));\n+        }\n+    }\n+\n+    // Transactional operations for logsegment\n+    void writeLogSegment(final ZKTransaction txn,\n+                         final List<ACL> acl,\n+                         final String inprogressSegmentName,\n+                         final LogSegmentMetadata metadata,\n+                         final String path) {\n+        byte[] finalisedData = metadata.getFinalisedData().getBytes(UTF_8);\n+        Op zkOp = Op.create(path, finalisedData, acl, CreateMode.PERSISTENT);\n+        txn.addOp(new ZKOp(zkOp) {\n+            @Override\n+            protected void commitOpResult(OpResult opResult) {\n+                addLogSegmentToCache(inprogressSegmentName, metadata);\n+            }\n+\n+            @Override\n+            protected void abortOpResult(Throwable t, OpResult opResult) {\n+                // no-op\n+            }\n+        });\n+    }\n+\n+    void deleteLogSegment(final ZKTransaction txn,\n+                          final String logSegmentName,\n+                          final String logSegmentPath) {\n+        Op zkOp = Op.delete(logSegmentPath, -1);\n+        txn.addOp(new ZKOp(zkOp) {\n+            @Override\n+            protected void commitOpResult(OpResult opResult) {\n+                removeLogSegmentFromCache(logSegmentName);\n+            }\n+            @Override\n+            protected void abortOpResult(Throwable t, OpResult opResult) {\n+                // no-op\n+            }\n+        });\n+    }\n+\n+    /**\n+     * The caller could call this before any actions, which to hold the lock for\n+     * the write handler of its whole lifecycle. The lock will only be released\n+     * when closing the write handler.\n+     *\n+     * This method is useful to prevent releasing underlying zookeeper lock during\n+     * recovering/completing log segments. Releasing underlying zookeeper lock means\n+     * 1) increase latency when re-lock on starting new log segment. 2) increase the\n+     * possibility of a stream being re-acquired by other instances.\n+     *\n+     * @return future represents the lock result\n+     */\n+    Future<DistributedLock> lockHandler() {\n+        if (null != lockFuture) {\n+            return lockFuture;\n+        }\n+        lockFuture = lock.asyncAcquire();\n+        return lockFuture;\n+    }\n+\n+    Future<Void> unlockHandler() {\n+        if (null != lockFuture) {\n+            return lock.asyncClose();\n+        } else {\n+            return Future.Void();\n+        }\n+    }\n+\n+    void register(Watcher watcher) {\n+        this.zooKeeperClient.register(watcher);\n+    }\n+\n+    /**\n+     * Start a new log segment in a BookKeeper ledger.\n+     * First ensure that we have the write lock for this journal.\n+     * Then create a ledger and stream based on that ledger.\n+     * The ledger id is written to the inprogress znode, so that in the\n+     * case of a crash, a recovery process can find the ledger we were writing\n+     * to when we crashed.\n+     *\n+     * @param txId First transaction id to be written to the stream\n+     * @return\n+     * @throws IOException\n+     */\n+    public BKLogSegmentWriter startLogSegment(long txId) throws IOException {\n+        return startLogSegment(txId, false, false);\n+    }\n+\n+    /**\n+     * Start a new log segment in a BookKeeper ledger.\n+     * First ensure that we have the write lock for this journal.\n+     * Then create a ledger and stream based on that ledger.\n+     * The ledger id is written to the inprogress znode, so that in the\n+     * case of a crash, a recovery process can find the ledger we were writing\n+     * to when we crashed.\n+     *\n+     * @param txId First transaction id to be written to the stream\n+     * @param bestEffort\n+     * @param allowMaxTxID\n+     *          allow using max tx id to start log segment\n+     * @return\n+     * @throws IOException\n+     */\n+    public BKLogSegmentWriter startLogSegment(long txId, boolean bestEffort, boolean allowMaxTxID)\n+            throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        boolean success = false;\n+        try {\n+            BKLogSegmentWriter writer = doStartLogSegment(txId, bestEffort, allowMaxTxID);\n+            success = true;\n+            return writer;\n+        } finally {\n+            if (success) {\n+                openOpStats.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            } else {\n+                openOpStats.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            }\n+        }\n+    }\n+\n+    protected long assignLogSegmentSequenceNumber() throws IOException {\n+        // For any active stream we will always make sure that there is at least one\n+        // active ledger (except when the stream first starts out). Therefore when we\n+        // see no ledger metadata for a stream, we assume that this is the first ledger\n+        // in the stream\n+        long logSegmentSeqNo = DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO;\n+        boolean logSegmentsFound = false;\n+\n+        if (LogSegmentMetadata.supportsLogSegmentSequenceNo(conf.getDLLedgerMetadataLayoutVersion())) {\n+            List<LogSegmentMetadata> ledgerListDesc = getFilteredLedgerListDesc(false, false);\n+            Long nextLogSegmentSeqNo = DLUtils.nextLogSegmentSequenceNumber(ledgerListDesc);\n+\n+            if (null == nextLogSegmentSeqNo) {\n+                logSegmentsFound = false;\n+                // we don't find last assigned log segment sequence number\n+                // then we start the log segment with configured FirstLogSegmentSequenceNumber.\n+                logSegmentSeqNo = conf.getFirstLogSegmentSequenceNumber();\n+            } else {\n+                logSegmentsFound = true;\n+                // latest log segment is assigned with a sequence number, start with next sequence number\n+                logSegmentSeqNo = nextLogSegmentSeqNo;\n+            }\n+        }\n+\n+        // We only skip log segment sequence number validation only when no log segments found &\n+        // the maximum log segment sequence number is \"UNASSIGNED\".\n+        if (!logSegmentsFound &&\n+            (DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO == maxLogSegmentSequenceNo.getSequenceNumber())) {\n+            // no ledger seqno stored in /ledgers before\n+            LOG.info(\"No max ledger sequence number found while creating log segment {} for {}.\",\n+                logSegmentSeqNo, getFullyQualifiedName());\n+        } else if (maxLogSegmentSequenceNo.getSequenceNumber() + 1 != logSegmentSeqNo) {\n+            LOG.warn(\"Unexpected max log segment sequence number {} for {} : list of cached segments = {}\",\n+                new Object[]{maxLogSegmentSequenceNo.getSequenceNumber(), getFullyQualifiedName(),\n+                    getCachedLogSegments(LogSegmentMetadata.DESC_COMPARATOR)});\n+            // there is max log segment number recorded there and it isn't match. throw exception.\n+            throw new DLIllegalStateException(\"Unexpected max log segment sequence number \"\n+                + maxLogSegmentSequenceNo.getSequenceNumber() + \" for \" + getFullyQualifiedName()\n+                + \", expected \" + (logSegmentSeqNo - 1));\n+        }\n+\n+        return logSegmentSeqNo;\n+    }\n+\n+    protected BKLogSegmentWriter doStartLogSegment(long txId, boolean bestEffort, boolean allowMaxTxID) throws IOException {\n+        return FutureUtils.result(asyncStartLogSegment(txId, bestEffort, allowMaxTxID));\n+    }\n+\n+    protected Future<BKLogSegmentWriter> asyncStartLogSegment(long txId,\n+                                                              boolean bestEffort,\n+                                                              boolean allowMaxTxID) {\n+        Promise<BKLogSegmentWriter> promise = new Promise<BKLogSegmentWriter>();\n+        try {\n+            lock.checkOwnershipAndReacquire();\n+        } catch (LockingException e) {\n+            FutureUtils.setException(promise, e);\n+            return promise;\n+        }\n+        doStartLogSegment(txId, bestEffort, allowMaxTxID, promise);\n+        return promise;\n+    }\n+\n+    protected void doStartLogSegment(final long txId,\n+                                     final boolean bestEffort,\n+                                     final boolean allowMaxTxID,\n+                                     final Promise<BKLogSegmentWriter> promise) {\n+        // validate the tx id\n+        if ((txId < 0) ||\n+                (!allowMaxTxID && (txId == DistributedLogConstants.MAX_TXID))) {\n+            FutureUtils.setException(promise, new IOException(\"Invalid Transaction Id \" + txId));\n+            return;\n+        }\n+        if (this.sanityCheckTxnId) {\n+            long highestTxIdWritten = maxTxId.get();\n+            if (txId < highestTxIdWritten) {\n+                if (highestTxIdWritten == DistributedLogConstants.MAX_TXID) {\n+                    LOG.error(\"We've already marked the stream as ended and attempting to start a new log segment\");\n+                    FutureUtils.setException(promise, new EndOfStreamException(\"Writing to a stream after it has been marked as completed\"));\n+                    return;\n+                }\n+                else {\n+                    LOG.error(\"We've already seen TxId {} the max TXId is {}\", txId, highestTxIdWritten);\n+                    FutureUtils.setException(promise, new TransactionIdOutOfOrderException(txId, highestTxIdWritten));\n+                    return;\n+                }\n+            }\n+        }\n+\n+        try {\n+            ledgerAllocator.allocate();\n+        } catch (IOException e) {\n+            // failed to issue an allocation request\n+            failStartLogSegment(promise, bestEffort, e);\n+            return;\n+        }\n+\n+        // start the transaction from zookeeper\n+        final ZKTransaction txn = new ZKTransaction(zooKeeperClient);\n+\n+        // failpoint injected before creating ledger\n+        try {\n+            FailpointUtils.checkFailPoint(FailpointUtils.FailPointName.FP_StartLogSegmentBeforeLedgerCreate);\n+        } catch (IOException ioe) {\n+            failStartLogSegment(promise, bestEffort, ioe);\n+            return;\n+        }\n+\n+        ledgerAllocator.tryObtain(txn, new Transaction.OpListener<LedgerHandle>() {\n+            @Override\n+            public void onCommit(LedgerHandle lh) {\n+                // no-op\n+            }\n+\n+            @Override\n+            public void onAbort(Throwable t) {\n+                // no-op\n+            }\n+        }).addEventListener(new FutureEventListener<LedgerHandle>() {\n+\n+            @Override\n+            public void onSuccess(LedgerHandle lh) {\n+                // try-obtain succeed\n+                createInprogressLogSegment(\n+                        txn,\n+                        txId,\n+                        lh,\n+                        bestEffort,\n+                        promise);\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                failStartLogSegment(promise, bestEffort, cause);\n+            }\n+        });\n+    }\n+\n+    private void failStartLogSegment(Promise<BKLogSegmentWriter> promise,\n+                                     boolean bestEffort,\n+                                     Throwable cause) {\n+        if (bestEffort) {\n+            FutureUtils.setValue(promise, null);\n+        } else {\n+            FutureUtils.setException(promise, cause);\n+        }\n+    }\n+\n+    // once the ledger handle is obtained from allocator, this function should guarantee\n+    // either the transaction is executed or aborted. Otherwise, the ledger handle will\n+    // just leak from the allocation pool - hence cause \"No Ledger Allocator\"\n+    private void createInprogressLogSegment(ZKTransaction txn,\n+                                            final long txId,\n+                                            final LedgerHandle lh,\n+                                            boolean bestEffort,\n+                                            final Promise<BKLogSegmentWriter> promise) {\n+        final long logSegmentSeqNo;\n+        try {\n+            FailpointUtils.checkFailPoint(\n+                    FailpointUtils.FailPointName.FP_StartLogSegmentOnAssignLogSegmentSequenceNumber);\n+            logSegmentSeqNo = assignLogSegmentSequenceNumber();\n+        } catch (IOException e) {\n+            // abort the current prepared transaction\n+            txn.abort(e);\n+            failStartLogSegment(promise, bestEffort, e);\n+            return;\n+        }\n+\n+        final String inprogressZnodeName = inprogressZNodeName(lh.getId(), txId, logSegmentSeqNo);\n+        final String inprogressZnodePath = inprogressZNode(lh.getId(), txId, logSegmentSeqNo);\n+        final LogSegmentMetadata l =\n+            new LogSegmentMetadata.LogSegmentMetadataBuilder(inprogressZnodePath,\n+                conf.getDLLedgerMetadataLayoutVersion(), lh.getId(), txId)\n+                    .setLogSegmentSequenceNo(logSegmentSeqNo)\n+                    .setRegionId(regionId)\n+                    .setEnvelopeEntries(LogSegmentMetadata.supportsEnvelopedEntries(conf.getDLLedgerMetadataLayoutVersion()))\n+                    .build();\n+\n+        // Create an inprogress segment\n+        writeLogSegment(\n+                txn,\n+                zooKeeperClient.getDefaultACL(),\n+                inprogressZnodeName,\n+                l,\n+                inprogressZnodePath);\n+\n+        // Try storing max sequence number.\n+        LOG.debug(\"Try storing max sequence number in startLogSegment {} : {}\", inprogressZnodePath, logSegmentSeqNo);\n+        storeMaxSequenceNumber(txn, maxLogSegmentSequenceNo, logSegmentSeqNo, true);\n+\n+        // Try storing max tx id.\n+        LOG.debug(\"Try storing MaxTxId in startLogSegment  {} {}\", inprogressZnodePath, txId);\n+        storeMaxTxId(txn, maxTxId, txId);\n+\n+        txn.execute().addEventListener(FutureEventListenerRunnable.of(new FutureEventListener<Void>() {\n+\n+            @Override\n+            public void onSuccess(Void value) {\n+                try {\n+                    FutureUtils.setValue(promise, new BKLogSegmentWriter(\n+                            getFullyQualifiedName(),\n+                            inprogressZnodeName,\n+                            conf,\n+                            conf.getDLLedgerMetadataLayoutVersion(),\n+                            new BKLogSegmentEntryWriter(lh),\n+                            lock,\n+                            txId,\n+                            logSegmentSeqNo,\n+                            scheduler,\n+                            statsLogger,\n+                            perLogStatsLogger,\n+                            alertStatsLogger,\n+                            writeLimiter,\n+                            featureProvider,\n+                            dynConf));\n+                } catch (IOException ioe) {\n+                    failStartLogSegment(promise, false, ioe);\n+                }\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                failStartLogSegment(promise, false, cause);\n+            }\n+        }, scheduler));\n+    }\n+\n+    boolean shouldStartNewSegment(BKLogSegmentWriter writer) {\n+        return rollingPolicy.shouldRollover(writer, lastLedgerRollingTimeMillis);\n+    }\n+\n+    /**\n+     * Finalize a log segment. If the journal manager is currently\n+     * writing to a ledger, ensure that this is the ledger of the log segment\n+     * being finalized.\n+     * <p/>\n+     * Otherwise this is the recovery case. In the recovery case, ensure that\n+     * the firstTxId of the ledger matches firstTxId for the segment we are\n+     * trying to finalize.\n+     */\n+    Future<LogSegmentMetadata> completeAndCloseLogSegment(final BKLogSegmentWriter writer) {\n+        final Promise<LogSegmentMetadata> promise = new Promise<LogSegmentMetadata>();\n+        completeAndCloseLogSegment(writer, promise);\n+        return promise;\n+    }\n+\n+    private void completeAndCloseLogSegment(final BKLogSegmentWriter writer,\n+                                            final Promise<LogSegmentMetadata> promise) {\n+        writer.asyncClose().addEventListener(new FutureEventListener<Void>() {\n+            @Override\n+            public void onSuccess(Void value) {\n+                // in theory closeToFinalize should throw exception if a stream is in error.\n+                // just in case, add another checking here to make sure we don't close log segment is a stream is in error.\n+                if (writer.shouldFailCompleteLogSegment()) {\n+                    FutureUtils.setException(promise,\n+                            new IOException(\"LogSegmentWriter for \" + writer.getFullyQualifiedLogSegment() + \" is already in error.\"));\n+                    return;\n+                }\n+                doCompleteAndCloseLogSegment(\n+                        inprogressZNodeName(writer.getLogSegmentId(), writer.getStartTxId(), writer.getLogSegmentSequenceNumber()),\n+                        writer.getLogSegmentSequenceNumber(),\n+                        writer.getLogSegmentId(),\n+                        writer.getStartTxId(),\n+                        writer.getLastTxId(),\n+                        writer.getPositionWithinLogSegment(),\n+                        writer.getLastDLSN().getEntryId(),\n+                        writer.getLastDLSN().getSlotId(),\n+                        promise);\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                FutureUtils.setException(promise, cause);\n+            }\n+        });\n+    }\n+\n+    @VisibleForTesting\n+    LogSegmentMetadata completeAndCloseLogSegment(long logSegmentSeqNo,\n+                                                  long ledgerId,\n+                                                  long firstTxId,\n+                                                  long lastTxId,\n+                                                  int recordCount)\n+        throws IOException {\n+        return completeAndCloseLogSegment(inprogressZNodeName(ledgerId, firstTxId, logSegmentSeqNo), logSegmentSeqNo,\n+            ledgerId, firstTxId, lastTxId, recordCount, -1, -1);\n+    }\n+\n+    /**\n+     * Finalize a log segment. If the journal manager is currently\n+     * writing to a ledger, ensure that this is the ledger of the log segment\n+     * being finalized.\n+     * <p/>\n+     * Otherwise this is the recovery case. In the recovery case, ensure that\n+     * the firstTxId of the ledger matches firstTxId for the segment we are\n+     * trying to finalize.\n+     */\n+    LogSegmentMetadata completeAndCloseLogSegment(String inprogressZnodeName, long logSegmentSeqNo,\n+                                                  long ledgerId, long firstTxId, long lastTxId,\n+                                                  int recordCount, long lastEntryId, long lastSlotId)\n+            throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        boolean success = false;\n+        try {\n+            LogSegmentMetadata completedLogSegment =\n+                    doCompleteAndCloseLogSegment(inprogressZnodeName, logSegmentSeqNo,\n+                            ledgerId, firstTxId, lastTxId, recordCount,\n+                            lastEntryId, lastSlotId);\n+            success = true;\n+            return completedLogSegment;\n+        } finally {\n+            if (success) {\n+                closeOpStats.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            } else {\n+                closeOpStats.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            }\n+        }\n+    }\n+\n+    protected long computeStartSequenceId(LogSegmentMetadata segment) throws IOException {\n+        if (!segment.isInProgress()) {\n+            return segment.getStartSequenceId();\n+        }\n+\n+        long startSequenceId = DistributedLogConstants.UNASSIGNED_SEQUENCE_ID;\n+\n+        // we only record sequence id when both write version and logsegment's version support sequence id\n+        if (LogSegmentMetadata.supportsSequenceId(conf.getDLLedgerMetadataLayoutVersion())\n+                && segment.supportsSequenceId()) {\n+            List<LogSegmentMetadata> logSegmentDescList = getFilteredLedgerListDesc(false, false);\n+            startSequenceId = DLUtils.computeStartSequenceId(logSegmentDescList, segment);\n+        }\n+\n+        return startSequenceId;\n+    }\n+\n+    /**\n+     * Close log segment\n+     *\n+     * @param inprogressZnodeName\n+     * @param logSegmentSeqNo\n+     * @param ledgerId\n+     * @param firstTxId\n+     * @param lastTxId\n+     * @param recordCount\n+     * @param lastEntryId\n+     * @param lastSlotId\n+     * @throws IOException\n+     */\n+    protected LogSegmentMetadata doCompleteAndCloseLogSegment(\n+            String inprogressZnodeName,\n+            long logSegmentSeqNo,\n+            long ledgerId,\n+            long firstTxId,\n+            long lastTxId,\n+            int recordCount,\n+            long lastEntryId,\n+            long lastSlotId) throws IOException {\n+        Promise<LogSegmentMetadata> promise = new Promise<LogSegmentMetadata>();\n+        doCompleteAndCloseLogSegment(\n+                inprogressZnodeName,\n+                logSegmentSeqNo,\n+                ledgerId,\n+                firstTxId,\n+                lastTxId,\n+                recordCount,\n+                lastEntryId,\n+                lastSlotId,\n+                promise);\n+        return FutureUtils.result(promise);\n+    }\n+\n+    protected void doCompleteAndCloseLogSegment(final String inprogressZnodeName,\n+                                                long logSegmentSeqNo,\n+                                                long ledgerId,\n+                                                long firstTxId,\n+                                                long lastTxId,\n+                                                int recordCount,\n+                                                long lastEntryId,\n+                                                long lastSlotId,\n+                                                final Promise<LogSegmentMetadata> promise) {\n+        try {\n+            lock.checkOwnershipAndReacquire();\n+        } catch (IOException ioe) {\n+            FutureUtils.setException(promise, ioe);\n+            return;\n+        }\n+\n+        LOG.debug(\"Completing and Closing Log Segment {} {}\", firstTxId, lastTxId);\n+        final String inprogressZnodePath = inprogressZNode(inprogressZnodeName);\n+        LogSegmentMetadata inprogressLogSegment = readLogSegmentFromCache(inprogressZnodeName);\n+\n+        // validate log segment\n+        if (inprogressLogSegment.getLedgerId() != ledgerId) {\n+            FutureUtils.setException(promise, new IOException(\n+                \"Active ledger has different ID to inprogress. \"\n+                    + inprogressLogSegment.getLedgerId() + \" found, \"\n+                    + ledgerId + \" expected\"));\n+            return;\n+        }\n+        // validate the transaction id\n+        if (inprogressLogSegment.getFirstTxId() != firstTxId) {\n+            FutureUtils.setException(promise, new IOException(\"Transaction id not as expected, \"\n+                + inprogressLogSegment.getFirstTxId() + \" found, \" + firstTxId + \" expected\"));\n+            return;\n+        }\n+        // validate the log sequence number\n+        if (validateLogSegmentSequenceNumber) {\n+            synchronized (inprogressLSSNs) {\n+                if (inprogressLSSNs.isEmpty()) {\n+                    FutureUtils.setException(promise, new UnexpectedException(\n+                            \"Didn't find matched inprogress log segments when completing inprogress \"\n+                                    + inprogressLogSegment));\n+                    return;\n+                }\n+                long leastInprogressLSSN = inprogressLSSNs.getFirst();\n+                // the log segment sequence number in metadata {@link inprogressLogSegment.getLogSegmentSequenceNumber()}\n+                // should be same as the sequence number we are completing (logSegmentSeqNo)\n+                // and\n+                // it should also be same as the least inprogress log segment sequence number tracked in {@link inprogressLSSNs}\n+                if ((inprogressLogSegment.getLogSegmentSequenceNumber() != logSegmentSeqNo) ||\n+                        (leastInprogressLSSN != logSegmentSeqNo)) {\n+                    FutureUtils.setException(promise, new UnexpectedException(\n+                            \"Didn't find matched inprogress log segments when completing inprogress \"\n+                                    + inprogressLogSegment));\n+                    return;\n+                }\n+            }\n+        }\n+\n+        // store max sequence number.\n+        long maxSeqNo= Math.max(logSegmentSeqNo, maxLogSegmentSequenceNo.getSequenceNumber());\n+        if (maxLogSegmentSequenceNo.getSequenceNumber() == logSegmentSeqNo ||\n+                (maxLogSegmentSequenceNo.getSequenceNumber() == logSegmentSeqNo + 1)) {\n+            // ignore the case that a new inprogress log segment is pre-allocated\n+            // before completing current inprogress one\n+            LOG.info(\"Try storing max sequence number {} in completing {}.\",\n+                    new Object[] { logSegmentSeqNo, inprogressZnodePath });\n+        } else {\n+            LOG.warn(\"Unexpected max ledger sequence number {} found while completing log segment {} for {}\",\n+                    new Object[] { maxLogSegmentSequenceNo.getSequenceNumber(), logSegmentSeqNo, getFullyQualifiedName() });\n+            if (validateLogSegmentSequenceNumber) {\n+                FutureUtils.setException(promise, new DLIllegalStateException(\"Unexpected max log segment sequence number \"\n+                        + maxLogSegmentSequenceNo.getSequenceNumber() + \" for \" + getFullyQualifiedName()\n+                        + \", expected \" + (logSegmentSeqNo - 1)));\n+                return;\n+            }\n+        }\n+\n+        // Prepare the completion\n+        final String nameForCompletedLedger = completedLedgerZNodeName(firstTxId, lastTxId, logSegmentSeqNo);\n+        final String pathForCompletedLedger = completedLedgerZNode(firstTxId, lastTxId, logSegmentSeqNo);\n+        long startSequenceId;\n+        try {\n+            startSequenceId = computeStartSequenceId(inprogressLogSegment);\n+        } catch (IOException ioe) {\n+            FutureUtils.setException(promise, ioe);\n+            return;\n+        }\n+        // write completed ledger znode\n+        final LogSegmentMetadata completedLogSegment =\n+                inprogressLogSegment.completeLogSegment(\n+                        pathForCompletedLedger,\n+                        lastTxId,\n+                        recordCount,\n+                        lastEntryId,\n+                        lastSlotId,\n+                        startSequenceId);\n+        setLastLedgerRollingTimeMillis(completedLogSegment.getCompletionTime());\n+\n+        // prepare the transaction\n+        ZKTransaction txn = new ZKTransaction(zooKeeperClient);\n+\n+        // create completed log segment\n+        writeLogSegment(\n+                txn,\n+                zooKeeperClient.getDefaultACL(),\n+                nameForCompletedLedger,\n+                completedLogSegment,\n+                pathForCompletedLedger);\n+        // delete inprogress log segment\n+        deleteLogSegment(txn, inprogressZnodeName, inprogressZnodePath);\n+        // store max sequence number\n+        storeMaxSequenceNumber(txn, maxLogSegmentSequenceNo, maxSeqNo, false);\n+        // update max txn id.\n+        LOG.debug(\"Trying storing LastTxId in Finalize Path {} LastTxId {}\", pathForCompletedLedger, lastTxId);\n+        storeMaxTxId(txn, maxTxId, lastTxId);\n+\n+        txn.execute().addEventListener(FutureEventListenerRunnable.of(new FutureEventListener<Void>() {\n+            @Override\n+            public void onSuccess(Void value) {\n+                LOG.info(\"Completed {} to {} for {} : {}\",\n+                        new Object[] { inprogressZnodeName, nameForCompletedLedger, getFullyQualifiedName(), completedLogSegment });\n+                FutureUtils.setValue(promise, completedLogSegment);\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                FutureUtils.setException(promise, cause);\n+            }\n+        }, scheduler));\n+    }\n+\n+    public Future<Long> recoverIncompleteLogSegments() {\n+        try {\n+            FailpointUtils.checkFailPoint(FailpointUtils.FailPointName.FP_RecoverIncompleteLogSegments);\n+        } catch (IOException ioe) {\n+            return Future.exception(ioe);\n+        }\n+        return asyncGetFilteredLedgerList(false, false).flatMap(recoverLogSegmentsFunction);\n+    }\n+\n+    class RecoverLogSegmentFunction extends Function<LogSegmentMetadata, Future<LogSegmentMetadata>> {\n+\n+        @Override\n+        public Future<LogSegmentMetadata> apply(final LogSegmentMetadata l) {\n+            if (!l.isInProgress()) {\n+                return Future.value(l);\n+            }\n+\n+            LOG.info(\"Recovering last record in log segment {} for {}.\", l, getFullyQualifiedName());\n+            return asyncReadLastRecord(l, true, true, true).flatMap(\n+                    new AbstractFunction1<LogRecordWithDLSN, Future<LogSegmentMetadata>>() {\n+                        @Override\n+                        public Future<LogSegmentMetadata> apply(LogRecordWithDLSN lastRecord) {\n+                            return completeLogSegment(l, lastRecord);\n+                        }\n+                    });\n+        }\n+\n+        private Future<LogSegmentMetadata> completeLogSegment(LogSegmentMetadata l,\n+                                                              LogRecordWithDLSN lastRecord) {\n+            LOG.info(\"Recovered last record in log segment {} for {}.\", l, getFullyQualifiedName());\n+\n+            long endTxId = DistributedLogConstants.EMPTY_LOGSEGMENT_TX_ID;\n+            int recordCount = 0;\n+            long lastEntryId = -1;\n+            long lastSlotId = -1;\n+\n+            if (null != lastRecord) {\n+                endTxId = lastRecord.getTransactionId();\n+                recordCount = lastRecord.getLastPositionWithinLogSegment();\n+                lastEntryId = lastRecord.getDlsn().getEntryId();\n+                lastSlotId = lastRecord.getDlsn().getSlotId();\n+            }\n+\n+            if (endTxId == DistributedLogConstants.INVALID_TXID) {\n+                LOG.error(\"Unrecoverable corruption has occurred in segment \"\n+                    + l.toString() + \" at path \" + l.getZkPath()\n+                    + \". Unable to continue recovery.\");\n+                return Future.exception(new IOException(\"Unrecoverable corruption,\"\n+                    + \" please check logs.\"));\n+            } else if (endTxId == DistributedLogConstants.EMPTY_LOGSEGMENT_TX_ID) {\n+                // TODO: Empty ledger - Ideally we should just remove it?\n+                endTxId = l.getFirstTxId();\n+            }\n+\n+            Promise<LogSegmentMetadata> promise = new Promise<LogSegmentMetadata>();\n+            doCompleteAndCloseLogSegment(\n+                    l.getZNodeName(),\n+                    l.getLogSegmentSequenceNumber(),\n+                    l.getLedgerId(),\n+                    l.getFirstTxId(),\n+                    endTxId,\n+                    recordCount,\n+                    lastEntryId,\n+                    lastSlotId,\n+                    promise);\n+            return promise;\n+        }\n+\n+    }\n+\n+    public void deleteLog() throws IOException {\n+        lock.checkOwnershipAndReacquire();\n+        FutureUtils.result(purgeLogSegmentsOlderThanTxnId(-1));\n+\n+        try {\n+            Utils.closeQuietly(lock);\n+            zooKeeperClient.get().exists(logMetadata.getLogSegmentsPath(), false);\n+            zooKeeperClient.get().exists(logMetadata.getMaxTxIdPath(), false);\n+            if (logMetadata.getLogRootPath().toLowerCase().contains(\"distributedlog\")) {\n+                ZKUtil.deleteRecursive(zooKeeperClient.get(), logMetadata.getLogRootPath());\n+            } else {\n+                LOG.warn(\"Skip deletion of unrecognized ZK Path {}\", logMetadata.getLogRootPath());\n+            }\n+        } catch (InterruptedException ie) {\n+            LOG.error(\"Interrupted while deleting log znodes\", ie);\n+            throw new DLInterruptedException(\"Interrupted while deleting \" + logMetadata.getLogRootPath(), ie);\n+        } catch (KeeperException ke) {\n+            LOG.error(\"Error deleting\" + logMetadata.getLogRootPath() + \" in zookeeper\", ke);\n+        }\n+    }\n+\n+    Future<List<LogSegmentMetadata>> setLogSegmentsOlderThanDLSNTruncated(final DLSN dlsn) {\n+        if (DLSN.InvalidDLSN == dlsn) {\n+            List<LogSegmentMetadata> emptyList = new ArrayList<LogSegmentMetadata>(0);\n+            return Future.value(emptyList);\n+        }\n+        scheduleGetAllLedgersTaskIfNeeded();\n+        return asyncGetFullLedgerList(false, false).flatMap(\n+                new AbstractFunction1<List<LogSegmentMetadata>, Future<List<LogSegmentMetadata>>>() {\n+                    @Override\n+                    public Future<List<LogSegmentMetadata>> apply(List<LogSegmentMetadata> logSegments) {\n+                        return setLogSegmentsOlderThanDLSNTruncated(logSegments, dlsn);\n+                    }\n+                });\n+    }\n+\n+    private Future<List<LogSegmentMetadata>> setLogSegmentsOlderThanDLSNTruncated(List<LogSegmentMetadata> logSegments,\n+                                                                                  final DLSN dlsn) {\n+        LOG.debug(\"Setting truncation status on logs older than {} from {} for {}\",\n+                new Object[]{dlsn, logSegments, getFullyQualifiedName()});\n+        List<LogSegmentMetadata> truncateList = new ArrayList<LogSegmentMetadata>(logSegments.size());\n+        LogSegmentMetadata partialTruncate = null;\n+        LOG.info(\"{}: Truncating log segments older than {}\", getFullyQualifiedName(), dlsn);\n+        int numCandidates = getNumCandidateLogSegmentsToTruncate(logSegments);\n+        for (int i = 0; i < numCandidates; i++) {\n+            LogSegmentMetadata l = logSegments.get(i);\n+            if (!l.isInProgress()) {\n+                if (l.getLastDLSN().compareTo(dlsn) < 0) {\n+                    LOG.debug(\"{}: Truncating log segment {} \", getFullyQualifiedName(), l);\n+                    truncateList.add(l);\n+                } else if (l.getFirstDLSN().compareTo(dlsn) < 0) {\n+                    // Can be satisfied by at most one segment\n+                    if (null != partialTruncate) {\n+                        String logMsg = String.format(\"Potential metadata inconsistency for stream %s at segment %s\", getFullyQualifiedName(), l);\n+                        LOG.error(logMsg);\n+                        return Future.exception(new DLIllegalStateException(logMsg));\n+                    }\n+                    LOG.info(\"{}: Partially truncating log segment {} older than {}.\", new Object[] {getFullyQualifiedName(), l, dlsn});\n+                    partialTruncate = l;\n+                } else {\n+                    break;\n+                }\n+            } else {\n+                break;\n+            }\n+        }\n+        return setLogSegmentTruncationStatus(truncateList, partialTruncate, dlsn);\n+    }\n+\n+    private int getNumCandidateLogSegmentsToTruncate(List<LogSegmentMetadata> logSegments) {\n+        if (logSegments.isEmpty()) {\n+            return 0;\n+        } else {\n+            // we have to keep at least one completed log segment for sequence id\n+            int numCandidateLogSegments = 0;\n+            for (LogSegmentMetadata segment : logSegments) {\n+                if (segment.isInProgress()) {\n+                    break;\n+                } else {\n+                    ++numCandidateLogSegments;\n+                }\n+            }\n+\n+            return numCandidateLogSegments - 1;\n+        }\n+    }\n+\n+    Future<List<LogSegmentMetadata>> purgeLogSegmentsOlderThanTimestamp(final long minTimestampToKeep) {\n+        if (minTimestampToKeep >= Utils.nowInMillis()) {\n+            return Future.exception(new IllegalArgumentException(\n+                    \"Invalid timestamp \" + minTimestampToKeep + \" to purge logs for \" + getFullyQualifiedName()));\n+        }\n+        return asyncGetFullLedgerList(false, false).flatMap(\n+                new Function<List<LogSegmentMetadata>, Future<List<LogSegmentMetadata>>>() {\n+            @Override\n+            public Future<List<LogSegmentMetadata>> apply(List<LogSegmentMetadata> logSegments) {\n+                List<LogSegmentMetadata> purgeList = new ArrayList<LogSegmentMetadata>(logSegments.size());\n+\n+                int numCandidates = getNumCandidateLogSegmentsToTruncate(logSegments);\n+\n+                for (int iterator = 0; iterator < numCandidates; iterator++) {\n+                    LogSegmentMetadata l = logSegments.get(iterator);\n+                    // When application explicitly truncates segments; timestamp based purge is\n+                    // only used to cleanup log segments that have been marked for truncation\n+                    if ((l.isTruncated() || !conf.getExplicitTruncationByApplication()) &&\n+                        !l.isInProgress() && (l.getCompletionTime() < minTimestampToKeep)) {\n+                        purgeList.add(l);\n+                    } else {\n+                        // stop truncating log segments if we find either an inprogress or a partially\n+                        // truncated log segment\n+                        break;\n+                    }\n+                }\n+                LOG.info(\"Deleting log segments older than {} for {} : {}\",\n+                        new Object[] { minTimestampToKeep, getFullyQualifiedName(), purgeList });\n+                return deleteLogSegments(purgeList);\n+            }\n+        });\n+    }\n+\n+    Future<List<LogSegmentMetadata>> purgeLogSegmentsOlderThanTxnId(final long minTxIdToKeep) {\n+        return asyncGetFullLedgerList(true, false).flatMap(\n+            new AbstractFunction1<List<LogSegmentMetadata>, Future<List<LogSegmentMetadata>>>() {\n+                @Override\n+                public Future<List<LogSegmentMetadata>> apply(List<LogSegmentMetadata> logSegments) {\n+                    int numLogSegmentsToProcess;\n+\n+                    if (minTxIdToKeep < 0) {\n+                        // we are deleting the log, we can remove whole log segments\n+                        numLogSegmentsToProcess = logSegments.size();\n+                    } else {\n+                        numLogSegmentsToProcess = getNumCandidateLogSegmentsToTruncate(logSegments);\n+                    }\n+                    List<LogSegmentMetadata> purgeList = Lists.newArrayListWithExpectedSize(numLogSegmentsToProcess);\n+                    for (int iterator = 0; iterator < numLogSegmentsToProcess; iterator++) {\n+                        LogSegmentMetadata l = logSegments.get(iterator);\n+                        if ((minTxIdToKeep < 0) ||\n+                            ((l.isTruncated() || !conf.getExplicitTruncationByApplication()) &&\n+                            !l.isInProgress() && (l.getLastTxId() < minTxIdToKeep))) {\n+                            purgeList.add(l);\n+                        } else {\n+                            // stop truncating log segments if we find either an inprogress or a partially\n+                            // truncated log segment\n+                            break;\n+                        }\n+                    }\n+                    return deleteLogSegments(purgeList);\n+                }\n+            });\n+    }\n+\n+    private Future<List<LogSegmentMetadata>> setLogSegmentTruncationStatus(\n+            final List<LogSegmentMetadata> truncateList,\n+            LogSegmentMetadata partialTruncate,\n+            DLSN minActiveDLSN) {\n+        final List<LogSegmentMetadata> listToTruncate = Lists.newArrayListWithCapacity(truncateList.size() + 1);\n+        final List<LogSegmentMetadata> listAfterTruncated = Lists.newArrayListWithCapacity(truncateList.size() + 1);\n+        Transaction<Object> updateTxn = metadataUpdater.transaction();\n+        for(LogSegmentMetadata l : truncateList) {\n+            if (!l.isTruncated()) {\n+                LogSegmentMetadata newSegment = metadataUpdater.setLogSegmentTruncated(updateTxn, l);\n+                listToTruncate.add(l);\n+                listAfterTruncated.add(newSegment);\n+            }\n+        }\n+\n+        if (null != partialTruncate && (partialTruncate.isNonTruncated() ||\n+                (partialTruncate.isPartiallyTruncated() && (partialTruncate.getMinActiveDLSN().compareTo(minActiveDLSN) < 0)))) {\n+            LogSegmentMetadata newSegment = metadataUpdater.setLogSegmentPartiallyTruncated(\n+                    updateTxn, partialTruncate, minActiveDLSN);\n+            listToTruncate.add(partialTruncate);\n+            listAfterTruncated.add(newSegment);\n+        }\n+\n+        return updateTxn.execute().map(new AbstractFunction1<Void, List<LogSegmentMetadata>>() {\n+            @Override\n+            public List<LogSegmentMetadata> apply(Void value) {\n+                for (int i = 0; i < listToTruncate.size(); i++) {\n+                    removeLogSegmentFromCache(listToTruncate.get(i).getSegmentName());\n+                    LogSegmentMetadata newSegment = listAfterTruncated.get(i);\n+                    addLogSegmentToCache(newSegment.getSegmentName(), newSegment);\n+                }\n+                return listAfterTruncated;\n+            }\n+        });\n+    }\n+\n+    private Future<List<LogSegmentMetadata>> deleteLogSegments(\n+            final List<LogSegmentMetadata> logs) {\n+        if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"Purging logs for {} : {}\", getFullyQualifiedName(), logs);\n+        }\n+        return FutureUtils.processList(logs,\n+                new Function<LogSegmentMetadata, Future<LogSegmentMetadata>>() {\n+            @Override\n+            public Future<LogSegmentMetadata> apply(LogSegmentMetadata segment) {\n+                return deleteLogSegment(segment);\n+            }\n+        }, scheduler);\n+    }\n+\n+    private Future<LogSegmentMetadata> deleteLogSegment(\n+            final LogSegmentMetadata ledgerMetadata) {\n+        LOG.info(\"Deleting ledger {} for {}\", ledgerMetadata, getFullyQualifiedName());\n+        final Promise<LogSegmentMetadata> promise = new Promise<LogSegmentMetadata>();\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        promise.addEventListener(new FutureEventListener<LogSegmentMetadata>() {\n+            @Override\n+            public void onSuccess(LogSegmentMetadata segment) {\n+                deleteOpStats.registerSuccessfulEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                deleteOpStats.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n+            }\n+        });\n+        try {\n+            bookKeeperClient.get().asyncDeleteLedger(ledgerMetadata.getLedgerId(), new AsyncCallback.DeleteCallback() {\n+                @Override\n+                public void deleteComplete(int rc, Object ctx) {\n+                    if (BKException.Code.NoSuchLedgerExistsException == rc) {\n+                        LOG.warn(\"No ledger {} found to delete for {} : {}.\",\n+                                new Object[]{ledgerMetadata.getLedgerId(), getFullyQualifiedName(),\n+                                        ledgerMetadata});\n+                    } else if (BKException.Code.OK != rc) {\n+                        BKException bke = BKException.create(rc);\n+                        LOG.error(\"Couldn't delete ledger {} from bookkeeper for {} : \",\n+                                new Object[]{ledgerMetadata.getLedgerId(), getFullyQualifiedName(), bke});\n+                        promise.setException(bke);\n+                        return;\n+                    }\n+                    // after the ledger is deleted, we delete the metadata znode\n+                    scheduler.submit(new Runnable() {\n+                        @Override\n+                        public void run() {\n+                            deleteLogSegmentMetadata(ledgerMetadata, promise);\n+                        }\n+                    });\n+                }\n+            }, null);\n+        } catch (IOException e) {\n+            promise.setException(BKException.create(BKException.Code.BookieHandleNotAvailableException));\n+        }\n+        return promise;\n+    }\n+\n+    private void deleteLogSegmentMetadata(final LogSegmentMetadata segmentMetadata,\n+                                          final Promise<LogSegmentMetadata> promise) {\n+        Transaction<Object> deleteTxn = metadataStore.transaction();\n+        metadataStore.deleteLogSegment(deleteTxn, segmentMetadata);\n+        deleteTxn.execute().addEventListener(new FutureEventListener<Void>() {\n+            @Override\n+            public void onSuccess(Void result) {\n+                // purge log segment\n+                removeLogSegmentFromCache(segmentMetadata.getZNodeName());\n+                promise.setValue(segmentMetadata);\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                if (cause instanceof ZKException) {\n+                    ZKException zke = (ZKException) cause;\n+                    if (KeeperException.Code.NONODE == zke.getKeeperExceptionCode()) {\n+                        LOG.error(\"No log segment {} found for {}.\",\n+                                segmentMetadata, getFullyQualifiedName());\n+                        // purge log segment\n+                        removeLogSegmentFromCache(segmentMetadata.getZNodeName());\n+                        promise.setValue(segmentMetadata);\n+                        return;\n+                    }\n+                }\n+                LOG.error(\"Couldn't purge {} for {}: with error {}\",\n+                        new Object[]{ segmentMetadata, getFullyQualifiedName(), cause });\n+                promise.setException(cause);\n+            }\n+        });\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        return Utils.closeSequence(scheduler,\n+                lock,\n+                ledgerAllocator\n+        ).flatMap(new AbstractFunction1<Void, Future<Void>>() {\n+            @Override\n+            public Future<Void> apply(Void result) {\n+                return BKLogWriteHandler.super.asyncClose();\n+            }\n+        });\n+    }\n+\n+    @Override\n+    public Future<Void> asyncAbort() {\n+        return asyncClose();\n+    }\n+\n+    String completedLedgerZNodeName(long firstTxId, long lastTxId, long logSegmentSeqNo) {\n+        if (DistributedLogConstants.LOGSEGMENT_NAME_VERSION == conf.getLogSegmentNameVersion()) {\n+            return String.format(\"%s_%018d\", DistributedLogConstants.COMPLETED_LOGSEGMENT_PREFIX, logSegmentSeqNo);\n+        } else {\n+            return String.format(\"%s_%018d_%018d\", DistributedLogConstants.COMPLETED_LOGSEGMENT_PREFIX,\n+                    firstTxId, lastTxId);\n+        }\n+    }\n+\n+    /**\n+     * Get the znode path for a finalize ledger\n+     */\n+    String completedLedgerZNode(long firstTxId, long lastTxId, long logSegmentSeqNo) {\n+        return String.format(\"%s/%s\", logMetadata.getLogSegmentsPath(),\n+                completedLedgerZNodeName(firstTxId, lastTxId, logSegmentSeqNo));\n+    }\n+\n+    /**\n+     * Get the name of the inprogress znode.\n+     *\n+     * @return name of the inprogress znode.\n+     */\n+    String inprogressZNodeName(long ledgerId, long firstTxId, long logSegmentSeqNo) {\n+        if (DistributedLogConstants.LOGSEGMENT_NAME_VERSION == conf.getLogSegmentNameVersion()) {\n+            // Lots of the problems are introduced due to different inprogress names with same ledger sequence number.\n+            return String.format(\"%s_%018d\", DistributedLogConstants.INPROGRESS_LOGSEGMENT_PREFIX, logSegmentSeqNo);\n+        } else {\n+            return DistributedLogConstants.INPROGRESS_LOGSEGMENT_PREFIX + \"_\" + Long.toString(firstTxId, 16);\n+        }\n+    }\n+\n+    /**\n+     * Get the znode path for the inprogressZNode\n+     */\n+    String inprogressZNode(long ledgerId, long firstTxId, long logSegmentSeqNo) {\n+        return logMetadata.getLogSegmentsPath() + \"/\" + inprogressZNodeName(ledgerId, firstTxId, logSegmentSeqNo);\n+    }\n+\n+    String inprogressZNode(String inprogressZNodeName) {\n+        return logMetadata.getLogSegmentsPath() + \"/\" + inprogressZNodeName;\n+    }\n+}"},{"sha":"bd60856159e152f24abbf81c0bbd4af864968a72","filename":"src/main/java/com/twitter/distributedlog/BKSyncLogReaderDLSN.java","status":"added","additions":260,"deletions":0,"changes":260,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Optional;\n+import com.twitter.distributedlog.callback.ReadAheadCallback;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.EndOfStreamException;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * Synchronous Log Reader based on {@link AsyncLogReader}\n+ */\n+class BKSyncLogReaderDLSN implements LogReader, Runnable, FutureEventListener<LogRecordWithDLSN>, ReadAheadCallback {\n+\n+    private final BKAsyncLogReaderDLSN reader;\n+    private final ScheduledExecutorService executorService;\n+    private final LinkedBlockingQueue<LogRecordWithDLSN> readAheadRecords;\n+    private final AtomicReference<IOException> readerException =\n+            new AtomicReference<IOException>(null);\n+    private final int maxNumCachedRecords;\n+    private final int maxReadAheadWaitTime;\n+    private ReadAheadCallback readAheadCallback = null;\n+    private Promise<Void> closeFuture;\n+    private final Optional<Long> startTransactionId;\n+    private final DLSN startDLSN;\n+    private DLSN lastSeenDLSN = DLSN.InvalidDLSN;\n+    // lock on variables that would be accessed by both background threads and foreground threads\n+    private final Object sharedLock = new Object();\n+\n+    BKSyncLogReaderDLSN(DistributedLogConfiguration conf,\n+                        BKAsyncLogReaderDLSN reader,\n+                        ScheduledExecutorService executorService,\n+                        Optional<Long> startTransactionId) {\n+        this.maxNumCachedRecords = conf.getReadAheadMaxRecords();\n+        this.maxReadAheadWaitTime = conf.getReadAheadWaitTime();\n+        this.reader = reader;\n+        this.executorService = executorService;\n+        this.readAheadRecords = new LinkedBlockingQueue<LogRecordWithDLSN>();\n+        this.startTransactionId = startTransactionId;\n+        this.startDLSN = reader.getStartDLSN();\n+        scheduleReadNext();\n+    }\n+\n+    @VisibleForTesting\n+    BKAsyncLogReaderDLSN getAsyncReader() {\n+        return reader;\n+    }\n+\n+    private void scheduleReadNext() {\n+        synchronized (sharedLock) {\n+            if (null != closeFuture) {\n+                return;\n+            }\n+        }\n+        this.executorService.submit(this);\n+    }\n+\n+    private void invokeReadAheadCallback() {\n+        synchronized (sharedLock) {\n+            if (null != readAheadCallback) {\n+                readAheadCallback.resumeReadAhead();\n+                readAheadCallback = null;\n+            }\n+        }\n+    }\n+\n+    private void setReadAheadCallback(ReadAheadCallback callback) {\n+        synchronized (sharedLock) {\n+            this.readAheadCallback = callback;\n+            if (readAheadRecords.size() < maxNumCachedRecords) {\n+                invokeReadAheadCallback();\n+            }\n+        }\n+    }\n+\n+    private void setLastSeenDLSN(DLSN dlsn) {\n+        synchronized (sharedLock) {\n+            this.lastSeenDLSN = dlsn;\n+        }\n+    }\n+\n+    // Background Read Future Listener\n+\n+    @Override\n+    public void resumeReadAhead() {\n+        scheduleReadNext();\n+    }\n+\n+    @Override\n+    public void onSuccess(LogRecordWithDLSN record) {\n+        setLastSeenDLSN(record.getDlsn());\n+        if (!startTransactionId.isPresent() || record.getTransactionId() >= startTransactionId.get()) {\n+            readAheadRecords.add(record);\n+        }\n+        if (readAheadRecords.size() >= maxNumCachedRecords) {\n+            setReadAheadCallback(this);\n+        } else {\n+            scheduleReadNext();\n+        }\n+    }\n+\n+    @Override\n+    public void onFailure(Throwable cause) {\n+        if (cause instanceof IOException) {\n+            readerException.compareAndSet(null, (IOException) cause);\n+        } else {\n+            readerException.compareAndSet(null, new IOException(\"Encountered exception on reading \"\n+                    + reader.getStreamName() + \" : \", cause));\n+        }\n+    }\n+\n+    // Background Read\n+\n+    @Override\n+    public void run() {\n+        this.reader.readNext().addEventListener(this);\n+    }\n+\n+    @Override\n+    public synchronized LogRecordWithDLSN readNext(boolean nonBlocking)\n+            throws IOException {\n+        if (null != readerException.get()) {\n+            throw readerException.get();\n+        }\n+        LogRecordWithDLSN record = null;\n+        if (nonBlocking) {\n+            record = readAheadRecords.poll();\n+        } else {\n+            try {\n+                // reader is still catching up, waiting for next record\n+                while (!reader.bkLedgerManager.isReadAheadCaughtUp()\n+                        && null == readerException.get()\n+                        && null == record) {\n+                    record = readAheadRecords.poll(maxReadAheadWaitTime,\n+                            TimeUnit.MILLISECONDS);\n+                }\n+                // reader caught up\n+                boolean shallWait = true;\n+                while (shallWait\n+                        && reader.bkLedgerManager.isReadAheadCaughtUp()\n+                        && null == record\n+                        && null == readerException.get()) {\n+                    record = readAheadRecords.poll(maxReadAheadWaitTime,\n+                            TimeUnit.MILLISECONDS);\n+                    if (null != record) {\n+                        break;\n+                    }\n+                    synchronized (sharedLock) {\n+                        DLSN lastDLSNSeenByReadAhead =\n+                                reader.bkLedgerManager.readAheadCache.getLastReadAheadUserDLSN();\n+\n+                        // if last seen DLSN by reader is same as the one seen by ReadAhead\n+                        // that means that reader is caught up with ReadAhead and ReadAhead\n+                        // is caught up with stream\n+                        shallWait = DLSN.InitialDLSN != lastDLSNSeenByReadAhead\n+                                && lastSeenDLSN.compareTo(lastDLSNSeenByReadAhead) < 0\n+                                && startDLSN.compareTo(lastDLSNSeenByReadAhead) <= 0;\n+                    }\n+                }\n+            } catch (InterruptedException e) {\n+                throw new DLInterruptedException(\"Interrupted on waiting next available log record for stream \"\n+                        + reader.getStreamName(), e);\n+            }\n+        }\n+        if (null != readerException.get()) {\n+            throw readerException.get();\n+        }\n+        if (null != record) {\n+            if (record.isEndOfStream()) {\n+                EndOfStreamException eos = new EndOfStreamException(\"End of Stream Reached for \"\n+                                        + reader.bkLedgerManager.getFullyQualifiedName());\n+                readerException.compareAndSet(null, eos);\n+                throw eos;\n+            }\n+            invokeReadAheadCallback();\n+        }\n+        return record;\n+    }\n+\n+    @Override\n+    public synchronized List<LogRecordWithDLSN> readBulk(boolean nonBlocking, int numLogRecords)\n+            throws IOException {\n+        LinkedList<LogRecordWithDLSN> retList =\n+                new LinkedList<LogRecordWithDLSN>();\n+\n+        int numRead = 0;\n+        LogRecordWithDLSN record = readNext(nonBlocking);\n+        while ((null != record)) {\n+            retList.add(record);\n+            numRead++;\n+            if (numRead >= numLogRecords) {\n+                break;\n+            }\n+            record = readNext(nonBlocking);\n+        }\n+        return retList;\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        Promise<Void> closePromise;\n+        synchronized (sharedLock) {\n+            if (null != closeFuture) {\n+                return closeFuture;\n+            }\n+            closeFuture = closePromise = new Promise<Void>();\n+        }\n+        reader.asyncClose().proxyTo(closePromise);\n+        return closePromise;\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        FutureUtils.result(asyncClose());\n+    }\n+\n+    //\n+    // Test Methods\n+    //\n+    @VisibleForTesting\n+    void disableReadAheadZKNotification() {\n+        reader.bkLedgerManager.disableReadAheadZKNotification();\n+    }\n+\n+    @VisibleForTesting\n+    LedgerReadPosition getReadAheadPosition() {\n+        if (null != reader.bkLedgerManager.readAheadWorker) {\n+            return reader.bkLedgerManager.readAheadWorker.getNextReadAheadPosition();\n+        }\n+        return null;\n+    }\n+}"},{"sha":"b638020ee3f22432bfa55150157aa2a6fc4f462e","filename":"src/main/java/com/twitter/distributedlog/BKSyncLogWriter.java","status":"added","additions":113,"deletions":0,"changes":113,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,113 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.util.FutureUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+class BKSyncLogWriter extends BKAbstractLogWriter implements LogWriter {\n+\n+    public BKSyncLogWriter(DistributedLogConfiguration conf,\n+                           DynamicDistributedLogConfiguration dynConf,\n+                           BKDistributedLogManager bkdlm) {\n+        super(conf, dynConf, bkdlm);\n+    }\n+    /**\n+     * Write log records to the stream.\n+     *\n+     * @param record operation\n+     */\n+    @Override\n+    public void write(LogRecord record) throws IOException {\n+        getLedgerWriter(record.getTransactionId(), false).write(record);\n+    }\n+\n+    /**\n+     * Write edits logs operation to the stream.\n+     *\n+     * @param records list of records\n+     */\n+    @Override\n+    @Deprecated\n+    public int writeBulk(List<LogRecord> records) throws IOException {\n+        return getLedgerWriter(records.get(0).getTransactionId(), false).writeBulk(records);\n+    }\n+\n+    /**\n+     * Flushes all the data up to this point,\n+     * adds the end of stream marker and marks the stream\n+     * as read-only in the metadata. No appends to the\n+     * stream will be allowed after this point\n+     */\n+    @Override\n+    public void markEndOfStream() throws IOException {\n+        FutureUtils.result(getLedgerWriter(DistributedLogConstants.MAX_TXID, true).markEndOfStream());\n+        closeAndComplete();\n+    }\n+\n+    /**\n+     * All data that has been written to the stream so far will be flushed.\n+     * New data can be still written to the stream while flush is ongoing.\n+     */\n+    @Override\n+    public long setReadyToFlush() throws IOException {\n+        checkClosedOrInError(\"setReadyToFlush\");\n+        long highestTransactionId = 0;\n+        BKLogSegmentWriter writer = getCachedLogWriter();\n+        if (null != writer) {\n+            highestTransactionId = Math.max(highestTransactionId, FutureUtils.result(writer.flush()));\n+        }\n+        return highestTransactionId;\n+    }\n+\n+    /**\n+     * Commit data that is already flushed.\n+     * <p/>\n+     * This API is optional as the writer implements a policy for automatically syncing\n+     * the log records in the buffer. The buffered edits can be flushed when the buffer\n+     * becomes full or a certain period of time is elapsed.\n+     */\n+    @Override\n+    public long flushAndSync() throws IOException {\n+        checkClosedOrInError(\"flushAndSync\");\n+\n+        LOG.debug(\"FlushAndSync Started\");\n+        long highestTransactionId = 0;\n+        BKLogSegmentWriter writer = getCachedLogWriter();\n+        if (null != writer) {\n+            highestTransactionId = Math.max(highestTransactionId, FutureUtils.result(writer.commit()));\n+            LOG.debug(\"FlushAndSync Completed\");\n+        } else {\n+            LOG.debug(\"FlushAndSync Completed - Nothing to Flush\");\n+        }\n+        return highestTransactionId;\n+    }\n+\n+    /**\n+     * Close the stream without necessarily flushing immediately.\n+     * This may be called if the stream is in error such as after a\n+     * previous write or close threw an exception.\n+     */\n+    @Override\n+    public void abort() throws IOException {\n+        super.abort();\n+    }\n+}"},{"sha":"4586602077231d5e5348dd978593f5e5e619304d","filename":"src/main/java/com/twitter/distributedlog/BKTransmitPacket.java","status":"added","additions":90,"deletions":0,"changes":90,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKTransmitPacket.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKTransmitPacket.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKTransmitPacket.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.util.Await;\n+import com.twitter.util.Duration;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+class BKTransmitPacket {\n+\n+    private final EntryBuffer recordSet;\n+    private final long transmitTime;\n+    private final Promise<Integer> transmitComplete;\n+\n+    BKTransmitPacket(EntryBuffer recordSet) {\n+        this.recordSet = recordSet;\n+        this.transmitTime = System.nanoTime();\n+        this.transmitComplete = new Promise<Integer>();\n+    }\n+\n+    EntryBuffer getRecordSet() {\n+        return recordSet;\n+    }\n+\n+    Promise<Integer> getTransmitFuture() {\n+        return transmitComplete;\n+    }\n+\n+    /**\n+     * Complete the transmit with result code <code>transmitRc</code>.\n+     * <p>It would notify all the waiters that are waiting via {@link #awaitTransmitComplete(long, TimeUnit)}\n+     * or {@link #addTransmitCompleteListener(FutureEventListener)}.\n+     *\n+     * @param transmitResult\n+     *          transmit result code.\n+     */\n+    public void notifyTransmitComplete(int transmitResult) {\n+        transmitComplete.setValue(transmitResult);\n+    }\n+\n+    /**\n+     * Register a transmit complete listener.\n+     * <p>The listener will be triggered with transmit result when transmit completes.\n+     * The method should be non-blocking.\n+     *\n+     * @param transmitCompleteListener\n+     *          listener on transmit completion\n+     * @see #awaitTransmitComplete(long, TimeUnit)\n+     */\n+    void addTransmitCompleteListener(FutureEventListener<Integer> transmitCompleteListener) {\n+        transmitComplete.addEventListener(transmitCompleteListener);\n+    }\n+\n+    /**\n+     * Await for the transmit to be complete\n+     *\n+     * @param timeout\n+     *          wait timeout\n+     * @param unit\n+     *          wait timeout unit\n+     */\n+    int awaitTransmitComplete(long timeout, TimeUnit unit)\n+        throws Exception {\n+        return Await.result(transmitComplete,\n+                Duration.fromTimeUnit(timeout, unit));\n+    }\n+\n+    public long getTransmitTime() {\n+        return transmitTime;\n+    }\n+\n+}"},{"sha":"fd22b8fdafc2e652c7d4c54618db3cc4a77e04c0","filename":"src/main/java/com/twitter/distributedlog/BookKeeperClient.java","status":"added","additions":313,"deletions":0,"changes":313,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBookKeeperClient.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBookKeeperClient.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBookKeeperClient.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,313 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.ZooKeeperClient.Credentials;\n+import com.twitter.distributedlog.ZooKeeperClient.DigestCredentials;\n+import com.twitter.distributedlog.exceptions.AlreadyClosedException;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.net.NetUtils;\n+import com.twitter.distributedlog.util.ConfUtils;\n+import com.twitter.util.Future;\n+import com.twitter.util.Promise;\n+import com.twitter.util.Return;\n+import com.twitter.util.Throw;\n+import org.apache.bookkeeper.client.AsyncCallback;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.BookKeeper;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+import org.apache.bookkeeper.client.RegionAwareEnsemblePlacementPolicy;\n+import org.apache.bookkeeper.conf.ClientConfiguration;\n+import org.apache.bookkeeper.feature.FeatureProvider;\n+import org.apache.bookkeeper.net.DNSToSwitchMapping;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.zookeeper.BoundExponentialBackoffRetryPolicy;\n+import org.apache.bookkeeper.zookeeper.RetryPolicy;\n+import org.apache.commons.configuration.ConfigurationException;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.Watcher;\n+import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n+import org.jboss.netty.util.HashedWheelTimer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import com.google.common.base.Optional;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+\n+/**\n+ * BookKeeper Client wrapper over {@link BookKeeper}.\n+ *\n+ * <h3>Metrics</h3>\n+ * <ul>\n+ * <li> bookkeeper operation stats are exposed under current scope by {@link BookKeeper}\n+ * </ul>\n+ */\n+public class BookKeeperClient implements ZooKeeperClient.ZooKeeperSessionExpireNotifier {\n+    static final Logger LOG = LoggerFactory.getLogger(BookKeeperClient.class);\n+\n+    // Parameters to build bookkeeper client\n+    private final DistributedLogConfiguration conf;\n+    private final String name;\n+    private final String zkServers;\n+    private final String ledgersPath;\n+    private final byte[] passwd;\n+    private final ClientSocketChannelFactory channelFactory;\n+    private final HashedWheelTimer requestTimer;\n+    private final StatsLogger statsLogger;\n+\n+    // bookkeeper client state\n+    private boolean closed = false;\n+    private BookKeeper bkc = null;\n+    private ZooKeeperClient zkc;\n+    private final boolean ownZK;\n+    // feature provider\n+    private final Optional<FeatureProvider> featureProvider;\n+\n+    private Watcher sessionExpireWatcher = null;\n+    private AtomicBoolean zkSessionExpired = new AtomicBoolean(false);\n+\n+    @SuppressWarnings(\"deprecation\")\n+    private synchronized void commonInitialization(\n+            DistributedLogConfiguration conf, String ledgersPath,\n+            ClientSocketChannelFactory channelFactory, StatsLogger statsLogger, HashedWheelTimer requestTimer,\n+            boolean registerExpirationHandler)\n+        throws IOException, InterruptedException, KeeperException {\n+        ClientConfiguration bkConfig = new ClientConfiguration();\n+        bkConfig.setAddEntryTimeout(conf.getBKClientWriteTimeout());\n+        bkConfig.setReadTimeout(conf.getBKClientReadTimeout());\n+        bkConfig.setZkLedgersRootPath(ledgersPath);\n+        bkConfig.setZkTimeout(conf.getBKClientZKSessionTimeoutMilliSeconds());\n+        bkConfig.setNumWorkerThreads(conf.getBKClientNumberWorkerThreads());\n+        bkConfig.setEnsemblePlacementPolicy(RegionAwareEnsemblePlacementPolicy.class);\n+        bkConfig.setZkRequestRateLimit(conf.getBKClientZKRequestRateLimit());\n+        bkConfig.setProperty(RegionAwareEnsemblePlacementPolicy.REPP_DISALLOW_BOOKIE_PLACEMENT_IN_REGION_FEATURE_NAME,\n+                DistributedLogConstants.DISALLOW_PLACEMENT_IN_REGION_FEATURE_NAME);\n+        // reload configuration from dl configuration with settings prefixed with 'bkc.'\n+        ConfUtils.loadConfiguration(bkConfig, conf, \"bkc.\");\n+\n+        Class<? extends DNSToSwitchMapping> dnsResolverCls;\n+        try {\n+            dnsResolverCls = conf.getEnsemblePlacementDnsResolverClass();\n+        } catch (ConfigurationException e) {\n+            LOG.error(\"Failed to load bk dns resolver : \", e);\n+            throw new IOException(\"Failed to load bk dns resolver : \", e);\n+        }\n+        final DNSToSwitchMapping dnsResolver =\n+                NetUtils.getDNSResolver(dnsResolverCls, conf.getBkDNSResolverOverrides());\n+\n+        this.bkc = BookKeeper.newBuilder()\n+            .config(bkConfig)\n+            .zk(zkc.get())\n+            .channelFactory(channelFactory)\n+            .statsLogger(statsLogger)\n+            .dnsResolver(dnsResolver)\n+            .requestTimer(requestTimer)\n+            .featureProvider(featureProvider.orNull())\n+            .build();\n+\n+        if (registerExpirationHandler) {\n+            sessionExpireWatcher = this.zkc.registerExpirationHandler(this);\n+        }\n+    }\n+\n+    BookKeeperClient(DistributedLogConfiguration conf,\n+                     String name,\n+                     String zkServers,\n+                     ZooKeeperClient zkc,\n+                     String ledgersPath,\n+                     ClientSocketChannelFactory channelFactory,\n+                     HashedWheelTimer requestTimer,\n+                     StatsLogger statsLogger,\n+                     Optional<FeatureProvider> featureProvider) {\n+        this.conf = conf;\n+        this.name = name;\n+        this.zkServers = zkServers;\n+        this.ledgersPath = ledgersPath;\n+        this.passwd = conf.getBKDigestPW().getBytes(UTF_8);\n+        this.channelFactory = channelFactory;\n+        this.requestTimer = requestTimer;\n+        this.statsLogger = statsLogger;\n+        this.featureProvider = featureProvider;\n+        this.ownZK = null == zkc;\n+        if (null != zkc) {\n+            // reference the passing zookeeper client\n+            this.zkc = zkc;\n+        }\n+    }\n+\n+    private synchronized void initialize() throws IOException {\n+        if (null != this.bkc) {\n+            return;\n+        }\n+        boolean registerExpirationHandler;\n+        if (null == this.zkc) {\n+            int zkSessionTimeout = conf.getBKClientZKSessionTimeoutMilliSeconds();\n+            RetryPolicy retryPolicy = null;\n+            if (conf.getBKClientZKNumRetries() > 0) {\n+                retryPolicy = new BoundExponentialBackoffRetryPolicy(\n+                        conf.getBKClientZKRetryBackoffStartMillis(),\n+                        conf.getBKClientZKRetryBackoffMaxMillis(), conf.getBKClientZKNumRetries());\n+            }\n+\n+            Credentials credentials = Credentials.NONE;\n+            if (conf.getZkAclId() != null) {\n+                credentials = new DigestCredentials(conf.getZkAclId(), conf.getZkAclId());\n+            }\n+\n+            this.zkc = new ZooKeeperClient(name + \":zk\", zkSessionTimeout, 2 * zkSessionTimeout, zkServers,\n+                                           retryPolicy, statsLogger.scope(\"bkc_zkc\"), conf.getZKClientNumberRetryThreads(),\n+                                           conf.getBKClientZKRequestRateLimit(), credentials);\n+        }\n+        registerExpirationHandler = conf.getBKClientZKNumRetries() <= 0;\n+\n+        try {\n+            commonInitialization(conf, ledgersPath, channelFactory, statsLogger, requestTimer, registerExpirationHandler);\n+        } catch (InterruptedException e) {\n+            throw new DLInterruptedException(\"Interrupted on creating bookkeeper client \" + name + \" : \", e);\n+        } catch (KeeperException e) {\n+            throw new ZKException(\"Error on creating bookkeeper client \" + name + \" : \", e);\n+        }\n+\n+        if (ownZK) {\n+            LOG.info(\"BookKeeper Client created {} with its own ZK Client : ledgersPath = {}, numRetries = {}, \" +\n+                    \"sessionTimeout = {}, backoff = {}, maxBackoff = {}, dnsResolver = {}, registerExpirationHandler = {}\",\n+                    new Object[] { name, ledgersPath,\n+                    conf.getBKClientZKNumRetries(), conf.getBKClientZKSessionTimeoutMilliSeconds(),\n+                    conf.getBKClientZKRetryBackoffStartMillis(), conf.getBKClientZKRetryBackoffMaxMillis(),\n+                    conf.getBkDNSResolverOverrides(), registerExpirationHandler });\n+        } else {\n+            LOG.info(\"BookKeeper Client created {} with shared zookeeper client : ledgersPath = {}, numRetries = {}, \" +\n+                    \"sessionTimeout = {}, backoff = {}, maxBackoff = {}, dnsResolver = {}, registerExpirationHandler = {}\",\n+                    new Object[] { name, ledgersPath,\n+                    conf.getZKNumRetries(), conf.getZKSessionTimeoutMilliseconds(),\n+                    conf.getZKRetryBackoffStartMillis(), conf.getZKRetryBackoffMaxMillis(),\n+                    conf.getBkDNSResolverOverrides(), registerExpirationHandler });\n+        }\n+    }\n+\n+\n+    public synchronized BookKeeper get() throws IOException {\n+        checkClosedOrInError();\n+        if (null == bkc) {\n+            initialize();\n+        }\n+        return bkc;\n+    }\n+\n+    // Util functions\n+    public Future<LedgerHandle> createLedger(int ensembleSize,\n+                                             int writeQuorumSize,\n+                                             int ackQuorumSize) {\n+        BookKeeper bk;\n+        try {\n+            bk = get();\n+        } catch (IOException ioe) {\n+            return Future.exception(ioe);\n+        }\n+        final Promise<LedgerHandle> promise = new Promise<LedgerHandle>();\n+        bk.asyncCreateLedger(ensembleSize, writeQuorumSize, ackQuorumSize,\n+                BookKeeper.DigestType.CRC32, passwd, new AsyncCallback.CreateCallback() {\n+                    @Override\n+                    public void createComplete(int rc, LedgerHandle lh, Object ctx) {\n+                        if (BKException.Code.OK == rc) {\n+                            promise.updateIfEmpty(new Return<LedgerHandle>(lh));\n+                        } else {\n+                            promise.updateIfEmpty(new Throw<LedgerHandle>(BKException.create(rc)));\n+                        }\n+                    }\n+                }, null);\n+        return promise;\n+    }\n+\n+    public Future<Void> deleteLedger(long lid,\n+                                     final boolean ignoreNonExistentLedger) {\n+        BookKeeper bk;\n+        try {\n+            bk = get();\n+        } catch (IOException ioe) {\n+            return Future.exception(ioe);\n+        }\n+        final Promise<Void> promise = new Promise<Void>();\n+        bk.asyncDeleteLedger(lid, new AsyncCallback.DeleteCallback() {\n+            @Override\n+            public void deleteComplete(int rc, Object ctx) {\n+                if (BKException.Code.OK == rc) {\n+                    promise.updateIfEmpty(new Return<Void>(null));\n+                } else if (BKException.Code.NoSuchLedgerExistsException == rc) {\n+                    if (ignoreNonExistentLedger) {\n+                        promise.updateIfEmpty(new Return<Void>(null));\n+                    } else {\n+                        promise.updateIfEmpty(new Throw<Void>(BKException.create(rc)));\n+                    }\n+                } else {\n+                    promise.updateIfEmpty(new Throw<Void>(BKException.create(rc)));\n+                }\n+            }\n+        }, null);\n+        return promise;\n+    }\n+\n+    public synchronized void close() {\n+        if (closed) {\n+            return;\n+        }\n+\n+        LOG.info(\"BookKeeper Client closed {}\", name);\n+        if (null != bkc) {\n+            try {\n+                bkc.close();\n+            } catch (InterruptedException e) {\n+                LOG.warn(\"Interrupted on closing bookkeeper client {} : \", name, e);\n+                Thread.currentThread().interrupt();\n+            } catch (BKException e) {\n+                LOG.warn(\"Error on closing bookkeeper client {} : \", name, e);\n+            }\n+        }\n+        if (null != zkc) {\n+            if (null != sessionExpireWatcher) {\n+                zkc.unregister(sessionExpireWatcher);\n+            }\n+            if (ownZK) {\n+                zkc.close();\n+            }\n+        }\n+        closed = true;\n+    }\n+\n+    @Override\n+    public void notifySessionExpired() {\n+        zkSessionExpired.set(true);\n+    }\n+\n+    public synchronized void checkClosedOrInError() throws AlreadyClosedException {\n+        if (closed) {\n+            LOG.error(\"BookKeeper Client {} is already closed\", name);\n+            throw new AlreadyClosedException(\"BookKeeper Client \" + name + \" is already closed\");\n+        }\n+\n+        if (zkSessionExpired.get()) {\n+            LOG.error(\"BookKeeper Client {}'s Zookeeper session has expired\", name);\n+            throw new AlreadyClosedException(\"BookKeeper Client \" + name + \"'s Zookeeper session has expired\");\n+        }\n+    }\n+}"},{"sha":"cad1096f5549315128b93a2a4a3ed5ee5a4fd68a","filename":"src/main/java/com/twitter/distributedlog/BookKeeperClientBuilder.java","status":"added","additions":209,"deletions":0,"changes":209,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBookKeeperClientBuilder.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBookKeeperClientBuilder.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBookKeeperClientBuilder.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,209 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Optional;\n+import com.google.common.base.Preconditions;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n+import org.jboss.netty.util.HashedWheelTimer;\n+import org.apache.bookkeeper.feature.FeatureProvider;\n+\n+import org.apache.bookkeeper.feature.Feature;\n+\n+/**\n+ * Builder to build bookkeeper client.\n+ */\n+public class BookKeeperClientBuilder {\n+\n+    /**\n+     * Create a bookkeeper client builder to build bookkeeper clients.\n+     *\n+     * @return bookkeeper client builder.\n+     */\n+    public static BookKeeperClientBuilder newBuilder() {\n+        return new BookKeeperClientBuilder();\n+    }\n+\n+    // client name\n+    private String name = null;\n+    // dl config\n+    private DistributedLogConfiguration dlConfig = null;\n+    // bookkeeper settings\n+    // zookeeper client\n+    private ZooKeeperClient zkc = null;\n+    // or zookeeper servers\n+    private String zkServers = null;\n+    // ledgers path\n+    private String ledgersPath = null;\n+    // statsLogger\n+    private StatsLogger statsLogger = NullStatsLogger.INSTANCE;\n+    // client channel factory\n+    private ClientSocketChannelFactory channelFactory = null;\n+    // request timer\n+    private HashedWheelTimer requestTimer = null;\n+    // feature provider\n+    private Optional<FeatureProvider> featureProvider = Optional.absent();\n+\n+    // Cached BookKeeper Client\n+    private BookKeeperClient cachedClient = null;\n+\n+    /**\n+     * Private bookkeeper builder.\n+     */\n+    private BookKeeperClientBuilder() {}\n+\n+    /**\n+     * Set client name.\n+     *\n+     * @param name\n+     *          client name.\n+     * @return builder\n+     */\n+    public synchronized BookKeeperClientBuilder name(String name) {\n+        this.name = name;\n+        return this;\n+    }\n+\n+    /**\n+     * <i>dlConfig</i> used to configure bookkeeper client.\n+     *\n+     * @param dlConfig\n+     *          distributedlog config.\n+     * @return builder.\n+     */\n+    public synchronized BookKeeperClientBuilder dlConfig(DistributedLogConfiguration dlConfig) {\n+        this.dlConfig = dlConfig;\n+        return this;\n+    }\n+\n+    /**\n+     * Set the zkc used to build bookkeeper client. If a zookeeper client is provided in this\n+     * method, bookkeeper client will use it rather than creating a brand new one.\n+     *\n+     * @param zkc\n+     *          zookeeper client.\n+     * @return builder\n+     * @see #zkServers(String)\n+     */\n+    public synchronized BookKeeperClientBuilder zkc(ZooKeeperClient zkc) {\n+        this.zkc = zkc;\n+        return this;\n+    }\n+\n+    /**\n+     * Set the zookeeper servers that bookkeeper client would connect to. If no zookeeper client\n+     * is provided by {@link #zkc(ZooKeeperClient)}, bookkeeper client will use the given string\n+     * to create a brand new zookeeper client.\n+     *\n+     * @param zkServers\n+     *          zookeeper servers that bookkeeper client would connect to.\n+     * @return builder\n+     * @see #zkc(ZooKeeperClient)\n+     */\n+    public synchronized BookKeeperClientBuilder zkServers(String zkServers) {\n+        this.zkServers = zkServers;\n+        return this;\n+    }\n+\n+    /**\n+     * Set the ledgers path that bookkeeper client is going to access.\n+     *\n+     * @param ledgersPath\n+     *          ledgers path\n+     * @return builder\n+     * @see org.apache.bookkeeper.conf.ClientConfiguration#getZkLedgersRootPath()\n+     */\n+    public synchronized BookKeeperClientBuilder ledgersPath(String ledgersPath) {\n+        this.ledgersPath = ledgersPath;\n+        return this;\n+    }\n+\n+    /**\n+     * Build BookKeeper client using existing <i>bkc</i> client.\n+     *\n+     * @param bkc\n+     *          bookkeeper client.\n+     * @return builder\n+     */\n+    public synchronized BookKeeperClientBuilder bkc(BookKeeperClient bkc) {\n+        this.cachedClient = bkc;\n+        return this;\n+    }\n+\n+    /**\n+     * Build BookKeeper client using existing <i>channelFactory</i>.\n+     *\n+     * @param channelFactory\n+     *          Channel Factory used to build bookkeeper client.\n+     * @return bookkeeper client builder.\n+     */\n+    public synchronized BookKeeperClientBuilder channelFactory(ClientSocketChannelFactory channelFactory) {\n+        this.channelFactory = channelFactory;\n+        return this;\n+    }\n+\n+    /**\n+     * Build BookKeeper client using existing <i>request timer</i>.\n+     *\n+     * @param requestTimer\n+     *          HashedWheelTimer used to build bookkeeper client.\n+     * @return bookkeeper client builder.\n+     */\n+    public synchronized BookKeeperClientBuilder requestTimer(HashedWheelTimer requestTimer) {\n+        this.requestTimer = requestTimer;\n+        return this;\n+    }\n+\n+    /**\n+     * Build BookKeeper Client using given stats logger <i>statsLogger</i>.\n+     *\n+     * @param statsLogger\n+     *          stats logger to report stats\n+     * @return builder.\n+     */\n+    public synchronized BookKeeperClientBuilder statsLogger(StatsLogger statsLogger) {\n+        this.statsLogger = statsLogger;\n+        return this;\n+    }\n+\n+    public synchronized BookKeeperClientBuilder featureProvider(Optional<FeatureProvider> featureProvider) {\n+        this.featureProvider = featureProvider;\n+        return this;\n+    }\n+\n+    private void validateParameters() {\n+        Preconditions.checkNotNull(name, \"Missing client name.\");\n+        Preconditions.checkNotNull(dlConfig, \"Missing DistributedLog Configuration.\");\n+        Preconditions.checkArgument(null == zkc || null == zkServers, \"Missing zookeeper setting.\");\n+        Preconditions.checkNotNull(ledgersPath, \"Missing Ledgers Root Path.\");\n+    }\n+\n+    public synchronized BookKeeperClient build() {\n+        if (null == cachedClient) {\n+            cachedClient = buildClient();\n+        }\n+        return cachedClient;\n+    }\n+\n+    private BookKeeperClient buildClient() {\n+        validateParameters();\n+        return new BookKeeperClient(dlConfig, name, zkServers, zkc, ledgersPath, channelFactory, requestTimer, statsLogger, featureProvider);\n+    }\n+}"},{"sha":"639de210ec31f735d7dcc62e0a5a560b5d3abcdf","filename":"src/main/java/com/twitter/distributedlog/DistributedLogConfiguration.java","status":"added","additions":3340,"deletions":0,"changes":3340,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"8a6d8249bb15f236ffa04e839fb6160218339752","filename":"src/main/java/com/twitter/distributedlog/DistributedLogConstants.java","status":"added","additions":68,"deletions":0,"changes":68,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConstants.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConstants.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConstants.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,68 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.zookeeper.ZooDefs.Ids;\n+import org.apache.zookeeper.data.ACL;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+\n+public class DistributedLogConstants {\n+    public static final byte[] EMPTY_BYTES = new byte[0];\n+    public static final String SCHEME_PREFIX = \"distributedlog\";\n+    public static final String BACKEND_BK = \"bk\";\n+    public static final long INVALID_TXID = -999;\n+    public static final long EMPTY_LOGSEGMENT_TX_ID = -99;\n+    public static final long MAX_TXID = Long.MAX_VALUE;\n+    public static final long SMALL_LOGSEGMENT_THRESHOLD = 10;\n+    public static final int LOGSEGMENT_NAME_VERSION = 1;\n+    public static final int FUTURE_TIMEOUT_IMMEDIATE = 0;\n+    public static final int FUTURE_TIMEOUT_INFINITE = -1;\n+    public static final long LOCK_IMMEDIATE = FUTURE_TIMEOUT_IMMEDIATE;\n+    public static final long LOCK_TIMEOUT_INFINITE = FUTURE_TIMEOUT_INFINITE;\n+    public static final long LOCK_OP_TIMEOUT_DEFAULT = 120;\n+    public static final long LOCK_REACQUIRE_TIMEOUT_DEFAULT = 120;\n+    public static final String UNKNOWN_CLIENT_ID = \"Unknown-ClientId\";\n+    public static final int LOCAL_REGION_ID = 0;\n+    public static final long LOGSEGMENT_DEFAULT_STATUS = 0;\n+    public static final long UNASSIGNED_LOGSEGMENT_SEQNO = 0;\n+    public static final long UNASSIGNED_SEQUENCE_ID = -1L;\n+    public static final long FIRST_LOGSEGMENT_SEQNO = 1;\n+    public static final long UNRESOLVED_LEDGER_ID = -1;\n+    public static final long LATENCY_WARN_THRESHOLD_IN_MILLIS = TimeUnit.SECONDS.toMillis(1);\n+    public static final int DL_INTERRUPTED_EXCEPTION_RESULT_CODE = Integer.MIN_VALUE + 1;\n+    public static final int ZK_CONNECTION_EXCEPTION_RESULT_CODE = Integer.MIN_VALUE + 2;\n+\n+    public static final String ALLOCATION_POOL_NODE = \".allocation_pool\";\n+    // log segment prefix\n+    public static final String INPROGRESS_LOGSEGMENT_PREFIX = \"inprogress\";\n+    public static final String COMPLETED_LOGSEGMENT_PREFIX = \"logrecs\";\n+    public static final String DISALLOW_PLACEMENT_IN_REGION_FEATURE_NAME = \"disallow_bookie_placement\";\n+    public static final byte[] CONTROL_RECORD_CONTENT = \"control\".getBytes(UTF_8);\n+\n+    // An ACL that gives all permissions to node creators and read permissions only to everyone else.\n+    public static final List<ACL> EVERYONE_READ_CREATOR_ALL =\n+        ImmutableList.<ACL>builder()\n+            .addAll(Ids.CREATOR_ALL_ACL)\n+            .addAll(Ids.READ_ACL_UNSAFE)\n+            .build();\n+}"},{"sha":"ccb07784ba9355cf0f5d013441ec86e48218bcde","filename":"src/main/java/com/twitter/distributedlog/DistributedLogManager.java","status":"added","additions":300,"deletions":0,"changes":300,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,300 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.callback.LogSegmentListener;\n+import com.twitter.distributedlog.subscription.SubscriptionStateStore;\n+import com.twitter.distributedlog.subscription.SubscriptionsStore;\n+import com.twitter.util.Future;\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * A DistributedLogManager is responsible for managing a single place of storing\n+ * edit logs. It may correspond to multiple files, a backup node, etc.\n+ * Even when the actual underlying storage is rolled, or failed and restored,\n+ * each conceptual place of storage corresponds to exactly one instance of\n+ * this class, which is created when the EditLog is first opened.\n+ */\n+public interface DistributedLogManager extends MetadataAccessor {\n+\n+    /**\n+     * Get log segments.\n+     *\n+     * @return log segments\n+     * @throws IOException\n+     */\n+    public List<LogSegmentMetadata> getLogSegments() throws IOException;\n+\n+    /**\n+     * Register <i>listener</i> on log segment updates of this stream.\n+     *\n+     * @param listener\n+     *          listener to receive update log segment list.\n+     */\n+    public void registerListener(LogSegmentListener listener) throws IOException ;\n+\n+    /**\n+     * Unregister <i>listener</i> on log segment updates from this stream.\n+     *\n+     * @param listener\n+     *          listener to receive update log segment list.\n+     */\n+    public void unregisterListener(LogSegmentListener listener);\n+\n+    /**\n+     * Open async log writer to write records to the log stream.\n+     *\n+     * @return result represents the open result\n+     */\n+    public Future<AsyncLogWriter> openAsyncLogWriter();\n+\n+    /**\n+     * Begin writing to the log stream identified by the name\n+     *\n+     * @return the writer interface to generate log records\n+     */\n+    public LogWriter startLogSegmentNonPartitioned() throws IOException;\n+\n+    /**\n+     * Begin writing to the log stream identified by the name\n+     *\n+     * @return the writer interface to generate log records\n+     */\n+    // @Deprecated\n+    public AsyncLogWriter startAsyncLogSegmentNonPartitioned() throws IOException;\n+\n+    /**\n+     * Begin appending to the end of the log stream which is being treated as a sequence of bytes\n+     *\n+     * @return the writer interface to generate log records\n+     */\n+    public AppendOnlyStreamWriter getAppendOnlyStreamWriter() throws IOException;\n+\n+    /**\n+     * Get a reader to read a log stream as a sequence of bytes\n+     *\n+     * @return the writer interface to generate log records\n+     */\n+    public AppendOnlyStreamReader getAppendOnlyStreamReader() throws IOException;\n+\n+    /**\n+     * Get the input stream starting with fromTxnId for the specified log\n+     *\n+     * @param fromTxnId - the first transaction id we want to read\n+     * @return the stream starting with transaction fromTxnId\n+     * @throws IOException if a stream cannot be found.\n+     */\n+    public LogReader getInputStream(long fromTxnId)\n+        throws IOException;\n+\n+    public LogReader getInputStream(DLSN fromDLSN) throws IOException;\n+\n+    /**\n+     * Open an async log reader to read records from a log starting from <code>fromTxnId</code>.\n+     *\n+     * @param fromTxnId\n+     *          transaction id to start reading from\n+     * @return async log reader\n+     */\n+    public Future<AsyncLogReader> openAsyncLogReader(long fromTxnId);\n+\n+    /**\n+     * Open an async log reader to read records from a log starting from <code>fromDLSN</code>\n+     *\n+     * @param fromDLSN\n+     *          dlsn to start reading from\n+     * @return async log reader\n+     */\n+    public Future<AsyncLogReader> openAsyncLogReader(DLSN fromDLSN);\n+\n+    // @Deprecated\n+    public AsyncLogReader getAsyncLogReader(long fromTxnId) throws IOException;\n+\n+    // @Deprecated\n+    public AsyncLogReader getAsyncLogReader(DLSN fromDLSN) throws IOException;\n+\n+    public Future<AsyncLogReader> getAsyncLogReaderWithLock(DLSN fromDLSN);\n+\n+    /**\n+     * Get a log reader with lock starting from <i>fromDLSN</i> and using <i>subscriberId</i>.\n+     * If two readers tried to open using same subscriberId, one would succeed, while the other\n+     * will be blocked until it gets the lock.\n+     *\n+     * @param fromDLSN\n+     *          start dlsn\n+     * @param subscriberId\n+     *          subscriber id\n+     * @return async log reader\n+     */\n+    public Future<AsyncLogReader> getAsyncLogReaderWithLock(DLSN fromDLSN, String subscriberId);\n+\n+    /**\n+     * Get a log reader using <i>subscriberId</i> with lock. The reader will start reading from\n+     * its last commit position recorded in subscription store. If no last commit position found\n+     * in subscription store, it would start reading from head of the stream.\n+     *\n+     * If the two readers tried to open using same subscriberId, one would succeed, while the other\n+     * will be blocked until it gets the lock.\n+     *\n+     * @param subscriberId\n+     *          subscriber id\n+     * @return async log reader\n+     */\n+    public Future<AsyncLogReader> getAsyncLogReaderWithLock(String subscriberId);\n+\n+    /**\n+     * Get the {@link DLSN} of first log record whose transaction id is not less than <code>transactionId</code>.\n+     *\n+     * @param transactionId\n+     *          transaction id\n+     * @return dlsn of first log record whose transaction id is not less than transactionId.\n+     */\n+    public Future<DLSN> getDLSNNotLessThanTxId(long transactionId);\n+\n+    /**\n+     * Get the last log record in the stream\n+     *\n+     * @return the last log record in the stream\n+     * @throws IOException if a stream cannot be found.\n+     */\n+    public LogRecordWithDLSN getLastLogRecord()\n+        throws IOException;\n+\n+    /**\n+     * Get the earliest Transaction Id available in the log\n+     *\n+     * @return earliest transaction id\n+     * @throws IOException\n+     */\n+    public long getFirstTxId() throws IOException;\n+\n+    /**\n+     * Get Latest Transaction Id in the log\n+     *\n+     * @return latest transaction id\n+     * @throws IOException\n+     */\n+    public long getLastTxId() throws IOException;\n+\n+    /**\n+     * Get Latest DLSN in the log\n+     *\n+     * @return last dlsn\n+     * @throws IOException\n+     */\n+    public DLSN getLastDLSN() throws IOException;\n+\n+    /**\n+     * Get Latest log record with DLSN in the log - async\n+     *\n+     * @return latest log record with DLSN\n+     */\n+    public Future<LogRecordWithDLSN> getLastLogRecordAsync();\n+\n+    /**\n+     * Get Latest Transaction Id in the log - async\n+     *\n+     * @return latest transaction id\n+     */\n+    public Future<Long> getLastTxIdAsync();\n+\n+    /**\n+     * Get first DLSN in the log.\n+     *\n+     * @return first dlsn in the stream\n+     */\n+    public Future<DLSN> getFirstDLSNAsync();\n+\n+    /**\n+     * Get Latest DLSN in the log - async\n+     *\n+     * @return latest transaction id\n+     */\n+    public Future<DLSN> getLastDLSNAsync();\n+\n+    /**\n+     * Get the number of log records in the active portion of the log\n+     * Any log segments that have already been truncated will not be included\n+     *\n+     * @return number of log records\n+     * @throws IOException\n+     */\n+    public long getLogRecordCount() throws IOException;\n+\n+    /**\n+     * Get the number of log records in the active portion of the log - async.\n+     * Any log segments that have already been truncated will not be included\n+     *\n+     * @return future number of log records\n+     * @throws IOException\n+     */\n+    public Future<Long> getLogRecordCountAsync(final DLSN beginDLSN);\n+\n+    /**\n+     * Run recovery on the log.\n+     *\n+     * @throws IOException\n+     */\n+    public void recover() throws IOException;\n+\n+    /**\n+     * Check if an end of stream marker was added to the stream\n+     * A stream with an end of stream marker cannot be appended to\n+     *\n+     * @return true if the marker was added to the stream, false otherwise\n+     * @throws IOException\n+     */\n+    public boolean isEndOfStreamMarked() throws IOException;\n+\n+    /**\n+     * Delete the log.\n+     *\n+     * @throws IOException if the deletion fails\n+     */\n+    public void delete() throws IOException;\n+\n+    /**\n+     * The DistributedLogManager may archive/purge any logs for transactionId\n+     * less than or equal to minImageTxId.\n+     * This is to be used only when the client explicitly manages deletion. If\n+     * the cleanup policy is based on sliding time window, then this method need\n+     * not be called.\n+     *\n+     * @param minTxIdToKeep the earliest txid that must be retained\n+     * @throws IOException if purging fails\n+     */\n+    public void purgeLogsOlderThan(long minTxIdToKeep) throws IOException;\n+\n+    /**\n+     * Get the subscription state storage provided by the distributed log manager\n+     *\n+     * @param subscriberId - Application specific Id associated with the subscriber\n+     * @return Subscription state store\n+     */\n+    @Deprecated\n+    public SubscriptionStateStore getSubscriptionStateStore(String subscriberId);\n+\n+    /**\n+     * Get the subscriptions store provided by the distributedlog manager.\n+     *\n+     * @return subscriptions store manages subscriptions for current stream.\n+     */\n+    public SubscriptionsStore getSubscriptionsStore();\n+\n+}"},{"sha":"4caeeba104c88a265e699d7259e350da06977628","filename":"src/main/java/com/twitter/distributedlog/DistributedLogManagerFactory.java","status":"added","additions":202,"deletions":0,"changes":202,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogManagerFactory.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogManagerFactory.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogManagerFactory.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,202 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Optional;\n+import com.twitter.distributedlog.acl.AccessControlManager;\n+import com.twitter.distributedlog.callback.NamespaceListener;\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+import com.twitter.distributedlog.exceptions.InvalidStreamNameException;\n+import com.twitter.distributedlog.namespace.DistributedLogNamespace;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.Collection;\n+import java.util.Map;\n+\n+/**\n+ * This is the legacy way to access bookkeeper based distributedlog namespace.\n+ * Use {@link DistributedLogNamespace} to manage logs instead if you could.\n+ */\n+@Deprecated\n+public class DistributedLogManagerFactory {\n+    static final Logger LOG = LoggerFactory.getLogger(DistributedLogManagerFactory.class);\n+\n+    public static enum ClientSharingOption {\n+        PerStreamClients,\n+        SharedZKClientPerStreamBKClient,\n+        SharedClients\n+    }\n+\n+    private final BKDistributedLogNamespace namespace;\n+\n+    public DistributedLogManagerFactory(DistributedLogConfiguration conf, URI uri)\n+            throws IOException, IllegalArgumentException {\n+        this(conf, uri, NullStatsLogger.INSTANCE);\n+    }\n+\n+    public DistributedLogManagerFactory(DistributedLogConfiguration conf, URI uri,\n+                                        StatsLogger statsLogger)\n+            throws IOException, IllegalArgumentException {\n+        this(conf,\n+             uri,\n+             statsLogger,\n+             DistributedLogConstants.UNKNOWN_CLIENT_ID,\n+             DistributedLogConstants.LOCAL_REGION_ID);\n+    }\n+\n+    public DistributedLogManagerFactory(DistributedLogConfiguration conf,\n+                                        URI uri,\n+                                        StatsLogger statsLogger,\n+                                        String clientId,\n+                                        int regionId)\n+            throws IOException, IllegalArgumentException {\n+        this.namespace = BKDistributedLogNamespace.newBuilder()\n+                .conf(conf)\n+                .uri(uri)\n+                .statsLogger(statsLogger)\n+                .clientId(clientId)\n+                .regionId(regionId)\n+                .build();\n+    }\n+\n+    public DistributedLogNamespace getNamespace() {\n+        return namespace;\n+    }\n+\n+    public void registerNamespaceListener(NamespaceListener listener) {\n+        namespace.registerNamespaceListener(listener);\n+    }\n+\n+    /**\n+     * Create a DistributedLogManager for <i>nameOfLogStream</i>, with default shared clients.\n+     *\n+     * @param nameOfLogStream\n+     *          name of log stream\n+     * @return distributedlog manager\n+     * @throws com.twitter.distributedlog.exceptions.InvalidStreamNameException if stream name is invalid\n+     * @throws IOException\n+     */\n+    public DistributedLogManager createDistributedLogManagerWithSharedClients(String nameOfLogStream)\n+        throws InvalidStreamNameException, IOException {\n+        return createDistributedLogManager(nameOfLogStream, ClientSharingOption.SharedClients);\n+    }\n+\n+    /**\n+     * Create a DistributedLogManager for <i>nameOfLogStream</i>, with specified client sharing options.\n+     *\n+     * @param nameOfLogStream\n+     *          name of log stream.\n+     * @param clientSharingOption\n+     *          specifies if the ZK/BK clients are shared\n+     * @return distributedlog manager instance.\n+     * @throws com.twitter.distributedlog.exceptions.InvalidStreamNameException if stream name is invalid\n+     * @throws IOException\n+     */\n+    public DistributedLogManager createDistributedLogManager(\n+            String nameOfLogStream,\n+            ClientSharingOption clientSharingOption)\n+        throws InvalidStreamNameException, IOException {\n+        Optional<DistributedLogConfiguration> streamConfiguration = Optional.absent();\n+        Optional<DynamicDistributedLogConfiguration> dynamicStreamConfiguration = Optional.absent();\n+        return createDistributedLogManager(nameOfLogStream,\n+            clientSharingOption,\n+            streamConfiguration,\n+            dynamicStreamConfiguration);\n+    }\n+\n+    /**\n+     * Create a DistributedLogManager for <i>nameOfLogStream</i>, with specified client sharing options.\n+     * This method allows the caller to override global configuration options by supplying stream\n+     * configuration overrides. Stream config overrides come in two flavors, static and dynamic. Static\n+     * config never changes, and DynamicDistributedLogConfiguration is a) reloaded periodically and\n+     * b) safe to access from any context.\n+     *\n+     * @param nameOfLogStream\n+     *          name of log stream.\n+     * @param clientSharingOption\n+     *          specifies if the ZK/BK clients are shared\n+     * @param streamConfiguration\n+     *          stream configuration overrides.\n+     * @param dynamicStreamConfiguration\n+     *          dynamic stream configuration overrides.\n+     * @return distributedlog manager instance.\n+     * @throws com.twitter.distributedlog.exceptions.InvalidStreamNameException if stream name is invalid\n+     * @throws IOException\n+     */\n+    public DistributedLogManager createDistributedLogManager(\n+            String nameOfLogStream,\n+            ClientSharingOption clientSharingOption,\n+            Optional<DistributedLogConfiguration> streamConfiguration,\n+            Optional<DynamicDistributedLogConfiguration> dynamicStreamConfiguration)\n+        throws InvalidStreamNameException, IOException {\n+        return namespace.createDistributedLogManager(\n+            nameOfLogStream,\n+            clientSharingOption,\n+            streamConfiguration,\n+            dynamicStreamConfiguration);\n+    }\n+\n+    public MetadataAccessor createMetadataAccessor(String nameOfMetadataNode)\n+            throws InvalidStreamNameException, IOException {\n+        return namespace.createMetadataAccessor(nameOfMetadataNode);\n+    }\n+\n+    public synchronized AccessControlManager createAccessControlManager() throws IOException {\n+        return namespace.createAccessControlManager();\n+    }\n+\n+    public boolean checkIfLogExists(String nameOfLogStream)\n+        throws IOException, IllegalArgumentException {\n+        return namespace.logExists(nameOfLogStream);\n+    }\n+\n+    public Collection<String> enumerateAllLogsInNamespace()\n+        throws IOException, IllegalArgumentException {\n+        return namespace.enumerateAllLogsInNamespace();\n+    }\n+\n+    public Map<String, byte[]> enumerateLogsWithMetadataInNamespace()\n+        throws IOException, IllegalArgumentException {\n+        return namespace.enumerateLogsWithMetadataInNamespace();\n+    }\n+\n+    /**\n+     * This method is to initialize the metadata for a unpartitioned stream with name <i>streamName</i>.\n+     *\n+     * TODO: after 0.2 is upgraded to 0.3, remove this.\n+     *\n+     * @param streamName\n+     *          stream name.\n+     * @throws IOException\n+     */\n+    public void createUnpartitionedStream(final String streamName) throws IOException {\n+        namespace.createLog(streamName);\n+    }\n+\n+    /**\n+     * Close the distributed log manager factory, freeing any resources it may hold.\n+     */\n+    public void close() {\n+        namespace.close();\n+    }\n+}"},{"sha":"b1bd701027c1dd2bc946cf8d4e1a195e6b22adbb","filename":"src/main/java/com/twitter/distributedlog/Entry.java","status":"added","additions":389,"deletions":0,"changes":389,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEntry.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEntry.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEntry.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,389 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Optional;\n+import com.google.common.base.Preconditions;\n+import com.twitter.distributedlog.exceptions.LogRecordTooLongException;\n+import com.twitter.distributedlog.exceptions.WriteException;\n+import com.twitter.distributedlog.io.CompressionCodec;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+\n+import javax.annotation.Nullable;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+/**\n+ * A set of {@link LogRecord}s.\n+ */\n+public class Entry {\n+\n+    /**\n+     * Create a new log record set.\n+     *\n+     * @param logName\n+     *          name of the log\n+     * @param initialBufferSize\n+     *          initial buffer size\n+     * @param envelopeBeforeTransmit\n+     *          if envelope the buffer before transmit\n+     * @param codec\n+     *          compression codec\n+     * @param statsLogger\n+     *          stats logger to receive stats\n+     * @return writer to build a log record set.\n+     */\n+    public static Writer newEntry(\n+            String logName,\n+            int initialBufferSize,\n+            boolean envelopeBeforeTransmit,\n+            CompressionCodec.Type codec,\n+            StatsLogger statsLogger) {\n+        return new EnvelopedEntryWriter(\n+                logName,\n+                initialBufferSize,\n+                envelopeBeforeTransmit,\n+                codec,\n+                statsLogger);\n+    }\n+\n+    public static Builder newBuilder() {\n+        return new Builder();\n+    }\n+\n+    /**\n+     * Build the record set object.\n+     */\n+    public static class Builder {\n+\n+        private long logSegmentSequenceNumber = -1;\n+        private long entryId = -1;\n+        private long startSequenceId = Long.MIN_VALUE;\n+        private boolean envelopeEntry = true;\n+        // input stream\n+        private InputStream in = null;\n+        // or bytes array\n+        private byte[] data = null;\n+        private int offset = -1;\n+        private int length = -1;\n+        private Optional<Long> txidToSkipTo = Optional.absent();\n+        private Optional<DLSN> dlsnToSkipTo = Optional.absent();\n+        private boolean deserializeRecordSet = true;\n+\n+        private Builder() {}\n+\n+        /**\n+         * Reset the builder.\n+         *\n+         * @return builder\n+         */\n+        public Builder reset() {\n+            logSegmentSequenceNumber = -1;\n+            entryId = -1;\n+            startSequenceId = Long.MIN_VALUE;\n+            envelopeEntry = true;\n+            // input stream\n+            in = null;\n+            // or bytes array\n+            data = null;\n+            offset = -1;\n+            length = -1;\n+            txidToSkipTo = Optional.absent();\n+            dlsnToSkipTo = Optional.absent();\n+            return this;\n+        }\n+\n+        /**\n+         * Set the segment info of the log segment that this record\n+         * set belongs to.\n+         *\n+         * @param lssn\n+         *          log segment sequence number\n+         * @param startSequenceId\n+         *          start sequence id of this log segment\n+         * @return builder\n+         */\n+        public Builder setLogSegmentInfo(long lssn, long startSequenceId) {\n+            this.logSegmentSequenceNumber = lssn;\n+            this.startSequenceId = startSequenceId;\n+            return this;\n+        }\n+\n+        /**\n+         * Set the entry id of this log record set.\n+         *\n+         * @param entryId\n+         *          entry id assigned for this log record set.\n+         * @return builder\n+         */\n+        public Builder setEntryId(long entryId) {\n+            this.entryId = entryId;\n+            return this;\n+        }\n+\n+        /**\n+         * Set whether this record set is enveloped or not.\n+         *\n+         * @param enabled\n+         *          flag indicates whether this record set is enveloped or not.\n+         * @return builder\n+         */\n+        public Builder setEnvelopeEntry(boolean enabled) {\n+            this.envelopeEntry = enabled;\n+            return this;\n+        }\n+\n+        /**\n+         * Set the serialized bytes data of this record set.\n+         *\n+         * @param data\n+         *          serialized bytes data of this record set.\n+         * @param offset\n+         *          offset of the bytes data\n+         * @param length\n+         *          length of the bytes data\n+         * @return builder\n+         */\n+        public Builder setData(byte[] data, int offset, int length) {\n+            this.data = data;\n+            this.offset = offset;\n+            this.length = length;\n+            return this;\n+        }\n+\n+        /**\n+         * Set the input stream of the serialized bytes data of this record set.\n+         *\n+         * @param in\n+         *          input stream\n+         * @return builder\n+         */\n+        public Builder setInputStream(InputStream in) {\n+            this.in = in;\n+            return this;\n+        }\n+\n+        /**\n+         * Set the record set starts from <code>dlsn</code>.\n+         *\n+         * @param dlsn\n+         *          dlsn to skip to\n+         * @return builder\n+         */\n+        public Builder skipTo(@Nullable DLSN dlsn) {\n+            this.dlsnToSkipTo = Optional.fromNullable(dlsn);\n+            return this;\n+        }\n+\n+        /**\n+         * Set the record set starts from <code>txid</code>.\n+         *\n+         * @param txid\n+         *          txid to skip to\n+         * @return builder\n+         */\n+        public Builder skipTo(long txid) {\n+            this.txidToSkipTo = Optional.of(txid);\n+            return this;\n+        }\n+\n+        /**\n+         * Enable/disable deserialize record set.\n+         *\n+         * @param enabled\n+         *          flag to enable/disable dserialize record set.\n+         * @return builder\n+         */\n+        public Builder deserializeRecordSet(boolean enabled) {\n+            this.deserializeRecordSet = enabled;\n+            return this;\n+        }\n+\n+        public Entry build() {\n+            Preconditions.checkNotNull(data, \"Serialized data isn't provided\");\n+            Preconditions.checkArgument(offset >= 0 && length >= 0\n+                    && (offset + length) <= data.length,\n+                    \"Invalid offset or length of serialized data\");\n+            return new Entry(\n+                    logSegmentSequenceNumber,\n+                    entryId,\n+                    startSequenceId,\n+                    envelopeEntry,\n+                    deserializeRecordSet,\n+                    data,\n+                    offset,\n+                    length,\n+                    txidToSkipTo,\n+                    dlsnToSkipTo);\n+        }\n+\n+        public Entry.Reader buildReader() throws IOException {\n+            Preconditions.checkArgument(data != null || in != null,\n+                    \"Serialized data or input stream isn't provided\");\n+            InputStream in;\n+            if (null != this.in) {\n+                in = this.in;\n+            } else {\n+                Preconditions.checkArgument(offset >= 0 && length >= 0\n+                                && (offset + length) <= data.length,\n+                        \"Invalid offset or length of serialized data\");\n+                in = new ByteArrayInputStream(data, offset, length);\n+            }\n+            return new EnvelopedEntryReader(\n+                    logSegmentSequenceNumber,\n+                    entryId,\n+                    startSequenceId,\n+                    in,\n+                    envelopeEntry,\n+                    deserializeRecordSet,\n+                    NullStatsLogger.INSTANCE);\n+        }\n+\n+    }\n+\n+    private final long logSegmentSequenceNumber;\n+    private final long entryId;\n+    private final long startSequenceId;\n+    private final boolean envelopedEntry;\n+    private final boolean deserializeRecordSet;\n+    private final byte[] data;\n+    private final int offset;\n+    private final int length;\n+    private final Optional<Long> txidToSkipTo;\n+    private final Optional<DLSN> dlsnToSkipTo;\n+\n+    private Entry(long logSegmentSequenceNumber,\n+                  long entryId,\n+                  long startSequenceId,\n+                  boolean envelopedEntry,\n+                  boolean deserializeRecordSet,\n+                  byte[] data,\n+                  int offset,\n+                  int length,\n+                  Optional<Long> txidToSkipTo,\n+                  Optional<DLSN> dlsnToSkipTo) {\n+        this.logSegmentSequenceNumber = logSegmentSequenceNumber;\n+        this.entryId = entryId;\n+        this.startSequenceId = startSequenceId;\n+        this.envelopedEntry = envelopedEntry;\n+        this.deserializeRecordSet = deserializeRecordSet;\n+        this.data = data;\n+        this.offset = offset;\n+        this.length = length;\n+        this.txidToSkipTo = txidToSkipTo;\n+        this.dlsnToSkipTo = dlsnToSkipTo;\n+    }\n+\n+    /**\n+     * Get raw data of this record set.\n+     *\n+     * @return raw data representation of this record set.\n+     */\n+    public byte[] getRawData() {\n+        return data;\n+    }\n+\n+    /**\n+     * Create reader to iterate over this record set.\n+     *\n+     * @return reader to iterate over this record set.\n+     * @throws IOException if the record set is invalid record set.\n+     */\n+    public Reader reader() throws IOException {\n+        InputStream in = new ByteArrayInputStream(data, offset, length);\n+        Reader reader = new EnvelopedEntryReader(\n+                logSegmentSequenceNumber,\n+                entryId,\n+                startSequenceId,\n+                in,\n+                envelopedEntry,\n+                deserializeRecordSet,\n+                NullStatsLogger.INSTANCE);\n+        if (txidToSkipTo.isPresent()) {\n+            reader.skipTo(txidToSkipTo.get());\n+        }\n+        if (dlsnToSkipTo.isPresent()) {\n+            reader.skipTo(dlsnToSkipTo.get());\n+        }\n+        return reader;\n+    }\n+\n+    /**\n+     * Writer to append {@link LogRecord}s to {@link Entry}.\n+     */\n+    public interface Writer extends EntryBuffer {\n+\n+        /**\n+         * Write a {@link LogRecord} to this record set.\n+         *\n+         * @param record\n+         *          record to write\n+         * @param transmitPromise\n+         *          callback for transmit result. the promise is only\n+         *          satisfied when this record set is transmitted.\n+         * @throws LogRecordTooLongException if the record is too long\n+         * @throws WriteException when encountered exception writing the record\n+         */\n+        void writeRecord(LogRecord record, Promise<DLSN> transmitPromise)\n+                throws LogRecordTooLongException, WriteException;\n+\n+        /**\n+         * Reset the writer to write records.\n+         */\n+        void reset();\n+\n+    }\n+\n+    /**\n+     * Reader to read {@link LogRecord}s from this record set.\n+     */\n+    public interface Reader {\n+\n+        /**\n+         * Read next log record from this record set.\n+         *\n+         * @return next log record from this record set.\n+         */\n+        LogRecordWithDLSN nextRecord() throws IOException;\n+\n+        /**\n+         * Skip the reader to the record whose transaction id is <code>txId</code>.\n+         *\n+         * @param txId\n+         *          transaction id to skip to.\n+         * @return true if skip succeeds, otherwise false.\n+         * @throws IOException\n+         */\n+        boolean skipTo(long txId) throws IOException;\n+\n+        /**\n+         * Skip the reader to the record whose DLSN is <code>dlsn</code>.\n+         *\n+         * @param dlsn\n+         *          DLSN to skip to.\n+         * @return true if skip succeeds, otherwise false.\n+         * @throws IOException\n+         */\n+        boolean skipTo(DLSN dlsn) throws IOException;\n+\n+    }\n+\n+}"},{"sha":"394fbaddefc5d843eb495645f94ecf7557d73f11","filename":"src/main/java/com/twitter/distributedlog/EntryBuffer.java","status":"added","additions":70,"deletions":0,"changes":70,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEntryBuffer.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEntryBuffer.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEntryBuffer.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,70 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.exceptions.InvalidEnvelopedEntryException;\n+import com.twitter.distributedlog.io.Buffer;\n+import com.twitter.distributedlog.io.TransmitListener;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Write representation of a {@link Entry}.\n+ * It is a buffer of log record set, used for transmission.\n+ */\n+public interface EntryBuffer extends TransmitListener {\n+\n+    /**\n+     * Return if this record set contains user records.\n+     *\n+     * @return true if this record set contains user records, otherwise\n+     * return false.\n+     */\n+    boolean hasUserRecords();\n+\n+    /**\n+     * Return number of records in current record set.\n+     *\n+     * @return number of records in current record set.\n+     */\n+    int getNumRecords();\n+\n+    /**\n+     * Return number of bytes in current record set.\n+     *\n+     * @return number of bytes in current record set.\n+     */\n+    int getNumBytes();\n+\n+    /**\n+     * Return max tx id in current record set.\n+     *\n+     * @return max tx id.\n+     */\n+    long getMaxTxId();\n+\n+    /**\n+     * Get the buffer to transmit.\n+     *\n+     * @return the buffer to transmit.\n+     * @throws InvalidEnvelopedEntryException if the record set buffer is invalid\n+     * @throws IOException when encountered IOException during serialization\n+     */\n+    Buffer getBuffer() throws InvalidEnvelopedEntryException, IOException;\n+\n+}"},{"sha":"55d3be97c401b821e741468f986eee53f4a547dc","filename":"src/main/java/com/twitter/distributedlog/EnvelopedEntry.java","status":"added","additions":296,"deletions":0,"changes":296,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntry.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntry.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntry.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,296 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import com.google.common.base.Preconditions;\n+\n+import com.twitter.distributedlog.exceptions.InvalidEnvelopedEntryException;\n+import org.apache.bookkeeper.stats.Counter;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+\n+import com.twitter.distributedlog.annotations.DistributedLogAnnotations.Compression;\n+import com.twitter.distributedlog.io.CompressionCodec;\n+import com.twitter.distributedlog.io.CompressionUtils;\n+import com.twitter.distributedlog.util.BitMaskUtils;\n+\n+/**\n+ * An enveloped entry written to BookKeeper.\n+ *\n+ * Data type in brackets. Interpretation should be on the basis of data types and not individual\n+ * bytes to honor Endianness.\n+ *\n+ * Entry Structure:\n+ * ---------------\n+ * Bytes 0                                  : Version (Byte)\n+ * Bytes 1 - (DATA = 1+Header.length-1)     : Header (Integer)\n+ * Bytes DATA - DATA+3                      : Payload Length (Integer)\n+ * BYTES DATA+4 - DATA+4+payload.length-1   : Payload (Byte[])\n+ *\n+ * V1 Header Structure: // Offsets relative to the start of the header.\n+ * -------------------\n+ * Bytes 0 - 3                              : Flags (Integer)\n+ * Bytes 4 - 7                              : Original payload size before compression (Integer)\n+ *\n+ *      Flags: // 32 Bits\n+ *      -----\n+ *      0 ... 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n+ *                                      |_|\n+ *                                       |\n+ *                               Compression Type\n+ *\n+ *      Compression Type: // 2 Bits (Least significant)\n+ *      ----------------\n+ *      00      : No Compression\n+ *      01      : LZ4 Compression\n+ *      10      : Unused\n+ *      11      : Unused\n+ */\n+public class EnvelopedEntry {\n+\n+    public static final int VERSION_LENGTH = 1; // One byte long\n+    public static final byte VERSION_ONE = 1;\n+\n+    public static final byte LOWEST_SUPPORTED_VERSION = VERSION_ONE;\n+    public static final byte HIGHEST_SUPPORTED_VERSION = VERSION_ONE;\n+    public static final byte CURRENT_VERSION = VERSION_ONE;\n+\n+    private final OpStatsLogger compressionStat;\n+    private final OpStatsLogger decompressionStat;\n+    private final Counter compressedEntryBytes;\n+    private final Counter decompressedEntryBytes;\n+    private final byte version;\n+\n+    private Header header = new Header();\n+    private Payload payloadCompressed = new Payload();\n+    private Payload payloadDecompressed = new Payload();\n+\n+    public EnvelopedEntry(byte version,\n+                          StatsLogger statsLogger) throws InvalidEnvelopedEntryException {\n+        Preconditions.checkNotNull(statsLogger);\n+        if (version < LOWEST_SUPPORTED_VERSION || version > HIGHEST_SUPPORTED_VERSION) {\n+            throw new InvalidEnvelopedEntryException(\"Invalid enveloped entry version \" + version + \", expected to be in [ \"\n+                    + LOWEST_SUPPORTED_VERSION + \" ~ \" + HIGHEST_SUPPORTED_VERSION + \" ]\");\n+        }\n+        this.version = version;\n+        this.compressionStat = statsLogger.getOpStatsLogger(\"compression_time\");\n+        this.decompressionStat = statsLogger.getOpStatsLogger(\"decompression_time\");\n+        this.compressedEntryBytes = statsLogger.getCounter(\"compressed_bytes\");\n+        this.decompressedEntryBytes = statsLogger.getCounter(\"decompressed_bytes\");\n+    }\n+\n+    /**\n+     * @param statsLogger\n+     *          Used for getting stats for (de)compression time\n+     * @param compressionType\n+     *          The compression type to use\n+     * @param decompressed\n+     *          The decompressed payload\n+     *          NOTE: The size of the byte array passed as the decompressed payload can be larger\n+     *                than the actual contents to be compressed.\n+     */\n+    public EnvelopedEntry(byte version,\n+                          CompressionCodec.Type compressionType,\n+                          byte[] decompressed,\n+                          int length,\n+                          StatsLogger statsLogger)\n+            throws InvalidEnvelopedEntryException {\n+        this(version, statsLogger);\n+        Preconditions.checkNotNull(compressionType);\n+        Preconditions.checkNotNull(decompressed);\n+        Preconditions.checkArgument(length >= 0, \"Invalid bytes length \" + length);\n+\n+        this.header = new Header(compressionType, length);\n+        this.payloadDecompressed = new Payload(length, decompressed);\n+    }\n+\n+    private boolean isReady() {\n+        return (header.ready && payloadDecompressed.ready);\n+    }\n+\n+    @Compression\n+    public void writeFully(DataOutputStream out) throws IOException {\n+        Preconditions.checkNotNull(out);\n+        if (!isReady()) {\n+            throw new IOException(\"Entry not writable\");\n+        }\n+        // Version\n+        out.writeByte(version);\n+        // Header\n+        header.write(out);\n+        // Compress\n+        CompressionCodec codec = CompressionUtils.getCompressionCodec(header.compressionType);\n+        byte[] compressed = codec.compress(\n+                payloadDecompressed.payload,\n+                0,\n+                payloadDecompressed.length,\n+                compressionStat);\n+        this.payloadCompressed = new Payload(compressed.length, compressed);\n+        this.compressedEntryBytes.add(payloadCompressed.length);\n+        this.decompressedEntryBytes.add(payloadDecompressed.length);\n+        payloadCompressed.write(out);\n+    }\n+\n+    @Compression\n+    public void readFully(DataInputStream in) throws IOException {\n+        Preconditions.checkNotNull(in);\n+        // Make sure we're reading the right versioned entry.\n+        byte version = in.readByte();\n+        if (version != this.version) {\n+            throw new IOException(String.format(\"Version mismatch while reading. Received: %d,\" +\n+                    \" Required: %d\", version, this.version));\n+        }\n+        header.read(in);\n+        payloadCompressed.read(in);\n+        // Decompress\n+        CompressionCodec codec = CompressionUtils.getCompressionCodec(header.compressionType);\n+        byte[] decompressed = codec.decompress(\n+                payloadCompressed.payload,\n+                0,\n+                payloadCompressed.length,\n+                header.decompressedSize,\n+                decompressionStat);\n+        this.payloadDecompressed = new Payload(decompressed.length, decompressed);\n+        this.compressedEntryBytes.add(payloadCompressed.length);\n+        this.decompressedEntryBytes.add(payloadDecompressed.length);\n+    }\n+\n+    public byte[] getDecompressedPayload() throws IOException {\n+        if (!isReady()) {\n+            throw new IOException(\"Decompressed payload is not initialized\");\n+        }\n+        return payloadDecompressed.payload;\n+    }\n+\n+    public static class Header {\n+        public static final int COMPRESSION_CODEC_MASK = 0x3;\n+        public static final int COMPRESSION_CODEC_NONE = 0x0;\n+        public static final int COMPRESSION_CODEC_LZ4 = 0x1;\n+\n+        private int flags = 0;\n+        private int decompressedSize = 0;\n+        private CompressionCodec.Type compressionType = CompressionCodec.Type.UNKNOWN;\n+\n+        // Whether this struct is ready for reading/writing.\n+        private boolean ready = false;\n+\n+        // Used while reading.\n+        public Header() {\n+        }\n+\n+        public Header(CompressionCodec.Type compressionType,\n+                      int decompressedSize) {\n+            this.compressionType = compressionType;\n+            this.decompressedSize = decompressedSize;\n+            this.flags = 0;\n+            switch (compressionType) {\n+                case NONE:\n+                    this.flags = (int) BitMaskUtils.set(flags, COMPRESSION_CODEC_MASK,\n+                                                        COMPRESSION_CODEC_NONE);\n+                    break;\n+                case LZ4:\n+                    this.flags = (int) BitMaskUtils.set(flags, COMPRESSION_CODEC_MASK,\n+                                                        COMPRESSION_CODEC_LZ4);\n+                    break;\n+                default:\n+                    throw new RuntimeException(String.format(\"Unknown Compression Type: %s\",\n+                                                             compressionType));\n+            }\n+            // This can now be written.\n+            this.ready = true;\n+        }\n+\n+        private void write(DataOutputStream out) throws IOException {\n+            out.writeInt(flags);\n+            out.writeInt(decompressedSize);\n+        }\n+\n+        private void read(DataInputStream in) throws IOException {\n+            this.flags = in.readInt();\n+            int compressionType = (int) BitMaskUtils.get(flags, COMPRESSION_CODEC_MASK);\n+            if (compressionType == COMPRESSION_CODEC_NONE) {\n+                this.compressionType = CompressionCodec.Type.NONE;\n+            } else if (compressionType == COMPRESSION_CODEC_LZ4) {\n+                this.compressionType = CompressionCodec.Type.LZ4;\n+            } else {\n+                throw new IOException(String.format(\"Unsupported Compression Type: %s\",\n+                                                    compressionType));\n+            }\n+            this.decompressedSize = in.readInt();\n+            // Values can now be read.\n+            this.ready = true;\n+        }\n+    }\n+\n+    public static class Payload {\n+        private int length = 0;\n+        private byte[] payload = null;\n+\n+        // Whether this struct is ready for reading/writing.\n+        private boolean ready = false;\n+\n+        // Used for reading\n+        Payload() {\n+        }\n+\n+        Payload(int length, byte[] payload) {\n+            this.length = length;\n+            this.payload = payload;\n+            this.ready = true;\n+        }\n+\n+        private void write(DataOutputStream out) throws IOException {\n+            out.writeInt(length);\n+            out.write(payload, 0, length);\n+        }\n+\n+        private void read(DataInputStream in) throws IOException {\n+            this.length = in.readInt();\n+            this.payload = new byte[length];\n+            in.readFully(payload);\n+            this.ready = true;\n+        }\n+    }\n+\n+    /**\n+     * Return an InputStream that reads from the provided InputStream, decompresses the data\n+     * and returns a new InputStream wrapping the underlying payload.\n+     *\n+     * Note that src is modified by this call.\n+     *\n+     * @return\n+     *      New Input stream with the underlying payload.\n+     * @throws Exception\n+     */\n+    public static InputStream fromInputStream(InputStream src,\n+                                              StatsLogger statsLogger) throws IOException {\n+        src.mark(VERSION_LENGTH);\n+        byte version = new DataInputStream(src).readByte();\n+        src.reset();\n+        EnvelopedEntry entry = new EnvelopedEntry(version, statsLogger);\n+        entry.readFully(new DataInputStream(src));\n+        return new ByteArrayInputStream(entry.getDecompressedPayload());\n+    }\n+\n+}"},{"sha":"79e44082c1d9c1047771f1fdb630a65ee5852c93","filename":"src/main/java/com/twitter/distributedlog/EnvelopedEntryReader.java","status":"added","additions":92,"deletions":0,"changes":92,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntryReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntryReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntryReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import org.apache.bookkeeper.stats.StatsLogger;\n+\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+/**\n+ * Record reader to read records from an enveloped entry buffer.\n+ */\n+class EnvelopedEntryReader implements Entry.Reader, RecordStream {\n+\n+    private final long logSegmentSeqNo;\n+    private final long entryId;\n+    private final LogRecord.Reader reader;\n+\n+    // slot id\n+    private long slotId = 0;\n+\n+    EnvelopedEntryReader(long logSegmentSeqNo,\n+                         long entryId,\n+                         long startSequenceId,\n+                         InputStream in,\n+                         boolean envelopedEntry,\n+                         boolean deserializeRecordSet,\n+                         StatsLogger statsLogger)\n+            throws IOException {\n+        this.logSegmentSeqNo = logSegmentSeqNo;\n+        this.entryId = entryId;\n+        InputStream src = in;\n+        if (envelopedEntry) {\n+            src = EnvelopedEntry.fromInputStream(in, statsLogger);\n+        }\n+        this.reader = new LogRecord.Reader(\n+                this,\n+                new DataInputStream(src),\n+                startSequenceId,\n+                deserializeRecordSet);\n+    }\n+\n+    @Override\n+    public LogRecordWithDLSN nextRecord() throws IOException {\n+        return reader.readOp();\n+    }\n+\n+    @Override\n+    public boolean skipTo(long txId) throws IOException {\n+        return reader.skipTo(txId, true);\n+    }\n+\n+    @Override\n+    public boolean skipTo(DLSN dlsn) throws IOException {\n+        return reader.skipTo(dlsn);\n+    }\n+\n+    //\n+    // Record Stream\n+    //\n+\n+    @Override\n+    public void advance(int numRecords) {\n+        slotId += numRecords;\n+    }\n+\n+    @Override\n+    public DLSN getCurrentPosition() {\n+        return new DLSN(logSegmentSeqNo, entryId, slotId);\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return \"EnvelopedReader\";\n+    }\n+}"},{"sha":"df5628869c70809947dd1c4a32396587c516fea9","filename":"src/main/java/com/twitter/distributedlog/EnvelopedEntryWriter.java","status":"added","additions":192,"deletions":0,"changes":192,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntryWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntryWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FEnvelopedEntryWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,192 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.Entry.Writer;\n+import com.twitter.distributedlog.exceptions.InvalidEnvelopedEntryException;\n+import com.twitter.distributedlog.exceptions.LogRecordTooLongException;\n+import com.twitter.distributedlog.exceptions.WriteCancelledException;\n+import com.twitter.distributedlog.exceptions.WriteException;\n+import com.twitter.distributedlog.io.Buffer;\n+import com.twitter.distributedlog.io.CompressionCodec;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import static com.twitter.distributedlog.LogRecord.MAX_LOGRECORD_SIZE;\n+\n+/**\n+ * {@link com.twitter.distributedlog.io.Buffer} based log record set writer.\n+ */\n+class EnvelopedEntryWriter implements Writer {\n+\n+    static final Logger logger = LoggerFactory.getLogger(EnvelopedEntryWriter.class);\n+\n+    private static class WriteRequest {\n+\n+        private final int numRecords;\n+        private final Promise<DLSN> promise;\n+\n+        WriteRequest(int numRecords, Promise<DLSN> promise) {\n+            this.numRecords = numRecords;\n+            this.promise = promise;\n+        }\n+\n+    }\n+\n+    private final String logName;\n+    private final Buffer buffer;\n+    private final LogRecord.Writer writer;\n+    private final List<WriteRequest> writeRequests;\n+    private final boolean envelopeBeforeTransmit;\n+    private final CompressionCodec.Type codec;\n+    private final StatsLogger statsLogger;\n+    private int count = 0;\n+    private boolean hasUserData = false;\n+    private long maxTxId = Long.MIN_VALUE;\n+\n+    EnvelopedEntryWriter(String logName,\n+                         int initialBufferSize,\n+                         boolean envelopeBeforeTransmit,\n+                         CompressionCodec.Type codec,\n+                         StatsLogger statsLogger) {\n+        this.logName = logName;\n+        this.buffer = new Buffer(initialBufferSize * 6 / 5);\n+        this.writer = new LogRecord.Writer(new DataOutputStream(buffer));\n+        this.writeRequests = new LinkedList<WriteRequest>();\n+        this.envelopeBeforeTransmit = envelopeBeforeTransmit;\n+        this.codec = codec;\n+        this.statsLogger = statsLogger;\n+    }\n+\n+    @Override\n+    public synchronized void reset() {\n+        cancelPromises(new WriteCancelledException(logName, \"Record Set is reset\"));\n+        count = 0;\n+        this.buffer.reset();\n+    }\n+\n+    @Override\n+    public synchronized void writeRecord(LogRecord record,\n+                                         Promise<DLSN> transmitPromise)\n+            throws LogRecordTooLongException, WriteException {\n+        int logRecordSize = record.getPersistentSize();\n+        if (logRecordSize > MAX_LOGRECORD_SIZE) {\n+            throw new LogRecordTooLongException(\n+                    \"Log Record of size \" + logRecordSize + \" written when only \"\n+                            + MAX_LOGRECORD_SIZE + \" is allowed\");\n+        }\n+\n+        try {\n+            this.writer.writeOp(record);\n+            int numRecords = 1;\n+            if (!record.isControl()) {\n+                hasUserData = true;\n+            }\n+            if (record.isRecordSet()) {\n+                numRecords = LogRecordSet.numRecords(record);\n+            }\n+            count += numRecords;\n+            writeRequests.add(new WriteRequest(numRecords, transmitPromise));\n+            maxTxId = Math.max(maxTxId, record.getTransactionId());\n+        } catch (IOException e) {\n+            logger.error(\"Failed to append record to record set of {} : \",\n+                    logName, e);\n+            throw new WriteException(logName, \"Failed to append record to record set of \"\n+                    + logName);\n+        }\n+    }\n+\n+    private synchronized void satisfyPromises(long lssn, long entryId) {\n+        long nextSlotId = 0;\n+        for (WriteRequest request : writeRequests) {\n+            request.promise.setValue(new DLSN(lssn, entryId, nextSlotId));\n+            nextSlotId += request.numRecords;\n+        }\n+        writeRequests.clear();\n+    }\n+\n+    private synchronized void cancelPromises(Throwable reason) {\n+        for (WriteRequest request : writeRequests) {\n+            request.promise.setException(reason);\n+        }\n+        writeRequests.clear();\n+    }\n+\n+    @Override\n+    public synchronized long getMaxTxId() {\n+        return maxTxId;\n+    }\n+\n+    @Override\n+    public synchronized boolean hasUserRecords() {\n+        return hasUserData;\n+    }\n+\n+    @Override\n+    public int getNumBytes() {\n+        return buffer.size();\n+    }\n+\n+    @Override\n+    public synchronized int getNumRecords() {\n+        return count;\n+    }\n+\n+    @Override\n+    public synchronized Buffer getBuffer() throws InvalidEnvelopedEntryException, IOException {\n+        if (!envelopeBeforeTransmit) {\n+            return buffer;\n+        }\n+        // We can't escape this allocation because things need to be read from one byte array\n+        // and then written to another. This is the destination.\n+        Buffer toSend = new Buffer(buffer.size());\n+        byte[] decompressed = buffer.getData();\n+        int length = buffer.size();\n+        EnvelopedEntry entry = new EnvelopedEntry(EnvelopedEntry.CURRENT_VERSION,\n+                                                  codec,\n+                                                  decompressed,\n+                                                  length,\n+                                                  statsLogger);\n+        // This will cause an allocation of a byte[] for compression. This can be avoided\n+        // but we can do that later only if needed.\n+        entry.writeFully(new DataOutputStream(toSend));\n+        return toSend;\n+    }\n+\n+    @Override\n+    public DLSN finalizeTransmit(long lssn, long entryId) {\n+        return new DLSN(lssn, entryId, count - 1);\n+    }\n+\n+    @Override\n+    public void completeTransmit(long lssn, long entryId) {\n+        satisfyPromises(lssn, entryId);\n+    }\n+\n+    @Override\n+    public void abortTransmit(Throwable reason) {\n+        cancelPromises(reason);\n+    }\n+}"},{"sha":"5a95e467f3693f0627f887aa0742cc2ea6a1a6a5","filename":"src/main/java/com/twitter/distributedlog/LedgerDescriptor.java","status":"added","additions":67,"deletions":0,"changes":67,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerDescriptor.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerDescriptor.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerDescriptor.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,67 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+public class LedgerDescriptor {\n+    private final long ledgerId;\n+    private final long logSegmentSequenceNo;\n+    private final boolean fenced;\n+\n+    public LedgerDescriptor(long ledgerId, long logSegmentSequenceNo, boolean fenced) {\n+        this.ledgerId = ledgerId;\n+        this.logSegmentSequenceNo = logSegmentSequenceNo;\n+        this.fenced = fenced;\n+    }\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getLogSegmentSequenceNo() {\n+        return logSegmentSequenceNo;\n+    }\n+\n+    public boolean isFenced() {\n+        return fenced;\n+    }\n+\n+    // Only compares the key portion\n+    @Override\n+    public boolean equals(Object other) {\n+        if (!(other instanceof LedgerDescriptor)) {\n+            return false;\n+        }\n+        LedgerDescriptor key = (LedgerDescriptor) other;\n+        return ledgerId == key.ledgerId &&\n+            fenced == key.fenced;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return (int) (ledgerId * 13 ^ (fenced ? 0xFFFF : 0xF0F0) * 17);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        sb.append(\"(lid=\").append(ledgerId).append(\", lseqno=\").append(logSegmentSequenceNo)\n+                .append(\", fenced=\").append(fenced).append(\")\");\n+        return sb.toString();\n+    }\n+}\n+"},{"sha":"33e8c7d7cb3df78bac3cc38bc9f139b99a91d7a5","filename":"src/main/java/com/twitter/distributedlog/LedgerHandleCache.java","status":"added","additions":463,"deletions":0,"changes":463,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerHandleCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerHandleCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerHandleCache.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,463 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Stopwatch;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.client.AsyncCallback;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.BookKeeper;\n+import org.apache.bookkeeper.client.LedgerEntry;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.Enumeration;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+\n+/**\n+ * A central place on managing open ledgers.\n+ */\n+public class LedgerHandleCache {\n+    static final Logger LOG = LoggerFactory.getLogger(LedgerHandleCache.class);\n+\n+    public static Builder newBuilder() {\n+        return new Builder();\n+    }\n+\n+    public static class Builder {\n+\n+        private BookKeeperClient bkc;\n+        private String digestpw;\n+        private StatsLogger statsLogger = NullStatsLogger.INSTANCE;\n+\n+        private Builder() {}\n+\n+        public Builder bkc(BookKeeperClient bkc) {\n+            this.bkc = bkc;\n+            return this;\n+        }\n+\n+        public Builder conf(DistributedLogConfiguration conf) {\n+            this.digestpw = conf.getBKDigestPW();\n+            return this;\n+        }\n+\n+        public Builder statsLogger(StatsLogger statsLogger) {\n+            this.statsLogger = statsLogger;\n+            return this;\n+        }\n+\n+        public LedgerHandleCache build() {\n+            Preconditions.checkNotNull(bkc, \"No bookkeeper client is provided\");\n+            Preconditions.checkNotNull(digestpw, \"No bookkeeper digest password is provided\");\n+            Preconditions.checkNotNull(statsLogger, \"No stats logger is provided\");\n+            return new LedgerHandleCache(bkc, digestpw, statsLogger);\n+        }\n+    }\n+\n+    final ConcurrentHashMap<LedgerDescriptor, RefCountedLedgerHandle> handlesMap =\n+        new ConcurrentHashMap<LedgerDescriptor, RefCountedLedgerHandle>();\n+\n+    private final BookKeeperClient bkc;\n+    private final String digestpw;\n+\n+    private final OpStatsLogger openStats;\n+    private final OpStatsLogger openNoRecoveryStats;\n+\n+    private LedgerHandleCache(BookKeeperClient bkc, String digestpw, StatsLogger statsLogger) {\n+        this.bkc = bkc;\n+        this.digestpw = digestpw;\n+        // Stats\n+        openStats = statsLogger.getOpStatsLogger(\"open_ledger\");\n+        openNoRecoveryStats = statsLogger.getOpStatsLogger(\"open_ledger_no_recovery\");\n+    }\n+\n+    /**\n+     * Open the given ledger <i>ledgerDesc</i>.\n+     *\n+     * @param ledgerDesc\n+     *          ledger description\n+     * @param callback\n+     *          open callback.\n+     * @param ctx\n+     *          callback context\n+     */\n+    private void asyncOpenLedger(LedgerDescriptor ledgerDesc, AsyncCallback.OpenCallback callback, Object ctx) {\n+        try {\n+            if (!ledgerDesc.isFenced()) {\n+                bkc.get().asyncOpenLedgerNoRecovery(ledgerDesc.getLedgerId(),\n+                        BookKeeper.DigestType.CRC32, digestpw.getBytes(UTF_8), callback, ctx);\n+            } else {\n+                bkc.get().asyncOpenLedger(ledgerDesc.getLedgerId(),\n+                        BookKeeper.DigestType.CRC32, digestpw.getBytes(UTF_8), callback, ctx);\n+            }\n+        } catch (IOException ace) {\n+            // :) when we can't get bkc, it means bookie handle not available\n+            callback.openComplete(BKException.Code.BookieHandleNotAvailableException, null, ctx);\n+        }\n+    }\n+\n+    /**\n+     * Open the log segment.\n+     *\n+     * @param metadata\n+     *          the log segment metadata\n+     * @param fence\n+     *          whether to fence the log segment during open\n+     * @return a future presenting the open result.\n+     */\n+    public Future<LedgerDescriptor> asyncOpenLedger(LogSegmentMetadata metadata, boolean fence) {\n+        final Stopwatch stopwatch = Stopwatch.createStarted();\n+        final OpStatsLogger openStatsLogger = fence ? openStats : openNoRecoveryStats;\n+        final Promise<LedgerDescriptor> promise = new Promise<LedgerDescriptor>();\n+        final LedgerDescriptor ledgerDesc = new LedgerDescriptor(metadata.getLedgerId(), metadata.getLogSegmentSequenceNumber(), fence);\n+        RefCountedLedgerHandle refhandle = handlesMap.get(ledgerDesc);\n+        if (null == refhandle) {\n+            asyncOpenLedger(ledgerDesc, new AsyncCallback.OpenCallback() {\n+                @Override\n+                public void openComplete(int rc, LedgerHandle lh, Object ctx) {\n+                    if (BKException.Code.OK != rc) {\n+                        promise.setException(BKException.create(rc));\n+                        return;\n+                    }\n+                    RefCountedLedgerHandle newRefHandle = new RefCountedLedgerHandle(lh);\n+                    RefCountedLedgerHandle oldRefHandle = handlesMap.putIfAbsent(ledgerDesc, newRefHandle);\n+                    if (null != oldRefHandle) {\n+                        oldRefHandle.addRef();\n+                        if (newRefHandle.removeRef()) {\n+                            newRefHandle.handle.asyncClose(new AsyncCallback.CloseCallback() {\n+                                @Override\n+                                public void closeComplete(int i, LedgerHandle ledgerHandle, Object o) {\n+                                    // No action necessary\n+                                }\n+                            }, null);\n+                        }\n+                    }\n+                    promise.setValue(ledgerDesc);\n+                }\n+            }, null);\n+        } else {\n+            refhandle.addRef();\n+            promise.setValue(ledgerDesc);\n+        }\n+        return promise.addEventListener(new FutureEventListener<LedgerDescriptor>() {\n+            @Override\n+            public void onSuccess(LedgerDescriptor value) {\n+                openStatsLogger.registerSuccessfulEvent(stopwatch.elapsed(TimeUnit.MICROSECONDS));\n+            }\n+\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                openStatsLogger.registerFailedEvent(stopwatch.elapsed(TimeUnit.MICROSECONDS));\n+            }\n+        });\n+    }\n+\n+    /**\n+     * Open a ledger synchronously.\n+     *\n+     * @param metadata\n+     *          log segment metadata\n+     * @param fence\n+     *          whether to fence the log segment during open\n+     * @return ledger descriptor\n+     * @throws BKException\n+     */\n+    public LedgerDescriptor openLedger(LogSegmentMetadata metadata, boolean fence) throws BKException {\n+        return FutureUtils.bkResult(asyncOpenLedger(metadata, fence));\n+    }\n+\n+    private RefCountedLedgerHandle getLedgerHandle(LedgerDescriptor ledgerDescriptor) {\n+        return null == ledgerDescriptor ? null : handlesMap.get(ledgerDescriptor);\n+    }\n+\n+    /**\n+     * Close the ledger asynchronously.\n+     *\n+     * @param ledgerDesc\n+     *          ledger descriptor.\n+     * @return future presenting the closing result.\n+     */\n+    public Future<Void> asyncCloseLedger(LedgerDescriptor ledgerDesc) {\n+        final Promise<Void> promise = new Promise<Void>();\n+\n+        RefCountedLedgerHandle refhandle = getLedgerHandle(ledgerDesc);\n+        if ((null != refhandle) && (refhandle.removeRef())) {\n+            refhandle = handlesMap.remove(ledgerDesc);\n+            if (refhandle.getRefCount() > 0) {\n+                // In the rare race condition that a ref count was added immediately\n+                // after the close de-refed it and the remove was called\n+\n+                // Try to put the handle back in the map\n+                handlesMap.putIfAbsent(ledgerDesc, refhandle);\n+\n+                // ReadOnlyLedgerHandles don't have much overhead, so lets just leave\n+                // the handle open even if it had already been replaced\n+                promise.setValue(null);\n+            } else {\n+                refhandle.handle.asyncClose(new AsyncCallback.CloseCallback() {\n+                    @Override\n+                    public void closeComplete(int rc, LedgerHandle ledgerHandle, Object ctx) {\n+                        if (BKException.Code.OK == rc) {\n+                            promise.setValue(null);\n+                        } else {\n+                            promise.setException(BKException.create(rc));\n+                        }\n+                    }\n+                }, null);\n+            }\n+        } else {\n+            promise.setValue(null);\n+        }\n+        return promise;\n+    }\n+\n+    /**\n+     * Close the ledger synchronously.\n+     *\n+     * @param ledgerDesc\n+     *          ledger descriptor.\n+     * @throws BKException\n+     */\n+    public void closeLedger(LedgerDescriptor ledgerDesc) throws BKException {\n+        FutureUtils.bkResult(asyncCloseLedger(ledgerDesc));\n+    }\n+\n+    /**\n+     * Get the last add confirmed of <code>ledgerDesc</code>.\n+     *\n+     * @param ledgerDesc\n+     *          ledger descriptor.\n+     * @return last add confirmed of <code>ledgerDesc</code>\n+     * @throws BKException\n+     */\n+    public long getLastAddConfirmed(LedgerDescriptor ledgerDesc) throws BKException {\n+        RefCountedLedgerHandle refhandle = getLedgerHandle(ledgerDesc);\n+\n+        if (null == refhandle) {\n+            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n+            throw BKException.create(BKException.Code.UnexpectedConditionException);\n+        }\n+\n+        return refhandle.handle.getLastAddConfirmed();\n+    }\n+\n+    /**\n+     * Whether a ledger is closed or not.\n+     *\n+     * @param ledgerDesc\n+     *          ledger descriptor.\n+     * @return true if a ledger is closed, otherwise false.\n+     * @throws BKException\n+     */\n+    public boolean isLedgerHandleClosed(LedgerDescriptor ledgerDesc) throws BKException {\n+        RefCountedLedgerHandle refhandle = getLedgerHandle(ledgerDesc);\n+\n+        if (null == refhandle) {\n+            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n+            throw BKException.create(BKException.Code.UnexpectedConditionException);\n+        }\n+\n+        return refhandle.handle.isClosed();\n+    }\n+\n+    /**\n+     * Async try read last confirmed.\n+     *\n+     * @param ledgerDesc\n+     *          ledger descriptor\n+     * @return future presenting read last confirmed result.\n+     */\n+    public Future<Long> asyncTryReadLastConfirmed(LedgerDescriptor ledgerDesc) {\n+        RefCountedLedgerHandle refHandle = handlesMap.get(ledgerDesc);\n+        if (null == refHandle) {\n+            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n+            return Future.exception(BKException.create(BKException.Code.UnexpectedConditionException));\n+        }\n+        final Promise<Long> promise = new Promise<Long>();\n+        refHandle.handle.asyncTryReadLastConfirmed(new AsyncCallback.ReadLastConfirmedCallback() {\n+            @Override\n+            public void readLastConfirmedComplete(int rc, long lastAddConfirmed, Object ctx) {\n+                if (BKException.Code.OK == rc) {\n+                    promise.setValue(lastAddConfirmed);\n+                } else {\n+                    promise.setException(BKException.create(rc));\n+                }\n+            }\n+        }, null);\n+        return promise;\n+    }\n+\n+    /**\n+     * Try read last confirmed.\n+     *\n+     * @param ledgerDesc\n+     *          ledger descriptor\n+     * @return last confirmed\n+     * @throws BKException\n+     */\n+    public long tryReadLastConfirmed(LedgerDescriptor ledgerDesc) throws BKException {\n+        return FutureUtils.bkResult(asyncTryReadLastConfirmed(ledgerDesc));\n+    }\n+\n+    /**\n+     * Async read last confirmed and entry\n+     *\n+     * @param ledgerDesc\n+     *          ledger descriptor\n+     * @param entryId\n+     *          entry id to read\n+     * @param timeOutInMillis\n+     *          time out if no newer entry available\n+     * @param parallel\n+     *          whether to read from replicas in parallel\n+     */\n+    public Future<Pair<Long, LedgerEntry>> asyncReadLastConfirmedAndEntry(\n+            LedgerDescriptor ledgerDesc,\n+            long entryId,\n+            long timeOutInMillis,\n+            boolean parallel) {\n+        RefCountedLedgerHandle refHandle = handlesMap.get(ledgerDesc);\n+        if (null == refHandle) {\n+            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n+            return Future.exception(BKException.create(BKException.Code.UnexpectedConditionException));\n+        }\n+        final Promise<Pair<Long, LedgerEntry>> promise = new Promise<Pair<Long, LedgerEntry>>();\n+        refHandle.handle.asyncReadLastConfirmedAndEntry(entryId, timeOutInMillis, parallel,\n+                new AsyncCallback.ReadLastConfirmedAndEntryCallback() {\n+                    @Override\n+                    public void readLastConfirmedAndEntryComplete(int rc, long lac, LedgerEntry ledgerEntry, Object ctx) {\n+                        if (BKException.Code.OK == rc) {\n+                            promise.setValue(Pair.of(lac, ledgerEntry));\n+                        } else {\n+                            promise.setException(BKException.create(rc));\n+                        }\n+                    }\n+                }, null);\n+        return promise;\n+    }\n+\n+    /**\n+     * Async Read Entries\n+     *\n+     * @param ledgerDesc\n+     *          ledger descriptor\n+     * @param first\n+     *          first entry\n+     * @param last\n+     *          second entry\n+     */\n+    public Future<Enumeration<LedgerEntry>> asyncReadEntries(\n+            LedgerDescriptor ledgerDesc, long first, long last) {\n+        RefCountedLedgerHandle refHandle = handlesMap.get(ledgerDesc);\n+        if (null == refHandle) {\n+            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n+            return Future.exception(BKException.create(BKException.Code.UnexpectedConditionException));\n+        }\n+        final Promise<Enumeration<LedgerEntry>> promise = new Promise<Enumeration<LedgerEntry>>();\n+        refHandle.handle.asyncReadEntries(first, last, new AsyncCallback.ReadCallback() {\n+            @Override\n+            public void readComplete(int rc, LedgerHandle lh, Enumeration<LedgerEntry> entries, Object ctx) {\n+                if (BKException.Code.OK == rc) {\n+                    promise.setValue(entries);\n+                } else {\n+                    promise.setException(BKException.create(rc));\n+                }\n+            }\n+        }, null);\n+        return promise;\n+    }\n+\n+    public Enumeration<LedgerEntry> readEntries(LedgerDescriptor ledgerDesc, long first, long last)\n+            throws BKException {\n+        return FutureUtils.bkResult(asyncReadEntries(ledgerDesc, first, last));\n+    }\n+\n+    public long getLength(LedgerDescriptor ledgerDesc) throws BKException {\n+        RefCountedLedgerHandle refhandle = getLedgerHandle(ledgerDesc);\n+\n+        if (null == refhandle) {\n+            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n+            throw BKException.create(BKException.Code.UnexpectedConditionException);\n+        }\n+\n+        return refhandle.handle.getLength();\n+    }\n+\n+    public void clear() {\n+        if (null != handlesMap) {\n+            Iterator<Map.Entry<LedgerDescriptor, RefCountedLedgerHandle>> handlesMapIter = handlesMap.entrySet().iterator();\n+            while (handlesMapIter.hasNext()) {\n+                Map.Entry<LedgerDescriptor, RefCountedLedgerHandle> entry = handlesMapIter.next();\n+                // Make it inaccessible through the map\n+                handlesMapIter.remove();\n+                // now close the ledger\n+                entry.getValue().forceClose();\n+            }\n+        }\n+    }\n+\n+    static class RefCountedLedgerHandle {\n+        public final LedgerHandle handle;\n+        final AtomicLong refcount = new AtomicLong(0);\n+\n+        RefCountedLedgerHandle(LedgerHandle lh) {\n+            this.handle = lh;\n+            addRef();\n+        }\n+\n+        long getRefCount() {\n+            return refcount.get();\n+        }\n+\n+        public void addRef() {\n+            refcount.incrementAndGet();\n+        }\n+\n+        public boolean removeRef() {\n+            return (refcount.decrementAndGet() == 0);\n+        }\n+\n+        public void forceClose() {\n+            try {\n+                handle.close();\n+            } catch (BKException.BKLedgerClosedException exc) {\n+                // Ignore\n+            } catch (Exception exc) {\n+                LOG.warn(\"Exception while closing ledger {}\", handle, exc);\n+            }\n+        }\n+\n+    }\n+}"},{"sha":"550d314dfbf64f95733bc8830d75f023e5692ddf","filename":"src/main/java/com/twitter/distributedlog/LedgerReadPosition.java","status":"added","additions":171,"deletions":0,"changes":171,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerReadPosition.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerReadPosition.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerReadPosition.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LedgerReadPosition {\n+    static final Logger LOG = LoggerFactory.getLogger(LedgerReadPosition.class);\n+\n+    private static enum PartialOrderingComparisonResult {\n+        NotComparable,\n+        GreaterThan,\n+        LessThan,\n+        EqualTo\n+    }\n+\n+    long ledgerId = DistributedLogConstants.UNRESOLVED_LEDGER_ID;\n+    long logSegmentSequenceNo;\n+    long entryId;\n+\n+    public LedgerReadPosition(long ledgerId, long logSegmentSequenceNo, long entryId) {\n+        this.ledgerId = ledgerId;\n+        this.logSegmentSequenceNo = logSegmentSequenceNo;\n+        this.entryId = entryId;\n+    }\n+\n+    public LedgerReadPosition(LedgerReadPosition that) {\n+        this.ledgerId = that.ledgerId;\n+        this.logSegmentSequenceNo = that.logSegmentSequenceNo;\n+        this.entryId = that.entryId;\n+    }\n+\n+\n+    public LedgerReadPosition(final DLSN dlsn) {\n+        this(dlsn.getLogSegmentSequenceNo(), dlsn.getEntryId());\n+    }\n+\n+    public LedgerReadPosition(long logSegmentSequenceNo, long entryId) {\n+        this.logSegmentSequenceNo = logSegmentSequenceNo;\n+        this.entryId = entryId;\n+    }\n+\n+    public long getLedgerId() {\n+        if (DistributedLogConstants.UNRESOLVED_LEDGER_ID == ledgerId) {\n+            LOG.trace(\"Ledger Id is not initialized\");\n+            throw new IllegalStateException(\"Ledger Id is not initialized\");\n+        }\n+        return ledgerId;\n+    }\n+\n+    public long getLogSegmentSequenceNumber() {\n+        return logSegmentSequenceNo;\n+    }\n+\n+    public long getEntryId() {\n+        return entryId;\n+    }\n+\n+    public void advance() {\n+        entryId++;\n+    }\n+\n+    public void positionOnNewLogSegment(long ledgerId, long logSegmentSequenceNo) {\n+        this.ledgerId = ledgerId;\n+        this.logSegmentSequenceNo = logSegmentSequenceNo;\n+        this.entryId = 0L;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"(lid=%d, lseqNo=%d, eid=%d)\", ledgerId, logSegmentSequenceNo, entryId);\n+    }\n+\n+    public boolean definitelyLessThanOrEqualTo(LedgerReadPosition threshold) {\n+        PartialOrderingComparisonResult result = comparePartiallyOrdered(threshold);\n+        return ((result == PartialOrderingComparisonResult.LessThan) ||\n+            (result == PartialOrderingComparisonResult.EqualTo));\n+    }\n+\n+    public boolean definitelyLessThan(LedgerReadPosition threshold) {\n+        PartialOrderingComparisonResult result = comparePartiallyOrdered(threshold);\n+        return result == PartialOrderingComparisonResult.LessThan;\n+    }\n+\n+    private PartialOrderingComparisonResult comparePartiallyOrdered(LedgerReadPosition threshold) {\n+        // If no threshold is passed we cannot make a definitive comparison\n+        if (null == threshold) {\n+            return PartialOrderingComparisonResult.NotComparable;\n+        }\n+\n+        if (this.logSegmentSequenceNo != threshold.logSegmentSequenceNo) {\n+            if (this.logSegmentSequenceNo < threshold.logSegmentSequenceNo) {\n+                return PartialOrderingComparisonResult.LessThan;\n+            } else {\n+                return PartialOrderingComparisonResult.GreaterThan;\n+            }\n+        } else if (this.ledgerId != threshold.ledgerId) {\n+            // When logSegmentSequenceNo is equal we cannot definitely say that this\n+            // position is less than the threshold unless ledgerIds are equal\n+            // since LogSegmentSequenceNumber maybe inferred from transactionIds in older\n+            // versions of the metadata.\n+            return PartialOrderingComparisonResult.NotComparable;\n+        } else if (this.getEntryId() < threshold.getEntryId()) {\n+            return PartialOrderingComparisonResult.LessThan;\n+        } else if (this.getEntryId() > threshold.getEntryId()) {\n+            return PartialOrderingComparisonResult.GreaterThan;\n+        } else {\n+            return PartialOrderingComparisonResult.EqualTo;\n+        }\n+    }\n+\n+    /**\n+     * Comparator for the key portion\n+     */\n+    public static final ReadAheadCacheKeyComparator COMPARATOR = new ReadAheadCacheKeyComparator();\n+\n+    // Only compares the key portion\n+    @Override\n+    public boolean equals(Object other) {\n+        if (!(other instanceof LedgerReadPosition)) {\n+            return false;\n+        }\n+        LedgerReadPosition key = (LedgerReadPosition) other;\n+        return ledgerId == key.ledgerId &&\n+            entryId == key.entryId;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return (int) (ledgerId * 13 ^ entryId * 17);\n+    }\n+\n+    /**\n+     * Compare EntryKey.\n+     */\n+    protected static class ReadAheadCacheKeyComparator implements Comparator<LedgerReadPosition>, Serializable {\n+\n+        private static final long serialVersionUID = 0L;\n+\n+        @Override\n+        public int compare(LedgerReadPosition left, LedgerReadPosition right) {\n+            long ret = left.ledgerId - right.ledgerId;\n+            if (ret == 0) {\n+                ret = left.entryId - right.entryId;\n+            }\n+            return (ret < 0) ? -1 : ((ret > 0) ? 1 : 0);\n+        }\n+    }\n+\n+}\n+\n+"},{"sha":"aaecdd579c73326f0a4a895996d274d7db81a8ca","filename":"src/main/java/com/twitter/distributedlog/LocalDLMEmulator.java","status":"added","additions":384,"deletions":0,"changes":384,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLocalDLMEmulator.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLocalDLMEmulator.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLocalDLMEmulator.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,384 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Optional;\n+import com.twitter.distributedlog.metadata.BKDLConfig;\n+import com.twitter.distributedlog.metadata.DLMetadata;\n+import org.apache.bookkeeper.conf.ServerConfiguration;\n+import org.apache.bookkeeper.proto.BookieServer;\n+import org.apache.bookkeeper.shims.zk.ZooKeeperServerShim;\n+import org.apache.bookkeeper.util.IOUtils;\n+import org.apache.bookkeeper.util.LocalBookKeeper;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.WatchedEvent;\n+import org.apache.zookeeper.Watcher;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.net.BindException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Utility class for setting up bookkeeper ensembles\n+ * and bringing individual bookies up and down\n+ */\n+public class LocalDLMEmulator {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalDLMEmulator.class);\n+\n+    public static final String DLOG_NAMESPACE = \"/messaging/distributedlog\";\n+\n+    private static final int DEFAULT_BOOKIE_INITIAL_PORT = 0; // Use ephemeral ports\n+    private static final int DEFAULT_ZK_TIMEOUT_SEC = 10;\n+    private static final int DEFAULT_ZK_PORT = 2181;\n+    private static final String DEFAULT_ZK_HOST = \"127.0.0.1\";\n+    private static final String DEFAULT_ZK_ENSEMBLE = DEFAULT_ZK_HOST + \":\" + DEFAULT_ZK_PORT;\n+    private static final int DEFAULT_NUM_BOOKIES = 3;\n+    private static final ServerConfiguration DEFAULT_SERVER_CONFIGURATION = new ServerConfiguration();\n+\n+    private final String zkEnsemble;\n+    private final URI uri;\n+    private final List<File> tmpDirs = new ArrayList<File>();\n+    private final int zkTimeoutSec;\n+    private final Thread bkStartupThread;\n+    private final String zkHost;\n+    private final int zkPort;\n+    private final int numBookies;\n+\n+    public static class Builder {\n+        private int zkTimeoutSec = DEFAULT_ZK_TIMEOUT_SEC;\n+        private int numBookies = DEFAULT_NUM_BOOKIES;\n+        private String zkHost = DEFAULT_ZK_HOST;\n+        private int zkPort = DEFAULT_ZK_PORT;\n+        private int initialBookiePort = DEFAULT_BOOKIE_INITIAL_PORT;\n+        private boolean shouldStartZK = true;\n+        private Optional<ServerConfiguration> serverConf = Optional.absent();\n+\n+        public Builder numBookies(int numBookies) {\n+            this.numBookies = numBookies;\n+            return this;\n+        }\n+        public Builder zkHost(String zkHost) {\n+            this.zkHost = zkHost;\n+            return this;\n+        }\n+        public Builder zkPort(int zkPort) {\n+            this.zkPort = zkPort;\n+            return this;\n+        }\n+        public Builder zkTimeoutSec(int zkTimeoutSec) {\n+            this.zkTimeoutSec = zkTimeoutSec;\n+            return this;\n+        }\n+        public Builder initialBookiePort(int initialBookiePort) {\n+            this.initialBookiePort = initialBookiePort;\n+            return this;\n+        }\n+        public Builder shouldStartZK(boolean shouldStartZK) {\n+            this.shouldStartZK = shouldStartZK;\n+            return this;\n+        }\n+        public Builder serverConf(ServerConfiguration serverConf) {\n+            this.serverConf = Optional.of(serverConf);\n+            return this;\n+        }\n+\n+        public LocalDLMEmulator build() throws Exception {\n+            ServerConfiguration conf = null;\n+            if (serverConf.isPresent()) {\n+                conf = serverConf.get();\n+            } else {\n+                conf = (ServerConfiguration) DEFAULT_SERVER_CONFIGURATION.clone();\n+                conf.setZkTimeout(zkTimeoutSec * 1000);\n+            }\n+\n+            return new LocalDLMEmulator(numBookies, shouldStartZK, zkHost, zkPort,\n+                initialBookiePort, zkTimeoutSec, conf);\n+        }\n+    }\n+\n+    public static Builder newBuilder() {\n+        return new Builder();\n+    }\n+\n+    public LocalDLMEmulator(final int numBookies) throws Exception {\n+        this(numBookies, true, DEFAULT_ZK_HOST, DEFAULT_ZK_PORT, DEFAULT_BOOKIE_INITIAL_PORT);\n+    }\n+\n+    public LocalDLMEmulator(final int numBookies, final String zkHost, final int zkPort) throws Exception {\n+        this(numBookies, false, zkHost, zkPort, DEFAULT_BOOKIE_INITIAL_PORT);\n+    }\n+\n+    public LocalDLMEmulator(final int numBookies, final String zkHost, final int zkPort, final ServerConfiguration serverConf) throws Exception {\n+        this(numBookies, false, zkHost, zkPort, DEFAULT_BOOKIE_INITIAL_PORT, DEFAULT_ZK_TIMEOUT_SEC, serverConf);\n+    }\n+\n+    public LocalDLMEmulator(final int numBookies, final int initialBookiePort) throws Exception {\n+        this(numBookies, true, DEFAULT_ZK_HOST, DEFAULT_ZK_PORT, initialBookiePort);\n+    }\n+\n+    public LocalDLMEmulator(final int numBookies, final String zkHost, final int zkPort, final int initialBookiePort) throws Exception {\n+        this(numBookies, false, zkHost, zkPort, initialBookiePort);\n+    }\n+\n+    private LocalDLMEmulator(final int numBookies, final boolean shouldStartZK, final String zkHost, final int zkPort, final int initialBookiePort) throws Exception {\n+        this(numBookies, shouldStartZK, zkHost, zkPort, initialBookiePort, DEFAULT_ZK_TIMEOUT_SEC, new ServerConfiguration());\n+    }\n+\n+    private LocalDLMEmulator(final int numBookies, final boolean shouldStartZK, final String zkHost, final int zkPort, final int initialBookiePort, final int zkTimeoutSec, final ServerConfiguration serverConf) throws Exception {\n+        this.numBookies = numBookies;\n+        this.zkHost = zkHost;\n+        this.zkPort = zkPort;\n+        this.zkEnsemble = zkHost + \":\" + zkPort;\n+        this.uri = URI.create(\"distributedlog://\" + zkEnsemble + DLOG_NAMESPACE);\n+        this.zkTimeoutSec = zkTimeoutSec;\n+        this.bkStartupThread = new Thread() {\n+            public void run() {\n+                try {\n+                    LocalBookKeeper.startLocalBookies(zkHost, zkPort, numBookies, shouldStartZK, initialBookiePort, serverConf);\n+                } catch (InterruptedException e) {\n+                    // go away quietly\n+                } catch (Exception e) {\n+                    LOG.error(\"Error starting local bk\", e);\n+                }\n+            }\n+        };\n+    }\n+\n+    public void start() throws Exception {\n+        bkStartupThread.start();\n+        if (!LocalBookKeeper.waitForServerUp(zkEnsemble, zkTimeoutSec*1000)) {\n+            throw new Exception(\"Error starting zookeeper/bookkeeper\");\n+        }\n+        int bookiesUp = checkBookiesUp(numBookies, zkTimeoutSec);\n+        assert (numBookies == bookiesUp);\n+        // Provision \"/messaging/distributedlog\" namespace\n+        DLMetadata.create(new BKDLConfig(zkEnsemble, \"/ledgers\")).create(uri);\n+    }\n+\n+    public void teardown() throws Exception {\n+        if (bkStartupThread != null) {\n+            bkStartupThread.interrupt();\n+            bkStartupThread.join();\n+        }\n+        for (File dir : tmpDirs) {\n+            FileUtils.deleteDirectory(dir);\n+        }\n+    }\n+\n+    public String getZkServers() {\n+        return zkEnsemble;\n+    }\n+\n+    public URI getUri() {\n+        return uri;\n+    }\n+\n+    public BookieServer newBookie() throws Exception {\n+        ServerConfiguration bookieConf = new ServerConfiguration();\n+        bookieConf.setZkTimeout(zkTimeoutSec * 1000);\n+        bookieConf.setBookiePort(0);\n+        File tmpdir = File.createTempFile(\"bookie\" + UUID.randomUUID() + \"_\",\n+            \"test\");\n+        if (!tmpdir.delete()) {\n+            LOG.debug(\"Fail to delete tmpdir \" + tmpdir);\n+        }\n+        if (!tmpdir.mkdir()) {\n+            throw new IOException(\"Fail to create tmpdir \" + tmpdir);\n+        }\n+        tmpDirs.add(tmpdir);\n+\n+        bookieConf.setZkServers(zkEnsemble);\n+        bookieConf.setJournalDirName(tmpdir.getPath());\n+        bookieConf.setLedgerDirNames(new String[]{tmpdir.getPath()});\n+\n+        BookieServer b = new BookieServer(bookieConf);\n+        b.start();\n+        for (int i = 0; i < 10 && !b.isRunning(); i++) {\n+            Thread.sleep(10000);\n+        }\n+        if (!b.isRunning()) {\n+            throw new IOException(\"Bookie would not start\");\n+        }\n+        return b;\n+    }\n+\n+    /**\n+     * Check that a number of bookies are available\n+     *\n+     * @param count number of bookies required\n+     * @param timeout number of seconds to wait for bookies to start\n+     * @throws java.io.IOException if bookies are not started by the time the timeout hits\n+     */\n+    public int checkBookiesUp(int count, int timeout) throws Exception {\n+        ZooKeeper zkc = connectZooKeeper(zkHost, zkPort, zkTimeoutSec);\n+        try {\n+            int mostRecentSize = 0;\n+            for (int i = 0; i < timeout; i++) {\n+                try {\n+                    List<String> children = zkc.getChildren(\"/ledgers/available\",\n+                        false);\n+                    children.remove(\"readonly\");\n+                    mostRecentSize = children.size();\n+                    if ((mostRecentSize > count) || LOG.isDebugEnabled()) {\n+                        LOG.info(\"Found \" + mostRecentSize + \" bookies up, \"\n+                            + \"waiting for \" + count);\n+                        if ((mostRecentSize > count) || LOG.isTraceEnabled()) {\n+                            for (String child : children) {\n+                                LOG.info(\" server: \" + child);\n+                            }\n+                        }\n+                    }\n+                    if (mostRecentSize == count) {\n+                        break;\n+                    }\n+                } catch (KeeperException e) {\n+                    // ignore\n+                }\n+                Thread.sleep(1000);\n+            }\n+            return mostRecentSize;\n+        } finally {\n+            zkc.close();\n+        }\n+    }\n+\n+    public static String getBkLedgerPath() {\n+        return \"/ledgers\";\n+    }\n+\n+    public static ZooKeeper connectZooKeeper(String zkHost, int zkPort)\n+        throws IOException, KeeperException, InterruptedException {\n+            return connectZooKeeper(zkHost, zkPort, DEFAULT_ZK_TIMEOUT_SEC);\n+    }\n+\n+    public static ZooKeeper connectZooKeeper(String zkHost, int zkPort, int zkTimeoutSec)\n+        throws IOException, KeeperException, InterruptedException {\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        final String zkHostPort = zkHost + \":\" + zkPort;\n+\n+        ZooKeeper zkc = new ZooKeeper(zkHostPort, zkTimeoutSec * 1000, new Watcher() {\n+            public void process(WatchedEvent event) {\n+                if (event.getState() == Event.KeeperState.SyncConnected) {\n+                    latch.countDown();\n+                }\n+            }\n+        });\n+        if (!latch.await(zkTimeoutSec, TimeUnit.SECONDS)) {\n+            throw new IOException(\"Zookeeper took too long to connect\");\n+        }\n+        return zkc;\n+    }\n+\n+    public static URI createDLMURI(String path) throws Exception {\n+        return createDLMURI(DEFAULT_ZK_ENSEMBLE, path);\n+    }\n+\n+    public static URI createDLMURI(String zkServers, String path) throws Exception {\n+        return URI.create(\"distributedlog://\" + zkServers + DLOG_NAMESPACE + path);\n+    }\n+\n+    /**\n+     * Try to start zookkeeper locally on any port.\n+     */\n+    public static Pair<ZooKeeperServerShim, Integer> runZookeeperOnAnyPort(File zkDir) throws Exception {\n+        return runZookeeperOnAnyPort((int) (Math.random()*10000+7000), zkDir);\n+    }\n+\n+    /**\n+     * Try to start zookkeeper locally on any port beginning with some base port.\n+     * Dump some socket info when bind fails.\n+     */\n+    public static Pair<ZooKeeperServerShim, Integer> runZookeeperOnAnyPort(int basePort, File zkDir) throws Exception {\n+\n+        final int MAX_RETRIES = 20;\n+        final int MIN_PORT = 1025;\n+        final int MAX_PORT = 65535;\n+        ZooKeeperServerShim zks = null;\n+        int zkPort = basePort;\n+        boolean success = false;\n+        int retries = 0;\n+\n+        while (!success) {\n+            try {\n+                LOG.info(\"zk trying to bind to port \" + zkPort);\n+                zks = LocalBookKeeper.runZookeeper(1000, zkPort, zkDir);\n+                success = true;\n+            } catch (BindException be) {\n+                retries++;\n+                if (retries > MAX_RETRIES) {\n+                    throw be;\n+                }\n+                zkPort++;\n+                if (zkPort > MAX_PORT) {\n+                    zkPort = MIN_PORT;\n+                }\n+            }\n+        }\n+\n+        return Pair.of(zks, zkPort);\n+    }\n+\n+    public static void main(String[] args) throws Exception {\n+        try {\n+            if (args.length < 1) {\n+                System.out.println(\"Usage: LocalDLEmulator <zk_port>\");\n+                System.exit(-1);\n+            }\n+\n+            final int zkPort = Integer.parseInt(args[0]);\n+            final File zkDir = IOUtils.createTempDir(\"distrlog\", \"zookeeper\");\n+            final LocalDLMEmulator localDlm = LocalDLMEmulator.newBuilder()\n+                .zkPort(zkPort)\n+                .build();\n+\n+            Runtime.getRuntime().addShutdownHook(new Thread() {\n+                @Override\n+                public void run() {\n+                    try {\n+                        localDlm.teardown();\n+                        FileUtils.deleteDirectory(zkDir);\n+                        System.out.println(\"ByeBye!\");\n+                    } catch (Exception e) {\n+                        // do nothing\n+                    }\n+                }\n+            });\n+            localDlm.start();\n+\n+            System.out.println(String.format(\n+                \"DistributedLog Sandbox is running now. You could access distributedlog://%s:%s\",\n+                DEFAULT_ZK_HOST,\n+                zkPort));\n+        } catch (Exception ex) {\n+            System.out.println(\"Exception occurred running emulator \" + ex);\n+        }\n+    }\n+}"},{"sha":"c12de29a8daeeda5c71efc4ab5e82dfce46c8793","filename":"src/main/java/com/twitter/distributedlog/LogReader.java","status":"added","additions":195,"deletions":0,"changes":195,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,195 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * <i>LogReader</i> is a `synchronous` reader reading records from a DL log.\n+ *\n+ * <h3>Lifecycle of a Reader</h3>\n+ *\n+ * A reader is a <i>sequential</i> reader that read records from a DL log starting\n+ * from a given position. The position could be a <i>DLSN</i> (via {@link DistributedLogManager#getInputStream(DLSN)}\n+ * or a <i>Transaction ID</i> (via {@link DistributedLogManager#getInputStream(long)}.\n+ * <p>\n+ * After the reader is open, it could call {@link #readNext(boolean)} or {@link #readBulk(boolean, int)}\n+ * to read records out the log from provided position.\n+ * <p>\n+ * Closing the reader (via {@link #close()} will release all the resources occupied\n+ * by this reader instance.\n+ * <p>\n+ * Exceptions could be thrown during reading records. Once the exception is thrown,\n+ * the reader is set to an error state and it isn't usable anymore. It is the application's\n+ * responsibility to handle the exceptions and re-create readers if necessary.\n+ * <p>\n+ * Example:\n+ * <pre>\n+ * DistributedLogManager dlm = ...;\n+ * long nextTxId = ...;\n+ * LogReader reader = dlm.getInputStream(nextTxId);\n+ *\n+ * while (true) { // keep reading & processing records\n+ *     LogRecord record;\n+ *     try {\n+ *         record = reader.readNext(false);\n+ *         nextTxId = record.getTransactionId();\n+ *         // process the record\n+ *         ...\n+ *     } catch (IOException ioe) {\n+ *         // handle the exception\n+ *         ...\n+ *         reader = dlm.getInputStream(nextTxId + 1);\n+ *     }\n+ * }\n+ *\n+ * </pre>\n+ *\n+ * <h3>Read Records</h3>\n+ *\n+ * Reading records from an <i>endless</i> log in `synchronous` way isn't as\n+ * trivial as in `asynchronous` way (via {@link AsyncLogReader}. Because it\n+ * lacks of callback mechanism. LogReader introduces a flag `nonBlocking` on\n+ * controlling the <i>waiting</i> behavior on `synchronous` reads.\n+ *\n+ * <h4>Blocking vs NonBlocking</h4>\n+ *\n+ * <i>Blocking</i> (nonBlocking = false) means the reads will wait for records\n+ * before returning read calls. While <i>NonBlocking</i> (nonBlocking = true)\n+ * means the reads will only check readahead cache and return whatever records\n+ * available in the readahead cache.\n+ * <p>\n+ * The <i>waiting</i> period varies in <i>blocking</i> mode. If the reader is\n+ * catching up with writer (there are records in the log), the read call will\n+ * wait until records are read and returned. If the reader is caught up with\n+ * writer (there are no more records in the log at read time), the read call\n+ * will wait for a small period of time (defined in\n+ * {@link DistributedLogConfiguration#getReadAheadWaitTime()} and return whatever\n+ * records available in the readahead cache. In other words, if a reader sees\n+ * no record on blocking reads, it means the reader is `caught-up` with the\n+ * writer.\n+ * <p>\n+ * <i>Blocking</i> and <i>NonBlocking</i> modes are useful for building replicated\n+ * state machines. Applications could use <i>blocking</i> reads till caught up\n+ * with latest data. Once they are caught up with latest data, they could start\n+ * serving their service and turn to <i>non-blocking</i> read mode and tail read\n+ * data from the logs.\n+ * <p>\n+ * See examples below.\n+ *\n+ * <h4>Read Single Record</h4>\n+ *\n+ * {@link #readNext(boolean)} is reading individual records from a DL log.\n+ *\n+ * <pre>\n+ * LogReader reader = ...\n+ *\n+ * // keep reading records in blocking way until no records available in the log\n+ * LogRecord record = reader.readNext(false);\n+ * while (null != record) {\n+ *     // process the record\n+ *     ...\n+ *     // read next record\n+ *     records = reader.readNext(false);\n+ * }\n+ *\n+ * ...\n+ *\n+ * // reader is caught up with writer, doing non-blocking reads to tail the log\n+ * while (true) {\n+ *     record = reader.readNext(true)\n+ *     // process the new records\n+ *     ...\n+ * }\n+ * </pre>\n+ *\n+ * <h4>Read Batch of Records</h4>\n+ *\n+ * {@link #readBulk(boolean, int)} is a convenient way to read a batch of records\n+ * from a DL log.\n+ *\n+ * <pre>\n+ * LogReader reader = ...\n+ * int N = 10;\n+ *\n+ * // keep reading N records in blocking way until no records available in the log\n+ * List<LogRecord> records = reader.readBulk(false, N);\n+ * while (!records.isEmpty()) {\n+ *     // process the list of records\n+ *     ...\n+ *     if (records.size() < N) { // no more records available in the log\n+ *         break;\n+ *     }\n+ *     // read next N records\n+ *     records = reader.readBulk(false, N);\n+ * }\n+ *\n+ * ...\n+ *\n+ * // reader is caught up with writer, doing non-blocking reads to tail the log\n+ * while (true) {\n+ *     records = reader.readBulk(true, N)\n+ *     // process the new records\n+ *     ...\n+ * }\n+ *\n+ * </pre>\n+ *\n+ * @see AsyncLogReader\n+ *\n+ * NOTE:\n+ * 1. Extending {@link AsyncCloseable}: BKSyncLogReader is implemented based on BKAsyncLogReader, exposing\n+ *    the {@link AsyncCloseable} interface so the reader could be closed asynchronously\n+ */\n+public interface LogReader extends Closeable, AsyncCloseable {\n+\n+    /**\n+     * Read the next log record from the stream.\n+     * <p>\n+     * If <i>nonBlocking</i> is set to true, the call returns immediately by just polling\n+     * records from read ahead cache. It would return <i>null</i> if there isn't any records\n+     * available in the read ahead cache.\n+     * <p>\n+     * If <i>nonBlocking</i> is set to false, it would does blocking call. The call will\n+     * block until return a record if there are records in the stream (aka catching up).\n+     * Otherwise it would wait up to {@link DistributedLogConfiguration#getReadAheadWaitTime()}\n+     * milliseconds and return null if there isn't any more records in the stream.\n+     *\n+     * @param nonBlocking should the read make blocking calls to the backend or rely on the\n+     * readAhead cache\n+     * @return an operation from the stream or null if at end of stream\n+     * @throws IOException if there is an error reading from the stream\n+     */\n+    public LogRecordWithDLSN readNext(boolean nonBlocking) throws IOException;\n+\n+    /**\n+     * Read the next <i>numLogRecords</i> log records from the stream\n+     *\n+     * @param nonBlocking should the read make blocking calls to the backend or rely on the\n+     * readAhead cache\n+     * @param numLogRecords maximum number of log records returned by this call.\n+     * @return an operation from the stream or empty list if at end of stream\n+     * @throws IOException if there is an error reading from the stream\n+     * @see #readNext(boolean)\n+     */\n+    public List<LogRecordWithDLSN> readBulk(boolean nonBlocking, int numLogRecords) throws IOException;\n+}"},{"sha":"7fe994204a61787ded6ca59e4a980caa7d6855f8","filename":"src/main/java/com/twitter/distributedlog/LogSegmentMetadata.java","status":"added","additions":1118,"deletions":0,"changes":1118,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogSegmentMetadata.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogSegmentMetadata.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogSegmentMetadata.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,1118 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Comparator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Objects;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.util.Future;\n+import com.twitter.util.Promise;\n+import org.apache.zookeeper.AsyncCallback;\n+import org.apache.zookeeper.CreateMode;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.data.Stat;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.UnsupportedMetadataVersionException;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+\n+/**\n+ * Utility class for storing the metadata associated\n+ * with a single edit log segment, stored in a single ledger\n+ */\n+public class LogSegmentMetadata {\n+    static final Logger LOG = LoggerFactory.getLogger(LogSegmentMetadata.class);\n+\n+    public static enum LogSegmentMetadataVersion {\n+        VERSION_INVALID(0),\n+        VERSION_V1_ORIGINAL(1),\n+        VERSION_V2_LEDGER_SEQNO(2),\n+        VERSION_V3_MIN_ACTIVE_DLSN(3),\n+        VERSION_V4_ENVELOPED_ENTRIES(4),\n+        VERSION_V5_SEQUENCE_ID(5);\n+\n+        public final int value;\n+\n+        private LogSegmentMetadataVersion(int value) {\n+            this.value = value;\n+        }\n+\n+        public static LogSegmentMetadataVersion of(int version) {\n+            switch (version) {\n+                case 5:\n+                    return VERSION_V5_SEQUENCE_ID;\n+                case 4:\n+                    return VERSION_V4_ENVELOPED_ENTRIES;\n+                case 3:\n+                    return VERSION_V3_MIN_ACTIVE_DLSN;\n+                case 2:\n+                    return VERSION_V2_LEDGER_SEQNO;\n+                case 1:\n+                    return VERSION_V1_ORIGINAL;\n+                case 0:\n+                    return VERSION_INVALID;\n+                default:\n+                    throw new IllegalArgumentException(\"unknown version \" + version);\n+            }\n+        }\n+    }\n+\n+    public static enum TruncationStatus {\n+        ACTIVE (0), PARTIALLY_TRUNCATED(1), TRUNCATED (2);\n+        private final int value;\n+\n+        private TruncationStatus(int value) {\n+            this.value = value;\n+        }\n+    }\n+\n+    public static class LogSegmentMetadataBuilder {\n+        protected String zkPath;\n+        protected long ledgerId;\n+        protected LogSegmentMetadataVersion version;\n+        protected long firstTxId;\n+        protected int regionId;\n+        protected long status;\n+        protected long lastTxId;\n+        protected long completionTime;\n+        protected int recordCount;\n+        protected long logSegmentSequenceNo;\n+        protected long lastEntryId;\n+        protected long lastSlotId;\n+        protected long minActiveEntryId;\n+        protected long minActiveSlotId;\n+        protected long startSequenceId;\n+        protected boolean inprogress;\n+\n+        // This is a derived attribute.\n+        // Since we overwrite the original version with the target version, information that is\n+        // derived from the original version (e.g. does it support enveloping of entries)\n+        // is lost while parsing.\n+        // NOTE: This value is not stored in the Metadata store.\n+        protected boolean envelopeEntries = false;\n+\n+        LogSegmentMetadataBuilder(String zkPath,\n+                                  LogSegmentMetadataVersion version,\n+                                  long ledgerId,\n+                                  long firstTxId) {\n+            initialize();\n+            this.zkPath = zkPath;\n+            this.version = version;\n+            this.ledgerId = ledgerId;\n+            this.firstTxId = firstTxId;\n+        }\n+\n+        LogSegmentMetadataBuilder(String zkPath,\n+                                  int version,\n+                                  long ledgerId,\n+                                  long firstTxId) {\n+            this(zkPath, LogSegmentMetadataVersion.values()[version], ledgerId, firstTxId);\n+        }\n+\n+        private void initialize() {\n+            regionId = DistributedLogConstants.LOCAL_REGION_ID;\n+            status = DistributedLogConstants.LOGSEGMENT_DEFAULT_STATUS;\n+            lastTxId = DistributedLogConstants.INVALID_TXID;\n+            completionTime = 0;\n+            recordCount = 0;\n+            lastEntryId = -1;\n+            lastSlotId = -1;\n+            minActiveEntryId = 0;\n+            minActiveSlotId = 0;\n+            startSequenceId = DistributedLogConstants.UNASSIGNED_SEQUENCE_ID;\n+            inprogress = true;\n+        }\n+\n+        LogSegmentMetadataBuilder setRegionId(int regionId) {\n+            this.regionId = regionId;\n+            return this;\n+        }\n+\n+        LogSegmentMetadataBuilder setStatus(long status) {\n+            this.status = status;\n+            return this;\n+        }\n+\n+        public LogSegmentMetadataBuilder setLastTxId(long lastTxId) {\n+            this.lastTxId = lastTxId;\n+            return this;\n+        }\n+\n+        public LogSegmentMetadataBuilder setCompletionTime(long completionTime) {\n+            this.completionTime = completionTime;\n+            return this;\n+        }\n+\n+        public LogSegmentMetadataBuilder setRecordCount(int recordCount) {\n+            this.recordCount = recordCount;\n+            return this;\n+        }\n+\n+        public LogSegmentMetadataBuilder setRecordCount(LogRecord record) {\n+            this.recordCount = record.getLastPositionWithinLogSegment();\n+            return this;\n+        }\n+\n+        public LogSegmentMetadataBuilder setInprogress(boolean inprogress) {\n+            this.inprogress = inprogress;\n+            return this;\n+        }\n+\n+        LogSegmentMetadataBuilder setLogSegmentSequenceNo(long logSegmentSequenceNo) {\n+            this.logSegmentSequenceNo = logSegmentSequenceNo;\n+            return this;\n+        }\n+\n+        public LogSegmentMetadataBuilder setLastEntryId(long lastEntryId) {\n+            this.lastEntryId = lastEntryId;\n+            return this;\n+        }\n+\n+        LogSegmentMetadataBuilder setLastSlotId(long lastSlotId) {\n+            this.lastSlotId = lastSlotId;\n+            return this;\n+        }\n+\n+        LogSegmentMetadataBuilder setEnvelopeEntries(boolean envelopeEntries) {\n+            this.envelopeEntries = envelopeEntries;\n+            return this;\n+        }\n+\n+        LogSegmentMetadataBuilder setMinActiveEntryId(long minActiveEntryId) {\n+            this.minActiveEntryId = minActiveEntryId;\n+            return this;\n+        }\n+\n+        LogSegmentMetadataBuilder setMinActiveSlotId(long minActiveSlotId) {\n+            this.minActiveSlotId = minActiveSlotId;\n+            return this;\n+        }\n+\n+        LogSegmentMetadataBuilder setStartSequenceId(long startSequenceId) {\n+            this.startSequenceId = startSequenceId;\n+            return this;\n+        }\n+\n+        public LogSegmentMetadata build() {\n+            return new LogSegmentMetadata(\n+                zkPath,\n+                version,\n+                ledgerId,\n+                firstTxId,\n+                lastTxId,\n+                completionTime,\n+                inprogress,\n+                recordCount,\n+                    logSegmentSequenceNo,\n+                lastEntryId,\n+                lastSlotId,\n+                regionId,\n+                status,\n+                minActiveEntryId,\n+                minActiveSlotId,\n+                startSequenceId,\n+                envelopeEntries\n+            );\n+        }\n+\n+    }\n+\n+    /**\n+     * Mutator to mutate the metadata of a log segment. This mutator is going to create\n+     * a new instance of the log segment metadata without changing the existing one.\n+     */\n+    public static class Mutator extends LogSegmentMetadataBuilder {\n+\n+        Mutator(LogSegmentMetadata original) {\n+            super(original.getZkPath(), original.getVersion(), original.getLedgerId(), original.getFirstTxId());\n+            this.inprogress = original.isInProgress();\n+            this.logSegmentSequenceNo = original.getLogSegmentSequenceNumber();\n+            this.lastEntryId = original.getLastEntryId();\n+            this.lastSlotId = original.getLastSlotId();\n+            this.lastTxId = original.getLastTxId();\n+            this.completionTime = original.getCompletionTime();\n+            this.recordCount = original.getRecordCount();\n+            this.regionId = original.getRegionId();\n+            this.status = original.getStatus();\n+            this.minActiveEntryId = original.getMinActiveDLSN().getEntryId();\n+            this.minActiveSlotId = original.getMinActiveDLSN().getSlotId();\n+            this.startSequenceId = original.getStartSequenceId();\n+            this.envelopeEntries = original.getEnvelopeEntries();\n+        }\n+\n+        @VisibleForTesting\n+        public Mutator setVersion(LogSegmentMetadataVersion version) {\n+            this.version = version;\n+            return this;\n+        }\n+\n+        public Mutator setLogSegmentSequenceNumber(long seqNo) {\n+            this.logSegmentSequenceNo = seqNo;\n+            return this;\n+        }\n+\n+        public Mutator setZkPath(String zkPath) {\n+            this.zkPath = zkPath;\n+            return this;\n+        }\n+\n+        public Mutator setLastDLSN(DLSN dlsn) {\n+            this.logSegmentSequenceNo = dlsn.getLogSegmentSequenceNo();\n+            this.lastEntryId = dlsn.getEntryId();\n+            this.lastSlotId = dlsn.getSlotId();\n+            return this;\n+        }\n+\n+        public Mutator setMinActiveDLSN(DLSN dlsn) {\n+            if (this.logSegmentSequenceNo != dlsn.getLogSegmentSequenceNo()) {\n+                throw new IllegalArgumentException(\"Updating minDLSN in an incorrect log segment\");\n+            }\n+            this.minActiveEntryId = dlsn.getEntryId();\n+            this.minActiveSlotId = dlsn.getSlotId();\n+            return this;\n+        }\n+\n+        public Mutator setTruncationStatus(TruncationStatus truncationStatus) {\n+            status &= ~METADATA_TRUNCATION_STATUS_MASK;\n+            status |= (truncationStatus.value & METADATA_TRUNCATION_STATUS_MASK);\n+            return this;\n+        }\n+\n+        public Mutator setStartSequenceId(long startSequenceId) {\n+            this.startSequenceId = startSequenceId;\n+            return this;\n+        }\n+    }\n+\n+    private final String zkPath;\n+    private final long ledgerId;\n+    private final LogSegmentMetadataVersion version;\n+    private final long firstTxId;\n+    private final int regionId;\n+    private final long status;\n+    private final long lastTxId;\n+    private final long completionTime;\n+    private final int recordCount;\n+    private final DLSN lastDLSN;\n+    private final DLSN minActiveDLSN;\n+    private final long startSequenceId;\n+    private final boolean inprogress;\n+    // This is a derived attribute.\n+    // Since we overwrite the original version with the target version, information that is\n+    // derived from the original version (e.g. does it support enveloping of entries)\n+    // is lost while parsing.\n+    // NOTE: This value is not stored in the Metadata store.\n+    private final boolean envelopeEntries;\n+\n+    public static final Comparator<LogSegmentMetadata> COMPARATOR\n+        = new Comparator<LogSegmentMetadata>() {\n+\n+        public int compare(LogSegmentMetadata o1,\n+                           LogSegmentMetadata o2) {\n+            if ((o1.getLogSegmentSequenceNumber() == DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO) ||\n+                (o2.getLogSegmentSequenceNumber() == DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO)) {\n+                if (o1.firstTxId < o2.firstTxId) {\n+                    return -1;\n+                } else if (o1.firstTxId == o2.firstTxId) {\n+                    return 0;\n+                } else {\n+                    return 1;\n+                }\n+            } else {\n+                if (o1.getLogSegmentSequenceNumber() < o2.getLogSegmentSequenceNumber()) {\n+                    return -1;\n+                } else if (o1.getLogSegmentSequenceNumber() == o2.getLogSegmentSequenceNumber()) {\n+                    // make sure we won't move over inprogress log segment if it still presents in the list\n+                    if (o1.isInProgress() && !o2.isInProgress()) {\n+                        return -1;\n+                    } else if (!o1.isInProgress() && o2.isInProgress()) {\n+                        return 1;\n+                    } else {\n+                        return 0;\n+                    }\n+                } else {\n+                    return 1;\n+                }\n+            }\n+\n+\n+        }\n+    };\n+\n+    public static final Comparator<LogSegmentMetadata> DESC_COMPARATOR\n+        = new Comparator<LogSegmentMetadata>() {\n+        public int compare(LogSegmentMetadata o1,\n+                           LogSegmentMetadata o2) {\n+            if ((o1.getLogSegmentSequenceNumber() == DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO) ||\n+                (o2.getLogSegmentSequenceNumber() == DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO)) {\n+                if (o1.firstTxId > o2.firstTxId) {\n+                    return -1;\n+                } else if (o1.firstTxId == o2.firstTxId) {\n+                    return 0;\n+                } else {\n+                    return 1;\n+                }\n+            } else {\n+                if (o1.getLogSegmentSequenceNumber() > o2.getLogSegmentSequenceNumber()) {\n+                    return -1;\n+                } else if (o1.getLogSegmentSequenceNumber() == o2.getLogSegmentSequenceNumber()) {\n+                    // make sure we won't move over inprogress log segment if it still presents in the list\n+                    if (o1.isInProgress() && !o2.isInProgress()) {\n+                        return 1;\n+                    } else if (!o1.isInProgress() && o2.isInProgress()) {\n+                        return -1;\n+                    } else {\n+                        return 0;\n+                    }\n+                } else {\n+                    return 1;\n+                }\n+            }\n+        }\n+    };\n+\n+    public static final int LEDGER_METADATA_CURRENT_LAYOUT_VERSION =\n+                LogSegmentMetadataVersion.VERSION_V5_SEQUENCE_ID.value;\n+\n+    public static final int LEDGER_METADATA_OLDEST_SUPPORTED_VERSION =\n+        LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO.value;\n+\n+    static final int LOGRECORD_COUNT_SHIFT = 32;\n+    static final long LOGRECORD_COUNT_MASK = 0xffffffff00000000L;\n+    static final int REGION_SHIFT = 28;\n+    static final long MAX_REGION_ID = 0xfL;\n+    static final long REGION_MASK = 0x00000000f0000000L;\n+    static final int STATUS_BITS_SHIFT = 8;\n+    static final long STATUS_BITS_MASK = 0x000000000000ff00L;\n+    static final long UNUSED_BITS_MASK = 0x000000000fff0000L;\n+    static final long METADATA_VERSION_MASK = 0x00000000000000ffL;\n+\n+    //Metadata status bits\n+    static final long METADATA_TRUNCATION_STATUS_MASK = 0x3L;\n+    static final long METADATA_STATUS_BIT_MAX = 0xffL;\n+\n+    private LogSegmentMetadata(String zkPath,\n+                               LogSegmentMetadataVersion version,\n+                               long ledgerId,\n+                               long firstTxId,\n+                               long lastTxId,\n+                               long completionTime,\n+                               boolean inprogress,\n+                               int recordCount,\n+                               long logSegmentSequenceNumber,\n+                               long lastEntryId,\n+                               long lastSlotId,\n+                               int regionId,\n+                               long status,\n+                               long minActiveEntryId,\n+                               long minActiveSlotId,\n+                               long startSequenceId,\n+                               boolean envelopeEntries) {\n+        this.zkPath = zkPath;\n+        this.ledgerId = ledgerId;\n+        this.version = version;\n+        this.firstTxId = firstTxId;\n+        this.lastTxId = lastTxId;\n+        this.inprogress = inprogress;\n+        this.completionTime = completionTime;\n+        this.recordCount = recordCount;\n+        this.lastDLSN = new DLSN(logSegmentSequenceNumber, lastEntryId, lastSlotId);\n+        this.minActiveDLSN = new DLSN(logSegmentSequenceNumber, minActiveEntryId, minActiveSlotId);\n+        this.startSequenceId = startSequenceId;\n+        this.regionId = regionId;\n+        this.status = status;\n+        this.envelopeEntries = envelopeEntries;\n+    }\n+\n+    public String getZkPath() {\n+        return zkPath;\n+    }\n+\n+    public String getZNodeName() {\n+        return new File(zkPath).getName();\n+    }\n+\n+    public long getFirstTxId() {\n+        return firstTxId;\n+    }\n+\n+    public long getLastTxId() {\n+        return lastTxId;\n+    }\n+\n+    public long getCompletionTime() {\n+        return completionTime;\n+    }\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getLogSegmentSequenceNumber() {\n+        return lastDLSN.getLogSegmentSequenceNo();\n+    }\n+\n+    public int getVersion() {\n+        return version.value;\n+    }\n+\n+    public boolean getEnvelopeEntries() {\n+        return envelopeEntries;\n+    }\n+\n+    public long getLastEntryId() {\n+        return lastDLSN.getEntryId();\n+    }\n+\n+    long getStatus() {\n+        return status;\n+    }\n+\n+    public long getStartSequenceId() {\n+        // generate negative sequence id for log segments that created <= v4\n+        return supportsSequenceId() && startSequenceId != DistributedLogConstants.UNASSIGNED_SEQUENCE_ID ?\n+                startSequenceId : Long.MIN_VALUE + (getLogSegmentSequenceNumber() << 32L);\n+    }\n+\n+    public boolean isTruncated() {\n+        return ((status & METADATA_TRUNCATION_STATUS_MASK)\n+                == TruncationStatus.TRUNCATED.value);\n+    }\n+\n+    public boolean isPartiallyTruncated() {\n+        return ((status & METADATA_TRUNCATION_STATUS_MASK)\n+                == TruncationStatus.PARTIALLY_TRUNCATED.value);\n+    }\n+\n+    public boolean isNonTruncated() {\n+        return ((status & METADATA_TRUNCATION_STATUS_MASK)\n+                == TruncationStatus.ACTIVE.value);\n+    }\n+\n+    public long getLastSlotId() {\n+        return lastDLSN.getSlotId();\n+    }\n+\n+    public DLSN getLastDLSN() {\n+        return lastDLSN;\n+    }\n+\n+    public DLSN getMinActiveDLSN() {\n+        return minActiveDLSN;\n+    }\n+\n+    public DLSN getFirstDLSN() {\n+        return new DLSN(getLogSegmentSequenceNumber(), 0, 0);\n+    }\n+\n+    public int getRecordCount() {\n+        return recordCount;\n+    }\n+\n+    public int getRegionId() {\n+        return regionId;\n+    }\n+\n+    public boolean isInProgress() {\n+        return this.inprogress;\n+    }\n+\n+    @VisibleForTesting\n+    public boolean isDLSNinThisSegment(DLSN dlsn) {\n+        return dlsn.getLogSegmentSequenceNo() == getLogSegmentSequenceNumber();\n+    }\n+\n+    @VisibleForTesting\n+    public boolean isRecordPositionWithinSegmentScope(LogRecord record) {\n+        return record.getLastPositionWithinLogSegment() <= getRecordCount();\n+    }\n+\n+    @VisibleForTesting\n+    public boolean isRecordLastPositioninThisSegment(LogRecord record) {\n+        return record.getLastPositionWithinLogSegment() == getRecordCount();\n+    }\n+\n+    /**\n+     * complete current log segment. A new log segment metadata instance will be returned.\n+     *\n+     * @param zkPath\n+     *          zk path for the completed log segment.\n+     * @param newLastTxId\n+     *          last tx id\n+     * @param recordCount\n+     *          record count\n+     * @param lastEntryId\n+     *          last entry id\n+     * @param lastSlotId\n+     *          last slot id\n+     * @return completed log segment.\n+     */\n+    LogSegmentMetadata completeLogSegment(String zkPath,\n+                                                long newLastTxId,\n+                                                int recordCount,\n+                                                long lastEntryId,\n+                                                long lastSlotId,\n+                                                long startSequenceId) {\n+        assert this.lastTxId == DistributedLogConstants.INVALID_TXID;\n+\n+        return new Mutator(this)\n+                .setZkPath(zkPath)\n+                .setLastDLSN(new DLSN(this.lastDLSN.getLogSegmentSequenceNo(), lastEntryId, lastSlotId))\n+                .setLastTxId(newLastTxId)\n+                .setInprogress(false)\n+                .setCompletionTime(Utils.nowInMillis())\n+                .setRecordCount(recordCount)\n+                .setStartSequenceId(startSequenceId)\n+                .build();\n+    }\n+\n+    public static Future<LogSegmentMetadata> read(ZooKeeperClient zkc, String path) {\n+        return read(zkc, path, false);\n+    }\n+\n+    public static Future<LogSegmentMetadata> read(ZooKeeperClient zkc, String path, final boolean skipMinVersionCheck) {\n+        final Promise<LogSegmentMetadata> result = new Promise<LogSegmentMetadata>();\n+        try {\n+            zkc.get().getData(path, false, new AsyncCallback.DataCallback() {\n+                @Override\n+                public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {\n+                    if (KeeperException.Code.OK.intValue() != rc) {\n+                        result.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+                        return;\n+                    }\n+                    try {\n+                        LogSegmentMetadata metadata = parseData(path, data, skipMinVersionCheck);\n+                        result.setValue(metadata);\n+                    } catch (IOException ie) {\n+                        LOG.error(\"Error on parsing log segment metadata from {} : \", path, ie);\n+                        result.setException(ie);\n+                    }\n+                }\n+            }, null);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            result.setException(FutureUtils.zkException(e, path));\n+        } catch (InterruptedException e) {\n+            result.setException(FutureUtils.zkException(e, path));\n+        }\n+        return result;\n+    }\n+\n+    static LogSegmentMetadata parseDataV1(String path, byte[] data, String[] parts)\n+        throws IOException {\n+        long versionStatusCount = Long.valueOf(parts[0]);\n+\n+        long version = versionStatusCount & METADATA_VERSION_MASK;\n+        assert (version >= Integer.MIN_VALUE && version <= Integer.MAX_VALUE);\n+        assert (1 == version);\n+\n+        LogSegmentMetadataVersion llmv = LogSegmentMetadataVersion.VERSION_V1_ORIGINAL;\n+\n+        int regionId = (int)(versionStatusCount & REGION_MASK) >> REGION_SHIFT;\n+        assert (regionId >= 0 && regionId <= 0xf);\n+\n+        long status = (versionStatusCount & STATUS_BITS_MASK) >> STATUS_BITS_SHIFT;\n+        assert (status >= 0 && status <= METADATA_STATUS_BIT_MAX);\n+\n+        if (parts.length == 3) {\n+            long ledgerId = Long.valueOf(parts[1]);\n+            long txId = Long.valueOf(parts[2]);\n+            return new LogSegmentMetadataBuilder(path, llmv, ledgerId, txId)\n+                    .setRegionId(regionId)\n+                    .setStatus(status)\n+                    .build();\n+        } else if (parts.length == 5) {\n+            long recordCount = (versionStatusCount & LOGRECORD_COUNT_MASK) >> LOGRECORD_COUNT_SHIFT;\n+            assert (recordCount >= Integer.MIN_VALUE && recordCount <= Integer.MAX_VALUE);\n+\n+            long ledgerId = Long.valueOf(parts[1]);\n+            long firstTxId = Long.valueOf(parts[2]);\n+            long lastTxId = Long.valueOf(parts[3]);\n+            long completionTime = Long.valueOf(parts[4]);\n+            return new LogSegmentMetadataBuilder(path, llmv, ledgerId, firstTxId)\n+                .setInprogress(false)\n+                .setLastTxId(lastTxId)\n+                .setCompletionTime(completionTime)\n+                .setRecordCount((int) recordCount)\n+                .setRegionId(regionId)\n+                .setStatus(status)\n+                .build();\n+        } else {\n+            throw new IOException(\"Invalid log segment metadata : \"\n+                + new String(data, UTF_8));\n+        }\n+    }\n+\n+    static LogSegmentMetadata parseDataV2(String path, byte[] data, String[] parts)\n+        throws IOException {\n+        long versionStatusCount = Long.valueOf(parts[0]);\n+\n+        long version = versionStatusCount & METADATA_VERSION_MASK;\n+        assert (version >= Integer.MIN_VALUE && version <= Integer.MAX_VALUE);\n+        assert (2 == version);\n+\n+        LogSegmentMetadataVersion llmv = LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO;\n+\n+        int regionId = (int)((versionStatusCount & REGION_MASK) >> REGION_SHIFT);\n+        assert (regionId >= 0 && regionId <= 0xf);\n+\n+        long status = (versionStatusCount & STATUS_BITS_MASK) >> STATUS_BITS_SHIFT;\n+        assert (status >= 0 && status <= METADATA_STATUS_BIT_MAX);\n+\n+        if (parts.length == 4) {\n+            long ledgerId = Long.valueOf(parts[1]);\n+            long txId = Long.valueOf(parts[2]);\n+            long logSegmentSequenceNumber = Long.valueOf(parts[3]);\n+            return new LogSegmentMetadataBuilder(path, llmv, ledgerId, txId)\n+                .setLogSegmentSequenceNo(logSegmentSequenceNumber)\n+                .setRegionId(regionId)\n+                .setStatus(status)\n+                .build();\n+        } else if (parts.length == 8) {\n+            long recordCount = (versionStatusCount & LOGRECORD_COUNT_MASK) >> LOGRECORD_COUNT_SHIFT;\n+            assert (recordCount >= Integer.MIN_VALUE && recordCount <= Integer.MAX_VALUE);\n+\n+            long ledgerId = Long.valueOf(parts[1]);\n+            long firstTxId = Long.valueOf(parts[2]);\n+            long lastTxId = Long.valueOf(parts[3]);\n+            long completionTime = Long.valueOf(parts[4]);\n+            long logSegmentSequenceNumber = Long.valueOf(parts[5]);\n+            long lastEntryId = Long.valueOf(parts[6]);\n+            long lastSlotId = Long.valueOf(parts[7]);\n+            return new LogSegmentMetadataBuilder(path, llmv, ledgerId, firstTxId)\n+                .setInprogress(false)\n+                .setLastTxId(lastTxId)\n+                .setCompletionTime(completionTime)\n+                .setRecordCount((int) recordCount)\n+                .setLogSegmentSequenceNo(logSegmentSequenceNumber)\n+                .setLastEntryId(lastEntryId)\n+                .setLastSlotId(lastSlotId)\n+                .setRegionId(regionId)\n+                .setStatus(status)\n+                .build();\n+        } else {\n+            throw new IOException(\"Invalid logsegment metadata : \"\n+                + new String(data, UTF_8));\n+        }\n+\n+    }\n+\n+    static LogSegmentMetadata parseDataVersionsWithMinActiveDLSN(String path, byte[] data, String[] parts)\n+        throws IOException {\n+        long versionStatusCount = Long.valueOf(parts[0]);\n+\n+        long version = versionStatusCount & METADATA_VERSION_MASK;\n+        assert (version >= Integer.MIN_VALUE && version <= Integer.MAX_VALUE);\n+        assert (LogSegmentMetadataVersion.VERSION_V3_MIN_ACTIVE_DLSN.value <= version &&\n+                LogSegmentMetadataVersion.VERSION_V4_ENVELOPED_ENTRIES.value >= version);\n+\n+        LogSegmentMetadataVersion llmv = LogSegmentMetadataVersion.of((int) version);\n+\n+        int regionId = (int)((versionStatusCount & REGION_MASK) >> REGION_SHIFT);\n+        assert (regionId >= 0 && regionId <= 0xf);\n+\n+        long status = (versionStatusCount & STATUS_BITS_MASK) >> STATUS_BITS_SHIFT;\n+        assert (status >= 0 && status <= METADATA_STATUS_BIT_MAX);\n+\n+        if (parts.length == 6) {\n+            long ledgerId = Long.valueOf(parts[1]);\n+            long txId = Long.valueOf(parts[2]);\n+            long logSegmentSequenceNumber = Long.valueOf(parts[3]);\n+            long minActiveEntryId = Long.valueOf(parts[4]);\n+            long minActiveSlotId = Long.valueOf(parts[5]);\n+\n+            LogSegmentMetadataBuilder builder = new LogSegmentMetadataBuilder(path, llmv, ledgerId, txId)\n+                .setLogSegmentSequenceNo(logSegmentSequenceNumber)\n+                .setMinActiveEntryId(minActiveEntryId)\n+                .setMinActiveSlotId(minActiveSlotId)\n+                .setRegionId(regionId)\n+                .setStatus(status);\n+            if (supportsEnvelopedEntries((int) version)) {\n+                builder = builder.setEnvelopeEntries(true);\n+            }\n+            return builder.build();\n+        } else if (parts.length == 10) {\n+            long recordCount = (versionStatusCount & LOGRECORD_COUNT_MASK) >> LOGRECORD_COUNT_SHIFT;\n+            assert (recordCount >= Integer.MIN_VALUE && recordCount <= Integer.MAX_VALUE);\n+\n+            long ledgerId = Long.valueOf(parts[1]);\n+            long firstTxId = Long.valueOf(parts[2]);\n+            long lastTxId = Long.valueOf(parts[3]);\n+            long completionTime = Long.valueOf(parts[4]);\n+            long logSegmentSequenceNumber = Long.valueOf(parts[5]);\n+            long lastEntryId = Long.valueOf(parts[6]);\n+            long lastSlotId = Long.valueOf(parts[7]);\n+            long minActiveEntryId = Long.valueOf(parts[8]);\n+            long minActiveSlotId = Long.valueOf(parts[9]);\n+            LogSegmentMetadataBuilder builder = new LogSegmentMetadataBuilder(path, llmv, ledgerId, firstTxId)\n+                .setInprogress(false)\n+                .setLastTxId(lastTxId)\n+                .setCompletionTime(completionTime)\n+                .setRecordCount((int) recordCount)\n+                .setLogSegmentSequenceNo(logSegmentSequenceNumber)\n+                .setLastEntryId(lastEntryId)\n+                .setLastSlotId(lastSlotId)\n+                .setMinActiveEntryId(minActiveEntryId)\n+                .setMinActiveSlotId(minActiveSlotId)\n+                .setRegionId(regionId)\n+                .setStatus(status);\n+            if (supportsEnvelopedEntries((int) version)) {\n+                builder = builder.setEnvelopeEntries(true);\n+            }\n+            return builder.build();\n+        } else {\n+            throw new IOException(\"Invalid logsegment metadata : \"\n+                + new String(data, UTF_8));\n+        }\n+\n+    }\n+\n+    static LogSegmentMetadata parseDataVersionsWithSequenceId(String path, byte[] data, String[] parts)\n+        throws IOException {\n+        long versionStatusCount = Long.valueOf(parts[0]);\n+\n+        long version = versionStatusCount & METADATA_VERSION_MASK;\n+        assert (version >= Integer.MIN_VALUE && version <= Integer.MAX_VALUE);\n+        assert (LogSegmentMetadataVersion.VERSION_V5_SEQUENCE_ID.value <= version &&\n+                LogSegmentMetadata.LEDGER_METADATA_CURRENT_LAYOUT_VERSION >= version);\n+\n+        LogSegmentMetadataVersion llmv = LogSegmentMetadataVersion.of((int) version);\n+\n+        int regionId = (int)((versionStatusCount & REGION_MASK) >> REGION_SHIFT);\n+        assert (regionId >= 0 && regionId <= 0xf);\n+\n+        long status = (versionStatusCount & STATUS_BITS_MASK) >> STATUS_BITS_SHIFT;\n+        assert (status >= 0 && status <= METADATA_STATUS_BIT_MAX);\n+\n+        if (parts.length == 7) {\n+            long ledgerId = Long.valueOf(parts[1]);\n+            long txId = Long.valueOf(parts[2]);\n+            long logSegmentSequenceNumber = Long.valueOf(parts[3]);\n+            long minActiveEntryId = Long.valueOf(parts[4]);\n+            long minActiveSlotId = Long.valueOf(parts[5]);\n+            long startSequenceId = Long.valueOf(parts[6]);\n+\n+            LogSegmentMetadataBuilder builder = new LogSegmentMetadataBuilder(path, llmv, ledgerId, txId)\n+                    .setLogSegmentSequenceNo(logSegmentSequenceNumber)\n+                    .setMinActiveEntryId(minActiveEntryId)\n+                    .setMinActiveSlotId(minActiveSlotId)\n+                    .setRegionId(regionId)\n+                    .setStatus(status)\n+                    .setStartSequenceId(startSequenceId)\n+                    .setEnvelopeEntries(true);\n+            return builder.build();\n+        } else if (parts.length == 11) {\n+            long recordCount = (versionStatusCount & LOGRECORD_COUNT_MASK) >> LOGRECORD_COUNT_SHIFT;\n+            assert (recordCount >= Integer.MIN_VALUE && recordCount <= Integer.MAX_VALUE);\n+\n+            long ledgerId = Long.valueOf(parts[1]);\n+            long firstTxId = Long.valueOf(parts[2]);\n+            long lastTxId = Long.valueOf(parts[3]);\n+            long completionTime = Long.valueOf(parts[4]);\n+            long logSegmentSequenceNumber = Long.valueOf(parts[5]);\n+            long lastEntryId = Long.valueOf(parts[6]);\n+            long lastSlotId = Long.valueOf(parts[7]);\n+            long minActiveEntryId = Long.valueOf(parts[8]);\n+            long minActiveSlotId = Long.valueOf(parts[9]);\n+            long startSequenceId = Long.valueOf(parts[10]);\n+            LogSegmentMetadataBuilder builder = new LogSegmentMetadataBuilder(path, llmv, ledgerId, firstTxId)\n+                    .setInprogress(false)\n+                    .setLastTxId(lastTxId)\n+                    .setCompletionTime(completionTime)\n+                    .setRecordCount((int) recordCount)\n+                    .setLogSegmentSequenceNo(logSegmentSequenceNumber)\n+                    .setLastEntryId(lastEntryId)\n+                    .setLastSlotId(lastSlotId)\n+                    .setMinActiveEntryId(minActiveEntryId)\n+                    .setMinActiveSlotId(minActiveSlotId)\n+                    .setRegionId(regionId)\n+                    .setStatus(status)\n+                    .setStartSequenceId(startSequenceId)\n+                    .setEnvelopeEntries(true);\n+            return builder.build();\n+        } else {\n+            throw new IOException(\"Invalid log segment metadata : \"\n+                    + new String(data, UTF_8));\n+        }\n+    }\n+\n+    public static LogSegmentMetadata parseData(String path, byte[] data)\n+            throws IOException {\n+        return parseData(path, data, false);\n+    }\n+\n+    static LogSegmentMetadata parseData(String path, byte[] data, boolean skipMinVersionCheck) throws IOException {\n+        String[] parts = new String(data, UTF_8).split(\";\");\n+        long version;\n+        try {\n+            version = Long.valueOf(parts[0]) & METADATA_VERSION_MASK;\n+        } catch (Exception exc) {\n+            throw new IOException(\"Invalid ledger entry, \"\n+                + new String(data, UTF_8));\n+        }\n+\n+        if (!skipMinVersionCheck && version < LogSegmentMetadata.LEDGER_METADATA_OLDEST_SUPPORTED_VERSION) {\n+            throw new UnsupportedMetadataVersionException(\"Ledger metadata version '\" + version + \"' is no longer supported: \"\n+                + new String(data, UTF_8));\n+        }\n+\n+        if (version > LogSegmentMetadata.LEDGER_METADATA_CURRENT_LAYOUT_VERSION) {\n+            throw new UnsupportedMetadataVersionException(\"Metadata version '\" + version + \"' is higher than the highest supported version : \"\n+                + new String(data, UTF_8));\n+        }\n+\n+        if (LogSegmentMetadataVersion.VERSION_V1_ORIGINAL.value == version) {\n+            return parseDataV1(path, data, parts);\n+        } else if (LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO.value == version) {\n+            return parseDataV2(path, data, parts);\n+        } else if (LogSegmentMetadataVersion.VERSION_V4_ENVELOPED_ENTRIES.value >= version &&\n+                   LogSegmentMetadataVersion.VERSION_V3_MIN_ACTIVE_DLSN.value <= version) {\n+            return parseDataVersionsWithMinActiveDLSN(path, data, parts);\n+        } else {\n+            assert(version >= LogSegmentMetadataVersion.VERSION_V5_SEQUENCE_ID.value);\n+            return parseDataVersionsWithSequenceId(path, data, parts);\n+        }\n+    }\n+\n+    public String getFinalisedData() {\n+        return getFinalisedData(this.version);\n+    }\n+\n+    public String getFinalisedData(LogSegmentMetadataVersion version) {\n+        String finalisedData;\n+        final long logSegmentSeqNo = getLogSegmentSequenceNumber();\n+        final long lastEntryId = getLastEntryId();\n+        final long lastSlotId = getLastSlotId();\n+        final long minActiveEntryId = minActiveDLSN.getEntryId();\n+        final long minActiveSlotId = minActiveDLSN.getSlotId();\n+\n+        if (LogSegmentMetadataVersion.VERSION_V1_ORIGINAL == version) {\n+            if (inprogress) {\n+                finalisedData = String.format(\"%d;%d;%d\",\n+                    version.value, ledgerId, firstTxId);\n+            } else {\n+                long versionAndCount = ((long) version.value) | ((long)recordCount << LOGRECORD_COUNT_SHIFT);\n+                finalisedData = String.format(\"%d;%d;%d;%d;%d\",\n+                    versionAndCount, ledgerId, firstTxId, lastTxId, completionTime);\n+            }\n+        } else {\n+            long versionStatusCount = ((long) version.value);\n+            versionStatusCount |= ((status & METADATA_STATUS_BIT_MAX) << STATUS_BITS_SHIFT);\n+            versionStatusCount |= (((long) regionId & MAX_REGION_ID) << REGION_SHIFT);\n+            if (!inprogress) {\n+                versionStatusCount |= ((long)recordCount << LOGRECORD_COUNT_SHIFT);\n+            }\n+            if (LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO == version) {\n+                if (inprogress) {\n+                    finalisedData = String.format(\"%d;%d;%d;%d\",\n+                        versionStatusCount, ledgerId, firstTxId, logSegmentSeqNo);\n+                } else {\n+                    finalisedData = String.format(\"%d;%d;%d;%d;%d;%d;%d;%d\",\n+                        versionStatusCount, ledgerId, firstTxId, lastTxId, completionTime,\n+                        logSegmentSeqNo, lastEntryId, lastSlotId);\n+                }\n+            } else if (LogSegmentMetadataVersion.VERSION_V4_ENVELOPED_ENTRIES.value >= version.value &&\n+                        LogSegmentMetadataVersion.VERSION_V3_MIN_ACTIVE_DLSN.value <= version.value) {\n+                if (inprogress) {\n+                    finalisedData = String.format(\"%d;%d;%d;%d;%d;%d\",\n+                        versionStatusCount, ledgerId, firstTxId, logSegmentSeqNo, minActiveEntryId, minActiveSlotId);\n+                } else {\n+                    finalisedData = String.format(\"%d;%d;%d;%d;%d;%d;%d;%d;%d;%d\",\n+                        versionStatusCount, ledgerId, firstTxId, lastTxId, completionTime,\n+                        logSegmentSeqNo, lastEntryId, lastSlotId, minActiveEntryId, minActiveSlotId);\n+                }\n+            } else if (LogSegmentMetadataVersion.VERSION_V5_SEQUENCE_ID.value <= version.value &&\n+                        LogSegmentMetadata.LEDGER_METADATA_CURRENT_LAYOUT_VERSION >= version.value) {\n+                if (inprogress) {\n+                    finalisedData = String.format(\"%d;%d;%d;%d;%d;%d;%d\",\n+                        versionStatusCount, ledgerId, firstTxId, logSegmentSeqNo, minActiveEntryId, minActiveSlotId, startSequenceId);\n+                } else {\n+                    finalisedData = String.format(\"%d;%d;%d;%d;%d;%d;%d;%d;%d;%d;%d\",\n+                        versionStatusCount, ledgerId, firstTxId, lastTxId, completionTime,\n+                        logSegmentSeqNo, lastEntryId, lastSlotId, minActiveEntryId, minActiveSlotId, startSequenceId);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Unsupported log segment ledger metadata version '\" + version + \"'\");\n+            }\n+        }\n+        return finalisedData;\n+    }\n+\n+    String getSegmentName() {\n+        String[] parts = this.zkPath.split(\"/\");\n+        if (parts.length <= 0) {\n+            throw new IllegalStateException(\"ZK Path is not valid\");\n+        }\n+        return parts[parts.length - 1];\n+    }\n+\n+    public void write(ZooKeeperClient zkc)\n+        throws IOException, KeeperException.NodeExistsException {\n+        String finalisedData = getFinalisedData(version);\n+        try {\n+            zkc.get().create(zkPath, finalisedData.getBytes(UTF_8),\n+                zkc.getDefaultACL(), CreateMode.PERSISTENT);\n+        } catch (KeeperException.NodeExistsException nee) {\n+            throw nee;\n+        } catch (InterruptedException ie) {\n+            throw new DLInterruptedException(\"Interrupted on creating ledger znode \" + zkPath, ie);\n+        } catch (Exception e) {\n+            LOG.error(\"Error creating ledger znode {}\", zkPath, e);\n+            throw new IOException(\"Error creating ledger znode \" + zkPath);\n+        }\n+    }\n+\n+    boolean checkEquivalence(ZooKeeperClient zkc, String path) {\n+        try {\n+            LogSegmentMetadata other = FutureUtils.result(read(zkc, path));\n+            if (LOG.isTraceEnabled()) {\n+                LOG.trace(\"Verifying {} against {}\", this, other);\n+            }\n+\n+            boolean retVal;\n+\n+            // All fields may not be comparable so only compare the ones\n+            // that can be compared\n+            // completionTime is set when a node is finalized, so that\n+            // cannot be compared\n+            // if the node is inprogress, don't compare the lastTxId either\n+            if (this.getLogSegmentSequenceNumber() != other.getLogSegmentSequenceNumber() ||\n+                this.ledgerId != other.ledgerId ||\n+                this.firstTxId != other.firstTxId) {\n+                retVal = false;\n+            } else if (this.inprogress) {\n+                retVal = other.inprogress;\n+            } else {\n+                retVal = (!other.inprogress && (this.lastTxId == other.lastTxId));\n+            }\n+\n+            if (!retVal) {\n+                LOG.warn(\"Equivalence check failed between {} and {}\", this, other);\n+            }\n+\n+            return retVal;\n+        } catch (Exception e) {\n+            LOG.error(\"Could not check equivalence between:\" + this + \" and data in \" + path, e);\n+            return false;\n+        }\n+    }\n+\n+    public boolean equals(Object o) {\n+        if (!(o instanceof LogSegmentMetadata)) {\n+            return false;\n+        }\n+        LogSegmentMetadata ol = (LogSegmentMetadata) o;\n+        return getLogSegmentSequenceNumber() == ol.getLogSegmentSequenceNumber()\n+            && ledgerId == ol.ledgerId\n+            && firstTxId == ol.firstTxId\n+            && lastTxId == ol.lastTxId\n+            && version == ol.version\n+            && completionTime == ol.completionTime\n+            && Objects.equal(lastDLSN, ol.lastDLSN)\n+            && Objects.equal(minActiveDLSN, ol.minActiveDLSN)\n+            && startSequenceId == ol.startSequenceId\n+            && status == ol.status;\n+    }\n+\n+    public int hashCode() {\n+        int hash = 1;\n+        hash = hash * 31 + (int) ledgerId;\n+        hash = hash * 31 + (int) firstTxId;\n+        hash = hash * 31 + (int) lastTxId;\n+        hash = hash * 31 + version.value;\n+        hash = hash * 31 + (int) completionTime;\n+        hash = hash * 31 + (int) getLogSegmentSequenceNumber();\n+        return hash;\n+    }\n+\n+    public String toString() {\n+        return \"[LedgerId:\" + ledgerId +\n+            \", firstTxId:\" + firstTxId +\n+            \", lastTxId:\" + lastTxId +\n+            \", version:\" + version +\n+            \", completionTime:\" + completionTime +\n+            \", recordCount:\" + recordCount +\n+            \", regionId:\" + regionId +\n+            \", status:\" + status +\n+            \", logSegmentSequenceNumber:\" + getLogSegmentSequenceNumber() +\n+            \", lastEntryId:\" + getLastEntryId() +\n+            \", lastSlotId:\" + getLastSlotId() +\n+            \", inprogress:\" + inprogress +\n+            \", minActiveDLSN:\" + minActiveDLSN +\n+            \", startSequenceId:\" + startSequenceId +\n+            \"]\";\n+    }\n+\n+    public Mutator mutator() {\n+        return new Mutator(this);\n+    }\n+\n+\n+    //\n+    // Version Checking Utilities\n+    //\n+\n+    public boolean supportsLogSegmentSequenceNo() {\n+        return supportsLogSegmentSequenceNo(version.value);\n+    }\n+\n+    /**\n+     * Whether the provided version supports log segment sequence number.\n+     *\n+     * @param version\n+     *          log segment metadata version\n+     * @return true if this log segment supports log segment sequence number.\n+     */\n+    public static boolean supportsLogSegmentSequenceNo(int version) {\n+        return version >= LogSegmentMetadataVersion.VERSION_V2_LEDGER_SEQNO.value;\n+    }\n+\n+    /**\n+     * Whether the provided version supports enveloping entries before writing to bookkeeper.\n+     *\n+     * @param version\n+     *          log segment metadata version\n+     * @return true if this log segment supports enveloping entries\n+     */\n+    public static boolean supportsEnvelopedEntries(int version) {\n+        return version >= LogSegmentMetadataVersion.VERSION_V4_ENVELOPED_ENTRIES.value;\n+    }\n+\n+    public boolean supportsSequenceId() {\n+        return supportsSequenceId(version.value);\n+    }\n+\n+    /**\n+     * Whether the provided version supports sequence id.\n+     *\n+     * @param version\n+     *          log segment metadata version\n+     * @return true if the log segment support sequence id.\n+     */\n+    public static boolean supportsSequenceId(int version) {\n+        return version >= LogSegmentMetadataVersion.VERSION_V5_SEQUENCE_ID.value;\n+    }\n+\n+}"},{"sha":"d7de58606e93a5b983dc03aa489d4a21065207ca","filename":"src/main/java/com/twitter/distributedlog/LogWriter.java","status":"added","additions":78,"deletions":0,"changes":78,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLogWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,78 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.io.Abortable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.List;\n+\n+/*\n+* A generic interface class to support writing log records into\n+* a persistent distributed log.\n+*/\n+public interface LogWriter extends Closeable, Abortable {\n+    /**\n+     * Write a log record to the stream.\n+     *\n+     * @param record single log record\n+     * @throws IOException\n+     */\n+    public void write(LogRecord record) throws IOException;\n+\n+\n+    /**\n+     * Write a list of log records to the stream.\n+     *\n+     * @param records list of log records\n+     * @throws IOException\n+     */\n+    @Deprecated\n+    public int writeBulk(List<LogRecord> records) throws IOException;\n+\n+    /**\n+     * All data that has been written to the stream so far will be sent to\n+     * persistent storage.\n+     * The transmission is asynchronous and new data can be still written to the\n+     * stream while flushing is performed.\n+     *\n+     * TODO: rename this to flush()\n+     */\n+    public long setReadyToFlush() throws IOException;\n+\n+    /**\n+     * Flush and sync all data that is ready to be flush\n+     * {@link #setReadyToFlush()} into underlying persistent store.\n+     * @throws IOException\n+     *\n+     * TODO: rename this to commit()\n+     */\n+    public long flushAndSync() throws IOException;\n+\n+    /**\n+     * Flushes all the data up to this point,\n+     * adds the end of stream marker and marks the stream\n+     * as read-only in the metadata. No appends to the\n+     * stream will be allowed after this point\n+     *\n+     * @throws IOException\n+     */\n+    public void markEndOfStream() throws IOException;\n+\n+}"},{"sha":"80cf350b63a2797768467180971bd4d5b6b4e0e9","filename":"src/main/java/com/twitter/distributedlog/MaxLogSegmentSequenceNo.java","status":"added","additions":100,"deletions":0,"changes":100,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxLogSegmentSequenceNo.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxLogSegmentSequenceNo.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxLogSegmentSequenceNo.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,100 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.util.DLUtils;\n+import org.apache.bookkeeper.meta.ZkVersion;\n+import org.apache.bookkeeper.versioning.Version;\n+import org.apache.bookkeeper.versioning.Versioned;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.data.Stat;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Utility class for storing and reading max ledger sequence number\n+ */\n+class MaxLogSegmentSequenceNo {\n+\n+    static final Logger LOG = LoggerFactory.getLogger(MaxLogSegmentSequenceNo.class);\n+\n+    Version version;\n+    long maxSeqNo;\n+\n+    MaxLogSegmentSequenceNo(Versioned<byte[]> logSegmentsData) {\n+        if (null != logSegmentsData\n+                && null != logSegmentsData.getValue()\n+                && null != logSegmentsData.getVersion()) {\n+            version = logSegmentsData.getVersion();\n+            try {\n+                maxSeqNo = DLUtils.deserializeLogSegmentSequenceNumber(logSegmentsData.getValue());\n+            } catch (NumberFormatException nfe) {\n+                maxSeqNo = DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO;\n+            }\n+        } else {\n+            maxSeqNo = DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO;\n+            if (null != logSegmentsData && null != logSegmentsData.getVersion()) {\n+                version = logSegmentsData.getVersion();\n+            } else {\n+                version = new ZkVersion(-1);\n+            }\n+        }\n+    }\n+\n+    synchronized int getZkVersion() {\n+        return ((ZkVersion) version).getZnodeVersion();\n+    }\n+\n+    synchronized long getSequenceNumber() {\n+        return maxSeqNo;\n+    }\n+\n+    synchronized MaxLogSegmentSequenceNo update(int zkVersion, long logSegmentSeqNo) {\n+        return update(new ZkVersion(zkVersion), logSegmentSeqNo);\n+    }\n+\n+    synchronized MaxLogSegmentSequenceNo update(ZkVersion version, long logSegmentSeqNo) {\n+        if (version.compare(this.version) == Version.Occurred.AFTER) {\n+            this.version = version;\n+            this.maxSeqNo = logSegmentSeqNo;\n+        }\n+        return this;\n+    }\n+\n+    synchronized void store(ZooKeeperClient zkc, String path, long logSegmentSeqNo) throws IOException {\n+        try {\n+            Stat stat = zkc.get().setData(path,\n+                    DLUtils.serializeLogSegmentSequenceNumber(logSegmentSeqNo), getZkVersion());\n+            update(stat.getVersion(), logSegmentSeqNo);\n+        } catch (KeeperException ke) {\n+            throw new ZKException(\"Error writing max ledger sequence number \" + logSegmentSeqNo + \" to \"\n+                                  + path + \" : \", ke);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException zce) {\n+            throw new IOException(\"Error writing max ledger sequence number \" + logSegmentSeqNo + \" to \"\n+                    + path + \" : \", zce);\n+        } catch (InterruptedException e) {\n+            throw new DLInterruptedException(\"Error writing max ledger sequence number \" + logSegmentSeqNo + \" to \"\n+                    + path + \" : \", e);\n+        }\n+    }\n+\n+}"},{"sha":"ea301e2c3c13f5cc3294bfe852210f91f53b1828","filename":"src/main/java/com/twitter/distributedlog/MaxTxId.java","status":"added","additions":104,"deletions":0,"changes":104,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxTxId.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxTxId.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxTxId.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.util.DLUtils;\n+import org.apache.bookkeeper.versioning.Versioned;\n+import org.apache.zookeeper.data.Stat;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Utility class for storing and reading\n+ * the max seen txid in zookeeper\n+ */\n+class MaxTxId {\n+    static final Logger LOG = LoggerFactory.getLogger(MaxTxId.class);\n+\n+    private final ZooKeeperClient zkc;\n+    private final String path;\n+    private final boolean enabled;\n+\n+    private long currentMax;\n+\n+    MaxTxId(ZooKeeperClient zkc, String path, boolean enabled,\n+            Versioned<byte[]> maxTxIdData) {\n+        this.zkc = zkc;\n+        this.path = path;\n+        this.enabled = enabled && null != maxTxIdData && null != maxTxIdData.getVersion()\n+                && null != maxTxIdData.getValue();\n+        if (this.enabled) {\n+            try {\n+                this.currentMax = DLUtils.deserializeTransactionId(maxTxIdData.getValue());\n+            } catch (NumberFormatException e) {\n+                LOG.warn(\"Invalid txn id stored in {}\", path, e);\n+                this.currentMax = 0L;\n+            }\n+        } else {\n+            this.currentMax = -1L;\n+        }\n+    }\n+\n+    String getZkPath() {\n+        return path;\n+    }\n+\n+    synchronized void setMaxTxId(long txId) {\n+        if (enabled && this.currentMax < txId) {\n+            this.currentMax = txId;\n+        }\n+    }\n+\n+    synchronized byte[] couldStore(long maxTxId) {\n+        if (enabled && currentMax < maxTxId) {\n+            return DLUtils.serializeTransactionId(maxTxId);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    /**\n+     * Store the highest TxID encountered so far so that we\n+     * can enforce the monotonically non-decreasing property\n+     * This is best effort as this enforcement is only done\n+     *\n+     * @param maxTxId - the maximum transaction id seen so far\n+     * @throws IOException\n+     */\n+    synchronized void store(long maxTxId) throws IOException {\n+        if (enabled && currentMax < maxTxId) {\n+            if (LOG.isTraceEnabled()) {\n+                LOG.trace(\"Setting maxTxId to \" + maxTxId);\n+            }\n+            String txidStr = Long.toString(maxTxId);\n+            try {\n+                Stat stat = zkc.get().setData(path, txidStr.getBytes(\"UTF-8\"), -1);\n+                currentMax = maxTxId;\n+            } catch (Exception e) {\n+                LOG.error(\"Error writing new MaxTxId value {}\", maxTxId, e);\n+            }\n+        }\n+    }\n+\n+    synchronized long get() {\n+        return currentMax;\n+    }\n+\n+}"},{"sha":"f6ff587a198e2762596645481b094747667e9ddc","filename":"src/main/java/com/twitter/distributedlog/MetadataAccessor.java","status":"added","additions":43,"deletions":0,"changes":43,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMetadataAccessor.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMetadataAccessor.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMetadataAccessor.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+public interface MetadataAccessor extends Closeable, AsyncCloseable {\n+    /**\n+     * Get the name of the stream managed by this log manager\n+     * @return streamName\n+     */\n+    public String getStreamName();\n+\n+    public void createOrUpdateMetadata(byte[] metadata) throws IOException;\n+\n+    public void deleteMetadata() throws IOException;\n+\n+    public byte[] getMetadata() throws IOException;\n+\n+    /**\n+     * Close the distributed log metadata, freeing any resources it may hold.\n+     */\n+    public void close() throws IOException;\n+\n+}"},{"sha":"58933e556f0681f8a14de95c64c359dd1341bc3d","filename":"src/main/java/com/twitter/distributedlog/ReadAheadCache.java","status":"added","additions":311,"deletions":0,"changes":311,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,311 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.io.IOException;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import com.google.common.base.Stopwatch;\n+import com.google.common.base.Ticker;\n+import com.twitter.distributedlog.callback.ReadAheadCallback;\n+import com.twitter.distributedlog.exceptions.InvalidEnvelopedEntryException;\n+import com.twitter.distributedlog.exceptions.LogReadException;\n+import org.apache.bookkeeper.client.LedgerEntry;\n+import org.apache.bookkeeper.stats.AlertStatsLogger;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ReadAheadCache {\n+    static final Logger LOG = LoggerFactory.getLogger(ReadAheadCache.class);\n+\n+    private final String streamName;\n+    private final LinkedBlockingQueue<LogRecordWithDLSN> readAheadRecords;\n+    private final int maxCachedRecords;\n+    private final AtomicReference<DLSN> minActiveDLSN = new AtomicReference<DLSN>(DLSN.NonInclusiveLowerBound);\n+    private DLSN lastReadAheadDLSN = DLSN.InvalidDLSN;\n+    private DLSN lastReadAheadUserDLSN = DLSN.InvalidDLSN;\n+    private final AtomicReference<IOException> lastException = new AtomicReference<IOException>();\n+    private final boolean deserializeRecordSet;\n+    // callbacks\n+    private final AsyncNotification notification;\n+    private ReadAheadCallback readAheadCallback = null;\n+\n+    // variables for idle reader detection\n+    private final Stopwatch lastEntryProcessTime;\n+\n+    // Stats\n+    private final AtomicLong cacheBytes = new AtomicLong(0);\n+\n+    private final AlertStatsLogger alertStatsLogger;\n+    private final StatsLogger statsLogger;\n+    private final OpStatsLogger readAheadDeliveryLatencyStat;\n+    private final OpStatsLogger negativeReadAheadDeliveryLatencyStat;\n+    // Flags on controlling delivery latency stats collection\n+    private final boolean traceDeliveryLatencyEnabled;\n+    private volatile boolean suppressDeliveryLatency = true;\n+    private final long deliveryLatencyWarnThresholdMillis;\n+\n+    public ReadAheadCache(String streamName,\n+                          StatsLogger statsLogger,\n+                          AlertStatsLogger alertStatsLogger,\n+                          AsyncNotification notification,\n+                          int maxCachedRecords,\n+                          boolean deserializeRecordSet,\n+                          boolean traceDeliveryLatencyEnabled,\n+                          long deliveryLatencyWarnThresholdMillis,\n+                          Ticker ticker) {\n+        this.streamName = streamName;\n+        this.maxCachedRecords = maxCachedRecords;\n+        this.notification = notification;\n+        this.deserializeRecordSet = deserializeRecordSet;\n+\n+        // create the readahead queue\n+        readAheadRecords = new LinkedBlockingQueue<LogRecordWithDLSN>();\n+\n+        // start the idle reader detection\n+        lastEntryProcessTime = Stopwatch.createStarted(ticker);\n+\n+        // Flags to control delivery latency tracing\n+        this.traceDeliveryLatencyEnabled = traceDeliveryLatencyEnabled;\n+        this.deliveryLatencyWarnThresholdMillis = deliveryLatencyWarnThresholdMillis;\n+        // Stats\n+        StatsLogger readAheadStatsLogger = statsLogger.scope(\"readahead\");\n+        this.statsLogger = readAheadStatsLogger;\n+        this.alertStatsLogger = alertStatsLogger;\n+        this.readAheadDeliveryLatencyStat =\n+                readAheadStatsLogger.getOpStatsLogger(\"delivery_latency\");\n+        this.negativeReadAheadDeliveryLatencyStat =\n+                readAheadStatsLogger.getOpStatsLogger(\"negative_delivery_latency\");\n+    }\n+\n+    DLSN getLastReadAheadUserDLSN() {\n+        return lastReadAheadUserDLSN;\n+    }\n+\n+    /**\n+     * Trigger read ahead callback\n+     */\n+    private synchronized void invokeReadAheadCallback() {\n+        if (null != readAheadCallback) {\n+            if (LOG.isTraceEnabled()) {\n+                LOG.trace(\"Cache has space, schedule the read ahead\");\n+            }\n+            readAheadCallback.resumeReadAhead();\n+            readAheadCallback = null;\n+        }\n+    }\n+\n+    /**\n+     * Register a readhead callback.\n+     *\n+     * @param readAheadCallback\n+     *          read ahead callback\n+     */\n+    public synchronized void setReadAheadCallback(ReadAheadCallback readAheadCallback) {\n+        this.readAheadCallback = readAheadCallback;\n+        if (!isCacheFull()) {\n+            invokeReadAheadCallback();\n+        }\n+    }\n+\n+    private void setLastException(IOException exc) {\n+        lastException.set(exc);\n+    }\n+\n+    /**\n+     * Poll next record from the readahead queue.\n+     *\n+     * @return next record from readahead queue. null if no records available in the queue.\n+     * @throws IOException\n+     */\n+    public LogRecordWithDLSN getNextReadAheadRecord() throws IOException {\n+        if (null != lastException.get()) {\n+            throw lastException.get();\n+        }\n+\n+        LogRecordWithDLSN record = readAheadRecords.poll();\n+\n+        if (null != record) {\n+            cacheBytes.addAndGet(-record.getPayload().length);\n+            if (!isCacheFull()) {\n+                invokeReadAheadCallback();\n+            }\n+        }\n+\n+        return record;\n+    }\n+\n+    /**\n+     * Check whether the readahead becomes stall.\n+     *\n+     * @param idleReaderErrorThreshold\n+     *          idle reader error threshold\n+     * @param timeUnit\n+     *          time unit of the idle reader error threshold\n+     * @return true if the readahead becomes stall, otherwise false.\n+     */\n+    public boolean isReadAheadIdle(int idleReaderErrorThreshold, TimeUnit timeUnit) {\n+        return (lastEntryProcessTime.elapsed(timeUnit) > idleReaderErrorThreshold);\n+    }\n+\n+    /**\n+     * Set an ledger entry to readahead cache\n+     *\n+     * @param key\n+     *          read position of the entry\n+     * @param entry\n+     *          the ledger entry\n+     * @param reason\n+     *          the reason to add the entry to readahead (for logging)\n+     * @param envelopeEntries\n+     *          whether this entry an enveloped entries or not\n+     * @param startSequenceId\n+     *          the start sequence id\n+     */\n+    public void set(LedgerReadPosition key,\n+                    LedgerEntry entry,\n+                    String reason,\n+                    boolean envelopeEntries,\n+                    long startSequenceId) {\n+        processNewLedgerEntry(key, entry, reason, envelopeEntries, startSequenceId);\n+        lastEntryProcessTime.reset().start();\n+        AsyncNotification n = notification;\n+        if (null != n) {\n+            n.notifyOnOperationComplete();\n+        }\n+    }\n+\n+    public boolean isCacheFull() {\n+        return getNumCachedRecords() >= maxCachedRecords;\n+    }\n+\n+    /**\n+     * Return number cached records.\n+     *\n+     * @return number cached records.\n+     */\n+    public int getNumCachedRecords() {\n+        return readAheadRecords.size();\n+    }\n+\n+    /**\n+     * Return number cached bytes.\n+     *\n+     * @return number cached bytes.\n+     */\n+    public long getNumCachedBytes() {\n+        return cacheBytes.get();\n+    }\n+\n+    public void setSuppressDeliveryLatency(boolean suppressed) {\n+        this.suppressDeliveryLatency = suppressed;\n+    }\n+\n+    public void setMinActiveDLSN(DLSN minActiveDLSN) {\n+        this.minActiveDLSN.set(minActiveDLSN);\n+    }\n+\n+    /**\n+     * Process the new ledger entry and propagate the records into readahead queue.\n+     *\n+     * @param readPosition\n+     *          position of the ledger entry\n+     * @param ledgerEntry\n+     *          ledger entry\n+     * @param reason\n+     *          reason to add this ledger entry\n+     * @param envelopeEntries\n+     *          whether this entry is enveloped\n+     * @param startSequenceId\n+     *          the start sequence id of this log segment\n+     */\n+    private void processNewLedgerEntry(final LedgerReadPosition readPosition,\n+                                       final LedgerEntry ledgerEntry,\n+                                       final String reason,\n+                                       boolean envelopeEntries,\n+                                       long startSequenceId) {\n+        try {\n+            Entry.Reader reader = Entry.newBuilder()\n+                    .setLogSegmentInfo(readPosition.getLogSegmentSequenceNumber(), startSequenceId)\n+                    .setEntryId(ledgerEntry.getEntryId())\n+                    .setEnvelopeEntry(envelopeEntries)\n+                    .deserializeRecordSet(deserializeRecordSet)\n+                    .setInputStream(ledgerEntry.getEntryInputStream())\n+                    .buildReader();\n+            while(true) {\n+                LogRecordWithDLSN record = reader.nextRecord();\n+\n+                if (null == record) {\n+                    break;\n+                }\n+\n+                if (lastReadAheadDLSN.compareTo(record.getDlsn()) >= 0) {\n+                    LOG.error(\"Out of order reads last {} : curr {}\", lastReadAheadDLSN, record.getDlsn());\n+                    throw new LogReadException(\"Out of order reads\");\n+                }\n+                lastReadAheadDLSN = record.getDlsn();\n+\n+                if (record.isControl()) {\n+                    continue;\n+                }\n+                lastReadAheadUserDLSN = lastReadAheadDLSN;\n+\n+                if (minActiveDLSN.get().compareTo(record.getDlsn()) > 0) {\n+                    continue;\n+                }\n+\n+                if (traceDeliveryLatencyEnabled && !suppressDeliveryLatency) {\n+                    long currentMs = System.currentTimeMillis();\n+                    long deliveryMs = currentMs - record.getTransactionId();\n+                    if (deliveryMs >= 0) {\n+                        readAheadDeliveryLatencyStat.registerSuccessfulEvent(deliveryMs);\n+                    } else {\n+                        negativeReadAheadDeliveryLatencyStat.registerSuccessfulEvent(-deliveryMs);\n+                    }\n+                    if (deliveryMs > deliveryLatencyWarnThresholdMillis) {\n+                        LOG.warn(\"Record {} for stream {} took long time to deliver : publish time = {}, available time = {}, delivery time = {}, reason = {}.\",\n+                                 new Object[] { record.getDlsn(), streamName, record.getTransactionId(), currentMs, deliveryMs, reason });\n+                    }\n+                }\n+                readAheadRecords.add(record);\n+                cacheBytes.addAndGet(record.getPayload().length);\n+            }\n+        } catch (InvalidEnvelopedEntryException ieee) {\n+            alertStatsLogger.raise(\"Found invalid enveloped entry on stream {} : \", streamName, ieee);\n+            setLastException(ieee);\n+        } catch (IOException exc) {\n+            setLastException(exc);\n+        }\n+    }\n+\n+    public void clear() {\n+        readAheadRecords.clear();\n+        cacheBytes.set(0L);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"%s: Cache Bytes: %d, Num Cached Records: %d\",\n+            streamName, cacheBytes.get(), getNumCachedRecords());\n+    }\n+}"},{"sha":"97f694fe0119522febd42da0461ae72f07d31c26","filename":"src/main/java/com/twitter/distributedlog/ReadUtils.java","status":"added","additions":834,"deletions":0,"changes":834,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,834 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.io.IOException;\n+import java.util.Enumeration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.LedgerEntry;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.base.Optional;\n+import com.google.common.collect.Lists;\n+import com.twitter.distributedlog.selector.FirstDLSNNotLessThanSelector;\n+import com.twitter.distributedlog.selector.FirstTxIdNotLessThanSelector;\n+import com.twitter.distributedlog.selector.LastRecordSelector;\n+import com.twitter.distributedlog.selector.LogRecordSelector;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.FutureUtils.FutureEventListenerRunnable;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import scala.runtime.AbstractFunction0;\n+import scala.runtime.BoxedUnit;\n+\n+/**\n+ * Utility function for readers\n+ */\n+public class ReadUtils {\n+\n+    static final Logger LOG = LoggerFactory.getLogger(ReadUtils.class);\n+\n+    private static final int MIN_SEARCH_BATCH_SIZE = 2;\n+\n+    //\n+    // Read First & Last Record Functions\n+    //\n+\n+    /**\n+     * Read last record from a ledger.\n+     *\n+     * @param streamName\n+     *          fully qualified stream name (used for logging)\n+     * @param l\n+     *          ledger descriptor.\n+     * @param fence\n+     *          whether to fence the ledger.\n+     * @param includeControl\n+     *          whether to include control record.\n+     * @param includeEndOfStream\n+     *          whether to include end of stream.\n+     * @param scanStartBatchSize\n+     *          first num entries used for read last record scan\n+     * @param scanMaxBatchSize\n+     *          max num entries used for read last record scan\n+     * @param numRecordsScanned\n+     *          num of records scanned to get last record\n+     * @param executorService\n+     *          executor service used for processing entries\n+     * @param handleCache\n+     *          ledger handle cache\n+     * @return a future with last record.\n+     */\n+    public static Future<LogRecordWithDLSN> asyncReadLastRecord(\n+            final String streamName,\n+            final LogSegmentMetadata l,\n+            final boolean fence,\n+            final boolean includeControl,\n+            final boolean includeEndOfStream,\n+            final int scanStartBatchSize,\n+            final int scanMaxBatchSize,\n+            final AtomicInteger numRecordsScanned,\n+            final ExecutorService executorService,\n+            final LedgerHandleCache handleCache) {\n+        final LogRecordSelector selector = new LastRecordSelector();\n+        return asyncReadRecord(streamName, l, fence, includeControl, includeEndOfStream, scanStartBatchSize,\n+                               scanMaxBatchSize, numRecordsScanned, executorService, handleCache,\n+                               selector, true /* backward */, 0L);\n+    }\n+\n+    /**\n+     * Read first record from a ledger with a DLSN larger than that given.\n+     *\n+     * @param streamName\n+     *          fully qualified stream name (used for logging)\n+     * @param l\n+     *          ledger descriptor.\n+     * @param scanStartBatchSize\n+     *          first num entries used for read last record scan\n+     * @param scanMaxBatchSize\n+     *          max num entries used for read last record scan\n+     * @param numRecordsScanned\n+     *          num of records scanned to get last record\n+     * @param executorService\n+     *          executor service used for processing entries\n+     * @param dlsn\n+     *          threshold dlsn\n+     * @return a future with last record.\n+     */\n+    public static Future<LogRecordWithDLSN> asyncReadFirstUserRecord(\n+            final String streamName,\n+            final LogSegmentMetadata l,\n+            final int scanStartBatchSize,\n+            final int scanMaxBatchSize,\n+            final AtomicInteger numRecordsScanned,\n+            final ExecutorService executorService,\n+            final LedgerHandleCache handleCache,\n+            final DLSN dlsn) {\n+        long startEntryId = 0L;\n+        if (l.getLogSegmentSequenceNumber() == dlsn.getLogSegmentSequenceNo()) {\n+            startEntryId = dlsn.getEntryId();\n+        }\n+        final LogRecordSelector selector = new FirstDLSNNotLessThanSelector(dlsn);\n+        return asyncReadRecord(streamName, l, false, false, false, scanStartBatchSize,\n+                               scanMaxBatchSize, numRecordsScanned, executorService, handleCache,\n+                               selector, false /* backward */, startEntryId);\n+    }\n+\n+    //\n+    // Private methods for scanning log segments\n+    //\n+\n+    private static class ScanContext {\n+        // variables to about current scan state\n+        final AtomicInteger numEntriesToScan;\n+        final AtomicLong curStartEntryId;\n+        final AtomicLong curEndEntryId;\n+\n+        // scan settings\n+        final long startEntryId;\n+        final long endEntryId;\n+        final int scanStartBatchSize;\n+        final int scanMaxBatchSize;\n+        final boolean includeControl;\n+        final boolean includeEndOfStream;\n+        final boolean backward;\n+\n+        // number of records scanned\n+        final AtomicInteger numRecordsScanned;\n+\n+        ScanContext(long startEntryId, long endEntryId,\n+                    int scanStartBatchSize,\n+                    int scanMaxBatchSize,\n+                    boolean includeControl,\n+                    boolean includeEndOfStream,\n+                    boolean backward,\n+                    AtomicInteger numRecordsScanned) {\n+            this.startEntryId = startEntryId;\n+            this.endEntryId = endEntryId;\n+            this.scanStartBatchSize = scanStartBatchSize;\n+            this.scanMaxBatchSize = scanMaxBatchSize;\n+            this.includeControl = includeControl;\n+            this.includeEndOfStream = includeEndOfStream;\n+            this.backward = backward;\n+            // Scan state\n+            this.numEntriesToScan = new AtomicInteger(scanStartBatchSize);\n+            if (backward) {\n+                this.curStartEntryId = new AtomicLong(\n+                        Math.max(startEntryId, (endEntryId - scanStartBatchSize + 1)));\n+                this.curEndEntryId = new AtomicLong(endEntryId);\n+            } else {\n+                this.curStartEntryId = new AtomicLong(startEntryId);\n+                this.curEndEntryId = new AtomicLong(\n+                        Math.min(endEntryId, (startEntryId + scanStartBatchSize - 1)));\n+            }\n+            this.numRecordsScanned = numRecordsScanned;\n+        }\n+\n+        boolean moveToNextRange() {\n+            if (backward) {\n+                return moveBackward();\n+            } else {\n+                return moveForward();\n+            }\n+        }\n+\n+        boolean moveBackward() {\n+            long nextEndEntryId = curStartEntryId.get() - 1;\n+            if (nextEndEntryId < startEntryId) {\n+                // no entries to read again\n+                return false;\n+            }\n+            curEndEntryId.set(nextEndEntryId);\n+            // update num entries to scan\n+            numEntriesToScan.set(\n+                    Math.min(numEntriesToScan.get() * 2, scanMaxBatchSize));\n+            // update start entry id\n+            curStartEntryId.set(Math.max(startEntryId, nextEndEntryId - numEntriesToScan.get() + 1));\n+            return true;\n+        }\n+\n+        boolean moveForward() {\n+            long nextStartEntryId = curEndEntryId.get() + 1;\n+            if (nextStartEntryId > endEntryId) {\n+                // no entries to read again\n+                return false;\n+            }\n+            curStartEntryId.set(nextStartEntryId);\n+            // update num entries to scan\n+            numEntriesToScan.set(\n+                    Math.min(numEntriesToScan.get() * 2, scanMaxBatchSize));\n+            // update start entry id\n+            curEndEntryId.set(Math.min(endEntryId, nextStartEntryId + numEntriesToScan.get() - 1));\n+            return true;\n+        }\n+    }\n+\n+    private static class SingleEntryScanContext extends ScanContext {\n+        SingleEntryScanContext(long entryId) {\n+            super(entryId, entryId, 1, 1, true, true, false, new AtomicInteger(0));\n+        }\n+    }\n+\n+    /**\n+     * Read record from a given range of ledger entries.\n+     *\n+     * @param streamName\n+     *          fully qualified stream name (used for logging)\n+     * @param ledgerDescriptor\n+     *          ledger descriptor.\n+     * @param handleCache\n+     *          ledger handle cache.\n+     * @param executorService\n+     *          executor service used for processing entries\n+     * @param context\n+     *          scan context\n+     * @return a future with the log record.\n+     */\n+    private static Future<LogRecordWithDLSN> asyncReadRecordFromEntries(\n+            final String streamName,\n+            final LedgerDescriptor ledgerDescriptor,\n+            LedgerHandleCache handleCache,\n+            final LogSegmentMetadata metadata,\n+            final ExecutorService executorService,\n+            final ScanContext context,\n+            final LogRecordSelector selector) {\n+        final Promise<LogRecordWithDLSN> promise = new Promise<LogRecordWithDLSN>();\n+        final long startEntryId = context.curStartEntryId.get();\n+        final long endEntryId = context.curEndEntryId.get();\n+        if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"{} reading entries [{} - {}] from {}.\",\n+                    new Object[] { streamName, startEntryId, endEntryId, ledgerDescriptor });\n+        }\n+        FutureEventListener<Enumeration<LedgerEntry>> readEntriesListener =\n+            new FutureEventListener<Enumeration<LedgerEntry>>() {\n+                @Override\n+                public void onSuccess(final Enumeration<LedgerEntry> entries) {\n+                    if (LOG.isDebugEnabled()) {\n+                        LOG.debug(\"{} finished reading entries [{} - {}] from {}\",\n+                                new Object[]{ streamName, startEntryId, endEntryId, ledgerDescriptor });\n+                    }\n+                    LogRecordWithDLSN record = null;\n+                    while (entries.hasMoreElements()) {\n+                        LedgerEntry entry = entries.nextElement();\n+                        try {\n+                            visitEntryRecords(\n+                                    streamName, metadata, ledgerDescriptor.getLogSegmentSequenceNo(), entry, context, selector);\n+                        } catch (IOException ioe) {\n+                            // exception is only thrown due to bad ledger entry, so it might be corrupted\n+                            // we shouldn't do anything beyond this point. throw the exception to application\n+                            promise.setException(ioe);\n+                            return;\n+                        }\n+                    }\n+\n+                    record = selector.result();\n+                    if (LOG.isDebugEnabled()) {\n+                        LOG.debug(\"{} got record from entries [{} - {}] of {} : {}\",\n+                                new Object[]{streamName, startEntryId, endEntryId,\n+                                        ledgerDescriptor, record});\n+                    }\n+                    promise.setValue(record);\n+                }\n+\n+                @Override\n+                public void onFailure(final Throwable cause) {\n+                    String errMsg = \"Error reading entries [\" + startEntryId + \"-\" + endEntryId\n+                                + \"] for reading record of \" + streamName;\n+                    promise.setException(new IOException(errMsg,\n+                            BKException.create(FutureUtils.bkResultCode(cause))));\n+                }\n+            };\n+        handleCache.asyncReadEntries(ledgerDescriptor, startEntryId, endEntryId)\n+                .addEventListener(FutureEventListenerRunnable.of(readEntriesListener, executorService));\n+        return promise;\n+    }\n+\n+    /**\n+     * Process each record using LogRecordSelector.\n+     *\n+     * @param streamName\n+     *          fully qualified stream name (used for logging)\n+     * @param logSegmentSeqNo\n+     *          ledger sequence number\n+     * @param entry\n+     *          ledger entry\n+     * @param context\n+     *          scan context\n+     * @return log record with dlsn inside the ledger entry\n+     * @throws IOException\n+     */\n+    private static void visitEntryRecords(\n+            String streamName,\n+            LogSegmentMetadata metadata,\n+            long logSegmentSeqNo,\n+            LedgerEntry entry,\n+            ScanContext context,\n+            LogRecordSelector selector) throws IOException {\n+        Entry.Reader reader = Entry.newBuilder()\n+                .setLogSegmentInfo(logSegmentSeqNo, metadata.getStartSequenceId())\n+                .setEntryId(entry.getEntryId())\n+                .setEnvelopeEntry(metadata.getEnvelopeEntries())\n+                .setInputStream(entry.getEntryInputStream())\n+                .buildReader();\n+        LogRecordWithDLSN nextRecord = reader.nextRecord();\n+        while (nextRecord != null) {\n+            LogRecordWithDLSN record = nextRecord;\n+            nextRecord = reader.nextRecord();\n+            context.numRecordsScanned.incrementAndGet();\n+            if (!context.includeControl && record.isControl()) {\n+                continue;\n+            }\n+            if (!context.includeEndOfStream && record.isEndOfStream()) {\n+                continue;\n+            }\n+            selector.process(record);\n+        }\n+    }\n+\n+    /**\n+     * Scan entries for the given record.\n+     *\n+     * @param streamName\n+     *          fully qualified stream name (used for logging)\n+     * @param ledgerDescriptor\n+     *          ledger descriptor.\n+     * @param handleCache\n+     *          ledger handle cache.\n+     * @param executorService\n+     *          executor service used for processing entries\n+     * @param promise\n+     *          promise to return desired record.\n+     * @param context\n+     *          scan context\n+     */\n+    private static void asyncReadRecordFromEntries(\n+            final String streamName,\n+            final LedgerDescriptor ledgerDescriptor,\n+            final LedgerHandleCache handleCache,\n+            final LogSegmentMetadata metadata,\n+            final ExecutorService executorService,\n+            final Promise<LogRecordWithDLSN> promise,\n+            final ScanContext context,\n+            final LogRecordSelector selector) {\n+        FutureEventListener<LogRecordWithDLSN> readEntriesListener =\n+            new FutureEventListener<LogRecordWithDLSN>() {\n+                @Override\n+                public void onSuccess(LogRecordWithDLSN value) {\n+                    if (LOG.isDebugEnabled()) {\n+                        LOG.debug(\"{} read record from [{} - {}] of {} : {}\",\n+                                new Object[]{streamName, context.curStartEntryId.get(), context.curEndEntryId.get(),\n+                                        ledgerDescriptor, value});\n+                    }\n+                    if (null != value) {\n+                        promise.setValue(value);\n+                        return;\n+                    }\n+                    if (!context.moveToNextRange()) {\n+                        // no entries to read again\n+                        promise.setValue(null);\n+                        return;\n+                    }\n+                    // scan next range\n+                    asyncReadRecordFromEntries(streamName,\n+                            ledgerDescriptor,\n+                            handleCache,\n+                            metadata,\n+                            executorService,\n+                            promise,\n+                            context,\n+                            selector);\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause) {\n+                    promise.setException(cause);\n+                }\n+            };\n+        asyncReadRecordFromEntries(streamName, ledgerDescriptor, handleCache, metadata, executorService, context, selector)\n+                .addEventListener(FutureEventListenerRunnable.of(readEntriesListener, executorService));\n+    }\n+\n+    private static void asyncReadRecordFromLogSegment(\n+            final String streamName,\n+            final LedgerDescriptor ledgerDescriptor,\n+            final LedgerHandleCache handleCache,\n+            final LogSegmentMetadata metadata,\n+            final ExecutorService executorService,\n+            final int scanStartBatchSize,\n+            final int scanMaxBatchSize,\n+            final boolean includeControl,\n+            final boolean includeEndOfStream,\n+            final Promise<LogRecordWithDLSN> promise,\n+            final AtomicInteger numRecordsScanned,\n+            final LogRecordSelector selector,\n+            final boolean backward,\n+            final long startEntryId) {\n+        final long lastAddConfirmed;\n+        try {\n+            lastAddConfirmed = handleCache.getLastAddConfirmed(ledgerDescriptor);\n+        } catch (BKException e) {\n+            promise.setException(e);\n+            return;\n+        }\n+        if (lastAddConfirmed < 0) {\n+            if (LOG.isDebugEnabled()) {\n+                LOG.debug(\"Ledger {} is empty for {}.\", new Object[] { ledgerDescriptor, streamName });\n+            }\n+            promise.setValue(null);\n+            return;\n+        }\n+        final ScanContext context = new ScanContext(\n+                startEntryId, lastAddConfirmed,\n+                scanStartBatchSize, scanMaxBatchSize,\n+                includeControl, includeEndOfStream, backward, numRecordsScanned);\n+        asyncReadRecordFromEntries(streamName, ledgerDescriptor, handleCache, metadata, executorService,\n+                                   promise, context, selector);\n+    }\n+\n+    private static Future<LogRecordWithDLSN> asyncReadRecord(\n+            final String streamName,\n+            final LogSegmentMetadata l,\n+            final boolean fence,\n+            final boolean includeControl,\n+            final boolean includeEndOfStream,\n+            final int scanStartBatchSize,\n+            final int scanMaxBatchSize,\n+            final AtomicInteger numRecordsScanned,\n+            final ExecutorService executorService,\n+            final LedgerHandleCache handleCache,\n+            final LogRecordSelector selector,\n+            final boolean backward,\n+            final long startEntryId) {\n+\n+        final Promise<LogRecordWithDLSN> promise = new Promise<LogRecordWithDLSN>();\n+\n+        FutureEventListener<LedgerDescriptor> openLedgerListener =\n+            new FutureEventListener<LedgerDescriptor>() {\n+                @Override\n+                public void onSuccess(final LedgerDescriptor ledgerDescriptor) {\n+                    if (LOG.isDebugEnabled()) {\n+                        LOG.debug(\"{} Opened logsegment {} for reading record\",\n+                                streamName, l);\n+                    }\n+                    promise.ensure(new AbstractFunction0<BoxedUnit>() {\n+                        @Override\n+                        public BoxedUnit apply() {\n+                            handleCache.asyncCloseLedger(ledgerDescriptor);\n+                            return BoxedUnit.UNIT;\n+                        }\n+                    });\n+                    if (LOG.isDebugEnabled()) {\n+                        LOG.debug(\"{} {} scanning {}.\", new Object[]{\n+                                (backward ? \"backward\" : \"forward\"), streamName, l});\n+                    }\n+                    asyncReadRecordFromLogSegment(\n+                            streamName, ledgerDescriptor, handleCache, l, executorService,\n+                            scanStartBatchSize, scanMaxBatchSize,\n+                            includeControl, includeEndOfStream,\n+                            promise, numRecordsScanned, selector, backward, startEntryId);\n+                }\n+\n+                @Override\n+                public void onFailure(final Throwable cause) {\n+                    String errMsg = \"Error opening log segment [\" + l + \"] for reading record of \" + streamName;\n+                    promise.setException(new IOException(errMsg,\n+                            BKException.create(FutureUtils.bkResultCode(cause))));\n+                }\n+            };\n+        handleCache.asyncOpenLedger(l, fence)\n+                .addEventListener(FutureEventListenerRunnable.of(openLedgerListener, executorService));\n+        return promise;\n+    }\n+\n+    //\n+    // Search Functions\n+    //\n+\n+    /**\n+     * Get the log record whose transaction id is not less than provided <code>transactionId</code>.\n+     *\n+     * <p>\n+     * It uses a binary-search like algorithm to find the log record whose transaction id is not less than\n+     * provided <code>transactionId</code> within a log <code>segment</code>. You could think of a log segment\n+     * in terms of a sequence of records whose transaction ids are non-decreasing.\n+     *\n+     * - The sequence of records within a log segment is divided into N pieces.\n+     * - Find the piece of records that contains a record whose transaction id is not less than provided\n+     *   <code>transactionId</code>.\n+     *\n+     * N could be chosen based on trading off concurrency and latency.\n+     * </p>\n+     *\n+     * @param logName\n+     *          name of the log\n+     * @param segment\n+     *          metadata of the log segment\n+     * @param transactionId\n+     *          transaction id\n+     * @param executorService\n+     *          executor service used for processing entries\n+     * @param handleCache\n+     *          ledger handle cache\n+     * @param nWays\n+     *          how many number of entries to search in parallel\n+     * @return found log record. none if all transaction ids are less than provided <code>transactionId</code>.\n+     */\n+    public static Future<Optional<LogRecordWithDLSN>> getLogRecordNotLessThanTxId(\n+            final String logName,\n+            final LogSegmentMetadata segment,\n+            final long transactionId,\n+            final ExecutorService executorService,\n+            final LedgerHandleCache handleCache,\n+            final int nWays) {\n+        if (!segment.isInProgress()) {\n+            if (segment.getLastTxId() < transactionId) {\n+                // all log records whose transaction id is less than provided transactionId\n+                // then return none\n+                Optional<LogRecordWithDLSN> noneRecord = Optional.absent();\n+                return Future.value(noneRecord);\n+            }\n+        }\n+\n+        final Promise<Optional<LogRecordWithDLSN>> promise =\n+                new Promise<Optional<LogRecordWithDLSN>>();\n+        final FutureEventListener<LedgerDescriptor> openLedgerListener =\n+            new FutureEventListener<LedgerDescriptor>() {\n+                @Override\n+                public void onSuccess(final LedgerDescriptor ld) {\n+                    promise.ensure(new AbstractFunction0<BoxedUnit>() {\n+                        @Override\n+                        public BoxedUnit apply() {\n+                            handleCache.asyncCloseLedger(ld);\n+                            return BoxedUnit.UNIT;\n+                        }\n+\n+                    });\n+                    long lastEntryId;\n+                    try {\n+                        lastEntryId = handleCache.getLastAddConfirmed(ld);\n+                    } catch (BKException e) {\n+                        promise.setException(e);\n+                        return;\n+                    }\n+                    if (lastEntryId < 0) {\n+                        // it means that the log segment is created but not written yet or an empty log segment.\n+                        // it is equivalent to 'all log records whose transaction id is less than provided transactionId'\n+                        Optional<LogRecordWithDLSN> nonRecord = Optional.absent();\n+                        promise.setValue(nonRecord);\n+                        return;\n+                    }\n+                    // all log records whose transaction id is not less than provided transactionId\n+                    if (segment.getFirstTxId() >= transactionId) {\n+                        final FirstTxIdNotLessThanSelector selector =\n+                                new FirstTxIdNotLessThanSelector(transactionId);\n+                        asyncReadRecordFromEntries(\n+                                logName,\n+                                ld,\n+                                handleCache,\n+                                segment,\n+                                executorService,\n+                                new SingleEntryScanContext(0L),\n+                                selector\n+                        ).addEventListener(new FutureEventListener<LogRecordWithDLSN>() {\n+                            @Override\n+                            public void onSuccess(LogRecordWithDLSN value) {\n+                                promise.setValue(Optional.of(selector.result()));\n+                            }\n+\n+                            @Override\n+                            public void onFailure(Throwable cause) {\n+                                promise.setException(cause);\n+                            }\n+                        });\n+\n+                        return;\n+                    }\n+                    getLogRecordNotLessThanTxIdFromEntries(\n+                            logName,\n+                            ld,\n+                            segment,\n+                            transactionId,\n+                            executorService,\n+                            handleCache,\n+                            Lists.newArrayList(0L, lastEntryId),\n+                            nWays,\n+                            Optional.<LogRecordWithDLSN>absent(),\n+                            promise);\n+                }\n+\n+                @Override\n+                public void onFailure(final Throwable cause) {\n+                    String errMsg = \"Error opening log segment [\" + segment\n+                            + \"] for find record from \" + logName;\n+                    promise.setException(new IOException(errMsg,\n+                            BKException.create(FutureUtils.bkResultCode(cause))));\n+                }\n+            };\n+        handleCache.asyncOpenLedger(segment, false)\n+                .addEventListener(FutureEventListenerRunnable.of(openLedgerListener, executorService));\n+        return promise;\n+    }\n+\n+    /**\n+     * Find the log record whose transaction id is not less than provided <code>transactionId</code> from\n+     * entries between <code>startEntryId</code> and <code>endEntryId</code>.\n+     *\n+     * @param logName\n+     *          name of the log\n+     * @param segment\n+     *          log segment\n+     * @param transactionId\n+     *          provided transaction id to search\n+     * @param executorService\n+     *          executor service\n+     * @param handleCache\n+     *          handle cache\n+     * @param entriesToSearch\n+     *          list of entries to search\n+     * @param nWays\n+     *          how many entries to search in parallel\n+     * @param prevFoundRecord\n+     *          the log record found in previous search\n+     * @param promise\n+     *          promise to satisfy the result\n+     */\n+    private static void getLogRecordNotLessThanTxIdFromEntries(\n+            final String logName,\n+            final LedgerDescriptor ld,\n+            final LogSegmentMetadata segment,\n+            final long transactionId,\n+            final ExecutorService executorService,\n+            final LedgerHandleCache handleCache,\n+            final List<Long> entriesToSearch,\n+            final int nWays,\n+            final Optional<LogRecordWithDLSN> prevFoundRecord,\n+            final Promise<Optional<LogRecordWithDLSN>> promise) {\n+        final List<Future<LogRecordWithDLSN>> searchResults =\n+                Lists.newArrayListWithExpectedSize(entriesToSearch.size());\n+        for (Long entryId : entriesToSearch) {\n+            LogRecordSelector selector = new FirstTxIdNotLessThanSelector(transactionId);\n+            Future<LogRecordWithDLSN> searchResult = asyncReadRecordFromEntries(\n+                    logName,\n+                    ld,\n+                    handleCache,\n+                    segment,\n+                    executorService,\n+                    new SingleEntryScanContext(entryId),\n+                    selector);\n+            searchResults.add(searchResult);\n+        }\n+        FutureEventListener<List<LogRecordWithDLSN>> processSearchResultsListener =\n+                new FutureEventListener<List<LogRecordWithDLSN>>() {\n+                    @Override\n+                    public void onSuccess(List<LogRecordWithDLSN> resultList) {\n+                        processSearchResults(\n+                                logName,\n+                                ld,\n+                                segment,\n+                                transactionId,\n+                                executorService,\n+                                handleCache,\n+                                resultList,\n+                                nWays,\n+                                prevFoundRecord,\n+                                promise);\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        promise.setException(cause);\n+                    }\n+                };\n+        Future.collect(searchResults).addEventListener(\n+                FutureEventListenerRunnable.of(processSearchResultsListener, executorService));\n+    }\n+\n+    /**\n+     * Process the search results\n+     */\n+    static void processSearchResults(\n+            final String logName,\n+            final LedgerDescriptor ld,\n+            final LogSegmentMetadata segment,\n+            final long transactionId,\n+            final ExecutorService executorService,\n+            final LedgerHandleCache handleCache,\n+            final List<LogRecordWithDLSN> searchResults,\n+            final int nWays,\n+            final Optional<LogRecordWithDLSN> prevFoundRecord,\n+            final Promise<Optional<LogRecordWithDLSN>> promise) {\n+        int found = -1;\n+        for (int i = 0; i < searchResults.size(); i++) {\n+            LogRecordWithDLSN record = searchResults.get(i);\n+            if (record.getTransactionId() >= transactionId) {\n+                found = i;\n+                break;\n+            }\n+        }\n+        if (found == -1) { // all log records' transaction id is less than provided transaction id\n+            promise.setValue(prevFoundRecord);\n+            return;\n+        }\n+        // we found a log record\n+        LogRecordWithDLSN foundRecord = searchResults.get(found);\n+\n+        // we found it\n+        //   - it is not the first record\n+        //   - it is the first record in first search entry\n+        //   - its entry is adjacent to previous search entry\n+        if (foundRecord.getDlsn().getSlotId() != 0L\n+                || found == 0\n+                || foundRecord.getDlsn().getEntryId() == (searchResults.get(found - 1).getDlsn().getEntryId() + 1)) {\n+            promise.setValue(Optional.of(foundRecord));\n+            return;\n+        }\n+\n+        // otherwise, we need to search\n+        List<Long> nextSearchBatch = getEntriesToSearch(\n+                transactionId,\n+                searchResults.get(found - 1),\n+                searchResults.get(found),\n+                nWays);\n+        if (nextSearchBatch.isEmpty()) {\n+            promise.setValue(prevFoundRecord);\n+            return;\n+        }\n+        getLogRecordNotLessThanTxIdFromEntries(\n+                logName,\n+                ld,\n+                segment,\n+                transactionId,\n+                executorService,\n+                handleCache,\n+                nextSearchBatch,\n+                nWays,\n+                Optional.of(foundRecord),\n+                promise);\n+    }\n+\n+    /**\n+     * Get the entries to search provided <code>transactionId</code> between\n+     * <code>firstRecord</code> and <code>lastRecord</code>. <code>firstRecord</code>\n+     * and <code>lastRecord</code> are already searched, which the transaction id\n+     * of <code>firstRecord</code> is less than <code>transactionId</code> and the\n+     * transaction id of <code>lastRecord</code> is not less than <code>transactionId</code>.\n+     *\n+     * @param transactionId\n+     *          transaction id to search\n+     * @param firstRecord\n+     *          log record that already searched whose transaction id is leass than <code>transactionId</code>.\n+     * @param lastRecord\n+     *          log record that already searched whose transaction id is not less than <code>transactionId</code>.\n+     * @param nWays\n+     *          N-ways to search\n+     * @return the list of entries to search\n+     */\n+    static List<Long> getEntriesToSearch(\n+            long transactionId,\n+            LogRecordWithDLSN firstRecord,\n+            LogRecordWithDLSN lastRecord,\n+            int nWays) {\n+        long txnDiff = lastRecord.getTransactionId() - firstRecord.getTransactionId();\n+        if (txnDiff > 0) {\n+            if (lastRecord.getTransactionId() == transactionId) {\n+                List<Long> entries = getEntriesToSearch(\n+                        firstRecord.getDlsn().getEntryId() + 1,\n+                        lastRecord.getDlsn().getEntryId() - 2,\n+                        Math.max(MIN_SEARCH_BATCH_SIZE, nWays - 1));\n+                entries.add(lastRecord.getDlsn().getEntryId() - 1);\n+                return entries;\n+            } else {\n+                // TODO: improve it by estimating transaction ids.\n+                return getEntriesToSearch(\n+                        firstRecord.getDlsn().getEntryId() + 1,\n+                        lastRecord.getDlsn().getEntryId() - 1,\n+                        nWays);\n+            }\n+        } else {\n+            // unexpected condition\n+            return Lists.newArrayList();\n+        }\n+    }\n+\n+    static List<Long> getEntriesToSearch(\n+            long startEntryId,\n+            long endEntryId,\n+            int nWays) {\n+        if (startEntryId > endEntryId) {\n+            return Lists.newArrayList();\n+        }\n+        long numEntries = endEntryId - startEntryId + 1;\n+        long step = Math.max(1L, numEntries / nWays);\n+        List<Long> entryList = Lists.newArrayListWithExpectedSize(nWays);\n+        for (long i = startEntryId, j = nWays - 1; i <= endEntryId && j > 0; i += step, j--) {\n+            entryList.add(i);\n+        }\n+        if (entryList.get(entryList.size() - 1) < endEntryId) {\n+            entryList.add(endEntryId);\n+        }\n+        return entryList;\n+    }\n+}"},{"sha":"9b5cdd08e69c0fa2df3ab4e5cc58597043cb4589","filename":"src/main/java/com/twitter/distributedlog/WriteLimiter.java","status":"added","additions":57,"deletions":0,"changes":57,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FWriteLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FWriteLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FWriteLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,57 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.twitter.distributedlog.exceptions.OverCapacityException;\n+import com.twitter.distributedlog.util.PermitLimiter;\n+\n+public class WriteLimiter {\n+\n+    String streamName;\n+    final PermitLimiter streamLimiter;\n+    final PermitLimiter globalLimiter;\n+\n+    public WriteLimiter(String streamName, PermitLimiter streamLimiter, PermitLimiter globalLimiter) {\n+        this.streamName = streamName;\n+        this.streamLimiter = streamLimiter;\n+        this.globalLimiter = globalLimiter;\n+    }\n+\n+    public void acquire() throws OverCapacityException {\n+        if (!streamLimiter.acquire()) {\n+            throw new OverCapacityException(String.format(\"Stream write capacity exceeded for stream %s\", streamName));\n+        }\n+        try {\n+            if (!globalLimiter.acquire()) {\n+                throw new OverCapacityException(\"Global write capacity exceeded\");\n+            }\n+        } catch (OverCapacityException ex) {\n+            streamLimiter.release(1);\n+            throw ex;\n+        }\n+    }\n+\n+    public void release() {\n+        release(1);\n+    }\n+\n+    public void release(int permits) {\n+        streamLimiter.release(permits);\n+        globalLimiter.release(permits);\n+    }\n+}"},{"sha":"4d7a0e1f68d83e9bf0bf2f19137dad6587005ca9","filename":"src/main/java/com/twitter/distributedlog/ZKMetadataAccessor.java","status":"added","additions":259,"deletions":0,"changes":259,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZKMetadataAccessor.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZKMetadataAccessor.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZKMetadataAccessor.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,259 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.twitter.distributedlog.exceptions.AlreadyClosedException;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.metadata.BKDLConfig;\n+import com.twitter.distributedlog.util.DLUtils;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.util.Future;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.zookeeper.BoundExponentialBackoffRetryPolicy;\n+import org.apache.bookkeeper.zookeeper.RetryPolicy;\n+import org.apache.zookeeper.CreateMode;\n+import org.apache.zookeeper.data.Stat;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ZKMetadataAccessor implements MetadataAccessor {\n+    static final Logger LOG = LoggerFactory.getLogger(ZKMetadataAccessor.class);\n+    protected final String name;\n+    protected Promise<Void> closePromise;\n+    protected final URI uri;\n+    // zookeeper clients\n+    // NOTE: The actual zookeeper client is initialized lazily when it is referenced by\n+    //       {@link com.twitter.distributedlog.ZooKeeperClient#get()}. So it is safe to\n+    //       keep builders and their client wrappers here, as they will be used when\n+    //       instantiating readers or writers.\n+    protected final ZooKeeperClientBuilder writerZKCBuilder;\n+    protected final ZooKeeperClient writerZKC;\n+    protected final boolean ownWriterZKC;\n+    protected final ZooKeeperClientBuilder readerZKCBuilder;\n+    protected final ZooKeeperClient readerZKC;\n+    protected final boolean ownReaderZKC;\n+\n+    ZKMetadataAccessor(String name,\n+                       DistributedLogConfiguration conf,\n+                       URI uri,\n+                       ZooKeeperClientBuilder writerZKCBuilder,\n+                       ZooKeeperClientBuilder readerZKCBuilder,\n+                       StatsLogger statsLogger) {\n+        this.name = name;\n+        this.uri = uri;\n+\n+        if (null == writerZKCBuilder) {\n+            RetryPolicy retryPolicy = null;\n+            if (conf.getZKNumRetries() > 0) {\n+                retryPolicy = new BoundExponentialBackoffRetryPolicy(\n+                    conf.getZKRetryBackoffStartMillis(),\n+                    conf.getZKRetryBackoffMaxMillis(), conf.getZKNumRetries());\n+            }\n+            this.writerZKCBuilder = ZooKeeperClientBuilder.newBuilder()\n+                    .name(String.format(\"dlzk:%s:dlm_writer_shared\", name))\n+                    .sessionTimeoutMs(conf.getZKSessionTimeoutMilliseconds())\n+                    .retryThreadCount(conf.getZKClientNumberRetryThreads())\n+                    .requestRateLimit(conf.getZKRequestRateLimit())\n+                    .zkAclId(conf.getZkAclId())\n+                    .uri(uri)\n+                    .retryPolicy(retryPolicy)\n+                    .statsLogger(statsLogger.scope(\"dlzk_dlm_writer_shared\"));\n+            this.ownWriterZKC = true;\n+        } else {\n+            this.writerZKCBuilder = writerZKCBuilder;\n+            this.ownWriterZKC = false;\n+        }\n+        this.writerZKC = this.writerZKCBuilder.build();\n+\n+        if (null == readerZKCBuilder) {\n+            String zkServersForWriter = DLUtils.getZKServersFromDLUri(uri);\n+            String zkServersForReader;\n+            try {\n+                BKDLConfig bkdlConfig = BKDLConfig.resolveDLConfig(this.writerZKC, uri);\n+                zkServersForReader = bkdlConfig.getDlZkServersForReader();\n+            } catch (IOException e) {\n+                LOG.warn(\"Error on resolving dl metadata bindings for {} : \", uri, e);\n+                zkServersForReader = zkServersForWriter;\n+            }\n+            if (zkServersForReader.equals(zkServersForWriter)) {\n+                LOG.info(\"Used same zookeeper servers '{}' for both writers and readers for {}.\",\n+                         zkServersForWriter, name);\n+                this.readerZKCBuilder = this.writerZKCBuilder;\n+                this.ownReaderZKC = false;\n+            } else {\n+                RetryPolicy retryPolicy = null;\n+                if (conf.getZKNumRetries() > 0) {\n+                    retryPolicy = new BoundExponentialBackoffRetryPolicy(\n+                        conf.getZKRetryBackoffStartMillis(),\n+                        conf.getZKRetryBackoffMaxMillis(), conf.getZKNumRetries());\n+                }\n+                this.readerZKCBuilder = ZooKeeperClientBuilder.newBuilder()\n+                        .name(String.format(\"dlzk:%s:dlm_reader_shared\", name))\n+                        .sessionTimeoutMs(conf.getZKSessionTimeoutMilliseconds())\n+                        .retryThreadCount(conf.getZKClientNumberRetryThreads())\n+                        .requestRateLimit(conf.getZKRequestRateLimit())\n+                        .zkServers(zkServersForReader)\n+                        .retryPolicy(retryPolicy)\n+                        .zkAclId(conf.getZkAclId())\n+                        .statsLogger(statsLogger.scope(\"dlzk_dlm_reader_shared\"));\n+                this.ownReaderZKC = true;\n+            }\n+        } else {\n+            this.readerZKCBuilder = readerZKCBuilder;\n+            this.ownReaderZKC = false;\n+        }\n+        this.readerZKC = this.readerZKCBuilder.build();\n+    }\n+\n+    /**\n+     * Get the name of the stream managed by this log manager\n+     *\n+     * @return streamName\n+     */\n+    @Override\n+    public String getStreamName() {\n+        return name;\n+    }\n+\n+    /**\n+     * Creates or update the metadata stored at the node associated with the\n+     * name and URI\n+     * @param metadata opaque metadata to be stored for the node\n+     * @throws IOException\n+     */\n+    @Override\n+    public void createOrUpdateMetadata(byte[] metadata) throws IOException {\n+        checkClosedOrInError(\"createOrUpdateMetadata\");\n+\n+        String zkPath = getZKPath();\n+        LOG.debug(\"Setting application specific metadata on {}\", zkPath);\n+        try {\n+            Stat currentStat = writerZKC.get().exists(zkPath, false);\n+            if (currentStat == null) {\n+                if (metadata.length > 0) {\n+                    Utils.zkCreateFullPathOptimistic(writerZKC,\n+                            zkPath,\n+                            metadata,\n+                            writerZKC.getDefaultACL(),\n+                            CreateMode.PERSISTENT);\n+                }\n+            } else {\n+                writerZKC.get().setData(zkPath, metadata, currentStat.getVersion());\n+            }\n+        } catch (InterruptedException ie) {\n+            throw new DLInterruptedException(\"Interrupted on creating or updating container metadata\", ie);\n+        } catch (Exception exc) {\n+            throw new IOException(\"Exception creating or updating container metadata\", exc);\n+        }\n+    }\n+\n+    /**\n+     * Delete the metadata stored at the associated node. This only deletes the metadata\n+     * and not the node itself\n+     * @throws IOException\n+     */\n+    @Override\n+    public void deleteMetadata() throws IOException {\n+        checkClosedOrInError(\"createOrUpdateMetadata\");\n+        createOrUpdateMetadata(null);\n+    }\n+\n+    /**\n+     * Retrieve the metadata stored at the node\n+     * @return byte array containing the metadata\n+     * @throws IOException\n+     */\n+    @Override\n+    public byte[] getMetadata() throws IOException {\n+        checkClosedOrInError(\"createOrUpdateMetadata\");\n+        String zkPath = getZKPath();\n+        LOG.debug(\"Getting application specific metadata from {}\", zkPath);\n+        try {\n+            Stat currentStat = readerZKC.get().exists(zkPath, false);\n+            if (currentStat == null) {\n+                return null;\n+            } else {\n+                return readerZKC.get().getData(zkPath, false, currentStat);\n+            }\n+        } catch (InterruptedException ie) {\n+            throw new DLInterruptedException(\"Error reading the max tx id from zk\", ie);\n+        } catch (Exception e) {\n+            throw new IOException(\"Error reading the max tx id from zk\", e);\n+        }\n+    }\n+\n+    /**\n+     * Close the metadata accessor, freeing any resources it may hold.\n+     * @return future represents the close result.\n+     */\n+    @Override\n+    public Future<Void> asyncClose() {\n+        Promise<Void> closeFuture;\n+        synchronized (this) {\n+            if (null != closePromise) {\n+                return closePromise;\n+            }\n+            closeFuture = closePromise = new Promise<Void>();\n+        }\n+        // NOTE: ownWriterZKC and ownReaderZKC are mostly used by tests\n+        //       the managers created by the namespace - whose zkc will be closed by namespace\n+        try {\n+            if (ownWriterZKC) {\n+                writerZKC.close();\n+            }\n+            if (ownReaderZKC) {\n+                readerZKC.close();\n+            }\n+        } catch (Exception e) {\n+            LOG.warn(\"Exception while closing distributed log manager\", e);\n+        }\n+        FutureUtils.setValue(closeFuture, null);\n+        return closeFuture;\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        FutureUtils.result(asyncClose());\n+    }\n+\n+    public synchronized void checkClosedOrInError(String operation) throws AlreadyClosedException {\n+        if (null != closePromise) {\n+            throw new AlreadyClosedException(\"Executing \" + operation + \" on already closed ZKMetadataAccessor\");\n+        }\n+    }\n+\n+    protected String getZKPath() {\n+        return String.format(\"%s/%s\", uri.getPath(), name);\n+    }\n+\n+    @VisibleForTesting\n+    protected ZooKeeperClient getReaderZKC() {\n+        return readerZKC;\n+    }\n+\n+    @VisibleForTesting\n+    protected ZooKeeperClient getWriterZKC() {\n+        return writerZKC;\n+    }\n+}"},{"sha":"912d592186434f970a8707281937421dbc8086db","filename":"src/main/java/com/twitter/distributedlog/ZooKeeperClient.java","status":"added","additions":399,"deletions":0,"changes":399,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClient.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClient.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClient.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,399 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Stopwatch;\n+import com.twitter.distributedlog.util.FailpointUtils;\n+import com.twitter.distributedlog.zk.ZKWatcherManager;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.zookeeper.BoundExponentialBackoffRetryPolicy;\n+import org.apache.bookkeeper.zookeeper.RetryPolicy;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.WatchedEvent;\n+import org.apache.zookeeper.Watcher;\n+import org.apache.zookeeper.Watcher.Event.EventType;\n+import org.apache.zookeeper.Watcher.Event.KeeperState;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.apache.zookeeper.ZooDefs;\n+import org.apache.zookeeper.data.ACL;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.CopyOnWriteArraySet;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+\n+/**\n+ * ZooKeeper Client wrapper over {@link org.apache.bookkeeper.zookeeper.ZooKeeperClient}.\n+ * It handles retries on session expires and provides a watcher manager {@link ZKWatcherManager}.\n+ *\n+ * <h3>Metrics</h3>\n+ * <ul>\n+ * <li> zookeeper operation stats are exposed under scope <code>zk</code> by\n+ * {@link org.apache.bookkeeper.zookeeper.ZooKeeperClient}\n+ * <li> stats on zookeeper watched events are exposed under scope <code>watcher</code> by\n+ * {@link org.apache.bookkeeper.zookeeper.ZooKeeperWatcherBase}\n+ * <li> stats about {@link ZKWatcherManager} are exposed under scope <code>watcher_manager</code>\n+ * </ul>\n+ */\n+public class ZooKeeperClient {\n+\n+    public static interface Credentials {\n+\n+        Credentials NONE = new Credentials() {\n+            @Override\n+            public void authenticate(ZooKeeper zooKeeper) {\n+                // noop\n+            }\n+        };\n+\n+        void authenticate(ZooKeeper zooKeeper);\n+    }\n+\n+    public static class DigestCredentials implements Credentials {\n+\n+        String username;\n+        String password;\n+\n+        public DigestCredentials(String username, String password) {\n+            this.username = username;\n+            this.password = password;\n+        }\n+\n+        @Override\n+        public void authenticate(ZooKeeper zooKeeper) {\n+            zooKeeper.addAuthInfo(\"digest\", String.format(\"%s:%s\", username, password).getBytes(UTF_8));\n+        }\n+    }\n+\n+    public interface ZooKeeperSessionExpireNotifier {\n+        void notifySessionExpired();\n+    }\n+\n+    /**\n+     * Indicates an error connecting to a zookeeper cluster.\n+     */\n+    public static class ZooKeeperConnectionException extends IOException {\n+        private static final long serialVersionUID = 6682391687004819361L;\n+\n+        public ZooKeeperConnectionException(String message) {\n+            super(message);\n+        }\n+\n+        public ZooKeeperConnectionException(String message, Throwable cause) {\n+            super(message, cause);\n+        }\n+    }\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(ZooKeeperClient.class.getName());\n+\n+    private final String name;\n+    private final int sessionTimeoutMs;\n+    private final int defaultConnectionTimeoutMs;\n+    private final String zooKeeperServers;\n+    // GuardedBy \"this\", but still volatile for tests, where we want to be able to see writes\n+    // made from within long synchronized blocks.\n+    private volatile ZooKeeper zooKeeper = null;\n+    private final RetryPolicy retryPolicy;\n+    private final StatsLogger statsLogger;\n+    private final int retryThreadCount;\n+    private final double requestRateLimit;\n+    private final Credentials credentials;\n+    private volatile boolean authenticated = false;\n+    private Stopwatch disconnectedStopwatch = null;\n+\n+    private boolean closed = false;\n+\n+    final Set<Watcher> watchers = new CopyOnWriteArraySet<Watcher>();\n+\n+    // watcher manager to manage watchers\n+    private final ZKWatcherManager watcherManager;\n+\n+    /**\n+     * Creates an unconnected client that will lazily attempt to connect on the first call to\n+     * {@link #get}.  All successful connections will be authenticated with the given\n+     * {@code credentials}.\n+     *\n+     * @param sessionTimeoutMs\n+     *          ZK session timeout in milliseconds\n+     * @param connectionTimeoutMs\n+     *          ZK connection timeout in milliseconds\n+     * @param zooKeeperServers\n+     *          the set of servers forming the ZK cluster\n+     */\n+    ZooKeeperClient(int sessionTimeoutMs, int connectionTimeoutMs, String zooKeeperServers) {\n+        this(\"default\", sessionTimeoutMs, connectionTimeoutMs, zooKeeperServers, null, NullStatsLogger.INSTANCE, 1, 0,\n+             Credentials.NONE);\n+    }\n+\n+    ZooKeeperClient(String name,\n+                    int sessionTimeoutMs,\n+                    int connectionTimeoutMs,\n+                    String zooKeeperServers,\n+                    RetryPolicy retryPolicy,\n+                    StatsLogger statsLogger,\n+                    int retryThreadCount,\n+                    double requestRateLimit,\n+                    Credentials credentials) {\n+        this.name = name;\n+        this.sessionTimeoutMs = sessionTimeoutMs;\n+        this.zooKeeperServers = zooKeeperServers;\n+        this.defaultConnectionTimeoutMs = connectionTimeoutMs;\n+        this.retryPolicy = retryPolicy;\n+        this.statsLogger = statsLogger;\n+        this.retryThreadCount = retryThreadCount;\n+        this.requestRateLimit = requestRateLimit;\n+        this.credentials = credentials;\n+        this.watcherManager = ZKWatcherManager.newBuilder()\n+                .name(name)\n+                .statsLogger(statsLogger.scope(\"watcher_manager\"))\n+                .build();\n+    }\n+\n+    public List<ACL> getDefaultACL() {\n+        if (Credentials.NONE == credentials) {\n+            return ZooDefs.Ids.OPEN_ACL_UNSAFE;\n+        } else {\n+            return DistributedLogConstants.EVERYONE_READ_CREATOR_ALL;\n+        }\n+    }\n+\n+    public ZKWatcherManager getWatcherManager() {\n+        return watcherManager;\n+    }\n+\n+    /**\n+     * Returns the current active ZK connection or establishes a new one if none has yet been\n+     * established or a previous connection was disconnected or had its session time out.\n+     *\n+     * @return a connected ZooKeeper client\n+     * @throws ZooKeeperConnectionException if there was a problem connecting to the ZK cluster\n+     * @throws InterruptedException if interrupted while waiting for a connection to be established\n+     * @throws TimeoutException if a connection could not be established within the configured\n+     * session timeout\n+     */\n+    public synchronized ZooKeeper get()\n+        throws ZooKeeperConnectionException, InterruptedException {\n+\n+        try {\n+            FailpointUtils.checkFailPoint(FailpointUtils.FailPointName.FP_ZooKeeperConnectionLoss);\n+        } catch (IOException ioe) {\n+            throw new ZooKeeperConnectionException(\"Client \" + name + \" failed on establishing zookeeper connection\", ioe);\n+        }\n+\n+        // This indicates that the client was explictly closed\n+        if (closed) {\n+            throw new ZooKeeperConnectionException(\"Client \" + name + \" has already been closed\");\n+        }\n+\n+        // the underneath zookeeper is retryable zookeeper\n+        if (zooKeeper != null && retryPolicy != null) {\n+            if (zooKeeper.getState().equals(ZooKeeper.States.CONNECTED)) {\n+                // the zookeeper client is connected\n+                disconnectedStopwatch = null;\n+            } else {\n+                if (disconnectedStopwatch == null) {\n+                    disconnectedStopwatch = Stopwatch.createStarted();\n+                } else {\n+                    long disconnectedMs = disconnectedStopwatch.elapsed(TimeUnit.MILLISECONDS);\n+                    if (disconnectedMs > defaultConnectionTimeoutMs) {\n+                        closeInternal();\n+                        authenticated = false;\n+                    }\n+                }\n+            }\n+        }\n+\n+        if (zooKeeper == null) {\n+            zooKeeper = buildZooKeeper();\n+            disconnectedStopwatch = null;\n+        }\n+\n+        // In case authenticate throws an exception, the caller can try to recover the client by\n+        // calling get again.\n+        if (!authenticated) {\n+            credentials.authenticate(zooKeeper);\n+            authenticated = true;\n+        }\n+\n+        return zooKeeper;\n+    }\n+\n+    private ZooKeeper buildZooKeeper()\n+        throws ZooKeeperConnectionException, InterruptedException {\n+        Watcher watcher = new Watcher() {\n+            @Override\n+            public void process(WatchedEvent event) {\n+                switch (event.getType()) {\n+                    case None:\n+                        switch (event.getState()) {\n+                            case Expired:\n+                                if (null == retryPolicy) {\n+                                    LOG.info(\"ZooKeeper {}' session expired. Event: {}\", name, event);\n+                                    closeInternal();\n+                                }\n+                                authenticated = false;\n+                                break;\n+                            case Disconnected:\n+                                if (null == retryPolicy) {\n+                                    LOG.info(\"ZooKeeper {} is disconnected from zookeeper now,\" +\n+                                            \" but it is OK unless we received EXPIRED event.\", name);\n+                                }\n+                                // Mark as not authenticated if expired or disconnected. In both cases\n+                                // we lose any attached auth info. Relying on Expired/Disconnected is\n+                                // sufficient since all Expired/Disconnected events are processed before\n+                                // all SyncConnected events, and the underlying member is not updated until\n+                                // SyncConnected is received.\n+                                authenticated = false;\n+                                break;\n+                            default:\n+                                break;\n+                        }\n+                }\n+\n+                try {\n+                    for (Watcher watcher : watchers) {\n+                        try {\n+                            watcher.process(event);\n+                        } catch (Throwable t) {\n+                            LOG.warn(\"Encountered unexpected exception from watcher {} : \", watcher, t);\n+                        }\n+                    }\n+                } catch (Throwable t) {\n+                    LOG.warn(\"Encountered unexpected exception when firing watched event {} : \", event, t);\n+                }\n+            }\n+        };\n+\n+        Set<Watcher> watchers = new HashSet<Watcher>();\n+        watchers.add(watcher);\n+\n+        ZooKeeper zk;\n+        try {\n+            RetryPolicy opRetryPolicy = null == retryPolicy ?\n+                    new BoundExponentialBackoffRetryPolicy(sessionTimeoutMs, sessionTimeoutMs, 0) : retryPolicy;\n+            RetryPolicy connectRetryPolicy = null == retryPolicy ?\n+                    new BoundExponentialBackoffRetryPolicy(sessionTimeoutMs, sessionTimeoutMs, 0) :\n+                    new BoundExponentialBackoffRetryPolicy(sessionTimeoutMs, sessionTimeoutMs, Integer.MAX_VALUE);\n+            zk = org.apache.bookkeeper.zookeeper.ZooKeeperClient.newBuilder()\n+                    .connectString(zooKeeperServers)\n+                    .sessionTimeoutMs(sessionTimeoutMs)\n+                    .watchers(watchers)\n+                    .operationRetryPolicy(opRetryPolicy)\n+                    .connectRetryPolicy(connectRetryPolicy)\n+                    .statsLogger(statsLogger)\n+                    .retryThreadCount(retryThreadCount)\n+                    .requestRateLimit(requestRateLimit)\n+                    .build();\n+        } catch (KeeperException e) {\n+            throw new ZooKeeperConnectionException(\"Problem connecting to servers: \" + zooKeeperServers, e);\n+        } catch (IOException e) {\n+            throw new ZooKeeperConnectionException(\"Problem connecting to servers: \" + zooKeeperServers, e);\n+        }\n+        return zk;\n+    }\n+\n+    /**\n+     * Clients that need to re-establish state after session expiration can register an\n+     * {@code onExpired} command to execute.\n+     *\n+     * @param onExpired the {@code Command} to register\n+     * @return the new {@link Watcher} which can later be passed to {@link #unregister} for\n+     *         removal.\n+     */\n+    public Watcher registerExpirationHandler(final ZooKeeperSessionExpireNotifier onExpired) {\n+        Watcher watcher = new Watcher() {\n+            @Override\n+            public void process(WatchedEvent event) {\n+                if (event.getType() == EventType.None && event.getState() == KeeperState.Expired) {\n+                    try {\n+                        onExpired.notifySessionExpired();\n+                    } catch (Exception exc) {\n+                        // do nothing\n+                    }\n+                }\n+            }\n+        };\n+        register(watcher);\n+        return watcher;\n+    }\n+\n+    /**\n+     * Clients that need to register a top-level {@code Watcher} should do so using this method.  The\n+     * registered {@code watcher} will remain registered across re-connects and session expiration\n+     * events.\n+     *\n+     * @param watcher the {@code Watcher to register}\n+     */\n+    public void register(Watcher watcher) {\n+        if (null != watcher) {\n+            watchers.add(watcher);\n+        }\n+    }\n+\n+    /**\n+     * Clients can attempt to unregister a top-level {@code Watcher} that has previously been\n+     * registered.\n+     *\n+     * @param watcher the {@code Watcher} to unregister as a top-level, persistent watch\n+     * @return whether the given {@code Watcher} was found and removed from the active set\n+     */\n+    public boolean unregister(Watcher watcher) {\n+        return null != watcher && watchers.remove(watcher);\n+    }\n+\n+    /**\n+     * Closes the current connection if any expiring the current ZooKeeper session.  Any subsequent\n+     * calls to this method will no-op until the next successful {@link #get}.\n+     */\n+    public synchronized void closeInternal() {\n+        if (zooKeeper != null) {\n+            try {\n+                LOG.info(\"Closing zookeeper client {}.\", name);\n+                zooKeeper.close();\n+                LOG.info(\"Closed zookeeper client {}.\", name);\n+            } catch (InterruptedException e) {\n+                Thread.currentThread().interrupt();\n+                LOG.warn(\"Interrupted trying to close zooKeeper {} : \", name, e);\n+            } finally {\n+                zooKeeper = null;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Closes the the underlying zookeeper instance.\n+     * Subsequent attempts to {@link #get} will fail\n+     */\n+    public synchronized void close() {\n+        if (closed) {\n+            return;\n+        }\n+        LOG.info(\"Close zookeeper client {}.\", name);\n+        closeInternal();\n+        closed = true;\n+    }\n+}"},{"sha":"90807b0f900ea3113b4f7a262abe9a7f6d64d49a","filename":"src/main/java/com/twitter/distributedlog/ZooKeeperClientBuilder.java","status":"added","additions":233,"deletions":0,"changes":233,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClientBuilder.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClientBuilder.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClientBuilder.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,233 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog;\n+\n+import com.google.common.base.Preconditions;\n+import com.twitter.distributedlog.ZooKeeperClient.Credentials;\n+import com.twitter.distributedlog.ZooKeeperClient.DigestCredentials;\n+import com.twitter.distributedlog.util.DLUtils;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.zookeeper.RetryPolicy;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.URI;\n+\n+/**\n+ * Builder to build zookeeper client.\n+ */\n+public class ZooKeeperClientBuilder {\n+\n+    static final Logger LOG = LoggerFactory.getLogger(ZooKeeperClientBuilder.class);\n+\n+    /**\n+     * Create a zookeeper client builder to build zookeeper clients.\n+     *\n+     * @return zookeeper client builder.\n+     */\n+    public static ZooKeeperClientBuilder newBuilder() {\n+        return new ZooKeeperClientBuilder();\n+    }\n+\n+    // name\n+    private String name = \"default\";\n+    // sessionTimeoutMs\n+    private int sessionTimeoutMs = -1;\n+    // conectionTimeoutMs\n+    private int conectionTimeoutMs = -1;\n+    // zkServers\n+    private String zkServers = null;\n+    // retry policy\n+    private RetryPolicy retryPolicy = null;\n+    // stats logger\n+    private StatsLogger statsLogger = NullStatsLogger.INSTANCE;\n+    // retry executor thread count\n+    private int retryThreadCount = 1;\n+    // zookeeper access requestRateLimit limit\n+    private double requestRateLimit = 0;\n+    // Did call the zkAclId setter on the builder, used to ensure the setter is set.\n+    private boolean zkAclIdSet = false;\n+    private String zkAclId;\n+\n+    // Cached ZooKeeper Client\n+    private ZooKeeperClient cachedClient = null;\n+\n+    private ZooKeeperClientBuilder() {}\n+\n+    /**\n+     * Set zookeeper client name\n+     *\n+     * @param name zookeeper client name\n+     * @return zookeeper client builder\n+     */\n+    public synchronized ZooKeeperClientBuilder name(String name) {\n+        this.name = name;\n+        return this;\n+    }\n+\n+    /**\n+     * Set zookeeper session timeout in milliseconds.\n+     *\n+     * @param sessionTimeoutMs\n+     *          session timeout in milliseconds.\n+     * @return zookeeper client builder.\n+     */\n+    public synchronized ZooKeeperClientBuilder sessionTimeoutMs(int sessionTimeoutMs) {\n+        this.sessionTimeoutMs = sessionTimeoutMs;\n+        if (this.conectionTimeoutMs <= 0) {\n+            this.conectionTimeoutMs = 2 * sessionTimeoutMs;\n+        }\n+        return this;\n+    }\n+\n+    public synchronized ZooKeeperClientBuilder retryThreadCount(int retryThreadCount) {\n+        this.retryThreadCount = retryThreadCount;\n+        return this;\n+    }\n+\n+    public synchronized ZooKeeperClientBuilder requestRateLimit(double requestRateLimit) {\n+        this.requestRateLimit = requestRateLimit;\n+        return this;\n+    }\n+\n+    /**\n+     * Set zookeeper connection timeout in milliseconds\n+     *\n+     * @param connectionTimeoutMs\n+     *          connection timeout ms.\n+     * @return builder\n+     */\n+    public synchronized ZooKeeperClientBuilder connectionTimeoutMs(int connectionTimeoutMs) {\n+        this.conectionTimeoutMs = connectionTimeoutMs;\n+        return this;\n+    }\n+\n+    /**\n+     * Set ZooKeeper Connect String.\n+     *\n+     * @param zkServers\n+     *          zookeeper servers to connect.\n+     * @return builder\n+     */\n+    public synchronized ZooKeeperClientBuilder zkServers(String zkServers) {\n+        this.zkServers = zkServers;\n+        return this;\n+    }\n+\n+    /**\n+     * Set DistributedLog URI.\n+     *\n+     * @param uri\n+     *          distributedlog uri.\n+     * @return builder.\n+     */\n+    public synchronized ZooKeeperClientBuilder uri(URI uri) {\n+        this.zkServers = DLUtils.getZKServersFromDLUri(uri);\n+        return this;\n+    }\n+\n+    /**\n+     * Build zookeeper client using existing <i>zkc</i> client.\n+     *\n+     * @param zkc\n+     *          zookeeper client.\n+     * @return builder\n+     */\n+    public synchronized ZooKeeperClientBuilder zkc(ZooKeeperClient zkc) {\n+        this.cachedClient = zkc;\n+        return this;\n+    }\n+\n+    /**\n+     * Build zookeeper client with given retry policy <i>retryPolicy</i>.\n+     *\n+     * @param retryPolicy\n+     *          retry policy\n+     * @return builder\n+     */\n+    public synchronized ZooKeeperClientBuilder retryPolicy(RetryPolicy retryPolicy) {\n+        this.retryPolicy = retryPolicy;\n+        return this;\n+    }\n+\n+    /**\n+     * Build zookeeper client with given stats logger <i>statsLogger</i>.\n+     *\n+     * @param statsLogger\n+     *          stats logger to expose zookeeper stats\n+     * @return builder\n+     */\n+    public synchronized ZooKeeperClientBuilder statsLogger(StatsLogger statsLogger) {\n+        this.statsLogger = statsLogger;\n+        return this;\n+    }\n+\n+    /**\n+     * * Build zookeeper client with given zk acl digest id <i>zkAclId</i>.\n+     */\n+    public synchronized ZooKeeperClientBuilder zkAclId(String zkAclId) {\n+        this.zkAclIdSet = true;\n+        this.zkAclId = zkAclId;\n+        return this;\n+    }\n+\n+    private void validateParameters() {\n+        Preconditions.checkNotNull(zkServers, \"No zk servers provided.\");\n+        Preconditions.checkArgument(conectionTimeoutMs > 0,\n+                \"Invalid connection timeout : %d\", conectionTimeoutMs);\n+        Preconditions.checkArgument(sessionTimeoutMs > 0,\n+                \"Invalid session timeout : %d\", sessionTimeoutMs);\n+        Preconditions.checkNotNull(statsLogger, \"No stats logger provided.\");\n+        Preconditions.checkArgument(zkAclIdSet, \"Zookeeper acl id not set.\");\n+    }\n+\n+    /**\n+     * Build a zookeeper client.\n+     *\n+     * @return zookeeper client.\n+     */\n+    public synchronized ZooKeeperClient build() {\n+        if (null == cachedClient) {\n+            cachedClient = buildClient();\n+        }\n+        return cachedClient;\n+    }\n+\n+    private ZooKeeperClient buildClient() {\n+        validateParameters();\n+\n+        Credentials credentials = Credentials.NONE;\n+        if (null != zkAclId) {\n+            credentials = new DigestCredentials(zkAclId, zkAclId);\n+        }\n+\n+        return new ZooKeeperClient(\n+                name,\n+                sessionTimeoutMs,\n+                conectionTimeoutMs,\n+                zkServers,\n+                retryPolicy,\n+                statsLogger,\n+                retryThreadCount,\n+                requestRateLimit,\n+                credentials\n+        );\n+    }\n+}"},{"sha":"5fcc87ea919a72410dbe29da9ceaa11341bb2c06","filename":"src/main/java/com/twitter/distributedlog/acl/AccessControlManager.java","status":"added","additions":74,"deletions":0,"changes":74,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FAccessControlManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FAccessControlManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FAccessControlManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,74 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.acl;\n+\n+/**\n+ * Access Control on stream operations\n+ */\n+public interface AccessControlManager {\n+\n+    /**\n+     * Whether allowing writing to a stream.\n+     *\n+     * @param stream\n+     *          Stream to write\n+     * @return true if allowing writing to the given stream, otherwise false.\n+     */\n+    boolean allowWrite(String stream);\n+\n+    /**\n+     * Whether allowing truncating a given stream.\n+     *\n+     * @param stream\n+     *          Stream to truncate\n+     * @return true if allowing truncating a given stream.\n+     */\n+    boolean allowTruncate(String stream);\n+\n+    /**\n+     * Whether allowing deleting a given stream.\n+     *\n+     * @param stream\n+     *          Stream to delete\n+     * @return true if allowing deleting a given stream.\n+     */\n+    boolean allowDelete(String stream);\n+\n+    /**\n+     * Whether allowing proxies to acquire a given stream.\n+     *\n+     * @param stream\n+     *          stream to acquire\n+     * @return true if allowing proxies to acquire the given stream.\n+     */\n+    boolean allowAcquire(String stream);\n+\n+    /**\n+     * Whether allowing proxies to release ownership for a given stream.\n+     *\n+     * @param stream\n+     *          stream to release\n+     * @return true if allowing proxies to release a given stream.\n+     */\n+    boolean allowRelease(String stream);\n+\n+    /**\n+     * Close the access control manager.\n+     */\n+    void close();\n+}"},{"sha":"e757595d49d108481f5dbc14c69a9320bc80ac37","filename":"src/main/java/com/twitter/distributedlog/acl/DefaultAccessControlManager.java","status":"added","additions":55,"deletions":0,"changes":55,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FDefaultAccessControlManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FDefaultAccessControlManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FDefaultAccessControlManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,55 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.acl;\n+\n+public class DefaultAccessControlManager implements AccessControlManager {\n+\n+    public static final DefaultAccessControlManager INSTANCE = new DefaultAccessControlManager();\n+\n+    private DefaultAccessControlManager() {\n+    }\n+\n+    @Override\n+    public boolean allowWrite(String stream) {\n+        return true;\n+    }\n+\n+    @Override\n+    public boolean allowTruncate(String stream) {\n+        return true;\n+    }\n+\n+    @Override\n+    public boolean allowDelete(String stream) {\n+        return true;\n+    }\n+\n+    @Override\n+    public boolean allowAcquire(String stream) {\n+        return true;\n+    }\n+\n+    @Override\n+    public boolean allowRelease(String stream) {\n+        return true;\n+    }\n+\n+    @Override\n+    public void close() {\n+    }\n+}"},{"sha":"bf1625674ff5d7510167e844e102539b835ac1ff","filename":"src/main/java/com/twitter/distributedlog/acl/ZKAccessControl.java","status":"added","additions":229,"deletions":0,"changes":229,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FZKAccessControl.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FZKAccessControl.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FZKAccessControl.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,229 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.acl;\n+\n+import com.google.common.base.Objects;\n+import com.twitter.distributedlog.ZooKeeperClient;\n+import com.twitter.distributedlog.thrift.AccessControlEntry;\n+import com.twitter.util.Future;\n+import com.twitter.util.Promise;\n+import org.apache.thrift.TException;\n+import org.apache.thrift.protocol.TJSONProtocol;\n+import org.apache.thrift.transport.TMemoryBuffer;\n+import org.apache.thrift.transport.TMemoryInputTransport;\n+import org.apache.zookeeper.AsyncCallback;\n+import org.apache.zookeeper.CreateMode;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.Watcher;\n+import org.apache.zookeeper.data.Stat;\n+\n+import java.io.IOException;\n+import java.io.UnsupportedEncodingException;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+\n+public class ZKAccessControl {\n+\n+    private static final int BUFFER_SIZE = 4096;\n+\n+    public static final AccessControlEntry DEFAULT_ACCESS_CONTROL_ENTRY = new AccessControlEntry();\n+\n+    public static class CorruptedAccessControlException extends IOException {\n+\n+        private static final long serialVersionUID = 5391285182476211603L;\n+\n+        public CorruptedAccessControlException(String zkPath, Throwable t) {\n+            super(\"Access Control @ \" + zkPath + \" is corrupted.\", t);\n+        }\n+    }\n+\n+    protected final AccessControlEntry accessControlEntry;\n+    protected final String zkPath;\n+    private int zkVersion;\n+\n+    public ZKAccessControl(AccessControlEntry ace, String zkPath) {\n+        this(ace, zkPath, -1);\n+    }\n+\n+    private ZKAccessControl(AccessControlEntry ace, String zkPath, int zkVersion) {\n+        this.accessControlEntry = ace;\n+        this.zkPath = zkPath;\n+        this.zkVersion = zkVersion;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hashCode(zkPath, accessControlEntry);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (!(obj instanceof ZKAccessControl)) {\n+            return false;\n+        }\n+        ZKAccessControl other = (ZKAccessControl) obj;\n+        return Objects.equal(zkPath, other.zkPath) &&\n+                Objects.equal(accessControlEntry, other.accessControlEntry);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        sb.append(\"entry(path=\").append(zkPath).append(\", acl=\")\n+                .append(accessControlEntry).append(\")\");\n+        return sb.toString();\n+    }\n+\n+    public String getZKPath() {\n+        return zkPath;\n+    }\n+\n+    public AccessControlEntry getAccessControlEntry() {\n+        return accessControlEntry;\n+    }\n+\n+    public Future<ZKAccessControl> create(ZooKeeperClient zkc) {\n+        final Promise<ZKAccessControl> promise = new Promise<ZKAccessControl>();\n+        try {\n+            zkc.get().create(zkPath, serialize(accessControlEntry), zkc.getDefaultACL(), CreateMode.PERSISTENT,\n+                    new AsyncCallback.StringCallback() {\n+                        @Override\n+                        public void processResult(int rc, String path, Object ctx, String name) {\n+                            if (KeeperException.Code.OK.intValue() == rc) {\n+                                ZKAccessControl.this.zkVersion = 0;\n+                                promise.setValue(ZKAccessControl.this);\n+                            } else {\n+                                promise.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+                            }\n+                        }\n+                    }, null);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            promise.setException(e);\n+        } catch (InterruptedException e) {\n+            promise.setException(e);\n+        } catch (IOException e) {\n+            promise.setException(e);\n+        }\n+        return promise;\n+    }\n+\n+    public Future<ZKAccessControl> update(ZooKeeperClient zkc) {\n+        final Promise<ZKAccessControl> promise = new Promise<ZKAccessControl>();\n+        try {\n+            zkc.get().setData(zkPath, serialize(accessControlEntry), zkVersion, new AsyncCallback.StatCallback() {\n+                @Override\n+                public void processResult(int rc, String path, Object ctx, Stat stat) {\n+                    if (KeeperException.Code.OK.intValue() == rc) {\n+                        ZKAccessControl.this.zkVersion = stat.getVersion();\n+                        promise.setValue(ZKAccessControl.this);\n+                    } else {\n+                        promise.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+                    }\n+                }\n+            }, null);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            promise.setException(e);\n+        } catch (InterruptedException e) {\n+            promise.setException(e);\n+        } catch (IOException e) {\n+            promise.setException(e);\n+        }\n+        return promise;\n+    }\n+\n+    public static Future<ZKAccessControl> read(final ZooKeeperClient zkc, final String zkPath, Watcher watcher) {\n+        final Promise<ZKAccessControl> promise = new Promise<ZKAccessControl>();\n+\n+        try {\n+            zkc.get().getData(zkPath, watcher, new AsyncCallback.DataCallback() {\n+                @Override\n+                public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {\n+                    if (KeeperException.Code.OK.intValue() == rc) {\n+                        try {\n+                            AccessControlEntry ace = deserialize(zkPath, data);\n+                            promise.setValue(new ZKAccessControl(ace, zkPath, stat.getVersion()));\n+                        } catch (IOException ioe) {\n+                            promise.setException(ioe);\n+                        }\n+                    } else {\n+                        promise.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+                    }\n+                }\n+            }, null);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            promise.setException(e);\n+        } catch (InterruptedException e) {\n+            promise.setException(e);\n+        }\n+        return promise;\n+    }\n+\n+    public static Future<Void> delete(final ZooKeeperClient zkc, final String zkPath) {\n+        final Promise<Void> promise = new Promise<Void>();\n+\n+        try {\n+            zkc.get().delete(zkPath, -1, new AsyncCallback.VoidCallback() {\n+                @Override\n+                public void processResult(int rc, String path, Object ctx) {\n+                    if (KeeperException.Code.OK.intValue() == rc ||\n+                            KeeperException.Code.NONODE.intValue() == rc) {\n+                        promise.setValue(null);\n+                    } else {\n+                        promise.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+                    }\n+                }\n+            }, null);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            promise.setException(e);\n+        } catch (InterruptedException e) {\n+            promise.setException(e);\n+        }\n+        return promise;\n+    }\n+\n+    static byte[] serialize(AccessControlEntry ace) throws IOException {\n+        TMemoryBuffer transport = new TMemoryBuffer(BUFFER_SIZE);\n+        TJSONProtocol protocol = new TJSONProtocol(transport);\n+        try {\n+            ace.write(protocol);\n+            transport.flush();\n+            return transport.toString(UTF_8.name()).getBytes(UTF_8);\n+        } catch (TException e) {\n+            throw new IOException(\"Failed to serialize access control entry : \", e);\n+        } catch (UnsupportedEncodingException uee) {\n+            throw new IOException(\"Failed to serialize acesss control entry : \", uee);\n+        }\n+    }\n+\n+    static AccessControlEntry deserialize(String zkPath, byte[] data) throws IOException {\n+        if (data.length == 0) {\n+            return DEFAULT_ACCESS_CONTROL_ENTRY;\n+        }\n+\n+        AccessControlEntry ace = new AccessControlEntry();\n+        TMemoryInputTransport transport = new TMemoryInputTransport(data);\n+        TJSONProtocol protocol = new TJSONProtocol(transport);\n+        try {\n+            ace.read(protocol);\n+        } catch (TException e) {\n+            throw new CorruptedAccessControlException(zkPath, e);\n+        }\n+        return ace;\n+    }\n+\n+}"},{"sha":"9c89b4a3b4b9dec122a3b61ea159299be12ad009","filename":"src/main/java/com/twitter/distributedlog/acl/ZKAccessControlManager.java","status":"added","additions":373,"deletions":0,"changes":373,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FZKAccessControlManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FZKAccessControlManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FZKAccessControlManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,373 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.acl;\n+\n+import com.google.common.collect.Sets;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n+import com.twitter.distributedlog.ZooKeeperClient;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.thrift.AccessControlEntry;\n+import com.twitter.util.Await;\n+import com.twitter.util.Future;\n+import com.twitter.util.FutureEventListener;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.util.ZkUtils;\n+import org.apache.zookeeper.AsyncCallback;\n+import org.apache.zookeeper.CreateMode;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.WatchedEvent;\n+import org.apache.zookeeper.Watcher;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.apache.zookeeper.data.Stat;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * ZooKeeper Based {@link com.twitter.distributedlog.acl.AccessControlManager}\n+ */\n+public class ZKAccessControlManager implements AccessControlManager, Watcher {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(ZKAccessControlManager.class);\n+\n+    private static final int ZK_RETRY_BACKOFF_MS = 500;\n+\n+    protected final DistributedLogConfiguration conf;\n+    protected final ZooKeeperClient zkc;\n+    protected final String zkRootPath;\n+    protected final ScheduledExecutorService scheduledExecutorService;\n+\n+    protected final ConcurrentMap<String, ZKAccessControl> streamEntries;\n+    protected ZKAccessControl defaultAccessControl;\n+    protected volatile boolean closed = false;\n+\n+    public ZKAccessControlManager(DistributedLogConfiguration conf,\n+                                  ZooKeeperClient zkc,\n+                                  String zkRootPath,\n+                                  ScheduledExecutorService scheduledExecutorService) throws IOException {\n+        this.conf = conf;\n+        this.zkc = zkc;\n+        this.zkRootPath = zkRootPath;\n+        this.scheduledExecutorService = scheduledExecutorService;\n+        this.streamEntries = new ConcurrentHashMap<String, ZKAccessControl>();\n+        try {\n+            Await.result(fetchDefaultAccessControlEntry());\n+        } catch (Throwable t) {\n+            if (t instanceof InterruptedException) {\n+                throw new DLInterruptedException(\"Interrupted on getting default access control entry for \" + zkRootPath, t);\n+            } else if (t instanceof KeeperException) {\n+                throw new IOException(\"Encountered zookeeper exception on getting default access control entry for \" + zkRootPath, t);\n+            } else if (t instanceof IOException) {\n+                throw (IOException) t;\n+            } else {\n+                throw new IOException(\"Encountered unknown exception on getting access control entries for \" + zkRootPath, t);\n+            }\n+        }\n+\n+        try {\n+            Await.result(fetchAccessControlEntries());\n+        } catch (Throwable t) {\n+            if (t instanceof InterruptedException) {\n+                throw new DLInterruptedException(\"Interrupted on getting access control entries for \" + zkRootPath, t);\n+            } else if (t instanceof KeeperException) {\n+                throw new IOException(\"Encountered zookeeper exception on getting access control entries for \" + zkRootPath, t);\n+            } else if (t instanceof IOException) {\n+                throw (IOException) t;\n+            } else {\n+                throw new IOException(\"Encountered unknown exception on getting access control entries for \" + zkRootPath, t);\n+            }\n+        }\n+    }\n+\n+    protected AccessControlEntry getAccessControlEntry(String stream) {\n+        ZKAccessControl entry = streamEntries.get(stream);\n+        entry = null == entry ? defaultAccessControl : entry;\n+        return entry.getAccessControlEntry();\n+    }\n+\n+    @Override\n+    public boolean allowWrite(String stream) {\n+        return !getAccessControlEntry(stream).isDenyWrite();\n+    }\n+\n+    @Override\n+    public boolean allowTruncate(String stream) {\n+        return !getAccessControlEntry(stream).isDenyTruncate();\n+    }\n+\n+    @Override\n+    public boolean allowDelete(String stream) {\n+        return !getAccessControlEntry(stream).isDenyDelete();\n+    }\n+\n+    @Override\n+    public boolean allowAcquire(String stream) {\n+        return !getAccessControlEntry(stream).isDenyAcquire();\n+    }\n+\n+    @Override\n+    public boolean allowRelease(String stream) {\n+        return !getAccessControlEntry(stream).isDenyRelease();\n+    }\n+\n+    @Override\n+    public void close() {\n+        closed = true;\n+    }\n+\n+    private Future<Void> fetchAccessControlEntries() {\n+        final Promise<Void> promise = new Promise<Void>();\n+        fetchAccessControlEntries(promise);\n+        return promise;\n+    }\n+\n+    private void fetchAccessControlEntries(final Promise<Void> promise) {\n+        try {\n+            zkc.get().getChildren(zkRootPath, this, new AsyncCallback.Children2Callback() {\n+                @Override\n+                public void processResult(int rc, String path, Object ctx, List<String> children, Stat stat) {\n+                    if (KeeperException.Code.OK.intValue() != rc) {\n+                        promise.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+                        return;\n+                    }\n+                    Set<String> streamsReceived = new HashSet<String>();\n+                    streamsReceived.addAll(children);\n+                    Set<String> streamsCached = streamEntries.keySet();\n+                    Set<String> streamsRemoved = Sets.difference(streamsCached, streamsReceived).immutableCopy();\n+                    for (String s : streamsRemoved) {\n+                        ZKAccessControl accessControl = streamEntries.remove(s);\n+                        if (null != accessControl) {\n+                            logger.info(\"Removed Access Control Entry for stream {} : {}\", s, accessControl.getAccessControlEntry());\n+                        }\n+                    }\n+                    if (streamsReceived.isEmpty()) {\n+                        promise.setValue(null);\n+                        return;\n+                    }\n+                    final AtomicInteger numPendings = new AtomicInteger(streamsReceived.size());\n+                    final AtomicInteger numFailures = new AtomicInteger(0);\n+                    for (String s : streamsReceived) {\n+                        final String streamName = s;\n+                        ZKAccessControl.read(zkc, zkRootPath + \"/\" + streamName, null)\n+                                .addEventListener(new FutureEventListener<ZKAccessControl>() {\n+\n+                                    @Override\n+                                    public void onSuccess(ZKAccessControl accessControl) {\n+                                        streamEntries.put(streamName, accessControl);\n+                                        logger.info(\"Added overrided access control for stream {} : {}\", streamName, accessControl.getAccessControlEntry());\n+                                        complete();\n+                                    }\n+\n+                                    @Override\n+                                    public void onFailure(Throwable cause) {\n+                                        if (cause instanceof KeeperException.NoNodeException) {\n+                                            streamEntries.remove(streamName);\n+                                        } else if (cause instanceof ZKAccessControl.CorruptedAccessControlException) {\n+                                            logger.warn(\"Access control is corrupted for stream {} @ {}, skipped it ...\",\n+                                                        new Object[] { streamName, zkRootPath, cause });\n+                                            streamEntries.remove(streamName);\n+                                        } else {\n+                                            if (1 == numFailures.incrementAndGet()) {\n+                                                promise.setException(cause);\n+                                            }\n+                                        }\n+                                        complete();\n+                                    }\n+\n+                                    private void complete() {\n+                                        if (0 == numPendings.decrementAndGet() && numFailures.get() == 0) {\n+                                            promise.setValue(null);\n+                                        }\n+                                    }\n+                                });\n+                    }\n+                }\n+            }, null);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            promise.setException(e);\n+        } catch (InterruptedException e) {\n+            promise.setException(e);\n+        }\n+    }\n+\n+    private Future<ZKAccessControl> fetchDefaultAccessControlEntry() {\n+        final Promise<ZKAccessControl> promise = new Promise<ZKAccessControl>();\n+        fetchDefaultAccessControlEntry(promise);\n+        return promise;\n+    }\n+\n+    private void fetchDefaultAccessControlEntry(final Promise<ZKAccessControl> promise) {\n+        ZKAccessControl.read(zkc, zkRootPath, this)\n+            .addEventListener(new FutureEventListener<ZKAccessControl>() {\n+                @Override\n+                public void onSuccess(ZKAccessControl accessControl) {\n+                    logger.info(\"Default Access Control will be changed from {} to {}\",\n+                                ZKAccessControlManager.this.defaultAccessControl,\n+                                accessControl);\n+                    ZKAccessControlManager.this.defaultAccessControl = accessControl;\n+                    promise.setValue(accessControl);\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause) {\n+                    if (cause instanceof KeeperException.NoNodeException) {\n+                        logger.info(\"Default Access Control is missing, creating one for {} ...\", zkRootPath);\n+                        createDefaultAccessControlEntryIfNeeded(promise);\n+                    } else {\n+                        promise.setException(cause);\n+                    }\n+                }\n+            });\n+    }\n+\n+    private void createDefaultAccessControlEntryIfNeeded(final Promise<ZKAccessControl> promise) {\n+        ZooKeeper zk;\n+        try {\n+            zk = zkc.get();\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            promise.setException(e);\n+            return;\n+        } catch (InterruptedException e) {\n+            promise.setException(e);\n+            return;\n+        }\n+        ZkUtils.asyncCreateFullPathOptimistic(zk, zkRootPath, new byte[0], zkc.getDefaultACL(),\n+                CreateMode.PERSISTENT, new AsyncCallback.StringCallback() {\n+            @Override\n+            public void processResult(int rc, String path, Object ctx, String name) {\n+                if (KeeperException.Code.OK.intValue() == rc) {\n+                    logger.info(\"Created zk path {} for default ACL.\", zkRootPath);\n+                    fetchDefaultAccessControlEntry(promise);\n+                } else {\n+                    promise.setException(KeeperException.create(KeeperException.Code.get(rc)));\n+                }\n+            }\n+        }, null);\n+    }\n+\n+    private void refetchDefaultAccessControlEntry(final int delayMs) {\n+        if (closed) {\n+            return;\n+        }\n+        scheduledExecutorService.schedule(new Runnable() {\n+            @Override\n+            public void run() {\n+                fetchDefaultAccessControlEntry().addEventListener(new FutureEventListener<ZKAccessControl>() {\n+                    @Override\n+                    public void onSuccess(ZKAccessControl value) {\n+                        // no-op\n+                    }\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        if (cause instanceof ZKAccessControl.CorruptedAccessControlException) {\n+                            logger.warn(\"Default access control entry is corrupted, ignore this update : \", cause);\n+                            return;\n+                        }\n+\n+                        logger.warn(\"Encountered an error on refetching default access control entry, retrying in {} ms : \",\n+                                    ZK_RETRY_BACKOFF_MS, cause);\n+                        refetchDefaultAccessControlEntry(ZK_RETRY_BACKOFF_MS);\n+                    }\n+                });\n+            }\n+        }, delayMs, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private void refetchAccessControlEntries(final int delayMs) {\n+        if (closed) {\n+            return;\n+        }\n+        scheduledExecutorService.schedule(new Runnable() {\n+            @Override\n+            public void run() {\n+                fetchAccessControlEntries().addEventListener(new FutureEventListener<Void>() {\n+                    @Override\n+                    public void onSuccess(Void value) {\n+                        // no-op\n+                    }\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        logger.warn(\"Encountered an error on refetching access control entries, retrying in {} ms : \",\n+                                    ZK_RETRY_BACKOFF_MS, cause);\n+                        refetchAccessControlEntries(ZK_RETRY_BACKOFF_MS);\n+                    }\n+                });\n+            }\n+        }, delayMs, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private void refetchAllAccessControlEntries(final int delayMs) {\n+        if (closed) {\n+            return;\n+        }\n+        scheduledExecutorService.schedule(new Runnable() {\n+            @Override\n+            public void run() {\n+                fetchDefaultAccessControlEntry().addEventListener(new FutureEventListener<ZKAccessControl>() {\n+                    @Override\n+                    public void onSuccess(ZKAccessControl value) {\n+                        fetchAccessControlEntries().addEventListener(new FutureEventListener<Void>() {\n+                            @Override\n+                            public void onSuccess(Void value) {\n+                                // no-op\n+                            }\n+\n+                            @Override\n+                            public void onFailure(Throwable cause) {\n+                                logger.warn(\"Encountered an error on fetching all access control entries, retrying in {} ms : \",\n+                                            ZK_RETRY_BACKOFF_MS, cause);\n+                                refetchAccessControlEntries(ZK_RETRY_BACKOFF_MS);\n+                            }\n+                        });\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Throwable cause) {\n+                        logger.warn(\"Encountered an error on refetching all access control entries, retrying in {} ms : \",\n+                                    ZK_RETRY_BACKOFF_MS, cause);\n+                        refetchAllAccessControlEntries(ZK_RETRY_BACKOFF_MS);\n+                    }\n+                });\n+            }\n+        }, delayMs, TimeUnit.MILLISECONDS);\n+    }\n+\n+    @Override\n+    public void process(WatchedEvent event) {\n+        if (Event.EventType.None.equals(event.getType())) {\n+            if (event.getState() == Event.KeeperState.Expired) {\n+                refetchAllAccessControlEntries(0);\n+            }\n+        } else if (Event.EventType.NodeDataChanged.equals(event.getType())) {\n+            logger.info(\"Default ACL for {} is changed, refetching ...\", zkRootPath);\n+            refetchDefaultAccessControlEntry(0);\n+        } else if (Event.EventType.NodeChildrenChanged.equals(event.getType())) {\n+            logger.info(\"List of ACLs for {} are changed, refetching ...\", zkRootPath);\n+            refetchAccessControlEntries(0);\n+        }\n+    }\n+}"},{"sha":"65109fc30db46ea55da00a24f91e2c37f085525e","filename":"src/main/java/com/twitter/distributedlog/acl/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,21 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+/**\n+ * Access Control for distributedlog streams.\n+ */\n+package com.twitter.distributedlog.acl;"},{"sha":"22b81a161a6bf1a83f609563f8330d670a90aa51","filename":"src/main/java/com/twitter/distributedlog/admin/DistributedLogAdmin.java","status":"added","additions":926,"deletions":0,"changes":926,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FDistributedLogAdmin.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FDistributedLogAdmin.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FDistributedLogAdmin.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,926 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.admin;\n+\n+import com.google.common.base.Preconditions;\n+import com.twitter.distributedlog.BookKeeperClient;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n+import com.twitter.distributedlog.DistributedLogManager;\n+import com.twitter.distributedlog.LedgerHandleCache;\n+import com.twitter.distributedlog.LogRecordWithDLSN;\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import com.twitter.distributedlog.ReadUtils;\n+import com.twitter.distributedlog.ZooKeeperClient;\n+import com.twitter.distributedlog.ZooKeeperClientBuilder;\n+import com.twitter.distributedlog.acl.ZKAccessControl;\n+import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n+import com.twitter.distributedlog.impl.federated.FederatedZKLogMetadataStore;\n+import com.twitter.distributedlog.metadata.BKDLConfig;\n+import com.twitter.distributedlog.metadata.DLMetadata;\n+import com.twitter.distributedlog.metadata.DryrunLogSegmentMetadataStoreUpdater;\n+import com.twitter.distributedlog.metadata.MetadataUpdater;\n+import com.twitter.distributedlog.metadata.LogSegmentMetadataStoreUpdater;\n+import com.twitter.distributedlog.thrift.AccessControlEntry;\n+import com.twitter.distributedlog.tools.DistributedLogTool;\n+import com.twitter.distributedlog.util.DLUtils;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.SchedulerUtils;\n+import com.twitter.util.Await;\n+import com.twitter.util.Function;\n+import com.twitter.util.Future;\n+import org.apache.bookkeeper.util.IOUtils;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.zookeeper.KeeperException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.runtime.AbstractFunction0;\n+import scala.runtime.BoxedUnit;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Admin Tool for DistributedLog.\n+ */\n+@SuppressWarnings(\"deprecation\")\n+public class DistributedLogAdmin extends DistributedLogTool {\n+\n+    static final Logger LOG = LoggerFactory.getLogger(DistributedLogAdmin.class);\n+\n+    /**\n+     * Fix inprogress segment with lower ledger sequence number.\n+     *\n+     * @param factory\n+     *          dlm factory.\n+     * @param metadataUpdater\n+     *          metadata updater.\n+     * @param streamName\n+     *          stream name.\n+     * @param verbose\n+     *          print verbose messages.\n+     * @param interactive\n+     *          is confirmation needed before executing actual action.\n+     * @throws IOException\n+     */\n+    public static void fixInprogressSegmentWithLowerSequenceNumber(final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+                                                                   final MetadataUpdater metadataUpdater,\n+                                                                   final String streamName,\n+                                                                   final boolean verbose,\n+                                                                   final boolean interactive) throws IOException {\n+        DistributedLogManager dlm = factory.createDistributedLogManagerWithSharedClients(streamName);\n+        try {\n+            List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+            if (verbose) {\n+                System.out.println(\"LogSegments for \" + streamName + \" : \");\n+                for (LogSegmentMetadata segment : segments) {\n+                    System.out.println(segment.getLogSegmentSequenceNumber() + \"\\t: \" + segment);\n+                }\n+            }\n+            LOG.info(\"Get log segments for {} : {}\", streamName, segments);\n+            // validate log segments\n+            long maxCompletedLogSegmentSequenceNumber = -1L;\n+            LogSegmentMetadata inprogressSegment = null;\n+            for (LogSegmentMetadata segment : segments) {\n+                if (!segment.isInProgress()) {\n+                    maxCompletedLogSegmentSequenceNumber = Math.max(maxCompletedLogSegmentSequenceNumber, segment.getLogSegmentSequenceNumber());\n+                } else {\n+                    // we already found an inprogress segment\n+                    if (null != inprogressSegment) {\n+                        throw new DLIllegalStateException(\"Multiple inprogress segments found for stream \" + streamName + \" : \" + segments);\n+                    }\n+                    inprogressSegment = segment;\n+                }\n+            }\n+            if (null == inprogressSegment || inprogressSegment.getLogSegmentSequenceNumber() > maxCompletedLogSegmentSequenceNumber) {\n+                // nothing to fix\n+                return;\n+            }\n+            final long newLogSegmentSequenceNumber = maxCompletedLogSegmentSequenceNumber + 1;\n+            if (interactive && !IOUtils.confirmPrompt(\"Confirm to fix (Y/N), Ctrl+C to break : \")) {\n+                return;\n+            }\n+            final LogSegmentMetadata newSegment =\n+                    FutureUtils.result(metadataUpdater.changeSequenceNumber(inprogressSegment, newLogSegmentSequenceNumber));\n+            LOG.info(\"Fixed {} : {} -> {} \",\n+                     new Object[] { streamName, inprogressSegment, newSegment });\n+            if (verbose) {\n+                System.out.println(\"Fixed \" + streamName + \" : \" + inprogressSegment.getZNodeName()\n+                                   + \" -> \" + newSegment.getZNodeName());\n+                System.out.println(\"\\t old: \" + inprogressSegment);\n+                System.out.println(\"\\t new: \" + newSegment);\n+                System.out.println();\n+            }\n+        } finally {\n+            dlm.close();\n+        }\n+    }\n+\n+    private static class LogSegmentCandidate {\n+        final LogSegmentMetadata metadata;\n+        final LogRecordWithDLSN lastRecord;\n+\n+        LogSegmentCandidate(LogSegmentMetadata metadata, LogRecordWithDLSN lastRecord) {\n+            this.metadata = metadata;\n+            this.lastRecord = lastRecord;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"LogSegmentCandidate[ metadata = \" + metadata + \", last record = \" + lastRecord + \" ]\";\n+        }\n+\n+    }\n+\n+    private static final Comparator<LogSegmentCandidate> LOG_SEGMENT_CANDIDATE_COMPARATOR =\n+            new Comparator<LogSegmentCandidate>() {\n+                @Override\n+                public int compare(LogSegmentCandidate o1, LogSegmentCandidate o2) {\n+                    return LogSegmentMetadata.COMPARATOR.compare(o1.metadata, o2.metadata);\n+                }\n+            };\n+\n+    private static class StreamCandidate {\n+\n+        final String streamName;\n+        final SortedSet<LogSegmentCandidate> segmentCandidates =\n+                new TreeSet<LogSegmentCandidate>(LOG_SEGMENT_CANDIDATE_COMPARATOR);\n+\n+        StreamCandidate(String streamName) {\n+            this.streamName = streamName;\n+        }\n+\n+        synchronized void addLogSegmentCandidate(LogSegmentCandidate segmentCandidate) {\n+            segmentCandidates.add(segmentCandidate);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"StreamCandidate[ name = \" + streamName + \", segments = \" + segmentCandidates + \" ]\";\n+        }\n+    }\n+\n+    public static void checkAndRepairDLNamespace(final URI uri,\n+                                                 final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+                                                 final MetadataUpdater metadataUpdater,\n+                                                 final ExecutorService executorService,\n+                                                 final BookKeeperClient bkc,\n+                                                 final String digestpw,\n+                                                 final boolean verbose,\n+                                                 final boolean interactive) throws IOException {\n+        checkAndRepairDLNamespace(uri, factory, metadataUpdater, executorService, bkc, digestpw, verbose, interactive, 1);\n+    }\n+\n+    public static void checkAndRepairDLNamespace(final URI uri,\n+                                                 final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+                                                 final MetadataUpdater metadataUpdater,\n+                                                 final ExecutorService executorService,\n+                                                 final BookKeeperClient bkc,\n+                                                 final String digestpw,\n+                                                 final boolean verbose,\n+                                                 final boolean interactive,\n+                                                 final int concurrency) throws IOException {\n+        Preconditions.checkArgument(concurrency > 0, \"Invalid concurrency \" + concurrency + \" found.\");\n+        // 0. getting streams under a given uri.\n+        Collection<String> streams = factory.enumerateAllLogsInNamespace();\n+        if (verbose) {\n+            System.out.println(\"- 0. checking \" + streams.size() + \" streams under \" + uri);\n+        }\n+        if (streams.size() == 0) {\n+            System.out.println(\"+ 0. nothing to check. quit.\");\n+            return;\n+        }\n+        Map<String, StreamCandidate> streamCandidates =\n+                checkStreams(factory, streams, executorService, bkc, digestpw, concurrency);\n+        if (verbose) {\n+            System.out.println(\"+ 0. \" + streamCandidates.size() + \" corrupted streams found.\");\n+        }\n+        if (interactive && !IOUtils.confirmPrompt(\"Do you want to fix all \" + streamCandidates.size() + \" corrupted streams (Y/N) : \")) {\n+            return;\n+        }\n+        if (verbose) {\n+            System.out.println(\"- 1. repairing \" + streamCandidates.size() + \" corrupted streams.\");\n+        }\n+        for (StreamCandidate candidate : streamCandidates.values()) {\n+            if (!repairStream(metadataUpdater, candidate, verbose, interactive)) {\n+                if (verbose) {\n+                    System.out.println(\"* 1. aborted repairing corrupted streams.\");\n+                }\n+                return;\n+            }\n+        }\n+        if (verbose) {\n+            System.out.println(\"+ 1. repaired \" + streamCandidates.size() + \" corrupted streams.\");\n+        }\n+    }\n+\n+    private static Map<String, StreamCandidate> checkStreams(\n+            final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+            final Collection<String> streams,\n+            final ExecutorService executorService,\n+            final BookKeeperClient bkc,\n+            final String digestpw,\n+            final int concurrency) throws IOException {\n+        final LinkedBlockingQueue<String> streamQueue =\n+                new LinkedBlockingQueue<String>();\n+        streamQueue.addAll(streams);\n+        final Map<String, StreamCandidate> candidateMap =\n+                new ConcurrentSkipListMap<String, StreamCandidate>();\n+        final AtomicInteger numPendingStreams = new AtomicInteger(streams.size());\n+        final CountDownLatch doneLatch = new CountDownLatch(1);\n+        Runnable checkRunnable = new Runnable() {\n+            @Override\n+            public void run() {\n+                while (!streamQueue.isEmpty()) {\n+                    String stream;\n+                    try {\n+                        stream = streamQueue.take();\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                        break;\n+                    }\n+                    StreamCandidate candidate;\n+                    try {\n+                        LOG.info(\"Checking stream {}.\", stream);\n+                        candidate = checkStream(factory, stream, executorService, bkc, digestpw);\n+                        LOG.info(\"Checked stream {} - {}.\", stream, candidate);\n+                    } catch (IOException e) {\n+                        LOG.error(\"Error on checking stream {} : \", stream, e);\n+                        doneLatch.countDown();\n+                        break;\n+                    }\n+                    if (null != candidate) {\n+                        candidateMap.put(stream, candidate);\n+                    }\n+                    if (numPendingStreams.decrementAndGet() == 0) {\n+                        doneLatch.countDown();\n+                    }\n+                }\n+            }\n+        };\n+        Thread[] threads = new Thread[concurrency];\n+        for (int i = 0; i < concurrency; i++) {\n+            threads[i] = new Thread(checkRunnable, \"check-thread-\" + i);\n+            threads[i].start();\n+        }\n+        try {\n+            doneLatch.await();\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+        }\n+        if (numPendingStreams.get() != 0) {\n+            throw new IOException(numPendingStreams.get() + \" streams left w/o checked\");\n+        }\n+        for (int i = 0; i < concurrency; i++) {\n+            threads[i].interrupt();\n+            try {\n+                threads[i].join();\n+            } catch (InterruptedException e) {\n+                Thread.currentThread().interrupt();\n+            }\n+        }\n+        return candidateMap;\n+    }\n+\n+    private static StreamCandidate checkStream(\n+            final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+            final String streamName,\n+            final ExecutorService executorService,\n+            final BookKeeperClient bkc,\n+            String digestpw) throws IOException {\n+        DistributedLogManager dlm = factory.createDistributedLogManagerWithSharedClients(streamName);\n+        try {\n+            List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+            if (segments.isEmpty()) {\n+                return null;\n+            }\n+            List<Future<LogSegmentCandidate>> futures =\n+                    new ArrayList<Future<LogSegmentCandidate>>(segments.size());\n+            for (LogSegmentMetadata segment : segments) {\n+                futures.add(checkLogSegment(streamName, segment, executorService, bkc, digestpw));\n+            }\n+            List<LogSegmentCandidate> segmentCandidates;\n+            try {\n+                segmentCandidates = Await.result(Future.collect(futures));\n+            } catch (Exception e) {\n+                throw new IOException(\"Failed on checking stream \" + streamName, e);\n+            }\n+            StreamCandidate streamCandidate = new StreamCandidate(streamName);\n+            for (LogSegmentCandidate segmentCandidate: segmentCandidates) {\n+                if (null != segmentCandidate) {\n+                    streamCandidate.addLogSegmentCandidate(segmentCandidate);\n+                }\n+            }\n+            if (streamCandidate.segmentCandidates.isEmpty()) {\n+                return null;\n+            }\n+            return streamCandidate;\n+        } finally {\n+            dlm.close();\n+        }\n+    }\n+\n+    private static Future<LogSegmentCandidate> checkLogSegment(\n+            final String streamName,\n+            final LogSegmentMetadata metadata,\n+            final ExecutorService executorService,\n+            final BookKeeperClient bkc,\n+            final String digestpw) {\n+        if (metadata.isInProgress()) {\n+            return Future.value(null);\n+        }\n+\n+        final LedgerHandleCache handleCache = LedgerHandleCache.newBuilder()\n+                .bkc(bkc)\n+                .conf(new DistributedLogConfiguration().setBKDigestPW(digestpw))\n+                .build();\n+        return ReadUtils.asyncReadLastRecord(\n+                streamName,\n+                metadata,\n+                true,\n+                false,\n+                true,\n+                4,\n+                16,\n+                new AtomicInteger(0),\n+                executorService,\n+                handleCache\n+        ).map(new Function<LogRecordWithDLSN, LogSegmentCandidate>() {\n+            @Override\n+            public LogSegmentCandidate apply(LogRecordWithDLSN record) {\n+                if (null != record &&\n+                    (record.getDlsn().compareTo(metadata.getLastDLSN()) > 0 ||\n+                     record.getTransactionId() > metadata.getLastTxId() ||\n+                     !metadata.isRecordPositionWithinSegmentScope(record))) {\n+                    return new LogSegmentCandidate(metadata, record);\n+                } else {\n+                    return null;\n+                }\n+            }\n+        }).ensure(new AbstractFunction0<BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply() {\n+                handleCache.clear();\n+                return BoxedUnit.UNIT;\n+            }\n+        });\n+    }\n+\n+    private static boolean repairStream(MetadataUpdater metadataUpdater,\n+                                        StreamCandidate streamCandidate,\n+                                        boolean verbose,\n+                                        boolean interactive) throws IOException {\n+        if (verbose) {\n+            System.out.println(\"Stream \" + streamCandidate.streamName + \" : \");\n+            for (LogSegmentCandidate segmentCandidate : streamCandidate.segmentCandidates) {\n+                System.out.println(\"  \" + segmentCandidate.metadata.getLogSegmentSequenceNumber()\n+                        + \" : metadata = \" + segmentCandidate.metadata + \", last dlsn = \"\n+                        + segmentCandidate.lastRecord.getDlsn());\n+            }\n+            System.out.println(\"-------------------------------------------\");\n+        }\n+        if (interactive && !IOUtils.confirmPrompt(\"Do you want to fix the stream \" + streamCandidate.streamName + \" (Y/N) : \")) {\n+            return false;\n+        }\n+        for (LogSegmentCandidate segmentCandidate : streamCandidate.segmentCandidates) {\n+            LogSegmentMetadata newMetadata = FutureUtils.result(\n+                    metadataUpdater.updateLastRecord(segmentCandidate.metadata, segmentCandidate.lastRecord));\n+            if (verbose) {\n+                System.out.println(\"  Fixed segment \" + segmentCandidate.metadata.getLogSegmentSequenceNumber() + \" : \");\n+                System.out.println(\"    old metadata : \" + segmentCandidate.metadata);\n+                System.out.println(\"    new metadata : \" + newMetadata);\n+            }\n+        }\n+        if (verbose) {\n+            System.out.println(\"-------------------------------------------\");\n+        }\n+        return true;\n+    }\n+\n+    //\n+    // Commands\n+    //\n+\n+    /**\n+     * Unbind the bookkeeper environment for a given distributedlog uri.\n+     */\n+    class UnbindCommand extends OptsCommand {\n+\n+        Options options = new Options();\n+\n+        UnbindCommand() {\n+            super(\"unbind\", \"unbind the bookkeeper environment bound for a given distributedlog instance.\");\n+            options.addOption(\"f\", \"force\", false, \"Force unbinding without prompt.\");\n+        }\n+\n+        @Override\n+        protected Options getOptions() {\n+            return options;\n+        }\n+\n+        @Override\n+        protected String getUsage() {\n+            return \"unbind [options] <distributedlog uri>\";\n+        }\n+\n+        @Override\n+        protected int runCmd(CommandLine cmdline) throws Exception {\n+            String[] args = cmdline.getArgs();\n+            if (args.length <= 0) {\n+                System.err.println(\"No distributedlog uri specified.\");\n+                printUsage();\n+                return -1;\n+            }\n+            boolean force = cmdline.hasOption(\"f\");\n+            URI uri = URI.create(args[0]);\n+            // resolving the uri to see if there is another bindings in this uri.\n+            ZooKeeperClient zkc = ZooKeeperClientBuilder.newBuilder().uri(uri)\n+                    .sessionTimeoutMs(10000).build();\n+            BKDLConfig bkdlConfig;\n+            try {\n+                bkdlConfig = BKDLConfig.resolveDLConfig(zkc, uri);\n+            } catch (IOException ie) {\n+                bkdlConfig = null;\n+            }\n+            if (null == bkdlConfig) {\n+                System.out.println(\"No bookkeeper is bound to \" + uri);\n+                return 0;\n+            } else {\n+                System.out.println(\"There is bookkeeper bound to \" + uri + \" : \");\n+                System.out.println(\"\");\n+                System.out.println(bkdlConfig.toString());\n+                System.out.println(\"\");\n+                if (!force && !IOUtils.confirmPrompt(\"Do you want to unbind \" + uri + \" :\\n\")) {\n+                    return 0;\n+                }\n+            }\n+            DLMetadata.unbind(uri);\n+            System.out.println(\"Unbound on \" + uri + \".\");\n+            return 0;\n+        }\n+    }\n+\n+    /**\n+     * Bind Command to bind bookkeeper environment for a given distributed uri.\n+     */\n+    class BindCommand extends OptsCommand {\n+\n+        Options options = new Options();\n+\n+        BindCommand() {\n+            super(\"bind\", \"bind the bookkeeper environment settings for a given distributedlog instance.\");\n+            options.addOption(\"l\", \"bkLedgers\", true, \"ZooKeeper ledgers path for bookkeeper instance.\");\n+            options.addOption(\"s\", \"bkZkServers\", true, \"ZooKeeper servers used for bookkeeper for writers.\");\n+            options.addOption(\"bkzr\", \"bkZkServersForReader\", true, \"ZooKeeper servers used for bookkeeper for readers.\");\n+            options.addOption(\"dlzw\", \"dlZkServersForWriter\", true, \"ZooKeeper servers used for distributedlog for writers.\");\n+            options.addOption(\"dlzr\", \"dlZkServersForReader\", true, \"ZooKeeper servers used for distributedlog for readers.\");\n+            options.addOption(\"i\", \"sanityCheckTxnID\", true, \"Flag to sanity check highest txn id.\");\n+            options.addOption(\"r\", \"encodeRegionID\", true, \"Flag to encode region id.\");\n+            options.addOption(\"seqno\", \"firstLogSegmentSeqNo\", true, \"The first log segment sequence number to use after upgrade\");\n+            options.addOption(\"fns\", \"federatedNamespace\", false, \"Flag to turn a namespace to federated namespace\");\n+            options.addOption(\"f\", \"force\", false, \"Force binding without prompt.\");\n+            options.addOption(\"c\", \"creation\", false, \"Whether is it a creation binding.\");\n+            options.addOption(\"q\", \"query\", false, \"Query the bookkeeper bindings\");\n+        }\n+\n+        @Override\n+        protected Options getOptions() {\n+            return options;\n+        }\n+\n+        @Override\n+        protected String getUsage() {\n+            return \"bind [options] <distributedlog uri>\";\n+        }\n+\n+        @Override\n+        protected int runCmd(CommandLine cmdline) throws Exception {\n+            boolean isQuery = cmdline.hasOption(\"q\");\n+            if (!isQuery && (!cmdline.hasOption(\"l\") || !cmdline.hasOption(\"s\"))) {\n+                System.err.println(\"Error: Neither zkServers nor ledgersPath specified for bookkeeper environment.\");\n+                printUsage();\n+                return -1;\n+            }\n+            String[] args = cmdline.getArgs();\n+            if (args.length <= 0) {\n+                System.err.println(\"No distributedlog uri specified.\");\n+                printUsage();\n+                return -1;\n+            }\n+            boolean force = cmdline.hasOption(\"f\");\n+            boolean creation = cmdline.hasOption(\"c\");\n+            String bkLedgersPath = cmdline.getOptionValue(\"l\");\n+            String bkZkServersForWriter = cmdline.getOptionValue(\"s\");\n+            boolean sanityCheckTxnID =\n+                    !cmdline.hasOption(\"i\") || Boolean.parseBoolean(cmdline.getOptionValue(\"i\"));\n+            boolean encodeRegionID =\n+                    cmdline.hasOption(\"r\") && Boolean.parseBoolean(cmdline.getOptionValue(\"r\"));\n+\n+            String bkZkServersForReader;\n+            if (cmdline.hasOption(\"bkzr\")) {\n+                bkZkServersForReader = cmdline.getOptionValue(\"bkzr\");\n+            } else {\n+                bkZkServersForReader = bkZkServersForWriter;\n+            }\n+\n+            URI uri = URI.create(args[0]);\n+\n+            String dlZkServersForWriter;\n+            String dlZkServersForReader;\n+            if (cmdline.hasOption(\"dlzw\")) {\n+                dlZkServersForWriter = cmdline.getOptionValue(\"dlzw\");\n+            } else {\n+                dlZkServersForWriter = DLUtils.getZKServersFromDLUri(uri);\n+            }\n+            if (cmdline.hasOption(\"dlzr\")) {\n+                dlZkServersForReader = cmdline.getOptionValue(\"dlzr\");\n+            } else {\n+                dlZkServersForReader = dlZkServersForWriter;\n+            }\n+\n+            // resolving the uri to see if there is another bindings in this uri.\n+            ZooKeeperClient zkc = ZooKeeperClientBuilder.newBuilder().uri(uri).zkAclId(null)\n+                    .sessionTimeoutMs(10000).build();\n+            try {\n+                BKDLConfig newBKDLConfig =\n+                        new BKDLConfig(dlZkServersForWriter, dlZkServersForReader,\n+                                       bkZkServersForWriter, bkZkServersForReader, bkLedgersPath)\n+                                .setSanityCheckTxnID(sanityCheckTxnID)\n+                                .setEncodeRegionID(encodeRegionID);\n+\n+                if (cmdline.hasOption(\"seqno\")) {\n+                    newBKDLConfig = newBKDLConfig.setFirstLogSegmentSeqNo(Long.parseLong(cmdline.getOptionValue(\"seqno\")));\n+                }\n+\n+                if (cmdline.hasOption(\"fns\")) {\n+                    newBKDLConfig = newBKDLConfig.setFederatedNamespace(true);\n+                }\n+\n+                BKDLConfig bkdlConfig;\n+                try {\n+                    bkdlConfig = BKDLConfig.resolveDLConfig(zkc, uri);\n+                } catch (IOException ie) {\n+                    bkdlConfig = null;\n+                }\n+                if (null == bkdlConfig) {\n+                    System.out.println(\"No bookkeeper is bound to \" + uri);\n+                } else {\n+                    System.out.println(\"There is bookkeeper bound to \" + uri + \" : \");\n+                    System.out.println(\"\");\n+                    System.out.println(bkdlConfig.toString());\n+                    System.out.println(\"\");\n+                    if (!isQuery) {\n+                        if (newBKDLConfig.equals(bkdlConfig)) {\n+                            System.out.println(\"No bookkeeper binding needs to be updated. Quit.\");\n+                            return 0;\n+                        } else if(!newBKDLConfig.isFederatedNamespace() && bkdlConfig.isFederatedNamespace()) {\n+                            System.out.println(\"You can't turn a federated namespace back to non-federated.\");\n+                            return 0;\n+                        } else {\n+                            if (!force && !IOUtils.confirmPrompt(\"Do you want to bind \" + uri\n+                                        + \" with new bookkeeper instance :\\n\" + newBKDLConfig)) {\n+                                return 0;\n+                            }\n+                        }\n+                    }\n+                }\n+                if (isQuery) {\n+                    System.out.println(\"Done.\");\n+                    return 0;\n+                }\n+                DLMetadata dlMetadata = DLMetadata.create(newBKDLConfig);\n+                if (creation) {\n+                    try {\n+                        dlMetadata.create(uri);\n+                        System.out.println(\"Created binding on \" + uri + \".\");\n+                    } catch (IOException ie) {\n+                        System.err.println(\"Failed to create binding on \" + uri + \" : \" + ie.getMessage());\n+                    }\n+                } else {\n+                    try {\n+                        dlMetadata.update(uri);\n+                        System.out.println(\"Updated binding on \" + uri + \" : \");\n+                        System.out.println(\"\");\n+                        System.out.println(newBKDLConfig.toString());\n+                        System.out.println(\"\");\n+                    } catch (IOException ie) {\n+                        System.err.println(\"Failed to update binding on \" + uri + \" : \" + ie.getMessage());\n+                    }\n+                }\n+                if (newBKDLConfig.isFederatedNamespace()) {\n+                    try {\n+                        FederatedZKLogMetadataStore.createFederatedNamespace(uri, zkc);\n+                    } catch (KeeperException.NodeExistsException nee) {\n+                        // ignore node exists exception\n+                    }\n+                }\n+                return 0;\n+            } finally {\n+                zkc.close();\n+            }\n+        }\n+    }\n+\n+    static class RepairSeqNoCommand extends PerDLCommand {\n+\n+        boolean dryrun = false;\n+        boolean verbose = false;\n+        final List<String> streams = new ArrayList<String>();\n+\n+        RepairSeqNoCommand() {\n+            super(\"repairseqno\", \"Repair a stream whose inprogress log segment has lower sequence number.\");\n+            options.addOption(\"d\", \"dryrun\", false, \"Dry run without repairing\");\n+            options.addOption(\"l\", \"list\", true, \"List of streams to repair, separated by comma\");\n+            options.addOption(\"v\", \"verbose\", false, \"Print verbose messages\");\n+        }\n+\n+        @Override\n+        protected void parseCommandLine(CommandLine cmdline) throws ParseException {\n+            super.parseCommandLine(cmdline);\n+            dryrun = cmdline.hasOption(\"d\");\n+            verbose = cmdline.hasOption(\"v\");\n+            force = !dryrun && cmdline.hasOption(\"f\");\n+            if (!cmdline.hasOption(\"l\")) {\n+                throw new ParseException(\"No streams provided to repair\");\n+            }\n+            String streamsList = cmdline.getOptionValue(\"l\");\n+            Collections.addAll(streams, streamsList.split(\",\"));\n+        }\n+\n+        @Override\n+        protected int runCmd() throws Exception {\n+            MetadataUpdater metadataUpdater = dryrun ?\n+                    new DryrunLogSegmentMetadataStoreUpdater(getConf(),\n+                            getLogSegmentMetadataStore()) :\n+                    LogSegmentMetadataStoreUpdater.createMetadataUpdater(getConf(),\n+                            getLogSegmentMetadataStore());\n+            System.out.println(\"List of streams : \");\n+            System.out.println(streams);\n+            if (!IOUtils.confirmPrompt(\"Do you want to repair all these streams (Y/N):\")) {\n+                return -1;\n+            }\n+            for (String stream : streams) {\n+                fixInprogressSegmentWithLowerSequenceNumber(getFactory(), metadataUpdater, stream, verbose, !getForce());\n+            }\n+            return 0;\n+        }\n+\n+        @Override\n+        protected String getUsage() {\n+            return \"repairseqno [options]\";\n+        }\n+    }\n+\n+    static class DLCKCommand extends PerDLCommand {\n+\n+        boolean dryrun = false;\n+        boolean verbose = false;\n+        int concurrency = 1;\n+\n+        DLCKCommand() {\n+            super(\"dlck\", \"Check and repair a distributedlog namespace\");\n+            options.addOption(\"d\", \"dryrun\", false, \"Dry run without repairing\");\n+            options.addOption(\"v\", \"verbose\", false, \"Print verbose messages\");\n+            options.addOption(\"cy\", \"concurrency\", true, \"Concurrency on checking streams\");\n+        }\n+\n+        @Override\n+        protected void parseCommandLine(CommandLine cmdline) throws ParseException {\n+            super.parseCommandLine(cmdline);\n+            dryrun = cmdline.hasOption(\"d\");\n+            verbose = cmdline.hasOption(\"v\");\n+            if (cmdline.hasOption(\"cy\")) {\n+                try {\n+                    concurrency = Integer.parseInt(cmdline.getOptionValue(\"cy\"));\n+                } catch (NumberFormatException nfe) {\n+                    throw new ParseException(\"Invalid concurrency value : \" + cmdline.getOptionValue(\"cy\"));\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected int runCmd() throws Exception {\n+            MetadataUpdater metadataUpdater = dryrun ?\n+                    new DryrunLogSegmentMetadataStoreUpdater(getConf(),\n+                            getLogSegmentMetadataStore()) :\n+                    LogSegmentMetadataStoreUpdater.createMetadataUpdater(getConf(),\n+                            getLogSegmentMetadataStore());\n+            ExecutorService executorService = Executors.newCachedThreadPool();\n+            BookKeeperClient bkc = getBookKeeperClient();\n+            try {\n+                checkAndRepairDLNamespace(getUri(), getFactory(), metadataUpdater, executorService,\n+                                          bkc, getConf().getBKDigestPW(), verbose, !getForce(), concurrency);\n+            } finally {\n+                SchedulerUtils.shutdownScheduler(executorService, 5, TimeUnit.MINUTES);\n+            }\n+            return 0;\n+        }\n+\n+        @Override\n+        protected String getUsage() {\n+            return \"dlck [options]\";\n+        }\n+    }\n+\n+    static class DeleteStreamACLCommand extends PerDLCommand {\n+\n+        String stream = null;\n+\n+        DeleteStreamACLCommand() {\n+            super(\"delete_stream_acl\", \"Delete ACL for a given stream\");\n+            options.addOption(\"s\", \"stream\", true, \"Stream to set ACL\");\n+        }\n+\n+        @Override\n+        protected void parseCommandLine(CommandLine cmdline) throws ParseException {\n+            super.parseCommandLine(cmdline);\n+            if (!cmdline.hasOption(\"s\")) {\n+                throw new ParseException(\"No stream to set ACL\");\n+            }\n+            stream = cmdline.getOptionValue(\"s\");\n+        }\n+\n+        @Override\n+        protected int runCmd() throws Exception {\n+            BKDLConfig bkdlConfig = BKDLConfig.resolveDLConfig(getZooKeeperClient(), getUri());\n+            if (null == bkdlConfig.getACLRootPath()) {\n+                // acl isn't enabled for this namespace.\n+                System.err.println(\"ACL isn't enabled for namespace \" + getUri());\n+                return -1;\n+            }\n+            String zkPath = getUri() + \"/\" + bkdlConfig.getACLRootPath() + \"/\" + stream;\n+            ZKAccessControl.delete(getZooKeeperClient(), zkPath);\n+            return 0;\n+        }\n+\n+        @Override\n+        protected String getUsage() {\n+            return null;\n+        }\n+    }\n+\n+    static class SetStreamACLCommand extends SetACLCommand {\n+\n+        String stream = null;\n+\n+        SetStreamACLCommand() {\n+            super(\"set_stream_acl\", \"Set Default ACL for a given stream\");\n+            options.addOption(\"s\", \"stream\", true, \"Stream to set ACL\");\n+        }\n+\n+        @Override\n+        protected void parseCommandLine(CommandLine cmdline) throws ParseException {\n+            super.parseCommandLine(cmdline);\n+            if (!cmdline.hasOption(\"s\")) {\n+                throw new ParseException(\"No stream to set ACL\");\n+            }\n+            stream = cmdline.getOptionValue(\"s\");\n+        }\n+\n+        @Override\n+        protected String getZKPath(String zkRootPath) {\n+            return zkRootPath + \"/\" + stream;\n+        }\n+\n+        @Override\n+        protected String getUsage() {\n+            return \"set_stream_acl [options]\";\n+        }\n+    }\n+\n+    static class SetDefaultACLCommand extends SetACLCommand {\n+\n+        SetDefaultACLCommand() {\n+            super(\"set_default_acl\", \"Set Default ACL for a namespace\");\n+        }\n+\n+        @Override\n+        protected String getZKPath(String zkRootPath) {\n+            return zkRootPath;\n+        }\n+\n+        @Override\n+        protected String getUsage() {\n+            return \"set_default_acl [options]\";\n+        }\n+    }\n+\n+    static abstract class SetACLCommand extends PerDLCommand {\n+\n+        boolean denyWrite = false;\n+        boolean denyTruncate = false;\n+        boolean denyDelete = false;\n+        boolean denyAcquire = false;\n+        boolean denyRelease = false;\n+\n+        protected SetACLCommand(String name, String description) {\n+            super(name, description);\n+            options.addOption(\"dw\", \"deny-write\", false, \"Deny write/bulkWrite requests\");\n+            options.addOption(\"dt\", \"deny-truncate\", false, \"Deny truncate requests\");\n+            options.addOption(\"dd\", \"deny-delete\", false, \"Deny delete requests\");\n+            options.addOption(\"da\", \"deny-acquire\", false, \"Deny acquire requests\");\n+            options.addOption(\"dr\", \"deny-release\", false, \"Deny release requests\");\n+        }\n+\n+        @Override\n+        protected void parseCommandLine(CommandLine cmdline) throws ParseException {\n+            super.parseCommandLine(cmdline);\n+            denyWrite = cmdline.hasOption(\"dw\");\n+            denyTruncate = cmdline.hasOption(\"dt\");\n+            denyDelete = cmdline.hasOption(\"dd\");\n+            denyAcquire = cmdline.hasOption(\"da\");\n+            denyRelease = cmdline.hasOption(\"dr\");\n+        }\n+\n+        protected abstract String getZKPath(String zkRootPath);\n+\n+        protected ZKAccessControl getZKAccessControl(ZooKeeperClient zkc, String zkPath) throws Exception {\n+            ZKAccessControl accessControl;\n+            try {\n+                accessControl = Await.result(ZKAccessControl.read(zkc, zkPath, null));\n+            } catch (KeeperException.NoNodeException nne) {\n+                accessControl = new ZKAccessControl(new AccessControlEntry(), zkPath);\n+            }\n+            return accessControl;\n+        }\n+\n+        protected void setZKAccessControl(ZooKeeperClient zkc, ZKAccessControl accessControl) throws Exception {\n+            String zkPath = accessControl.getZKPath();\n+            if (null == zkc.get().exists(zkPath, false)) {\n+                accessControl.create(zkc);\n+            } else {\n+                accessControl.update(zkc);\n+            }\n+        }\n+\n+        @Override\n+        protected int runCmd() throws Exception {\n+            BKDLConfig bkdlConfig = BKDLConfig.resolveDLConfig(getZooKeeperClient(), getUri());\n+            if (null == bkdlConfig.getACLRootPath()) {\n+                // acl isn't enabled for this namespace.\n+                System.err.println(\"ACL isn't enabled for namespace \" + getUri());\n+                return -1;\n+            }\n+            String zkPath = getZKPath(getUri().getPath() + \"/\" + bkdlConfig.getACLRootPath());\n+            ZKAccessControl accessControl = getZKAccessControl(getZooKeeperClient(), zkPath);\n+            AccessControlEntry acl = accessControl.getAccessControlEntry();\n+            acl.setDenyWrite(denyWrite);\n+            acl.setDenyTruncate(denyTruncate);\n+            acl.setDenyDelete(denyDelete);\n+            acl.setDenyAcquire(denyAcquire);\n+            acl.setDenyRelease(denyRelease);\n+            setZKAccessControl(getZooKeeperClient(), accessControl);\n+            return 0;\n+        }\n+\n+    }\n+\n+    public DistributedLogAdmin() {\n+        super();\n+        commands.clear();\n+        addCommand(new HelpCommand());\n+        addCommand(new BindCommand());\n+        addCommand(new UnbindCommand());\n+        addCommand(new RepairSeqNoCommand());\n+        addCommand(new DLCKCommand());\n+        addCommand(new SetDefaultACLCommand());\n+        addCommand(new SetStreamACLCommand());\n+        addCommand(new DeleteStreamACLCommand());\n+    }\n+\n+    @Override\n+    protected String getName() {\n+        return \"dlog_admin\";\n+    }\n+}"},{"sha":"a7d6adbaf2437c0d89c2176b988f45718d8d7c12","filename":"src/main/java/com/twitter/distributedlog/admin/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,21 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+/**\n+ * Admin Tools for DistributedLog\n+ */\n+package com.twitter.distributedlog.admin;"},{"sha":"289afd692bfe664738eef5d492ef9112a36a23d2","filename":"src/main/java/com/twitter/distributedlog/auditor/DLAuditor.java","status":"added","additions":621,"deletions":0,"changes":621,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fauditor%2FDLAuditor.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fauditor%2FDLAuditor.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fauditor%2FDLAuditor.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,621 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.auditor;\n+\n+import com.google.common.base.Objects;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.util.concurrent.SettableFuture;\n+import com.twitter.distributedlog.BKDistributedLogNamespace;\n+import com.twitter.distributedlog.BookKeeperClient;\n+import com.twitter.distributedlog.BookKeeperClientBuilder;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n+import com.twitter.distributedlog.DistributedLogManager;\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import com.twitter.distributedlog.namespace.DistributedLogNamespace;\n+import com.twitter.distributedlog.ZooKeeperClient;\n+import com.twitter.distributedlog.ZooKeeperClientBuilder;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.metadata.BKDLConfig;\n+import com.twitter.distributedlog.util.DLUtils;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.BookKeeper;\n+import org.apache.bookkeeper.client.BookKeeperAccessor;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+import org.apache.bookkeeper.meta.LedgerManager;\n+import org.apache.bookkeeper.proto.BookkeeperInternalCallbacks;\n+import org.apache.bookkeeper.zookeeper.BoundExponentialBackoffRetryPolicy;\n+import org.apache.bookkeeper.zookeeper.RetryPolicy;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.apache.zookeeper.AsyncCallback;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.data.Stat;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+\n+/**\n+ * DL Auditor will audit DL namespace, e.g. find leaked ledger, report disk usage by streams.\n+ */\n+@SuppressWarnings(\"deprecation\")\n+public class DLAuditor {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(DLAuditor.class);\n+\n+    private final DistributedLogConfiguration conf;\n+\n+    public DLAuditor(DistributedLogConfiguration conf) {\n+        this.conf = conf;\n+    }\n+\n+    private ZooKeeperClient getZooKeeperClient(com.twitter.distributedlog.DistributedLogManagerFactory factory) {\n+        DistributedLogNamespace namespace = factory.getNamespace();\n+        assert(namespace instanceof BKDistributedLogNamespace);\n+        return ((BKDistributedLogNamespace) namespace).getSharedWriterZKCForDL();\n+    }\n+\n+    private BookKeeperClient getBookKeeperClient(com.twitter.distributedlog.DistributedLogManagerFactory factory) {\n+        DistributedLogNamespace namespace = factory.getNamespace();\n+        assert(namespace instanceof BKDistributedLogNamespace);\n+        return ((BKDistributedLogNamespace) namespace).getReaderBKC();\n+    }\n+\n+    private String validateAndGetZKServers(List<URI> uris) {\n+        URI firstURI = uris.get(0);\n+        String zkServers = DLUtils.getZKServersFromDLUri(firstURI);\n+        for (URI uri : uris) {\n+            if (!zkServers.equalsIgnoreCase(DLUtils.getZKServersFromDLUri(uri))) {\n+                throw new IllegalArgumentException(\"Uris don't belong to same zookeeper cluster\");\n+            }\n+        }\n+        return zkServers;\n+    }\n+\n+    private BKDLConfig resolveBKDLConfig(ZooKeeperClient zkc, List<URI> uris) throws IOException {\n+        URI firstURI = uris.get(0);\n+        BKDLConfig bkdlConfig = BKDLConfig.resolveDLConfig(zkc, firstURI);\n+        for (URI uri : uris) {\n+            BKDLConfig anotherConfig = BKDLConfig.resolveDLConfig(zkc, uri);\n+            if (!(Objects.equal(bkdlConfig.getBkLedgersPath(), anotherConfig.getBkLedgersPath())\n+                    && Objects.equal(bkdlConfig.getBkZkServersForWriter(), anotherConfig.getBkZkServersForWriter()))) {\n+                throw new IllegalArgumentException(\"Uris don't use same bookkeeper cluster\");\n+            }\n+        }\n+        return bkdlConfig;\n+    }\n+\n+    public Pair<Set<Long>, Set<Long>> collectLedgers(List<URI> uris, List<List<String>> allocationPaths)\n+            throws IOException {\n+        Preconditions.checkArgument(uris.size() > 0, \"No uri provided to audit\");\n+\n+        String zkServers = validateAndGetZKServers(uris);\n+        RetryPolicy retryPolicy = new BoundExponentialBackoffRetryPolicy(\n+                conf.getZKRetryBackoffStartMillis(),\n+                conf.getZKRetryBackoffMaxMillis(),\n+                Integer.MAX_VALUE);\n+        ZooKeeperClient zkc = ZooKeeperClientBuilder.newBuilder()\n+                .name(\"DLAuditor-ZK\")\n+                .zkServers(zkServers)\n+                .sessionTimeoutMs(conf.getZKSessionTimeoutMilliseconds())\n+                .retryPolicy(retryPolicy)\n+                .zkAclId(conf.getZkAclId())\n+                .build();\n+        ExecutorService executorService = Executors.newCachedThreadPool();\n+        try {\n+            BKDLConfig bkdlConfig = resolveBKDLConfig(zkc, uris);\n+            logger.info(\"Resolved bookkeeper config : {}\", bkdlConfig);\n+\n+            BookKeeperClient bkc = BookKeeperClientBuilder.newBuilder()\n+                    .name(\"DLAuditor-BK\")\n+                    .dlConfig(conf)\n+                    .zkServers(bkdlConfig.getBkZkServersForWriter())\n+                    .ledgersPath(bkdlConfig.getBkLedgersPath())\n+                    .build();\n+            try {\n+                Set<Long> bkLedgers = collectLedgersFromBK(bkc, executorService);\n+                Set<Long> dlLedgers = collectLedgersFromDL(uris, allocationPaths);\n+                return Pair.of(bkLedgers, dlLedgers);\n+            } finally {\n+                bkc.close();\n+            }\n+        } finally {\n+            zkc.close();\n+            executorService.shutdown();\n+        }\n+    }\n+\n+    /**\n+     * Find leak ledgers phase 1: collect ledgers set.\n+     */\n+    private Set<Long> collectLedgersFromBK(BookKeeperClient bkc,\n+                                           final ExecutorService executorService)\n+            throws IOException {\n+        LedgerManager lm = BookKeeperAccessor.getLedgerManager(bkc.get());\n+\n+        final Set<Long> ledgers = new HashSet<Long>();\n+        final SettableFuture<Void> doneFuture = SettableFuture.create();\n+\n+        BookkeeperInternalCallbacks.Processor<Long> collector =\n+                new BookkeeperInternalCallbacks.Processor<Long>() {\n+            @Override\n+            public void process(Long lid,\n+                                final AsyncCallback.VoidCallback cb) {\n+                synchronized (ledgers) {\n+                    ledgers.add(lid);\n+                    if (0 == ledgers.size() % 1000) {\n+                        logger.info(\"Collected {} ledgers\", ledgers.size());\n+                    }\n+                }\n+                executorService.submit(new Runnable() {\n+                    @Override\n+                    public void run() {\n+                        cb.processResult(BKException.Code.OK, null, null);\n+                    }\n+                });\n+\n+            }\n+        };\n+        AsyncCallback.VoidCallback finalCb = new AsyncCallback.VoidCallback() {\n+            @Override\n+            public void processResult(int rc, String path, Object ctx) {\n+                if (BKException.Code.OK == rc) {\n+                    doneFuture.set(null);\n+                } else {\n+                    doneFuture.setException(BKException.create(rc));\n+                }\n+            }\n+        };\n+        lm.asyncProcessLedgers(collector, finalCb, null, BKException.Code.OK,\n+                BKException.Code.ZKException);\n+        try {\n+            doneFuture.get();\n+            logger.info(\"Collected total {} ledgers\", ledgers.size());\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            throw new DLInterruptedException(\"Interrupted on collecting ledgers : \", e);\n+        } catch (ExecutionException e) {\n+            if (e.getCause() instanceof IOException) {\n+                throw (IOException)(e.getCause());\n+            } else {\n+                throw new IOException(\"Failed to collect ledgers : \", e.getCause());\n+            }\n+        }\n+        return ledgers;\n+    }\n+\n+    /**\n+     * Find leak ledgers phase 2: collect ledgers from uris.\n+     */\n+    private Set<Long> collectLedgersFromDL(List<URI> uris, List<List<String>> allocationPaths)\n+            throws IOException {\n+        final Set<Long> ledgers = new TreeSet<Long>();\n+        List<com.twitter.distributedlog.DistributedLogManagerFactory> factories =\n+                new ArrayList<com.twitter.distributedlog.DistributedLogManagerFactory>(uris.size());\n+        try {\n+            for (URI uri : uris) {\n+                factories.add(new com.twitter.distributedlog.DistributedLogManagerFactory(conf, uri));\n+            }\n+            final CountDownLatch doneLatch = new CountDownLatch(uris.size());\n+            final AtomicInteger numFailures = new AtomicInteger(0);\n+            ExecutorService executor = Executors.newFixedThreadPool(uris.size());\n+            try {\n+                int i = 0;\n+                for (com.twitter.distributedlog.DistributedLogManagerFactory factory : factories) {\n+                    final com.twitter.distributedlog.DistributedLogManagerFactory dlFactory = factory;\n+                    final URI uri = uris.get(i);\n+                    final List<String> aps = allocationPaths.get(i);\n+                    i++;\n+                    executor.submit(new Runnable() {\n+                        @Override\n+                        public void run() {\n+                            try {\n+                                logger.info(\"Collecting ledgers from {} : {}\", uri, aps);\n+                                collectLedgersFromAllocator(uri, dlFactory, aps, ledgers);\n+                                synchronized (ledgers) {\n+                                    logger.info(\"Collected {} ledgers from allocators for {} : {} \",\n+                                            new Object[]{ledgers.size(), uri, ledgers});\n+                                }\n+                                collectLedgersFromDL(uri, dlFactory, ledgers);\n+                            } catch (IOException e) {\n+                                numFailures.incrementAndGet();\n+                                logger.info(\"Error to collect ledgers from DL : \", e);\n+                            }\n+                            doneLatch.countDown();\n+                        }\n+                    });\n+                }\n+                try {\n+                    doneLatch.await();\n+                    if (numFailures.get() > 0) {\n+                        throw new IOException(numFailures.get() + \" errors to collect ledgers from DL\");\n+                    }\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                    logger.warn(\"Interrupted on collecting ledgers from DL : \", e);\n+                    throw new DLInterruptedException(\"Interrupted on collecting ledgers from DL : \", e);\n+                }\n+            } finally {\n+                executor.shutdown();\n+            }\n+        } finally {\n+            for (com.twitter.distributedlog.DistributedLogManagerFactory factory : factories) {\n+                factory.close();\n+            }\n+        }\n+        return ledgers;\n+    }\n+\n+    private void collectLedgersFromAllocator(final URI uri,\n+                                             final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+                                             final List<String> allocationPaths,\n+                                             final Set<Long> ledgers) throws IOException {\n+        final LinkedBlockingQueue<String> poolQueue =\n+                new LinkedBlockingQueue<String>();\n+        for (String allocationPath : allocationPaths) {\n+            String rootPath = uri.getPath() + \"/\" + allocationPath;\n+            try {\n+                List<String> pools = getZooKeeperClient(factory).get().getChildren(rootPath, false);\n+                for (String pool : pools) {\n+                    poolQueue.add(rootPath + \"/\" + pool);\n+                }\n+            } catch (KeeperException e) {\n+                throw new ZKException(\"Failed to get list of pools from \" + rootPath, e);\n+            } catch (InterruptedException e) {\n+                Thread.currentThread().interrupt();\n+                throw new DLInterruptedException(\"Interrupted on getting list of pools from \" + rootPath, e);\n+            }\n+        }\n+\n+\n+        logger.info(\"Collecting ledgers from allocators for {} : {}\", uri, poolQueue);\n+\n+        executeAction(poolQueue, 10, new Action<String>() {\n+            @Override\n+            public void execute(String poolPath) throws IOException {\n+                try {\n+                    collectLedgersFromPool(poolPath);\n+                } catch (InterruptedException e) {\n+                    throw new DLInterruptedException(\"Interrupted on collecting ledgers from allocation pool \" + poolPath, e);\n+                } catch (KeeperException e) {\n+                    throw new ZKException(\"Failed to collect ledgers from allocation pool \" + poolPath, e.code());\n+                }\n+            }\n+\n+            private void collectLedgersFromPool(String poolPath)\n+                    throws InterruptedException, ZooKeeperClient.ZooKeeperConnectionException, KeeperException {\n+                List<String> allocators = getZooKeeperClient(factory).get()\n+                                        .getChildren(poolPath, false);\n+                for (String allocator : allocators) {\n+                    String allocatorPath = poolPath + \"/\" + allocator;\n+                    byte[] data = getZooKeeperClient(factory).get().getData(allocatorPath, false, new Stat());\n+                    if (null != data && data.length > 0) {\n+                        try {\n+                            long ledgerId = DLUtils.bytes2LedgerId(data);\n+                            synchronized (ledgers) {\n+                                ledgers.add(ledgerId);\n+                            }\n+                        } catch (NumberFormatException nfe) {\n+                            logger.warn(\"Invalid ledger found in allocator path {} : \", allocatorPath, nfe);\n+                        }\n+                    }\n+                }\n+            }\n+        });\n+\n+        logger.info(\"Collected ledgers from allocators for {}.\", uri);\n+    }\n+\n+    private void collectLedgersFromDL(final URI uri,\n+                                      final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+                                      final Set<Long> ledgers) throws IOException {\n+        logger.info(\"Enumerating {} to collect streams.\", uri);\n+        Collection<String> streams = factory.enumerateAllLogsInNamespace();\n+        final LinkedBlockingQueue<String> streamQueue = new LinkedBlockingQueue<String>();\n+        streamQueue.addAll(streams);\n+\n+        logger.info(\"Collected {} streams from uri {} : {}\",\n+                    new Object[] { streams.size(), uri, streams });\n+\n+        executeAction(streamQueue, 10, new Action<String>() {\n+            @Override\n+            public void execute(String stream) throws IOException {\n+                collectLedgersFromStream(factory, stream, ledgers);\n+            }\n+        });\n+    }\n+\n+    private List<Long> collectLedgersFromStream(com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+                                                String stream,\n+                                                Set<Long> ledgers)\n+            throws IOException {\n+        DistributedLogManager dlm = factory.createDistributedLogManager(stream,\n+                com.twitter.distributedlog.DistributedLogManagerFactory.ClientSharingOption.SharedClients);\n+        try {\n+            List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+            List<Long> sLedgers = new ArrayList<Long>();\n+            for (LogSegmentMetadata segment : segments) {\n+                synchronized (ledgers) {\n+                    ledgers.add(segment.getLedgerId());\n+                }\n+                sLedgers.add(segment.getLedgerId());\n+            }\n+            return sLedgers;\n+        } finally {\n+            dlm.close();\n+        }\n+    }\n+\n+    /**\n+     * Calculating stream space usage from given <i>uri</i>.\n+     *\n+     * @param uri dl uri\n+     * @throws IOException\n+     */\n+    public Map<String, Long> calculateStreamSpaceUsage(final URI uri) throws IOException {\n+        logger.info(\"Collecting stream space usage for {}.\", uri);\n+        com.twitter.distributedlog.DistributedLogManagerFactory factory =\n+                new com.twitter.distributedlog.DistributedLogManagerFactory(conf, uri);\n+        try {\n+            return calculateStreamSpaceUsage(uri, factory);\n+        } finally {\n+            factory.close();\n+        }\n+    }\n+\n+    private Map<String, Long> calculateStreamSpaceUsage(\n+            final URI uri, final com.twitter.distributedlog.DistributedLogManagerFactory factory)\n+        throws IOException {\n+        Collection<String> streams = factory.enumerateAllLogsInNamespace();\n+        final LinkedBlockingQueue<String> streamQueue = new LinkedBlockingQueue<String>();\n+        streamQueue.addAll(streams);\n+\n+        final Map<String, Long> streamSpaceUsageMap =\n+                new ConcurrentSkipListMap<String, Long>();\n+        final AtomicInteger numStreamsCollected = new AtomicInteger(0);\n+\n+        executeAction(streamQueue, 10, new Action<String>() {\n+            @Override\n+            public void execute(String stream) throws IOException {\n+                streamSpaceUsageMap.put(stream,\n+                        calculateStreamSpaceUsage(factory, stream));\n+                if (numStreamsCollected.incrementAndGet() % 1000 == 0) {\n+                    logger.info(\"Calculated {} streams from uri {}.\", numStreamsCollected.get(), uri);\n+                }\n+            }\n+        });\n+\n+        return streamSpaceUsageMap;\n+    }\n+\n+    private long calculateStreamSpaceUsage(final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n+                                           final String stream) throws IOException {\n+        DistributedLogManager dlm = factory.createDistributedLogManager(stream,\n+                com.twitter.distributedlog.DistributedLogManagerFactory.ClientSharingOption.SharedClients);\n+        long totalBytes = 0;\n+        try {\n+            List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+            for (LogSegmentMetadata segment : segments) {\n+                try {\n+                    LedgerHandle lh = getBookKeeperClient(factory).get().openLedgerNoRecovery(segment.getLedgerId(),\n+                            BookKeeper.DigestType.CRC32, conf.getBKDigestPW().getBytes(UTF_8));\n+                    totalBytes += lh.getLength();\n+                    lh.close();\n+                } catch (BKException e) {\n+                    logger.error(\"Failed to open ledger {} : \", segment.getLedgerId(), e);\n+                    throw new IOException(\"Failed to open ledger \" + segment.getLedgerId(), e);\n+                } catch (InterruptedException e) {\n+                    logger.warn(\"Interrupted on opening ledger {} : \", segment.getLedgerId(), e);\n+                    Thread.currentThread().interrupt();\n+                    throw new DLInterruptedException(\"Interrupted on opening ledger \" + segment.getLedgerId(), e);\n+                }\n+            }\n+        } finally {\n+            dlm.close();\n+        }\n+        return totalBytes;\n+    }\n+\n+    public long calculateLedgerSpaceUsage(URI uri) throws IOException {\n+        List<URI> uris = Lists.newArrayList(uri);\n+        String zkServers = validateAndGetZKServers(uris);\n+        RetryPolicy retryPolicy = new BoundExponentialBackoffRetryPolicy(\n+                conf.getZKRetryBackoffStartMillis(),\n+                conf.getZKRetryBackoffMaxMillis(),\n+                Integer.MAX_VALUE);\n+        ZooKeeperClient zkc = ZooKeeperClientBuilder.newBuilder()\n+                .name(\"DLAuditor-ZK\")\n+                .zkServers(zkServers)\n+                .sessionTimeoutMs(conf.getZKSessionTimeoutMilliseconds())\n+                .retryPolicy(retryPolicy)\n+                .zkAclId(conf.getZkAclId())\n+                .build();\n+        ExecutorService executorService = Executors.newCachedThreadPool();\n+        try {\n+            BKDLConfig bkdlConfig = resolveBKDLConfig(zkc, uris);\n+            logger.info(\"Resolved bookkeeper config : {}\", bkdlConfig);\n+\n+            BookKeeperClient bkc = BookKeeperClientBuilder.newBuilder()\n+                    .name(\"DLAuditor-BK\")\n+                    .dlConfig(conf)\n+                    .zkServers(bkdlConfig.getBkZkServersForWriter())\n+                    .ledgersPath(bkdlConfig.getBkLedgersPath())\n+                    .build();\n+            try {\n+                return calculateLedgerSpaceUsage(bkc, executorService);\n+            } finally {\n+                bkc.close();\n+            }\n+        } finally {\n+            zkc.close();\n+            executorService.shutdown();\n+        }\n+    }\n+\n+    private long calculateLedgerSpaceUsage(BookKeeperClient bkc,\n+                                           final ExecutorService executorService)\n+        throws IOException {\n+        final AtomicLong totalBytes = new AtomicLong(0);\n+        final AtomicLong totalEntries = new AtomicLong(0);\n+        final AtomicLong numLedgers = new AtomicLong(0);\n+\n+        LedgerManager lm = BookKeeperAccessor.getLedgerManager(bkc.get());\n+\n+        final SettableFuture<Void> doneFuture = SettableFuture.create();\n+        final BookKeeper bk = bkc.get();\n+\n+        BookkeeperInternalCallbacks.Processor<Long> collector =\n+                new BookkeeperInternalCallbacks.Processor<Long>() {\n+            @Override\n+            public void process(final Long lid,\n+                                final AsyncCallback.VoidCallback cb) {\n+                numLedgers.incrementAndGet();\n+                executorService.submit(new Runnable() {\n+                    @Override\n+                    public void run() {\n+                        bk.asyncOpenLedgerNoRecovery(lid, BookKeeper.DigestType.CRC32, conf.getBKDigestPW().getBytes(UTF_8),\n+                                new org.apache.bookkeeper.client.AsyncCallback.OpenCallback() {\n+                            @Override\n+                            public void openComplete(int rc, LedgerHandle lh, Object ctx) {\n+                                final int cbRc;\n+                                if (BKException.Code.OK == rc) {\n+                                    totalBytes.addAndGet(lh.getLength());\n+                                    totalEntries.addAndGet(lh.getLastAddConfirmed() + 1);\n+                                    cbRc = rc;\n+                                } else {\n+                                    cbRc = BKException.Code.ZKException;\n+                                }\n+                                executorService.submit(new Runnable() {\n+                                    @Override\n+                                    public void run() {\n+                                        cb.processResult(cbRc, null, null);\n+                                    }\n+                                });\n+                            }\n+                        }, null);\n+                    }\n+                });\n+            }\n+        };\n+        AsyncCallback.VoidCallback finalCb = new AsyncCallback.VoidCallback() {\n+            @Override\n+            public void processResult(int rc, String path, Object ctx) {\n+                if (BKException.Code.OK == rc) {\n+                    doneFuture.set(null);\n+                } else {\n+                    doneFuture.setException(BKException.create(rc));\n+                }\n+            }\n+        };\n+        lm.asyncProcessLedgers(collector, finalCb, null, BKException.Code.OK, BKException.Code.ZKException);\n+        try {\n+            doneFuture.get();\n+            logger.info(\"calculated {} ledgers\\n\\ttotal bytes = {}\\n\\ttotal entries = {}\",\n+                    new Object[] { numLedgers.get(), totalBytes.get(), totalEntries.get() });\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            throw new DLInterruptedException(\"Interrupted on calculating ledger space : \", e);\n+        } catch (ExecutionException e) {\n+            if (e.getCause() instanceof IOException) {\n+                throw (IOException)(e.getCause());\n+            } else {\n+                throw new IOException(\"Failed to calculate ledger space : \", e.getCause());\n+            }\n+        }\n+        return totalBytes.get();\n+    }\n+\n+    public void close() {\n+        // no-op\n+    }\n+\n+    static interface Action<T> {\n+        void execute(T item) throws IOException ;\n+    }\n+\n+    static <T> void executeAction(final LinkedBlockingQueue<T> queue,\n+                                  final int numThreads,\n+                                  final Action<T> action) throws IOException {\n+        final CountDownLatch failureLatch = new CountDownLatch(1);\n+        final CountDownLatch doneLatch = new CountDownLatch(queue.size());\n+        final AtomicInteger numFailures = new AtomicInteger(0);\n+        final AtomicInteger completedThreads = new AtomicInteger(0);\n+\n+        ExecutorService executorService = Executors.newFixedThreadPool(numThreads);\n+        try {\n+            for (int i = 0 ; i < numThreads; i++) {\n+                executorService.submit(new Runnable() {\n+                    @Override\n+                    public void run() {\n+                        while (true) {\n+                            T item = queue.poll();\n+                            if (null == item) {\n+                                break;\n+                            }\n+                            try {\n+                                action.execute(item);\n+                            } catch (IOException ioe) {\n+                                logger.error(\"Failed to execute action on item '{}'\", item, ioe);\n+                                numFailures.incrementAndGet();\n+                                failureLatch.countDown();\n+                                break;\n+                            }\n+                            doneLatch.countDown();\n+                        }\n+                        if (numFailures.get() == 0 && completedThreads.incrementAndGet() == numThreads) {\n+                            failureLatch.countDown();\n+                        }\n+                    }\n+                });\n+            }\n+            try {\n+                failureLatch.await();\n+                if (numFailures.get() > 0) {\n+                    throw new IOException(\"Encountered \" + numFailures.get() + \" failures on executing action.\");\n+                }\n+                doneLatch.await();\n+            } catch (InterruptedException ie) {\n+                Thread.currentThread().interrupt();\n+                logger.warn(\"Interrupted on executing action\", ie);\n+                throw new DLInterruptedException(\"Interrupted on executing action\", ie);\n+            }\n+        } finally {\n+            executorService.shutdown();\n+        }\n+    }\n+\n+}"},{"sha":"871997f70ecc0211907bf50cc38b71d57c2ef65f","filename":"src/main/java/com/twitter/distributedlog/bk/DynamicQuorumConfigProvider.java","status":"added","additions":37,"deletions":0,"changes":37,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FDynamicQuorumConfigProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FDynamicQuorumConfigProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FDynamicQuorumConfigProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,37 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.bk;\n+\n+import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n+\n+/**\n+ * Provider returns quorum configs based on dynamic configuration.\n+ */\n+public class DynamicQuorumConfigProvider implements QuorumConfigProvider {\n+\n+    private final DynamicDistributedLogConfiguration conf;\n+\n+    public DynamicQuorumConfigProvider(DynamicDistributedLogConfiguration conf) {\n+        this.conf = conf;\n+    }\n+\n+    @Override\n+    public QuorumConfig getQuorumConfig() {\n+        return conf.getQuorumConfig();\n+    }\n+}"},{"sha":"6c3f06e751404a74cd0c02ab088fafed16dabd87","filename":"src/main/java/com/twitter/distributedlog/bk/ImmutableQuorumConfigProvider.java","status":"added","additions":35,"deletions":0,"changes":35,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FImmutableQuorumConfigProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FImmutableQuorumConfigProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FImmutableQuorumConfigProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,35 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.bk;\n+\n+/**\n+ * Provider that returns an immutable quorum config.\n+ */\n+public class ImmutableQuorumConfigProvider implements QuorumConfigProvider {\n+\n+    private final QuorumConfig quorumConfig;\n+\n+    public ImmutableQuorumConfigProvider(QuorumConfig quorumConfig) {\n+        this.quorumConfig = quorumConfig;\n+    }\n+\n+    @Override\n+    public QuorumConfig getQuorumConfig() {\n+        return quorumConfig;\n+    }\n+}"},{"sha":"c14f374924648ac7ccf3e314692d267e9a091330","filename":"src/main/java/com/twitter/distributedlog/bk/LedgerAllocator.java","status":"added","additions":32,"deletions":0,"changes":32,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocator.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocator.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocator.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,32 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.bk;\n+\n+import com.twitter.distributedlog.util.Allocator;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+\n+import java.io.IOException;\n+\n+public interface LedgerAllocator extends Allocator<LedgerHandle, Object> {\n+\n+    /**\n+     * Start the ledger allocator. The implementaion should not be blocking call.\n+     */\n+    void start() throws IOException;\n+\n+}"},{"sha":"b76d03aa9ae4be7dc6f9215441709cc42da95ee9","filename":"src/main/java/com/twitter/distributedlog/bk/LedgerAllocatorDelegator.java","status":"added","additions":83,"deletions":0,"changes":83,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorDelegator.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorDelegator.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorDelegator.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e","patch":"@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.bk;\n+\n+import com.twitter.distributedlog.util.Transaction;\n+import com.twitter.distributedlog.util.Transaction.OpListener;\n+import com.twitter.util.Future;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Delegator of the underlying allocator. If it owns the allocator, it takes\n+ * the responsibility of start the allocator and close the allocator.\n+ */\n+public class LedgerAllocatorDelegator implements LedgerAllocator {\n+\n+    private final LedgerAllocator allocator;\n+    private final boolean ownAllocator;\n+\n+    /**\n+     * Create an allocator's delegator.\n+     *\n+     * @param allocator\n+     *          the underlying allocator\n+     * @param ownAllocator\n+     *          whether to own the allocator\n+     */\n+    public LedgerAllocatorDelegator(LedgerAllocator allocator,\n+                                    boolean ownAllocator)\n+            throws IOException {\n+        this.allocator = allocator;\n+        this.ownAllocator = ownAllocator;\n+        if (this.ownAllocator) {\n+            this.allocator.start();\n+        }\n+    }\n+\n+    @Override\n+    public void start() throws IOException {\n+        // no-op\n+    }\n+\n+    @Override\n+    public Future<Void> delete() {\n+        return Future.exception(new UnsupportedOperationException(\"Can't delete an allocator by delegator\"));\n+    }\n+\n+    @Override\n+    public void allocate() throws IOException {\n+        this.allocator.allocate();\n+    }\n+\n+    @Override\n+    public Future<LedgerHandle> tryObtain(Transaction<Object> txn,\n+                                          OpListener<LedgerHandle> listener) {\n+        return this.allocator.tryObtain(txn, listener);\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        if (ownAllocator) {\n+            return this.allocator.asyncClose();\n+        } else {\n+            return Future.value(null);\n+        }\n+    }\n+}"},{"sha":"dd0894e2e146d30a3c7a4198298d6e5e25e4f4cb","filename":"src/main/java/com/twitter/distributedlog/bk/LedgerAllocatorPool.java","status":"added","additions":0,"deletions":0,"changes":0,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorPool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorPool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorPool.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0db6d746eff6d446145c612c5a2b7bcc0d57a5dd","filename":"src/main/java/com/twitter/distributedlog/bk/LedgerAllocatorUtils.java","status":"added","additions":54,"deletions":0,"changes":54,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FLedgerAllocatorUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a9cc16c99ab0e2479e38118bb59c6ded0dd25f84","filename":"src/main/java/com/twitter/distributedlog/bk/QuorumConfig.java","status":"added","additions":92,"deletions":0,"changes":92,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FQuorumConfig.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FQuorumConfig.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FQuorumConfig.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2f654272418b9c1745d1924e5c73aa5c54d7777b","filename":"src/main/java/com/twitter/distributedlog/bk/QuorumConfigProvider.java","status":"added","additions":32,"deletions":0,"changes":32,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FQuorumConfigProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FQuorumConfigProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FQuorumConfigProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"dbabdc52781d3d5eb1ccf6123a0f2b084a527835","filename":"src/main/java/com/twitter/distributedlog/bk/SimpleLedgerAllocator.java","status":"added","additions":536,"deletions":0,"changes":536,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FSimpleLedgerAllocator.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FSimpleLedgerAllocator.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FSimpleLedgerAllocator.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"697d2e9639385a409527c2483158b7f931170c82","filename":"src/main/java/com/twitter/distributedlog/bk/package-info.java","status":"added","additions":24,"deletions":0,"changes":24,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"bedd4dcdc3fffe7a48a92d3056cff42544a864fd","filename":"src/main/java/com/twitter/distributedlog/callback/LogSegmentListener.java","status":"added","additions":37,"deletions":0,"changes":37,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentListener.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"3e89431bcedfe7691bf170aeb150b8dfb3ac20ae","filename":"src/main/java/com/twitter/distributedlog/callback/LogSegmentNamesListener.java","status":"added","additions":34,"deletions":0,"changes":34,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentNamesListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentNamesListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FLogSegmentNamesListener.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"fc63ff59cf3f9f0649f1e451c327135464a817ec","filename":"src/main/java/com/twitter/distributedlog/callback/NamespaceListener.java","status":"added","additions":34,"deletions":0,"changes":34,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FNamespaceListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FNamespaceListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FNamespaceListener.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7c46a1ae07854c8abfe1009dfbe7a7384c945e48","filename":"src/main/java/com/twitter/distributedlog/callback/ReadAheadCallback.java","status":"added","additions":25,"deletions":0,"changes":25,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FReadAheadCallback.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FReadAheadCallback.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2FReadAheadCallback.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2724d43f2deb9cc4b285e6e88418152dea78a04f","filename":"src/main/java/com/twitter/distributedlog/callback/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fcallback%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"91603c18ed1bb745a481591590878bf5cb24e2bc","filename":"src/main/java/com/twitter/distributedlog/config/ConcurrentBaseConfiguration.java","status":"added","additions":76,"deletions":0,"changes":76,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConcurrentBaseConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConcurrentBaseConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConcurrentBaseConfiguration.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"731a0b63882af2d52ccd30f2e41e27ecd042d30d","filename":"src/main/java/com/twitter/distributedlog/config/ConcurrentConstConfiguration.java","status":"added","additions":37,"deletions":0,"changes":37,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConcurrentConstConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConcurrentConstConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConcurrentConstConfiguration.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d4c44b77056b99739b596a05adecbb288b71872e","filename":"src/main/java/com/twitter/distributedlog/config/ConfigurationListener.java","status":"added","additions":32,"deletions":0,"changes":32,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigurationListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigurationListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigurationListener.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"dadfe8185097503924b792ebc96a39198e0bc667","filename":"src/main/java/com/twitter/distributedlog/config/ConfigurationSubscription.java","status":"added","additions":186,"deletions":0,"changes":186,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigurationSubscription.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigurationSubscription.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigurationSubscription.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2510f7437288d3db543b101e9de03e0d34d60531","filename":"src/main/java/com/twitter/distributedlog/config/DynamicConfigurationFactory.java","status":"added","additions":91,"deletions":0,"changes":91,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FDynamicConfigurationFactory.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FDynamicConfigurationFactory.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FDynamicConfigurationFactory.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ca43cfa1a9e73417a457de857758e6d0ebee4074","filename":"src/main/java/com/twitter/distributedlog/config/DynamicDistributedLogConfiguration.java","status":"added","additions":356,"deletions":0,"changes":356,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FDynamicDistributedLogConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FDynamicDistributedLogConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FDynamicDistributedLogConfiguration.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"b3c4e6c35c019a3baa525606e9d60164e608e3ac","filename":"src/main/java/com/twitter/distributedlog/config/FileConfigurationBuilder.java","status":"added","additions":28,"deletions":0,"changes":28,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FFileConfigurationBuilder.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FFileConfigurationBuilder.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FFileConfigurationBuilder.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"6efaa20e668feaafc6288ece82bf425b69236c76","filename":"src/main/java/com/twitter/distributedlog/config/PropertiesConfigurationBuilder.java","status":"added","additions":40,"deletions":0,"changes":40,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FPropertiesConfigurationBuilder.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FPropertiesConfigurationBuilder.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FPropertiesConfigurationBuilder.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"b4f77b44f8d1a9ba3e367df9286447601a37c9e4","filename":"src/main/java/com/twitter/distributedlog/config/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"8ed161027a89d89665c14d9ef909450443b42791","filename":"src/main/java/com/twitter/distributedlog/exceptions/ZKException.java","status":"added","additions":54,"deletions":0,"changes":54,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fexceptions%2FZKException.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fexceptions%2FZKException.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fexceptions%2FZKException.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f4843071a3987d7fe3e9461be248d9e4df6be681","filename":"src/main/java/com/twitter/distributedlog/feature/AbstractFeatureProvider.java","status":"added","additions":103,"deletions":0,"changes":103,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FAbstractFeatureProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FAbstractFeatureProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FAbstractFeatureProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"02a4d79a3e9a5110a22a57eeb38e2d2a3b888cd8","filename":"src/main/java/com/twitter/distributedlog/feature/ConfigurationFeatureProvider.java","status":"added","additions":76,"deletions":0,"changes":76,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FConfigurationFeatureProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FConfigurationFeatureProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FConfigurationFeatureProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"49b3354018a93b3978efca527191d5479033db9c","filename":"src/main/java/com/twitter/distributedlog/feature/CoreFeatureKeys.java","status":"added","additions":29,"deletions":0,"changes":29,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FCoreFeatureKeys.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FCoreFeatureKeys.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FCoreFeatureKeys.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"6554eaa149ac16f4509b4215ea88cc3a7b485b84","filename":"src/main/java/com/twitter/distributedlog/feature/DefaultFeatureProvider.java","status":"added","additions":47,"deletions":0,"changes":47,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FDefaultFeatureProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FDefaultFeatureProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FDefaultFeatureProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"1eeb1558ce1dc920587c510f4c5262a69ce952c0","filename":"src/main/java/com/twitter/distributedlog/feature/DynamicConfigurationFeatureProvider.java","status":"added","additions":132,"deletions":0,"changes":132,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FDynamicConfigurationFeatureProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FDynamicConfigurationFeatureProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FDynamicConfigurationFeatureProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e8d81341cdbd4cb6dba4cf1dc26aa54c01948510","filename":"src/main/java/com/twitter/distributedlog/feature/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f08cd0f05c2ad004b419fd8ff8feaa103df6cb56","filename":"src/main/java/com/twitter/distributedlog/function/DefaultValueMapFunction.java","status":"added","additions":41,"deletions":0,"changes":41,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FDefaultValueMapFunction.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FDefaultValueMapFunction.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FDefaultValueMapFunction.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"bc77d6a51c03300750e122e1476fdf6de8b5c641","filename":"src/main/java/com/twitter/distributedlog/function/GetLastTxIdFunction.java","status":"added","additions":43,"deletions":0,"changes":43,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FGetLastTxIdFunction.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FGetLastTxIdFunction.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FGetLastTxIdFunction.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"316a53f21dfcc6c9116033d633db9dfcf9014a06","filename":"src/main/java/com/twitter/distributedlog/function/VoidFunctions.java","status":"added","additions":34,"deletions":0,"changes":34,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FVoidFunctions.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FVoidFunctions.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2FVoidFunctions.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2da98dcda129373a886efe89ebe9088c5dc5441c","filename":"src/main/java/com/twitter/distributedlog/function/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffunction%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"b599dc668e132999a6b7b45ca24f9318aaf3a8b2","filename":"src/main/java/com/twitter/distributedlog/impl/BKDLUtils.java","status":"added","additions":98,"deletions":0,"changes":98,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FBKDLUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FBKDLUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FBKDLUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"57b4e6996c9148a039e4d5a5009f3e83e9358da7","filename":"src/main/java/com/twitter/distributedlog/impl/BKLogSegmentEntryWriter.java","status":"added","additions":61,"deletions":0,"changes":61,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FBKLogSegmentEntryWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FBKLogSegmentEntryWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FBKLogSegmentEntryWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"b84ab2e3035a33d88fab4e150ed0a65ff3901fae","filename":"src/main/java/com/twitter/distributedlog/impl/ZKLogMetadataStore.java","status":"added","additions":124,"deletions":0,"changes":124,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogMetadataStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e55b2f241869a2e3b775a2d629f33b63624635c8","filename":"src/main/java/com/twitter/distributedlog/impl/ZKLogSegmentFilters.java","status":"added","additions":89,"deletions":0,"changes":89,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentFilters.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentFilters.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentFilters.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"41b887e85f3cae3a64ad0ab36ddda25958800e20","filename":"src/main/java/com/twitter/distributedlog/impl/ZKLogSegmentMetadataStore.java","status":"added","additions":374,"deletions":0,"changes":374,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"61c1760e9d452513819b2358f41fd8fd0e329ba7","filename":"src/main/java/com/twitter/distributedlog/impl/ZKNamespaceWatcher.java","status":"added","additions":133,"deletions":0,"changes":133,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKNamespaceWatcher.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKNamespaceWatcher.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKNamespaceWatcher.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"9b5bea89870c6cf42c21a7b7d982aa8c44122fa8","filename":"src/main/java/com/twitter/distributedlog/impl/federated/FederatedZKLogMetadataStore.java","status":"added","additions":750,"deletions":0,"changes":750,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Ffederated%2FFederatedZKLogMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Ffederated%2FFederatedZKLogMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Ffederated%2FFederatedZKLogMetadataStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"078c040575d0acf18e27def1a8958a463f8a727a","filename":"src/main/java/com/twitter/distributedlog/impl/metadata/ZKLogMetadata.java","status":"added","additions":164,"deletions":0,"changes":164,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadata.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadata.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadata.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"88583178ea53f7d07f9dbd18a1f1551af49ecd96","filename":"src/main/java/com/twitter/distributedlog/impl/metadata/ZKLogMetadataForReader.java","status":"added","additions":103,"deletions":0,"changes":103,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"1de712f910e61aad5c2ae69754c6a8c1c9a88f70","filename":"src/main/java/com/twitter/distributedlog/impl/metadata/ZKLogMetadataForWriter.java","status":"added","additions":361,"deletions":0,"changes":361,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7c5c2e4a18c98ba2d2343a666e8a6d8acfe45332","filename":"src/main/java/com/twitter/distributedlog/impl/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ef67266be6348a664528f33536052fa08f430083","filename":"src/main/java/com/twitter/distributedlog/injector/AsyncFailureInjector.java","status":"added","additions":128,"deletions":0,"changes":128,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FAsyncFailureInjector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FAsyncFailureInjector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FAsyncFailureInjector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"89284943e1420c1108d426157c227de472bde02f","filename":"src/main/java/com/twitter/distributedlog/injector/AsyncRandomFailureInjector.java","status":"added","additions":175,"deletions":0,"changes":175,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FAsyncRandomFailureInjector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FAsyncRandomFailureInjector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FAsyncRandomFailureInjector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"16c8e4ee65201d49587ba212b33d694d989f5e21","filename":"src/main/java/com/twitter/distributedlog/injector/FailureInjector.java","status":"added","additions":37,"deletions":0,"changes":37,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FFailureInjector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FFailureInjector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FFailureInjector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"73aad5b6257ef83647ca549baea9b6d3699d3e3c","filename":"src/main/java/com/twitter/distributedlog/injector/RandomDelayFailureInjector.java","status":"added","additions":60,"deletions":0,"changes":60,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FRandomDelayFailureInjector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FRandomDelayFailureInjector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2FRandomDelayFailureInjector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ffee3405c5179c9e8507ee892aa3b40ffb196b2e","filename":"src/main/java/com/twitter/distributedlog/injector/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Finjector%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0d0b389cdf1a426056f486def35a4235501e0124","filename":"src/main/java/com/twitter/distributedlog/io/Abortable.java","status":"added","additions":41,"deletions":0,"changes":41,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAbortable.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAbortable.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAbortable.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"45995744f5529c87034e0218d6c4f8a4598e1162","filename":"src/main/java/com/twitter/distributedlog/io/Abortables.java","status":"added","additions":183,"deletions":0,"changes":183,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAbortables.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAbortables.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAbortables.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ed1062a536578bff95e587de614731b4b40cf19d","filename":"src/main/java/com/twitter/distributedlog/io/AsyncAbortable.java","status":"added","additions":57,"deletions":0,"changes":57,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncAbortable.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncAbortable.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncAbortable.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"817a8e256317c2c0e42350831c0e874849e363a9","filename":"src/main/java/com/twitter/distributedlog/io/AsyncCloseable.java","status":"added","additions":60,"deletions":0,"changes":60,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncCloseable.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncCloseable.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncCloseable.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"203895efa5b678b78e06c897cf65f540a04eb2e8","filename":"src/main/java/com/twitter/distributedlog/io/AsyncDeleteable.java","status":"added","additions":34,"deletions":0,"changes":34,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncDeleteable.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncDeleteable.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2FAsyncDeleteable.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"df2e91f2c5f744ff0dac48149a5fd1736ba02b60","filename":"src/main/java/com/twitter/distributedlog/io/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fio%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"60eacd5eca5f4ee972cdbbcd2982c65549a1f5bc","filename":"src/main/java/com/twitter/distributedlog/limiter/ChainedRequestLimiter.java","status":"added","additions":76,"deletions":0,"changes":76,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FChainedRequestLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FChainedRequestLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FChainedRequestLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"55e4c8b8a15d72443249e0434cddbedf5e403170","filename":"src/main/java/com/twitter/distributedlog/limiter/ComposableRequestLimiter.java","status":"added","additions":73,"deletions":0,"changes":73,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FComposableRequestLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FComposableRequestLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FComposableRequestLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"3f1909a2d07fbab27550678260e8b6898cc1bce0","filename":"src/main/java/com/twitter/distributedlog/limiter/GuavaRateLimiter.java","status":"added","additions":58,"deletions":0,"changes":58,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FGuavaRateLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FGuavaRateLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FGuavaRateLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"3a266d99234e7c26cc58fe78b84dc5f2bed32078","filename":"src/main/java/com/twitter/distributedlog/limiter/RateLimiter.java","status":"added","additions":54,"deletions":0,"changes":54,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FRateLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FRateLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FRateLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"6c5ad96202cd57e787bdadebb7f335735f1f27e9","filename":"src/main/java/com/twitter/distributedlog/limiter/RequestLimiter.java","status":"added","additions":24,"deletions":0,"changes":24,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FRequestLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FRequestLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FRequestLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d5f61a881f67924c91421e13f697e6abfda9d829","filename":"src/main/java/com/twitter/distributedlog/limiter/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ddff9c4da35e1dcea3d6f9a8048ad73b6a823b78","filename":"src/main/java/com/twitter/distributedlog/lock/DistributedLock.java","status":"added","additions":519,"deletions":0,"changes":519,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FDistributedLock.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FDistributedLock.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FDistributedLock.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"1914793d99ecce159cd7d846b3e86e84baf8cb03","filename":"src/main/java/com/twitter/distributedlog/lock/DistributedLockContext.java","status":"added","additions":43,"deletions":0,"changes":43,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FDistributedLockContext.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FDistributedLockContext.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FDistributedLockContext.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"032a9cdc3a198875b89a0f28c91b5eb8592d90f6","filename":"src/main/java/com/twitter/distributedlog/lock/EpochChangedException.java","status":"added","additions":33,"deletions":0,"changes":33,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FEpochChangedException.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FEpochChangedException.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FEpochChangedException.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"46b420d43fc53cf8cfe0bcdb7c587473e07f3fff","filename":"src/main/java/com/twitter/distributedlog/lock/LockAction.java","status":"added","additions":36,"deletions":0,"changes":36,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockAction.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockAction.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockAction.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"5b676bf7c10c2996870e25ae429ebd97b6335cc5","filename":"src/main/java/com/twitter/distributedlog/lock/LockClosedException.java","status":"added","additions":38,"deletions":0,"changes":38,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockClosedException.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockClosedException.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockClosedException.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"681c18080bf8a6e12433b849991691237e0f638e","filename":"src/main/java/com/twitter/distributedlog/lock/LockListener.java","status":"added","additions":28,"deletions":0,"changes":28,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockListener.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"dac1253c480086e76cc77e6f63b8c67e50741688","filename":"src/main/java/com/twitter/distributedlog/lock/LockSessionExpiredException.java","status":"added","additions":34,"deletions":0,"changes":34,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockSessionExpiredException.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockSessionExpiredException.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockSessionExpiredException.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2b99795b85d432030a6b66ed938106ea1ee78fec","filename":"src/main/java/com/twitter/distributedlog/lock/LockStateChangedException.java","status":"added","additions":36,"deletions":0,"changes":36,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockStateChangedException.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockStateChangedException.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockStateChangedException.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"3020980c8105ce593b6aff4d9a138d1c076395ab","filename":"src/main/java/com/twitter/distributedlog/lock/LockTimeoutException.java","status":"added","additions":34,"deletions":0,"changes":34,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockTimeoutException.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockTimeoutException.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockTimeoutException.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"73ffabcab08f023fa88088ecd04f294e1b4b38ee","filename":"src/main/java/com/twitter/distributedlog/lock/LockWaiter.java","status":"added","additions":95,"deletions":0,"changes":95,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockWaiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockWaiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FLockWaiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7bfc6c1b22c37dcceda6576c371352d1ac4edd67","filename":"src/main/java/com/twitter/distributedlog/lock/SessionLock.java","status":"added","additions":126,"deletions":0,"changes":126,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FSessionLock.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FSessionLock.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FSessionLock.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"43346266b9982e86c2c19e28f648597b37cc3813","filename":"src/main/java/com/twitter/distributedlog/lock/SessionLockFactory.java","status":"added","additions":38,"deletions":0,"changes":38,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FSessionLockFactory.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FSessionLockFactory.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FSessionLockFactory.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"87894dc276f5faff894830f752866fa0eaaa2171","filename":"src/main/java/com/twitter/distributedlog/lock/ZKSessionLock.java","status":"added","additions":1336,"deletions":0,"changes":1336,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FZKSessionLock.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FZKSessionLock.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FZKSessionLock.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"bb98e07fa7206e5899e5316d01ba0246667bba40","filename":"src/main/java/com/twitter/distributedlog/lock/ZKSessionLockFactory.java","status":"added","additions":133,"deletions":0,"changes":133,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FZKSessionLockFactory.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FZKSessionLockFactory.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FZKSessionLockFactory.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"02d905dd742031bf3f3771d826bf89c38269174f","filename":"src/main/java/com/twitter/distributedlog/lock/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"9716f95f171555e9395a91658e43627d07dcca74","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentCache.java","status":"added","additions":228,"deletions":0,"changes":228,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentCache.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"8b7d9b27ef663d6a4e9c0e39767494dcd6727a50","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentEntryWriter.java","status":"added","additions":72,"deletions":0,"changes":72,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f8bf1835c2acbc43abac8fd45c3b867781efdae3","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentFilter.java","status":"added","additions":42,"deletions":0,"changes":42,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentFilter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentFilter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentFilter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"430e15f7e33a03b3d82dfb71e03c2c5d1fa563c7","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentMetadataStore.java","status":"added","additions":162,"deletions":0,"changes":162,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a0b4610c64b34ddb1668e4e0974f2f2c10e7c6ab","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentWriter.java","status":"added","additions":87,"deletions":0,"changes":87,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0101bffa103aa903da39c98954e198ecf3434e44","filename":"src/main/java/com/twitter/distributedlog/logsegment/RollingPolicy.java","status":"added","additions":33,"deletions":0,"changes":33,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FRollingPolicy.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FRollingPolicy.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FRollingPolicy.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"8b1fa0f90414102a78fd2826e025440c46c24d95","filename":"src/main/java/com/twitter/distributedlog/logsegment/SizeBasedRollingPolicy.java","status":"added","additions":34,"deletions":0,"changes":34,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FSizeBasedRollingPolicy.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FSizeBasedRollingPolicy.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FSizeBasedRollingPolicy.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"bc88720afe37453676107c6589561a9221d0aa8c","filename":"src/main/java/com/twitter/distributedlog/logsegment/TimeBasedRollingPolicy.java","status":"added","additions":46,"deletions":0,"changes":46,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTimeBasedRollingPolicy.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTimeBasedRollingPolicy.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTimeBasedRollingPolicy.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0f5b877cb90c2ef1dfa2303d00ff52d771249107","filename":"src/main/java/com/twitter/distributedlog/logsegment/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"baa3240119402d57f7e86748e9eb68d556e492ee","filename":"src/main/java/com/twitter/distributedlog/metadata/BKDLConfig.java","status":"added","additions":400,"deletions":0,"changes":400,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FBKDLConfig.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FBKDLConfig.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FBKDLConfig.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"178074a217113d0867317c63dee16efadf093c07","filename":"src/main/java/com/twitter/distributedlog/metadata/DLConfig.java","status":"added","additions":39,"deletions":0,"changes":39,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDLConfig.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDLConfig.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDLConfig.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e0331c63cfba49a4681ea06e734c7d2740e57a34","filename":"src/main/java/com/twitter/distributedlog/metadata/DLMetadata.java","status":"added","additions":226,"deletions":0,"changes":226,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDLMetadata.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDLMetadata.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDLMetadata.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"b2a417e89260325f63b2367404a50724923f2471","filename":"src/main/java/com/twitter/distributedlog/metadata/DryrunLogSegmentMetadataStoreUpdater.java","status":"added","additions":51,"deletions":0,"changes":51,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDryrunLogSegmentMetadataStoreUpdater.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDryrunLogSegmentMetadataStoreUpdater.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FDryrunLogSegmentMetadataStoreUpdater.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"01dccb7afbec00c273a27601e9f0b9b9179e39b9","filename":"src/main/java/com/twitter/distributedlog/metadata/LogMetadataStore.java","status":"added","additions":66,"deletions":0,"changes":66,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogMetadataStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d205b3a03b17b5d02d83478c2ba3d5276077a648","filename":"src/main/java/com/twitter/distributedlog/metadata/LogSegmentMetadataStoreUpdater.java","status":"added","additions":184,"deletions":0,"changes":184,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogSegmentMetadataStoreUpdater.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogSegmentMetadataStoreUpdater.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogSegmentMetadataStoreUpdater.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"417cab8345ed9ce7be17daf890a3fc4d1c42743c","filename":"src/main/java/com/twitter/distributedlog/metadata/MetadataResolver.java","status":"added","additions":51,"deletions":0,"changes":51,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FMetadataResolver.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FMetadataResolver.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FMetadataResolver.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"b98f16841187f9f72c88ab359df507a427e49154","filename":"src/main/java/com/twitter/distributedlog/metadata/MetadataUpdater.java","status":"added","additions":120,"deletions":0,"changes":120,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FMetadataUpdater.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FMetadataUpdater.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FMetadataUpdater.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f2be95c0b7235ee0cc7407591900245561940ec4","filename":"src/main/java/com/twitter/distributedlog/metadata/ZkMetadataResolver.java","status":"added","additions":69,"deletions":0,"changes":69,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FZkMetadataResolver.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FZkMetadataResolver.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FZkMetadataResolver.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f740c77fc991109c345f9e133c24f68be4cb6553","filename":"src/main/java/com/twitter/distributedlog/metadata/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d42b5f2f55991706e6cb1b226270a628c1c4e112","filename":"src/main/java/com/twitter/distributedlog/namespace/DistributedLogNamespace.java","status":"added","additions":180,"deletions":0,"changes":180,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FDistributedLogNamespace.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FDistributedLogNamespace.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FDistributedLogNamespace.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a01bb7000a6cc4a7e185539d127b8f7c929aa940","filename":"src/main/java/com/twitter/distributedlog/namespace/DistributedLogNamespaceBuilder.java","status":"added","additions":211,"deletions":0,"changes":211,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FDistributedLogNamespaceBuilder.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FDistributedLogNamespaceBuilder.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FDistributedLogNamespaceBuilder.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f83652099cbee3ba0d97c551824e7469bdbdf5ec","filename":"src/main/java/com/twitter/distributedlog/namespace/NamespaceWatcher.java","status":"added","additions":61,"deletions":0,"changes":61,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FNamespaceWatcher.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FNamespaceWatcher.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FNamespaceWatcher.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d659f44b2c34dbbebd1b238ab9568d709f57b702","filename":"src/main/java/com/twitter/distributedlog/namespace/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2298fafd80b0bf9f9a78c309072e29f1747153a2","filename":"src/main/java/com/twitter/distributedlog/net/DNSResolver.java","status":"added","additions":113,"deletions":0,"changes":113,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolver.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolver.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolver.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a0298d00d64032ead2ae622b3c6bd8193b7149e4","filename":"src/main/java/com/twitter/distributedlog/net/DNSResolverForRacks.java","status":"added","additions":66,"deletions":0,"changes":66,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolverForRacks.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolverForRacks.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolverForRacks.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f5856402ed385047a2bf8d74d7917ac8deca351a","filename":"src/main/java/com/twitter/distributedlog/net/DNSResolverForRows.java","status":"added","additions":72,"deletions":0,"changes":72,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolverForRows.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolverForRows.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FDNSResolverForRows.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ce0d360ed63df7e69f2ce62332f8e42739b987d5","filename":"src/main/java/com/twitter/distributedlog/net/NetUtils.java","status":"added","additions":74,"deletions":0,"changes":74,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FNetUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FNetUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FNetUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"9093fef9e91050208950c17e603a356ce104f1ee","filename":"src/main/java/com/twitter/distributedlog/net/package-info.java","status":"added","additions":33,"deletions":0,"changes":33,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"4c1fe57acd96be2d0b793774229ecb5dfbbe60d3","filename":"src/main/java/com/twitter/distributedlog/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"98eae0053dc561b87528da92fc7ada8b9614b781","filename":"src/main/java/com/twitter/distributedlog/rate/MovingAverageRate.java","status":"added","additions":24,"deletions":0,"changes":24,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FMovingAverageRate.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FMovingAverageRate.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FMovingAverageRate.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"1a04b4fdc2d2e9fce0418b4868a4730e0720a32d","filename":"src/main/java/com/twitter/distributedlog/rate/MovingAverageRateFactory.java","status":"added","additions":63,"deletions":0,"changes":63,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FMovingAverageRateFactory.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FMovingAverageRateFactory.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FMovingAverageRateFactory.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a616324aa76d40bb854576e0b16772e5d5d9dd10","filename":"src/main/java/com/twitter/distributedlog/rate/SampledMovingAverageRate.java","status":"added","additions":58,"deletions":0,"changes":58,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FSampledMovingAverageRate.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FSampledMovingAverageRate.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FSampledMovingAverageRate.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"1f152211fe895ded6a58240d66187581220faad8","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadPhase.java","status":"added","additions":45,"deletions":0,"changes":45,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadPhase.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadPhase.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadPhase.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"5c0fd4b1ddafadd8434a23276f3593c60beb3102","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadTracker.java","status":"added","additions":84,"deletions":0,"changes":84,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"c91217813f1d895b67264f817eb4caa185ab8008","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadWorker.java","status":"added","additions":1526,"deletions":0,"changes":1526,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"4945133d6d94ba81c566506b3974d0eaf5a4039f","filename":"src/main/java/com/twitter/distributedlog/readahead/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"443c503048e00d27bb77a639a39b644cb5f5d157","filename":"src/main/java/com/twitter/distributedlog/selector/FirstDLSNNotLessThanSelector.java","status":"added","additions":46,"deletions":0,"changes":46,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstDLSNNotLessThanSelector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstDLSNNotLessThanSelector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstDLSNNotLessThanSelector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a51210f55bd5142af86227bc89d66a8427ca999f","filename":"src/main/java/com/twitter/distributedlog/selector/FirstRecordSelector.java","status":"added","additions":46,"deletions":0,"changes":46,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstRecordSelector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstRecordSelector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstRecordSelector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"03c2cbb1a6a0e0ad1d120b7b8728e3f75da4d965","filename":"src/main/java/com/twitter/distributedlog/selector/FirstTxIdNotLessThanSelector.java","status":"added","additions":51,"deletions":0,"changes":51,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstTxIdNotLessThanSelector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstTxIdNotLessThanSelector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FFirstTxIdNotLessThanSelector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"191342c9afe61ae6ed41962c17089eb1e1c4f6ea","filename":"src/main/java/com/twitter/distributedlog/selector/LastRecordSelector.java","status":"added","additions":38,"deletions":0,"changes":38,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FLastRecordSelector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FLastRecordSelector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FLastRecordSelector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"45d1c49cd69e87db974f1ed4519df8adb23b3fd0","filename":"src/main/java/com/twitter/distributedlog/selector/LogRecordSelector.java","status":"added","additions":40,"deletions":0,"changes":40,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FLogRecordSelector.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FLogRecordSelector.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FLogRecordSelector.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"be71aef0575ee137198d19ec26c0fbfbbbc69932","filename":"src/main/java/com/twitter/distributedlog/stats/BKExceptionStatsLogger.java","status":"added","additions":109,"deletions":0,"changes":109,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FBKExceptionStatsLogger.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FBKExceptionStatsLogger.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FBKExceptionStatsLogger.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e29cc47f03460655a3b652139b27fe993a886d55","filename":"src/main/java/com/twitter/distributedlog/stats/BroadCastStatsLogger.java","status":"added","additions":172,"deletions":0,"changes":172,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FBroadCastStatsLogger.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FBroadCastStatsLogger.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FBroadCastStatsLogger.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0432706b07041ef87cc150bd6fce9ddb8485ab2f","filename":"src/main/java/com/twitter/distributedlog/stats/OpStatsListener.java","status":"added","additions":51,"deletions":0,"changes":51,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FOpStatsListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FOpStatsListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FOpStatsListener.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"326f92b581c277c42eb23f1d389a1f1931cf90c9","filename":"src/main/java/com/twitter/distributedlog/stats/ReadAheadExceptionsLogger.java","status":"added","additions":60,"deletions":0,"changes":60,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FReadAheadExceptionsLogger.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FReadAheadExceptionsLogger.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FReadAheadExceptionsLogger.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"9e4c4f2ce2d29adedf1cb98c418bfeb83e87782b","filename":"src/main/java/com/twitter/distributedlog/subscription/SubscriptionStateStore.java","status":"added","additions":42,"deletions":0,"changes":42,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FSubscriptionStateStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FSubscriptionStateStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FSubscriptionStateStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"9905cea2a625171e265d1fbc1072a323a43872bf","filename":"src/main/java/com/twitter/distributedlog/subscription/SubscriptionsStore.java","status":"added","additions":59,"deletions":0,"changes":59,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FSubscriptionsStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FSubscriptionsStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FSubscriptionsStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"9cd2da549a0e93630cd43ea882b6fa44c85cbbfc","filename":"src/main/java/com/twitter/distributedlog/subscription/ZKSubscriptionStateStore.java","status":"added","additions":120,"deletions":0,"changes":120,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FZKSubscriptionStateStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FZKSubscriptionStateStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FZKSubscriptionStateStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"fb154c14394403c4b74f2f91817e3ce2ce2ebce4","filename":"src/main/java/com/twitter/distributedlog/subscription/ZKSubscriptionsStore.java","status":"added","additions":151,"deletions":0,"changes":151,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FZKSubscriptionsStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FZKSubscriptionsStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fsubscription%2FZKSubscriptionsStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"91724c762a0b7a58be32b602763f55b8368cc7dc","filename":"src/main/java/com/twitter/distributedlog/tools/DistributedLogTool.java","status":"added","additions":2679,"deletions":0,"changes":2679,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FDistributedLogTool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FDistributedLogTool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FDistributedLogTool.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"bb140664370fcdc934a1f206838a9d85d37700d6","filename":"src/main/java/com/twitter/distributedlog/tools/Tool.java","status":"added","additions":243,"deletions":0,"changes":243,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTool.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e2125bcfb2f6b9fc819dd15d9806cfa697c6f83f","filename":"src/main/java/com/twitter/distributedlog/tools/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"dcc3f5819e327a2082d7b803c32824b122982931","filename":"src/main/java/com/twitter/distributedlog/util/Allocator.java","status":"added","additions":102,"deletions":0,"changes":102,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FAllocator.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FAllocator.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FAllocator.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"95ef3e20ee502e4b7c685f4f797d949a77ff396a","filename":"src/main/java/com/twitter/distributedlog/util/CommandLineUtils.java","status":"added","additions":56,"deletions":0,"changes":56,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FCommandLineUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FCommandLineUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FCommandLineUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"46dd3b63cb8f1893d7c31996c5e2dcc1e00ffcbf","filename":"src/main/java/com/twitter/distributedlog/util/ConfUtils.java","status":"added","additions":65,"deletions":0,"changes":65,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FConfUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FConfUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FConfUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"42c624a7742bf41342bb86a61082ad6b972cde69","filename":"src/main/java/com/twitter/distributedlog/util/DLUtils.java","status":"added","additions":227,"deletions":0,"changes":227,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FDLUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FDLUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FDLUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"64101b3d7970732626c84c86276074c3b4b786be","filename":"src/main/java/com/twitter/distributedlog/util/FailpointUtils.java","status":"added","additions":134,"deletions":0,"changes":134,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFailpointUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFailpointUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFailpointUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f0540d7608ce62e6edee3efec5637463d8535699","filename":"src/main/java/com/twitter/distributedlog/util/FutureUtils.java","status":"added","additions":502,"deletions":0,"changes":502,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFutureUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFutureUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FFutureUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7357410b1c414c15d7ff5610d646fdc3fe04c056","filename":"src/main/java/com/twitter/distributedlog/util/LimitedPermitManager.java","status":"added","additions":179,"deletions":0,"changes":179,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FLimitedPermitManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FLimitedPermitManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FLimitedPermitManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e06023e6c946c3876b51637b49e31f5fca585871","filename":"src/main/java/com/twitter/distributedlog/util/MonitoredFuturePool.java","status":"added","additions":131,"deletions":0,"changes":131,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FMonitoredFuturePool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FMonitoredFuturePool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FMonitoredFuturePool.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2bc7f829e1a229f400663e84373d9677b827eded","filename":"src/main/java/com/twitter/distributedlog/util/MonitoredScheduledThreadPoolExecutor.java","status":"added","additions":241,"deletions":0,"changes":241,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FMonitoredScheduledThreadPoolExecutor.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FMonitoredScheduledThreadPoolExecutor.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FMonitoredScheduledThreadPoolExecutor.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d3385a66fb4481fbc38907f31a05fdce4bb40548","filename":"src/main/java/com/twitter/distributedlog/util/OrderedScheduler.java","status":"added","additions":480,"deletions":0,"changes":480,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FOrderedScheduler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FOrderedScheduler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FOrderedScheduler.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"61366ac367ff5f3df728bb1a1cf8f59412b05358","filename":"src/main/java/com/twitter/distributedlog/util/PermitLimiter.java","status":"added","additions":47,"deletions":0,"changes":47,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FPermitLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FPermitLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FPermitLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f93c7bffb5e752d42023213e37c4c558369466b0","filename":"src/main/java/com/twitter/distributedlog/util/PermitManager.java","status":"added","additions":83,"deletions":0,"changes":83,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FPermitManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FPermitManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FPermitManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d139a8048a2059a0bd3cdab536181c5c09344822","filename":"src/main/java/com/twitter/distributedlog/util/SafeQueueingFuturePool.java","status":"added","additions":115,"deletions":0,"changes":115,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSafeQueueingFuturePool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSafeQueueingFuturePool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSafeQueueingFuturePool.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"9f756f0eb8d9cbeb17a6cb38e052b7d7de21a1f4","filename":"src/main/java/com/twitter/distributedlog/util/SchedulerUtils.java","status":"added","additions":56,"deletions":0,"changes":56,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSchedulerUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSchedulerUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSchedulerUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7ec50ba89d235150a2b77319ad531cb8edaeb294","filename":"src/main/java/com/twitter/distributedlog/util/Sequencer.java","status":"added","additions":31,"deletions":0,"changes":31,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSequencer.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSequencer.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSequencer.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e859bea2096ff0baa8f0795164dc8cb2879b05e4","filename":"src/main/java/com/twitter/distributedlog/util/SimplePermitLimiter.java","status":"added","additions":100,"deletions":0,"changes":100,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSimplePermitLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSimplePermitLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSimplePermitLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"216d5eac6a08aec05c74b32fd61edc8aebafa1dd","filename":"src/main/java/com/twitter/distributedlog/util/Sizable.java","status":"added","additions":31,"deletions":0,"changes":31,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSizable.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSizable.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FSizable.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"96e564e0e8507f3834cc302f212ec08934063e26","filename":"src/main/java/com/twitter/distributedlog/util/TimeSequencer.java","status":"added","additions":39,"deletions":0,"changes":39,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTimeSequencer.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTimeSequencer.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTimeSequencer.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"422bbda2fee542dc61843e8033caaafbea1d5c69","filename":"src/main/java/com/twitter/distributedlog/util/Transaction.java","status":"added","additions":97,"deletions":0,"changes":97,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTransaction.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTransaction.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTransaction.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0731117411f39f9cab2049545c39e734f1886d16","filename":"src/main/java/com/twitter/distributedlog/util/Utils.java","status":"added","additions":569,"deletions":0,"changes":569,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"193b8144316aa619b485293100b39e11e37b8d26","filename":"src/main/java/com/twitter/distributedlog/util/package-info.java","status":"added","additions":21,"deletions":0,"changes":21,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2Fpackage-info.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2Fpackage-info.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2Fpackage-info.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7d76f2908edc5143a8f78dcfb729b341e44421ab","filename":"src/main/java/com/twitter/distributedlog/zk/DefaultZKOp.java","status":"added","additions":45,"deletions":0,"changes":45,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FDefaultZKOp.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FDefaultZKOp.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FDefaultZKOp.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"5675574a8aef59a47ee6f8079c9ad55ae37365c0","filename":"src/main/java/com/twitter/distributedlog/zk/ZKOp.java","status":"added","additions":63,"deletions":0,"changes":63,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKOp.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKOp.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKOp.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"57f9aa3e8ee6dfca7ee31969f7cda61e1c82ced0","filename":"src/main/java/com/twitter/distributedlog/zk/ZKTransaction.java","status":"added","additions":103,"deletions":0,"changes":103,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKTransaction.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKTransaction.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKTransaction.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d8855931f3cfd973647f22bf649f26afc4d870a0","filename":"src/main/java/com/twitter/distributedlog/zk/ZKVersionedSetOp.java","status":"added","additions":66,"deletions":0,"changes":66,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKVersionedSetOp.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKVersionedSetOp.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKVersionedSetOp.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"4068737122943743229fb04ca1a426cf54fbfaa7","filename":"src/main/java/com/twitter/distributedlog/zk/ZKWatcherManager.java","status":"added","additions":194,"deletions":0,"changes":194,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKWatcherManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKWatcherManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKWatcherManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"dcba24eaedf8060af074c5151589d2887f90b523","filename":"src/main/java/org/apache/bookkeeper/client/BookKeeperAccessor.java","status":"added","additions":40,"deletions":0,"changes":40,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Forg%2Fapache%2Fbookkeeper%2Fclient%2FBookKeeperAccessor.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Forg%2Fapache%2Fbookkeeper%2Fclient%2FBookKeeperAccessor.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Forg%2Fapache%2Fbookkeeper%2Fclient%2FBookKeeperAccessor.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"39a0f775ff5bb8785213bd1385a785aed76b6990","filename":"src/main/java/org/apache/bookkeeper/client/LedgerReader.java","status":"added","additions":212,"deletions":0,"changes":212,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Forg%2Fapache%2Fbookkeeper%2Fclient%2FLedgerReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fjava%2Forg%2Fapache%2Fbookkeeper%2Fclient%2FLedgerReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Forg%2Fapache%2Fbookkeeper%2Fclient%2FLedgerReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e69de29bb2d1d6434b8b29ae775ad8c2e48c5391","filename":"src/main/resources/config/decider.conf","status":"added","additions":0,"deletions":0,"changes":0,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fresources%2Fconfig%2Fdecider.conf","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fresources%2Fconfig%2Fdecider.conf","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fresources%2Fconfig%2Fdecider.conf?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e69de29bb2d1d6434b8b29ae775ad8c2e48c5391","filename":"src/main/resources/config/decider.yml","status":"added","additions":0,"deletions":0,"changes":0,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fresources%2Fconfig%2Fdecider.yml","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fresources%2Fconfig%2Fdecider.yml","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fresources%2Fconfig%2Fdecider.yml?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"16d9c6c81637f9f5488b122fc1ea9b9421c6c5c2","filename":"src/main/resources/findbugsExclude.xml","status":"added","additions":39,"deletions":0,"changes":39,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fresources%2FfindbugsExclude.xml","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fresources%2FfindbugsExclude.xml","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fresources%2FfindbugsExclude.xml?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2062ec8bc771e0d2b4a80bacd47a74ea72172519","filename":"src/main/thrift/metadata.thrift","status":"added","additions":22,"deletions":0,"changes":22,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fthrift%2Fmetadata.thrift","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Fmain%2Fthrift%2Fmetadata.thrift","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fthrift%2Fmetadata.thrift?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2c13b067c25ed4815a6319c0bcff15ed492afbb7","filename":"src/test/java/com/twitter/distributedlog/DLMTestUtil.java","status":"added","additions":559,"deletions":0,"changes":559,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ae71a1eb44f96edbbf85c5ae691722ff96108e87","filename":"src/test/java/com/twitter/distributedlog/NonBlockingReadsTestUtil.java","status":"added","additions":145,"deletions":0,"changes":145,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FNonBlockingReadsTestUtil.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FNonBlockingReadsTestUtil.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FNonBlockingReadsTestUtil.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"6b723f8547634b237d18c1561b4aef985adbc5e2","filename":"src/test/java/com/twitter/distributedlog/TestAppendOnlyStreamReader.java","status":"added","additions":207,"deletions":0,"changes":207,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d45a7271af34c612ca9cda28f27036ea958967da","filename":"src/test/java/com/twitter/distributedlog/TestAppendOnlyStreamWriter.java","status":"added","additions":336,"deletions":0,"changes":336,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e4fc5e3d917b2ed1b39fdcc2cababf9249c2d302","filename":"src/test/java/com/twitter/distributedlog/TestAsyncBulkWrite.java","status":"added","additions":351,"deletions":0,"changes":351,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncBulkWrite.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncBulkWrite.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncBulkWrite.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ccc2b6bf2e8ab761e59ba2e23c55ad2e5743624b","filename":"src/test/java/com/twitter/distributedlog/TestAsyncReaderLock.java","status":"added","additions":588,"deletions":0,"changes":588,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderLock.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderLock.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderLock.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a6a89ba7e06ad3e6db72697739cc6b7e88ef1d47","filename":"src/test/java/com/twitter/distributedlog/TestAsyncReaderWriter.java","status":"added","additions":2109,"deletions":0,"changes":2109,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0c8ca9a6e119d763ffd038c5ec23d34c598c5d51","filename":"src/test/java/com/twitter/distributedlog/TestBKDistributedLogManager.java","status":"added","additions":1278,"deletions":0,"changes":1278,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"04203be754e4bf6a9cd158769cda0db2c8076824","filename":"src/test/java/com/twitter/distributedlog/TestBKDistributedLogNamespace.java","status":"added","additions":426,"deletions":0,"changes":426,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogNamespace.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogNamespace.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogNamespace.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"51d05529adff3b5b78aefa403b9e4c42d0a2fc76","filename":"src/test/java/com/twitter/distributedlog/TestBKLogReadHandler.java","status":"added","additions":481,"deletions":0,"changes":481,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogReadHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogReadHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogReadHandler.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0baf9fe461197ebc6f513d8e362a7226258a1cb6","filename":"src/test/java/com/twitter/distributedlog/TestBKLogSegmentWriter.java","status":"added","additions":794,"deletions":0,"changes":794,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogSegmentWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogSegmentWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogSegmentWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"754f94597913fcb54385fce32acae39175fdcb19","filename":"src/test/java/com/twitter/distributedlog/TestBKLogWriteHandler.java","status":"added","additions":88,"deletions":0,"changes":88,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogWriteHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogWriteHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogWriteHandler.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"c45231739564e24d74b3787cf8c18903b9232d22","filename":"src/test/java/com/twitter/distributedlog/TestBKSyncLogReader.java","status":"added","additions":307,"deletions":0,"changes":307,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKSyncLogReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKSyncLogReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKSyncLogReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"c92aa6e85e0e1a4bea28f55abb8aa81c4602f108","filename":"src/test/java/com/twitter/distributedlog/TestDLMTestUtil.java","status":"added","additions":62,"deletions":0,"changes":62,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDLMTestUtil.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDLMTestUtil.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDLMTestUtil.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d348492d381631b6d240cb8566934bda27c3d9f0","filename":"src/test/java/com/twitter/distributedlog/TestDistributedLogBase.java","status":"added","additions":212,"deletions":0,"changes":212,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f0c8e9699c0825cd73f6f494fc528e9b587757f1","filename":"src/test/java/com/twitter/distributedlog/TestDistributedLogConfiguration.java","status":"added","additions":105,"deletions":0,"changes":105,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogConfiguration.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0e4737bacdf8df2255fef5e1a8ba21b8c939ae43","filename":"src/test/java/com/twitter/distributedlog/TestEntry.java","status":"added","additions":345,"deletions":0,"changes":345,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestEntry.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestEntry.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestEntry.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"37f261d25cc97479fb5a39243db4e55163a5007c","filename":"src/test/java/com/twitter/distributedlog/TestEnvelopedEntry.java","status":"added","additions":81,"deletions":0,"changes":81,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestEnvelopedEntry.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestEnvelopedEntry.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestEnvelopedEntry.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e86e45a45fe1d99a96d9d7ee75e27a6d6b2c071d","filename":"src/test/java/com/twitter/distributedlog/TestFailureAndRecovery.java","status":"added","additions":257,"deletions":0,"changes":257,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestFailureAndRecovery.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestFailureAndRecovery.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestFailureAndRecovery.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e31d06320a0c8080fc78cba4a76f191ef103021b","filename":"src/test/java/com/twitter/distributedlog/TestInterleavedReaders.java","status":"added","additions":408,"deletions":0,"changes":408,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestInterleavedReaders.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestInterleavedReaders.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestInterleavedReaders.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7d97e80eb61759978e976c3da34522da15214455","filename":"src/test/java/com/twitter/distributedlog/TestLedgerHandleCache.java","status":"added","additions":169,"deletions":0,"changes":169,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLedgerHandleCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLedgerHandleCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLedgerHandleCache.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"42b3ed54f9892bacc76f029057823a656160daf8","filename":"src/test/java/com/twitter/distributedlog/TestLogSegmentCreation.java","status":"added","additions":106,"deletions":0,"changes":106,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentCreation.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentCreation.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentCreation.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"cbc97d60d0cc8eaae610471705aaa5c611b0ed30","filename":"src/test/java/com/twitter/distributedlog/TestLogSegmentMetadata.java","status":"added","additions":162,"deletions":0,"changes":162,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentMetadata.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentMetadata.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentMetadata.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"b579b5e7814ea8f54f91651370d2e12de0d16a4b","filename":"src/test/java/com/twitter/distributedlog/TestLogSegmentsZK.java","status":"added","additions":245,"deletions":0,"changes":245,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentsZK.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentsZK.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLogSegmentsZK.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"90a33e8de3a37458ddbc5b6b839d800b4fb90c96","filename":"src/test/java/com/twitter/distributedlog/TestNonBlockingReads.java","status":"added","additions":322,"deletions":0,"changes":322,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestNonBlockingReads.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestNonBlockingReads.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestNonBlockingReads.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f513a28f99bbea65b819672a084b87ea7e0c8943","filename":"src/test/java/com/twitter/distributedlog/TestNonBlockingReadsMultiReader.java","status":"added","additions":169,"deletions":0,"changes":169,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestNonBlockingReadsMultiReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestNonBlockingReadsMultiReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestNonBlockingReadsMultiReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d28e2c6f8fdea1ae903425799f74521bf5036492","filename":"src/test/java/com/twitter/distributedlog/TestReadAhead.java","status":"added","additions":166,"deletions":0,"changes":166,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAhead.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAhead.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAhead.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e014311b03bc70c6e4f3a62c8870510b54096cfe","filename":"src/test/java/com/twitter/distributedlog/TestReadUtils.java","status":"added","additions":370,"deletions":0,"changes":370,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"3c8669b47d392f2d8259d2c25669b484378cc20e","filename":"src/test/java/com/twitter/distributedlog/TestReader.java","status":"added","additions":202,"deletions":0,"changes":202,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReader.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"54b1ab8b22c7313ec69eb021aad542212d75bf7c","filename":"src/test/java/com/twitter/distributedlog/TestRollLogSegments.java","status":"added","additions":419,"deletions":0,"changes":419,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestRollLogSegments.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestRollLogSegments.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestRollLogSegments.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d3062211d56c1ce5cdcd42e743d8d07c17451bed","filename":"src/test/java/com/twitter/distributedlog/TestSequenceID.java","status":"added","additions":254,"deletions":0,"changes":254,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestSequenceID.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestSequenceID.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestSequenceID.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"b375cf06ee0e49cd7195dd1d8afabfc1f0c4dbbe","filename":"src/test/java/com/twitter/distributedlog/TestTruncate.java","status":"added","additions":349,"deletions":0,"changes":349,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestTruncate.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestTruncate.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestTruncate.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ba2c9032ee59ac4303ead336fce881f4de5dd9a8","filename":"src/test/java/com/twitter/distributedlog/TestWriteLimiter.java","status":"added","additions":205,"deletions":0,"changes":205,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestWriteLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestWriteLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestWriteLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"983fb291be71f57591f7ce139dbd54c1fd0afe98","filename":"src/test/java/com/twitter/distributedlog/TestZooKeeperClient.java","status":"added","additions":437,"deletions":0,"changes":437,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestZooKeeperClient.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestZooKeeperClient.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestZooKeeperClient.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"df0d306cc2473a3159cd426b0ae9079ee768aeac","filename":"src/test/java/com/twitter/distributedlog/ZooKeeperClientUtils.java","status":"added","additions":95,"deletions":0,"changes":95,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClientUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClientUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClientUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"6747ef826e0c2a2c8c5a6f704182a726af181da7","filename":"src/test/java/com/twitter/distributedlog/ZooKeeperClusterTestCase.java","status":"added","additions":53,"deletions":0,"changes":53,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClusterTestCase.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClusterTestCase.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FZooKeeperClusterTestCase.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ff7d269b9ec3a90e7f49b83cae4349902730e8fa","filename":"src/test/java/com/twitter/distributedlog/acl/TestZKAccessControl.java","status":"added","additions":154,"deletions":0,"changes":154,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FTestZKAccessControl.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FTestZKAccessControl.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FTestZKAccessControl.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"5bc8e2b1b502f867c01bab6bd2ca6405c3777443","filename":"src/test/java/com/twitter/distributedlog/acl/TestZKAccessControlManager.java","status":"added","additions":177,"deletions":0,"changes":177,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FTestZKAccessControlManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FTestZKAccessControlManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Facl%2FTestZKAccessControlManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f1f4bf57f79fdfaebae5ccf9dc62b9345dec30c4","filename":"src/test/java/com/twitter/distributedlog/admin/TestDLCK.java","status":"added","additions":149,"deletions":0,"changes":149,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a1f9d1d6f53a0205332861a8e5ea70ead49f0a62","filename":"src/test/java/com/twitter/distributedlog/admin/TestDistributedLogAdmin.java","status":"added","additions":177,"deletions":0,"changes":177,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDistributedLogAdmin.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDistributedLogAdmin.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDistributedLogAdmin.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"181310ec3ead9d86d97c46486c1ae1a3953b7c9b","filename":"src/test/java/com/twitter/distributedlog/bk/TestLedgerAllocator.java","status":"added","additions":375,"deletions":0,"changes":375,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocator.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocator.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocator.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"bce502f252078068e818ab4a52bfe30c0a31ca2a","filename":"src/test/java/com/twitter/distributedlog/bk/TestLedgerAllocatorPool.java","status":"added","additions":310,"deletions":0,"changes":310,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocatorPool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocatorPool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocatorPool.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"eda60d5d7748d4e4d5909ac1ec5aef5f9ad94ee0","filename":"src/test/java/com/twitter/distributedlog/config/ConfigTestUtil.java","status":"added","additions":30,"deletions":0,"changes":30,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigTestUtil.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigTestUtil.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FConfigTestUtil.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"6626b3b8e4bbd6b99777bf5170756c2a244faa3a","filename":"src/test/java/com/twitter/distributedlog/config/PropertiesWriter.java","status":"added","additions":67,"deletions":0,"changes":67,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FPropertiesWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FPropertiesWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FPropertiesWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"4cdbafdadb6a4b1c0a8f58436cf16394c23b1a90","filename":"src/test/java/com/twitter/distributedlog/config/TestConcurrentBaseConfiguration.java","status":"added","additions":46,"deletions":0,"changes":46,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestConcurrentBaseConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestConcurrentBaseConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestConcurrentBaseConfiguration.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"dcb43b775ff408934f0194d1ab3d6a8289e94510","filename":"src/test/java/com/twitter/distributedlog/config/TestConfigurationSubscription.java","status":"added","additions":176,"deletions":0,"changes":176,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestConfigurationSubscription.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestConfigurationSubscription.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestConfigurationSubscription.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7ac8ae29e7879dae708f002aa47718900acdcdb2","filename":"src/test/java/com/twitter/distributedlog/config/TestDynamicConfigurationFactory.java","status":"added","additions":101,"deletions":0,"changes":101,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestDynamicConfigurationFactory.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestDynamicConfigurationFactory.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestDynamicConfigurationFactory.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2f78ec607820f4b1f192fc332801b574bf16ffa6","filename":"src/test/java/com/twitter/distributedlog/config/TestDynamicDistributedLogConfiguration.java","status":"added","additions":261,"deletions":0,"changes":261,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestDynamicDistributedLogConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestDynamicDistributedLogConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fconfig%2FTestDynamicDistributedLogConfiguration.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"7fa57ec6dee1df1f596ef045b6a2641434416d24","filename":"src/test/java/com/twitter/distributedlog/feature/TestConfigurationFeatureProvider.java","status":"added","additions":65,"deletions":0,"changes":65,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FTestConfigurationFeatureProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FTestConfigurationFeatureProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FTestConfigurationFeatureProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"35fac65ddde51da16d63f561f5491d65e7b4a0c7","filename":"src/test/java/com/twitter/distributedlog/feature/TestDynamicConfigurationFeatureProvider.java","status":"added","additions":160,"deletions":0,"changes":160,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FTestDynamicConfigurationFeatureProvider.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FTestDynamicConfigurationFeatureProvider.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ffeature%2FTestDynamicConfigurationFeatureProvider.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"eceab0e4d8ccac31b5f2437e51fc6021f6a3ba16","filename":"src/test/java/com/twitter/distributedlog/impl/TestZKLogMetadataStore.java","status":"added","additions":115,"deletions":0,"changes":115,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogMetadataStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"6cdf6c9a46d782226084cbef82313cc6e61b27a5","filename":"src/test/java/com/twitter/distributedlog/impl/TestZKLogSegmentFilters.java","status":"added","additions":74,"deletions":0,"changes":74,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentFilters.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentFilters.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentFilters.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"9de8421e5eb218647ae32b81358379ac61e0fd71","filename":"src/test/java/com/twitter/distributedlog/impl/TestZKLogSegmentMetadataStore.java","status":"added","additions":733,"deletions":0,"changes":733,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"a7527c07acaa8608ec7bf9f72ae46fc5ff3d147b","filename":"src/test/java/com/twitter/distributedlog/impl/TestZKNamespaceWatcher.java","status":"added","additions":186,"deletions":0,"changes":186,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKNamespaceWatcher.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKNamespaceWatcher.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKNamespaceWatcher.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2dc5061815ad65afcf17786d15f7f15906447c05","filename":"src/test/java/com/twitter/distributedlog/impl/federated/TestFederatedZKLogMetadataStore.java","status":"added","additions":447,"deletions":0,"changes":447,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Ffederated%2FTestFederatedZKLogMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Ffederated%2FTestFederatedZKLogMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Ffederated%2FTestFederatedZKLogMetadataStore.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"85aad626aba38b9b310cfb0582931b7de3eaff6d","filename":"src/test/java/com/twitter/distributedlog/impl/metadata/TestZKLogMetadata.java","status":"added","additions":59,"deletions":0,"changes":59,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadata.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadata.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadata.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0db241525e455f13d358909c6f8f00a56fed72b0","filename":"src/test/java/com/twitter/distributedlog/impl/metadata/TestZKLogMetadataForWriter.java","status":"added","additions":319,"deletions":0,"changes":319,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadataForWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadataForWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadataForWriter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"ce67c303b52bfcdff4f980fc79df3a7c793ecb6a","filename":"src/test/java/com/twitter/distributedlog/impl/metadata/TestZKLogMetadataForWriterUtilFunctions.java","status":"added","additions":204,"deletions":0,"changes":204,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadataForWriterUtilFunctions.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadataForWriterUtilFunctions.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogMetadataForWriterUtilFunctions.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e34caa2210ea693c8b328c019ea9936955fc3725","filename":"src/test/java/com/twitter/distributedlog/limiter/TestRequestLimiter.java","status":"added","additions":60,"deletions":0,"changes":60,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FTestRequestLimiter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FTestRequestLimiter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flimiter%2FTestRequestLimiter.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"2074c9eb3702c49b304019b1043b933ec7ca497a","filename":"src/test/java/com/twitter/distributedlog/lock/TestDistributedLock.java","status":"added","additions":835,"deletions":0,"changes":835,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FTestDistributedLock.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FTestDistributedLock.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FTestDistributedLock.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"629538e3c2ec3ead2b4382aac441ca36c429745c","filename":"src/test/java/com/twitter/distributedlog/lock/TestZKSessionLock.java","status":"added","additions":1175,"deletions":0,"changes":1175,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FTestZKSessionLock.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FTestZKSessionLock.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flock%2FTestZKSessionLock.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"3282f5cba520b5756feb8f748f0036adc374e069","filename":"src/test/java/com/twitter/distributedlog/logsegment/TestLogSegmentCache.java","status":"added","additions":220,"deletions":0,"changes":220,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestLogSegmentCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestLogSegmentCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestLogSegmentCache.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f3518f402a1de706211d86c3a4f40b4e262c255d","filename":"src/test/java/com/twitter/distributedlog/logsegment/TestRollingPolicy.java","status":"added","additions":63,"deletions":0,"changes":63,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestRollingPolicy.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestRollingPolicy.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FTestRollingPolicy.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"d4c2f310071690bf955c22639f0099f980540ecb","filename":"src/test/java/com/twitter/distributedlog/metadata/TestDLMetadata.java","status":"added","additions":194,"deletions":0,"changes":194,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestDLMetadata.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestDLMetadata.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestDLMetadata.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"99b5968a2b6681abb7251d21442b919f7a90528a","filename":"src/test/java/com/twitter/distributedlog/metadata/TestLogSegmentMetadataStoreUpdater.java","status":"added","additions":283,"deletions":0,"changes":283,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestLogSegmentMetadataStoreUpdater.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestLogSegmentMetadataStoreUpdater.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestLogSegmentMetadataStoreUpdater.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"866b7c2ab12ca1b387e24cc0e551159aa943c10c","filename":"src/test/java/com/twitter/distributedlog/metadata/TestZkMetadataResolver.java","status":"added","additions":199,"deletions":0,"changes":199,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestZkMetadataResolver.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestZkMetadataResolver.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FTestZkMetadataResolver.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"6e48deb57bfd1cacbfc1c986408134d5afe26932","filename":"src/test/java/com/twitter/distributedlog/namespace/TestDistributedLogNamespaceBuilder.java","status":"added","additions":124,"deletions":0,"changes":124,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FTestDistributedLogNamespaceBuilder.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FTestDistributedLogNamespaceBuilder.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnamespace%2FTestDistributedLogNamespaceBuilder.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"e5b8f04bb93666b988ed9ba7c7b54c258e554195","filename":"src/test/java/com/twitter/distributedlog/net/TestDNSResolver.java","status":"added","additions":96,"deletions":0,"changes":96,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FTestDNSResolver.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FTestDNSResolver.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FTestDNSResolver.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"0a928a030888da4f7e4d84997dcb047c0cbb54d2","filename":"src/test/java/com/twitter/distributedlog/net/TestNetUtils.java","status":"added","additions":82,"deletions":0,"changes":82,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FTestNetUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FTestNetUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fnet%2FTestNetUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"85c82e51c7078f6ddca362d727aeea2e3a12d7d8","filename":"src/test/java/com/twitter/distributedlog/rate/TestMovingAverageRate.java","status":"added","additions":99,"deletions":0,"changes":99,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FTestMovingAverageRate.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FTestMovingAverageRate.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Frate%2FTestMovingAverageRate.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"c06c935e397c201fd0111d723d54b5d91fa616df","filename":"src/test/java/com/twitter/distributedlog/selector/TestLogRecordSelectors.java","status":"added","additions":128,"deletions":0,"changes":128,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FTestLogRecordSelectors.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FTestLogRecordSelectors.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fselector%2FTestLogRecordSelectors.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"f9169c6dd04eed33024ee946a2d3aa1a26568b74","filename":"src/test/java/com/twitter/distributedlog/tools/TestDistributedLogTool.java","status":"added","additions":227,"deletions":0,"changes":227,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTestDistributedLogTool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTestDistributedLogTool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FTestDistributedLogTool.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"08b9b319bfa8a15ba7cf95af78df80e77f9c9a88","filename":"src/test/java/com/twitter/distributedlog/util/TestConfUtils.java","status":"added","additions":53,"deletions":0,"changes":53,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestConfUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestConfUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestConfUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"c60d4d2d60771f9dcc32d61855d74b78046bec10","filename":"src/test/java/com/twitter/distributedlog/util/TestDLUtils.java","status":"added","additions":273,"deletions":0,"changes":273,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestDLUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestDLUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestDLUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"12679e0895f6c3c175a855651a8aab5049ffc8c3","filename":"src/test/java/com/twitter/distributedlog/util/TestFutureUtils.java","status":"added","additions":71,"deletions":0,"changes":71,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestFutureUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestFutureUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestFutureUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"5953343d2529bfe150812a99ee091d43a61d11c0","filename":"src/test/java/com/twitter/distributedlog/util/TestPermitManager.java","status":"added","additions":91,"deletions":0,"changes":91,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestPermitManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestPermitManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestPermitManager.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"1991ad1f714ab0ad785710438884aa327bf182c7","filename":"src/test/java/com/twitter/distributedlog/util/TestSafeQueueingFuturePool.java","status":"added","additions":205,"deletions":0,"changes":205,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestSafeQueueingFuturePool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestSafeQueueingFuturePool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestSafeQueueingFuturePool.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"bdeda4f899aa3305dd3245b8e979796e65e789ed","filename":"src/test/java/com/twitter/distributedlog/util/TestTimeSequencer.java","status":"added","additions":42,"deletions":0,"changes":42,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestTimeSequencer.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestTimeSequencer.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestTimeSequencer.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"},{"sha":"c1e2f8b6664c869eac3be1ea741f11f4046d3ee3","filename":"src/test/java/com/twitter/distributedlog/util/TestUtils.java","status":"added","additions":126,"deletions":0,"changes":126,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/5a71ed88116fcdffcccdb99eb79055912c46a85e/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestUtils.java?ref=5a71ed88116fcdffcccdb99eb79055912c46a85e"}]}