{"sha":"e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","node_id":"MDY6Q29tbWl0NDc4NTkyNTI2OmUyYzZiYzBkN2ZhYTdiNzkxMmE1MWE3YTRlZDZlMWI5YWM1NjUzYmY=","commit":{"author":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-12-28T22:51:54Z"},"committer":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-12-29T10:11:23Z"},"message":"DL-195: ReadAhead Improvement (part 1) - Interface for LogSegmentEntryReader and LogSegmentEntryWriter\n\nCreate interface for log segment entry reader and writer to abstract data write/read operations.","tree":{"sha":"750b4d9cc5c2a7e972d77bdb3da72339bbfa2741","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/trees/750b4d9cc5c2a7e972d77bdb3da72339bbfa2741"},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/commits/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","comments_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/comments","author":null,"committer":null,"parents":[{"sha":"fd08cedc7e1e5df4cdf307a1dd615319bdc1bdd6","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/fd08cedc7e1e5df4cdf307a1dd615319bdc1bdd6","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/fd08cedc7e1e5df4cdf307a1dd615319bdc1bdd6"}],"stats":{"total":1532,"additions":1527,"deletions":5},"files":[{"sha":"16c0111faa6961f47f4c45b49848667ca305cf6b","filename":"src/main/java/com/twitter/distributedlog/BKLogWriteHandler.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -29,7 +29,7 @@\n import com.twitter.distributedlog.exceptions.TransactionIdOutOfOrderException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n import com.twitter.distributedlog.function.GetLastTxIdFunction;\n-import com.twitter.distributedlog.impl.BKLogSegmentEntryWriter;\n+import com.twitter.distributedlog.impl.logsegment.BKLogSegmentEntryWriter;\n import com.twitter.distributedlog.metadata.LogMetadataForWriter;\n import com.twitter.distributedlog.lock.DistributedLock;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;"},{"sha":"6c6017ec96e8d6b977271ac7fffa5e533f148267","filename":"src/main/java/com/twitter/distributedlog/DistributedLogConfiguration.java","status":"modified","additions":44,"deletions":0,"changes":44,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -352,6 +352,10 @@ public class DistributedLogConfiguration extends CompositeConfiguration {\n     public static final int BKDL_READAHEAD_NOSUCHLEDGER_EXCEPTION_ON_READLAC_ERROR_THRESHOLD_MILLIS_DEFAULT = 10000;\n     public static final String BKDL_READAHEAD_SKIP_BROKEN_ENTRIES = \"readAheadSkipBrokenEntries\";\n     public static final boolean BKDL_READAHEAD_SKIP_BROKEN_ENTRIES_DEFAULT = false;\n+    public static final String BKDL_NUM_PREFETCH_ENTRIES_PER_LOGSEGMENT = \"numPrefetchEntriesPerLogSegment\";\n+    public static final int BKDL_NUM_PREFETCH_ENTRIES_PER_LOGSEGMENT_DEFAULT = 4;\n+    public static final String BKDL_MAX_PREFETCH_ENTRIES_PER_LOGSEGMENT = \"maxPrefetchEntriesPerLogSegment\";\n+    public static final int BKDL_MAX_PREFETCH_ENTRIES_PER_LOGSEGMENT_DEFAULT = 32;\n \n     // Scan Settings\n     public static final String BKDL_FIRST_NUM_ENTRIES_PER_READ_LAST_RECORD_SCAN = \"firstNumEntriesEachPerLastRecordScan\";\n@@ -2770,6 +2774,46 @@ public DistributedLogConfiguration setReadAheadSkipBrokenEntries(boolean enabled\n         return this;\n     }\n \n+    /**\n+     * Get the number prefetch entries per log segment. Default value is 4.\n+     *\n+     * @return the number prefetch entries per log segment.\n+     */\n+    public int getNumPrefetchEntriesPerLogSegment() {\n+        return getInt(BKDL_NUM_PREFETCH_ENTRIES_PER_LOGSEGMENT, BKDL_NUM_PREFETCH_ENTRIES_PER_LOGSEGMENT_DEFAULT);\n+    }\n+\n+    /**\n+     * Set the number prefetch entries per log segment.\n+     *\n+     * @param numEntries the number prefetch entries per log segment.\n+     * @return configuration\n+     */\n+    public DistributedLogConfiguration setNumPrefetchEntriesPerLogSegment(int numEntries) {\n+        setProperty(BKDL_NUM_PREFETCH_ENTRIES_PER_LOGSEGMENT, numEntries);\n+        return this;\n+    }\n+\n+    /**\n+     * Get the max prefetch entries per log segment. Default value is 4.\n+     *\n+     * @return the max prefetch entries per log segment.\n+     */\n+    public int getMaxPrefetchEntriesPerLogSegment() {\n+        return getInt(BKDL_MAX_PREFETCH_ENTRIES_PER_LOGSEGMENT, BKDL_MAX_PREFETCH_ENTRIES_PER_LOGSEGMENT_DEFAULT);\n+    }\n+\n+    /**\n+     * Set the max prefetch entries per log segment.\n+     *\n+     * @param numEntries the max prefetch entries per log segment.\n+     * @return configuration\n+     */\n+    public DistributedLogConfiguration setMaxPrefetchEntriesPerLogSegment(int numEntries) {\n+        setProperty(BKDL_MAX_PREFETCH_ENTRIES_PER_LOGSEGMENT, numEntries);\n+        return this;\n+    }\n+\n     //\n     // DL Reader Scan Settings\n     //"},{"sha":"fd3b63f6f27827d6c7567f42064795ef390f1346","filename":"src/main/java/com/twitter/distributedlog/impl/logsegment/BKLogSegmentEntryReader.java","status":"added","additions":740,"deletions":0,"changes":740,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryReader.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -0,0 +1,740 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.impl.logsegment;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.Lists;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n+import com.twitter.distributedlog.Entry;\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import com.twitter.distributedlog.exceptions.BKTransmitException;\n+import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.EndOfLogSegmentException;\n+import com.twitter.distributedlog.exceptions.ReadCancelledException;\n+import com.twitter.distributedlog.logsegment.LogSegmentEntryReader;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.util.Future;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.client.AsyncCallback;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.BookKeeper;\n+import org.apache.bookkeeper.client.LedgerEntry;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Enumeration;\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+\n+/**\n+ * BookKeeper ledger based log segment entry reader.\n+ */\n+public class BKLogSegmentEntryReader implements Runnable, LogSegmentEntryReader, AsyncCallback.OpenCallback {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(BKLogSegmentEntryReader.class);\n+\n+    private class CacheEntry implements Runnable, AsyncCallback.ReadCallback,\n+            AsyncCallback.ReadLastConfirmedAndEntryCallback {\n+\n+        protected final long entryId;\n+        private boolean done;\n+        private LedgerEntry entry;\n+        private int rc;\n+\n+        private CacheEntry(long entryId) {\n+            this.entryId = entryId;\n+            this.entry = null;\n+            this.rc = BKException.Code.UnexpectedConditionException;\n+            this.done = false;\n+        }\n+\n+        long getEntryId() {\n+            return entryId;\n+        }\n+\n+        synchronized boolean isDone() {\n+            return done;\n+        }\n+\n+        void setValue(LedgerEntry entry) {\n+            synchronized (this) {\n+                if (done) {\n+                    return;\n+                }\n+                this.rc = BKException.Code.OK;\n+                this.entry = entry;\n+            }\n+            setDone(true);\n+        }\n+\n+        void setException(int rc) {\n+            synchronized (this) {\n+                if (done) {\n+                    return;\n+                }\n+                this.rc = rc;\n+            }\n+            setDone(false);\n+        }\n+\n+        void setDone(boolean success) {\n+            synchronized (this) {\n+                this.done = true;\n+            }\n+            onReadEntryDone(success);\n+        }\n+\n+        synchronized boolean isSuccess() {\n+            return BKException.Code.OK == rc;\n+        }\n+\n+        synchronized LedgerEntry getEntry() {\n+            return this.entry;\n+        }\n+\n+        synchronized int getRc() {\n+            return rc;\n+        }\n+\n+        @Override\n+        public void readComplete(int rc,\n+                                 LedgerHandle lh,\n+                                 Enumeration<LedgerEntry> entries,\n+                                 Object ctx) {\n+            if (isDone()) {\n+                return;\n+            }\n+            if (!checkReturnCodeAndHandleFailure(rc, false)) {\n+                return;\n+            }\n+            LedgerEntry entry = null;\n+            while (entries.hasMoreElements()) {\n+                // more entries are returned\n+                if (null != entry) {\n+                    setException(BKException.Code.UnexpectedConditionException);\n+                    return;\n+                }\n+                entry = entries.nextElement();\n+            }\n+            if (null == entry || entry.getEntryId() != entryId) {\n+                setException(BKException.Code.UnexpectedConditionException);\n+                return;\n+            }\n+            setValue(entry);\n+        }\n+\n+        @Override\n+        public void readLastConfirmedAndEntryComplete(int rc,\n+                                                      long entryId,\n+                                                      LedgerEntry entry,\n+                                                      Object ctx) {\n+            if (isDone()) {\n+                return;\n+            }\n+            if (!checkReturnCodeAndHandleFailure(rc, true)) {\n+                return;\n+            }\n+            if (null != entry && this.entryId == entryId) {\n+                setValue(entry);\n+                return;\n+            }\n+            // the long poll is timeout or interrupted; we will retry it again.\n+            issueRead(this);\n+        }\n+\n+        /**\n+         * Check return code and retry if needed.\n+         *\n+         * @param rc the return code\n+         * @param isLongPoll is it a long poll request\n+         * @return is the request successful or not\n+         */\n+        boolean checkReturnCodeAndHandleFailure(int rc, boolean isLongPoll) {\n+            if (BKException.Code.OK == rc) {\n+                numReadErrors.set(0);\n+                return true;\n+            }\n+            if (BKException.Code.BookieHandleNotAvailableException == rc ||\n+                    (isLongPoll && BKException.Code.NoSuchLedgerExistsException == rc)) {\n+                int numErrors = Math.max(1, numReadErrors.incrementAndGet());\n+                int nextReadBackoffTime = Math.min(numErrors * readAheadWaitTime, maxReadBackoffTime);\n+                scheduler.schedule(\n+                        this,\n+                        nextReadBackoffTime,\n+                        TimeUnit.MILLISECONDS);\n+            } else {\n+                setException(rc);\n+            }\n+            return false;\n+        }\n+\n+        @Override\n+        public void run() {\n+            issueRead(this);\n+        }\n+    }\n+\n+    private class PendingReadRequest {\n+        private final int numEntries;\n+        private final List<Entry.Reader> entries;\n+        private final Promise<List<Entry.Reader>> promise;\n+\n+        PendingReadRequest(int numEntries) {\n+            this.numEntries = numEntries;\n+            if (numEntries == 1) {\n+                this.entries = new ArrayList<Entry.Reader>(1);\n+            } else {\n+                this.entries = new ArrayList<Entry.Reader>();\n+            }\n+            this.promise = new Promise<List<Entry.Reader>>();\n+        }\n+\n+        Promise<List<Entry.Reader>> getPromise() {\n+            return promise;\n+        }\n+\n+        void setException(Throwable throwable) {\n+            FutureUtils.setException(promise, throwable);\n+        }\n+\n+        void addEntry(Entry.Reader entry) {\n+            entries.add(entry);\n+        }\n+\n+        void complete() {\n+            FutureUtils.setValue(promise, entries);\n+            onEntriesConsumed(entries.size());\n+        }\n+\n+        boolean hasReadEntries() {\n+            return entries.size() > 0;\n+        }\n+\n+        boolean hasReadEnoughEntries() {\n+            return entries.size() >= numEntries;\n+        }\n+    }\n+\n+    private final BookKeeper bk;\n+    private final DistributedLogConfiguration conf;\n+    private final OrderedScheduler scheduler;\n+    private final long startEntryId;\n+    private final long lssn;\n+    private final long startSequenceId;\n+    private final boolean envelopeEntries;\n+    private final int numPrefetchEntries;\n+    private final int maxPrefetchEntries;\n+    // state\n+    private Promise<Void> closePromise = null;\n+    private LogSegmentMetadata metadata;\n+    private LedgerHandle lh;\n+    private final List<LedgerHandle> openLedgerHandles;\n+    private CacheEntry outstandingLongPoll;\n+    private long nextEntryId;\n+    private final AtomicReference<Throwable> lastException = new AtomicReference<Throwable>(null);\n+    private final AtomicLong scheduleCount = new AtomicLong(0);\n+    // read retries\n+    private int readAheadWaitTime;\n+    private final int maxReadBackoffTime;\n+    private final AtomicInteger numReadErrors = new AtomicInteger(0);\n+    // readahead cache\n+    int cachedEntries = 0;\n+    int numOutstandingEntries = 0;\n+    final LinkedBlockingQueue<CacheEntry> readAheadEntries;\n+    // request queue\n+    final ConcurrentLinkedQueue<PendingReadRequest> readQueue;\n+\n+    BKLogSegmentEntryReader(LogSegmentMetadata metadata,\n+                            LedgerHandle lh,\n+                            long startEntryId,\n+                            BookKeeper bk,\n+                            OrderedScheduler scheduler,\n+                            DistributedLogConfiguration conf) {\n+        this.metadata = metadata;\n+        this.lssn = metadata.getLogSegmentSequenceNumber();\n+        this.startSequenceId = metadata.getStartSequenceId();\n+        this.envelopeEntries = metadata.getEnvelopeEntries();\n+        this.lh = lh;\n+        this.startEntryId = this.nextEntryId = Math.max(startEntryId, 0);\n+        this.bk = bk;\n+        this.conf = conf;\n+        this.numPrefetchEntries = conf.getNumPrefetchEntriesPerLogSegment();\n+        this.maxPrefetchEntries = conf.getMaxPrefetchEntriesPerLogSegment();\n+        this.scheduler = scheduler;\n+        this.openLedgerHandles = Lists.newArrayList();\n+        this.openLedgerHandles.add(lh);\n+        this.outstandingLongPoll = null;\n+        // create the readahead queue\n+        this.readAheadEntries = new LinkedBlockingQueue<CacheEntry>();\n+        // create the read request queue\n+        this.readQueue = new ConcurrentLinkedQueue<PendingReadRequest>();\n+        // read backoff settings\n+        this.readAheadWaitTime = conf.getReadAheadWaitTime();\n+        this.maxReadBackoffTime = 4 * conf.getReadAheadWaitTime();\n+    }\n+\n+    synchronized LedgerHandle getLh() {\n+        return lh;\n+    }\n+\n+    synchronized LogSegmentMetadata getSegment() {\n+        return metadata;\n+    }\n+\n+    @VisibleForTesting\n+    synchronized long getNextEntryId() {\n+        return nextEntryId;\n+    }\n+\n+    @Override\n+    public void start() {\n+        prefetchIfNecessary();\n+    }\n+\n+    //\n+    // Process on Log Segment Metadata Updates\n+    //\n+\n+    @Override\n+    public synchronized void onLogSegmentMetadataUpdated(LogSegmentMetadata segment) {\n+        if (metadata == segment ||\n+                LogSegmentMetadata.COMPARATOR.compare(metadata, segment) == 0 ||\n+                !(metadata.isInProgress() && !segment.isInProgress())) {\n+            return;\n+        }\n+        // segment is closed from inprogress, then re-open the log segment\n+        bk.asyncOpenLedger(\n+                segment.getLedgerId(),\n+                BookKeeper.DigestType.CRC32,\n+                conf.getBKDigestPW().getBytes(UTF_8),\n+                this,\n+                segment);\n+    }\n+\n+    @Override\n+    public void openComplete(int rc, LedgerHandle lh, Object ctx) {\n+        LogSegmentMetadata segment = (LogSegmentMetadata) ctx;\n+        if (BKException.Code.OK != rc) {\n+            // fail current reader or retry opening the reader\n+            failOrRetryOpenLedger(rc, segment);\n+            return;\n+        }\n+        // switch to new ledger handle if the log segment is moved to completed.\n+        CacheEntry longPollRead = null;\n+        synchronized (this) {\n+            if (isClosed()) {\n+                lh.asyncClose(new AsyncCallback.CloseCallback() {\n+                    @Override\n+                    public void closeComplete(int rc, LedgerHandle lh, Object ctx) {\n+                        logger.debug(\"Close the open ledger {} since the log segment reader is already closed\",\n+                                lh.getId());\n+                    }\n+                }, null);\n+                return;\n+            }\n+            this.metadata = segment;\n+            this.lh = lh;\n+            this.openLedgerHandles.add(lh);\n+            longPollRead = outstandingLongPoll;\n+        }\n+        if (null != longPollRead) {\n+            // reissue the long poll read when the log segment state is changed\n+            issueRead(longPollRead);\n+        }\n+        // notify readers\n+        notifyReaders();\n+    }\n+\n+    private void failOrRetryOpenLedger(int rc, final LogSegmentMetadata segment) {\n+        if (isClosed()) {\n+            return;\n+        }\n+        if (isBeyondLastAddConfirmed()) {\n+            // if the reader is already caught up, let's fail the reader immediately\n+            // as we need to pull the latest metadata of this log segment.\n+            setException(new BKTransmitException(\"Failed to open ledger for reading log segment \" + getSegment(), rc),\n+                    true);\n+            return;\n+        }\n+        // the reader is still catching up, retry opening the log segment later\n+        scheduler.schedule(new Runnable() {\n+            @Override\n+            public void run() {\n+                onLogSegmentMetadataUpdated(segment);\n+            }\n+        }, conf.getZKRetryBackoffStartMillis(), TimeUnit.MILLISECONDS);\n+    }\n+\n+    //\n+    // Change the state of this reader\n+    //\n+\n+    private boolean checkClosedOrInError() {\n+        if (null != lastException.get()) {\n+            cancelAllPendingReads(lastException.get());\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Set the reader into error state with return code <i>rc</i>.\n+     *\n+     * @param throwable exception indicating the error\n+     * @param isBackground is the reader set exception by background reads or foreground reads\n+     */\n+    private void setException(Throwable throwable, boolean isBackground) {\n+        lastException.compareAndSet(null, throwable);\n+        if (isBackground) {\n+            notifyReaders();\n+        }\n+    }\n+\n+    /**\n+     * Notify the readers with the state change.\n+     */\n+    private void notifyReaders() {\n+        processReadRequests();\n+    }\n+\n+    private void cancelAllPendingReads(Throwable throwExc) {\n+        for (PendingReadRequest request : readQueue) {\n+            request.setException(throwExc);\n+        }\n+        readQueue.clear();\n+    }\n+\n+    //\n+    // Background Read Operations\n+    //\n+\n+    private void onReadEntryDone(boolean success) {\n+        // we successfully read an entry\n+        synchronized (this) {\n+            --numOutstandingEntries;\n+        }\n+        // notify reader that there is entry ready\n+        notifyReaders();\n+        // stop prefetch if we already encountered exceptions\n+        if (success) {\n+            prefetchIfNecessary();\n+        }\n+    }\n+\n+    private void onEntriesConsumed(int numEntries) {\n+        synchronized (this) {\n+            cachedEntries -= numEntries;\n+        }\n+        prefetchIfNecessary();\n+    }\n+\n+    private void prefetchIfNecessary() {\n+        List<CacheEntry> entriesToFetch;\n+        synchronized (this) {\n+            if (cachedEntries >= maxPrefetchEntries) {\n+                return;\n+            }\n+            // we don't have enough entries, do prefetch\n+            int numEntriesToFetch = numPrefetchEntries - numOutstandingEntries;\n+            if (numEntriesToFetch <= 0) {\n+                return;\n+            }\n+            entriesToFetch = new ArrayList<CacheEntry>(numEntriesToFetch);\n+            for (int i = 0; i < numEntriesToFetch; i++) {\n+                if (cachedEntries >= maxPrefetchEntries) {\n+                    break;\n+                }\n+                if ((isLedgerClosed() && nextEntryId > getLastAddConfirmed()) ||\n+                        (!isLedgerClosed() && nextEntryId > getLastAddConfirmed() + 1)) {\n+                    break;\n+                }\n+                entriesToFetch.add(new CacheEntry(nextEntryId));\n+                ++numOutstandingEntries;\n+                ++cachedEntries;\n+                ++nextEntryId;\n+            }\n+        }\n+        for (CacheEntry entry : entriesToFetch) {\n+            readAheadEntries.add(entry);\n+            issueRead(entry);\n+        }\n+    }\n+\n+\n+    private void issueRead(CacheEntry cacheEntry) {\n+        if (isClosed()) {\n+            return;\n+        }\n+        if (isLedgerClosed()) {\n+            if (isNotBeyondLastAddConfirmed(cacheEntry.getEntryId())) {\n+                issueSimpleRead(cacheEntry);\n+                return;\n+            } else {\n+                // Reach the end of stream\n+                notifyReaders();\n+            }\n+        } else { // the ledger is still in progress\n+            if (isNotBeyondLastAddConfirmed(cacheEntry.getEntryId())) {\n+                issueSimpleRead(cacheEntry);\n+            } else {\n+                issueLongPollRead(cacheEntry);\n+            }\n+        }\n+    }\n+\n+    private void issueSimpleRead(CacheEntry cacheEntry) {\n+        getLh().asyncReadEntries(cacheEntry.entryId, cacheEntry.entryId, cacheEntry, null);\n+    }\n+\n+    private void issueLongPollRead(CacheEntry cacheEntry) {\n+        // register the read as outstanding reads\n+        synchronized (this) {\n+            this.outstandingLongPoll = cacheEntry;\n+        }\n+        getLh().asyncReadLastConfirmedAndEntry(\n+                cacheEntry.entryId,\n+                conf.getReadLACLongPollTimeout(),\n+                false,\n+                cacheEntry,\n+                null);\n+    }\n+\n+    //\n+    // Foreground Read Operations\n+    //\n+\n+    Entry.Reader processReadEntry(LedgerEntry entry) throws IOException {\n+        return Entry.newBuilder()\n+                .setLogSegmentInfo(lssn, startSequenceId)\n+                .setEntryId(entry.getEntryId())\n+                .setEnvelopeEntry(envelopeEntries)\n+                .deserializeRecordSet(false)\n+                .setInputStream(entry.getEntryInputStream())\n+                .buildReader();\n+    }\n+\n+    @Override\n+    public Future<List<Entry.Reader>> readNext(int numEntries) {\n+        final PendingReadRequest readRequest = new PendingReadRequest(numEntries);\n+\n+        if (checkClosedOrInError()) {\n+            readRequest.setException(lastException.get());\n+        } else {\n+            boolean wasQueueEmpty;\n+            synchronized (readQueue) {\n+                wasQueueEmpty = readQueue.isEmpty();\n+                readQueue.add(readRequest);\n+            }\n+            if (wasQueueEmpty) {\n+                processReadRequests();\n+            }\n+        }\n+        return readRequest.getPromise();\n+    }\n+\n+    private void processReadRequests() {\n+        if (isClosed()) {\n+            // the reader is already closed.\n+            return;\n+        }\n+\n+        long prevCount = scheduleCount.getAndIncrement();\n+        if (0 == prevCount) {\n+            scheduler.submit(this);\n+        }\n+    }\n+\n+    /**\n+     * The core function to propagate fetched entries to read requests\n+     */\n+    @Override\n+    public void run() {\n+        long scheduleCountLocal = scheduleCount.get();\n+        while (true) {\n+            PendingReadRequest nextRequest = null;\n+            synchronized (readQueue) {\n+                nextRequest = readQueue.peek();\n+            }\n+\n+            // if read queue is empty, nothing to read, return\n+            if (null == nextRequest) {\n+                scheduleCount.set(0L);\n+                return;\n+            }\n+\n+            // if the oldest pending promise is interrupted then we must\n+            // mark the reader in error and abort all pending reads since\n+            // we don't know the last consumed read\n+            if (null == lastException.get()) {\n+                if (nextRequest.getPromise().isInterrupted().isDefined()) {\n+                    setException(new DLInterruptedException(\"Interrupted on reading log segment \"\n+                            + getSegment() + \" : \" + nextRequest.getPromise().isInterrupted().get()), false);\n+                }\n+            }\n+\n+            // if the reader is in error state, stop read\n+            if (checkClosedOrInError()) {\n+                return;\n+            }\n+\n+            // read entries from readahead cache to satisfy next read request\n+            readEntriesFromReadAheadCache(nextRequest);\n+\n+            // check if we can satisfy the read request\n+            if (nextRequest.hasReadEntries()) {\n+                PendingReadRequest request;\n+                synchronized (readQueue) {\n+                    request = readQueue.poll();\n+                }\n+                if (null != request && nextRequest == request) {\n+                    request.complete();\n+                } else {\n+                    DLIllegalStateException ise = new DLIllegalStateException(\"Unexpected condition at reading from \"\n+                            + getSegment());\n+                    nextRequest.setException(ise);\n+                    if (null != request) {\n+                        request.setException(ise);\n+                    }\n+                    setException(ise, false);\n+                }\n+            } else {\n+                if (0 == scheduleCountLocal) {\n+                    return;\n+                }\n+                scheduleCountLocal = scheduleCount.decrementAndGet();\n+            }\n+        }\n+    }\n+\n+    private void readEntriesFromReadAheadCache(PendingReadRequest nextRequest) {\n+        while (!nextRequest.hasReadEnoughEntries()) {\n+            CacheEntry entry = readAheadEntries.peek();\n+            // no entry available in the read ahead cache\n+            if (null == entry) {\n+                if (isEndOfLogSegment()) {\n+                    setException(new EndOfLogSegmentException(getSegment().getZNodeName()), false);\n+                }\n+                return;\n+            }\n+            // entry is not complete yet.\n+            if (!entry.isDone()) {\n+                // we already reached end of the log segment\n+                if (isEndOfLogSegment(entry.getEntryId())) {\n+                    setException(new EndOfLogSegmentException(getSegment().getZNodeName()), false);\n+                }\n+                return;\n+            }\n+            if (entry.isSuccess()) {\n+                CacheEntry removedEntry = readAheadEntries.poll();\n+                if (entry != removedEntry) {\n+                    DLIllegalStateException ise = new DLIllegalStateException(\"Unexpected condition at reading from \"\n+                            + getSegment());\n+                    setException(ise, false);\n+                    return;\n+                }\n+                try {\n+                    nextRequest.addEntry(processReadEntry(entry.getEntry()));\n+                } catch (IOException e) {\n+                    setException(e, false);\n+                    return;\n+                }\n+            } else {\n+                setException(new BKTransmitException(\"Encountered issue on reading entry \" + entry.getEntryId()\n+                        + \" @ log segment \" + getSegment(), entry.getRc()), false);\n+                return;\n+            }\n+        }\n+    }\n+\n+    //\n+    // State Management\n+    //\n+\n+    private synchronized boolean isEndOfLogSegment() {\n+        return isEndOfLogSegment(nextEntryId);\n+    }\n+\n+    private boolean isEndOfLogSegment(long entryId) {\n+        return isLedgerClosed() && entryId > getLastAddConfirmed();\n+    }\n+\n+    private synchronized boolean isBeyondLastAddConfirmed() {\n+        return isBeyondLastAddConfirmed(nextEntryId);\n+    }\n+\n+    private boolean isBeyondLastAddConfirmed(long entryId) {\n+        return entryId > getLastAddConfirmed();\n+    }\n+\n+    private synchronized boolean isNotBeyondLastAddConfirmed() {\n+        return isNotBeyondLastAddConfirmed(nextEntryId);\n+    }\n+\n+    private boolean isNotBeyondLastAddConfirmed(long entryId) {\n+        return entryId <= getLastAddConfirmed();\n+    }\n+\n+    private boolean isLedgerClosed() {\n+        return getLh().isClosed();\n+    }\n+\n+    @Override\n+    public long getLastAddConfirmed() {\n+        return getLh().getLastAddConfirmed();\n+    }\n+\n+    synchronized boolean isClosed() {\n+        return null != closePromise;\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        final Promise<Void> closeFuture;\n+        ReadCancelledException exception;\n+        LedgerHandle[] lhsToClose;\n+        synchronized (this) {\n+            if (null != closePromise) {\n+                return closePromise;\n+            }\n+            closeFuture = closePromise = new Promise<Void>();\n+            lhsToClose = openLedgerHandles.toArray(new LedgerHandle[openLedgerHandles.size()]);\n+            // set the exception to cancel pending and subsequent reads\n+            exception = new ReadCancelledException(getSegment().getZNodeName(), \"Reader was closed\");\n+            setException(exception, false);\n+        }\n+\n+        // cancel all pending reads\n+        cancelAllPendingReads(exception);\n+\n+        // close all the open ledger\n+        BKUtils.closeLedgers(lhsToClose).proxyTo(closeFuture);\n+        return closeFuture;\n+    }\n+}"},{"sha":"34fe1c3792417643da963f078724cee02d3b2ed6","filename":"src/main/java/com/twitter/distributedlog/impl/logsegment/BKLogSegmentEntryWriter.java","status":"renamed","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryWriter.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -15,7 +15,7 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.twitter.distributedlog.impl;\n+package com.twitter.distributedlog.impl.logsegment;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.twitter.distributedlog.logsegment.LogSegmentEntryWriter;","previous_filename":"src/main/java/com/twitter/distributedlog/impl/BKLogSegmentEntryWriter.java"},{"sha":"c71c67ed69643e598982a08c7f7b3a628702fdb4","filename":"src/main/java/com/twitter/distributedlog/impl/logsegment/BKUtils.java","status":"added","additions":72,"deletions":0,"changes":72,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKUtils.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -0,0 +1,72 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.impl.logsegment;\n+\n+import com.google.common.collect.Lists;\n+import com.twitter.distributedlog.function.VoidFunctions;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.util.Future;\n+import com.twitter.util.Futures;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.client.AsyncCallback;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+\n+import java.util.List;\n+\n+/**\n+ * BookKeeper Util Functions\n+ */\n+public class BKUtils {\n+\n+    /**\n+     * Close a ledger <i>lh</i>.\n+     *\n+     * @param lh ledger handle\n+     * @return future represents close result.\n+     */\n+    public static Future<Void> closeLedger(LedgerHandle lh) {\n+        final Promise<Void> closePromise = new Promise<Void>();\n+        lh.asyncClose(new AsyncCallback.CloseCallback() {\n+            @Override\n+            public void closeComplete(int rc, LedgerHandle lh, Object ctx) {\n+                if (BKException.Code.OK != rc) {\n+                    FutureUtils.setException(closePromise, BKException.create(rc));\n+                } else {\n+                    FutureUtils.setValue(closePromise, null);\n+                }\n+            }\n+        }, null);\n+        return closePromise;\n+    }\n+\n+    /**\n+     * Close a list of ledgers <i>lhs</i>.\n+     *\n+     * @param lhs a list of ledgers\n+     * @return future represents close results.\n+     */\n+    public static Future<Void> closeLedgers(LedgerHandle ... lhs) {\n+        List<Future<Void>> closeResults = Lists.newArrayListWithExpectedSize(lhs.length);\n+        for (LedgerHandle lh : lhs) {\n+            closeResults.add(closeLedger(lh));\n+        }\n+        return Futures.collect(closeResults).map(VoidFunctions.LIST_TO_VOID_FUNC);\n+    }\n+\n+}"},{"sha":"d43f3d841f320f999e446eea9b7c74ae0d6e8451","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentEntryReader.java","status":"added","additions":67,"deletions":0,"changes":67,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryReader.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -0,0 +1,67 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.logsegment;\n+\n+import com.google.common.annotations.Beta;\n+import com.twitter.distributedlog.Entry;\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+import com.twitter.util.Future;\n+\n+import java.util.List;\n+\n+/**\n+ * An interface class to read the enveloped entry (serialized bytes of\n+ * {@link com.twitter.distributedlog.Entry}) from a log segment\n+ */\n+@Beta\n+public interface LogSegmentEntryReader extends AsyncCloseable {\n+\n+    /**\n+     * Start the reader. The method to signal the implementation\n+     * to start preparing the data for consumption {@link #readNext(int)}\n+     */\n+    void start();\n+\n+    /**\n+     * Update the log segment each time when the metadata has changed.\n+     *\n+     * @param segment new metadata of the log segment.\n+     */\n+    void onLogSegmentMetadataUpdated(LogSegmentMetadata segment);\n+\n+    /**\n+     * Read next <i>numEntries</i> entries from current log segment.\n+     * <p>\n+     * <i>numEntries</i> will be best-effort.\n+     *\n+     * @param numEntries num entries to read from current log segment\n+     * @return A promise that when satisified will contain a non-empty list of entries with their content.\n+     * @throws {@link com.twitter.distributedlog.exceptions.EndOfLogSegmentException} when\n+     *          read entries beyond the end of a <i>closed</i> log segment.\n+     */\n+    Future<List<Entry.Reader>> readNext(int numEntries);\n+\n+    /**\n+     * Return the last add confirmed entry id (LAC).\n+     *\n+     * @return the last add confirmed entry id.\n+     */\n+    long getLastAddConfirmed();\n+\n+}"},{"sha":"ff47691b346bae889937fd584c93ce4c3f53eb0c","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentEntryStore.java","status":"added","additions":46,"deletions":0,"changes":46,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryStore.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -0,0 +1,46 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.logsegment;\n+\n+import com.google.common.annotations.Beta;\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import com.twitter.util.Future;\n+\n+/**\n+ * Log Segment Store to read log segments\n+ */\n+@Beta\n+public interface LogSegmentEntryStore {\n+\n+    /**\n+     * Open the writer for writing data to the log <i>segment</i>.\n+     *\n+     * @param segment the log <i>segment</i> to write data to\n+     * @return future represent the opened writer\n+     */\n+    Future<LogSegmentEntryWriter> openWriter(LogSegmentMetadata segment);\n+\n+    /**\n+     * Open the reader for reading data to the log <i>segment</i>.\n+     *\n+     * @param segment the log <i>segment</i> to read data from\n+     * @return future represent the opened reader\n+     */\n+    Future<LogSegmentEntryReader> openReader(LogSegmentMetadata segment);\n+\n+}"},{"sha":"588c3663158e1d45215cf1b59800654a6b4dd81b","filename":"src/test/java/com/twitter/distributedlog/DLMTestUtil.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -17,7 +17,7 @@\n  */\n package com.twitter.distributedlog;\n \n-import com.twitter.distributedlog.impl.BKLogSegmentEntryWriter;\n+import com.twitter.distributedlog.impl.logsegment.BKLogSegmentEntryWriter;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.metadata.BKDLConfig;\n import com.twitter.distributedlog.metadata.DLMetadata;"},{"sha":"b3502554b8c6ce07fbd115ec3b103228583d19c7","filename":"src/test/java/com/twitter/distributedlog/TestBKLogSegmentWriter.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogSegmentWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogSegmentWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKLogSegmentWriter.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -21,7 +21,7 @@\n import com.twitter.distributedlog.exceptions.EndOfStreamException;\n import com.twitter.distributedlog.exceptions.WriteCancelledException;\n import com.twitter.distributedlog.exceptions.WriteException;\n-import com.twitter.distributedlog.impl.BKLogSegmentEntryWriter;\n+import com.twitter.distributedlog.impl.logsegment.BKLogSegmentEntryWriter;\n import com.twitter.distributedlog.io.Abortables;\n import com.twitter.distributedlog.lock.SessionLockFactory;\n import com.twitter.distributedlog.lock.ZKDistributedLock;"},{"sha":"a388b68e0d869b8ef695ff12543fa69e99ffdc69","filename":"src/test/java/com/twitter/distributedlog/TestDistributedLogBase.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -19,7 +19,7 @@\n \n import static org.junit.Assert.assertTrue;\n \n-import com.twitter.distributedlog.impl.BKLogSegmentEntryWriter;\n+import com.twitter.distributedlog.impl.logsegment.BKLogSegmentEntryWriter;\n import com.twitter.distributedlog.logsegment.LogSegmentEntryWriter;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.namespace.DistributedLogNamespace;"},{"sha":"9a194c4d12f20554048060b4abd174974ff5913e","filename":"src/test/java/com/twitter/distributedlog/impl/logsegment/TestBKLogSegmentEntryReader.java","status":"added","additions":553,"deletions":0,"changes":553,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FTestBKLogSegmentEntryReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FTestBKLogSegmentEntryReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FTestBKLogSegmentEntryReader.java?ref=e2c6bc0d7faa7b7912a51a7a4ed6e1b9ac5653bf","patch":"@@ -0,0 +1,553 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.impl.logsegment;\n+\n+import com.google.common.collect.Lists;\n+import com.twitter.distributedlog.AsyncLogWriter;\n+import com.twitter.distributedlog.BookKeeperClient;\n+import com.twitter.distributedlog.BookKeeperClientBuilder;\n+import com.twitter.distributedlog.DLMTestUtil;\n+import com.twitter.distributedlog.DLSN;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n+import com.twitter.distributedlog.DistributedLogManager;\n+import com.twitter.distributedlog.Entry;\n+import com.twitter.distributedlog.LogRecord;\n+import com.twitter.distributedlog.LogRecordWithDLSN;\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import com.twitter.distributedlog.TestDistributedLogBase;\n+import com.twitter.distributedlog.exceptions.EndOfLogSegmentException;\n+import com.twitter.distributedlog.exceptions.ReadCancelledException;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.util.Future;\n+import org.apache.bookkeeper.client.BookKeeper;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TestName;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Charsets.UTF_8;\n+import static org.junit.Assert.*;\n+\n+/**\n+ * Test Case for {@link BKLogSegmentEntryReader}\n+ */\n+public class TestBKLogSegmentEntryReader extends TestDistributedLogBase {\n+\n+    @Rule\n+    public TestName runtime = new TestName();\n+    private OrderedScheduler scheduler;\n+    private BookKeeperClient bkc;\n+\n+    @Before\n+    public void setup() throws Exception {\n+        super.setup();\n+        bkc = BookKeeperClientBuilder.newBuilder()\n+                .name(\"test-bk\")\n+                .dlConfig(conf)\n+                .ledgersPath(\"/ledgers\")\n+                .zkServers(bkutil.getZkServers())\n+                .build();\n+        scheduler = OrderedScheduler.newBuilder()\n+                .name(\"test-bk-logsegment-entry-reader\")\n+                .corePoolSize(1)\n+                .build();\n+    }\n+\n+    @After\n+    public void teardown() throws Exception {\n+        if (null != bkc) {\n+            bkc.close();\n+        }\n+        if (null != scheduler) {\n+            scheduler.shutdown();\n+        }\n+        super.teardown();\n+    }\n+\n+    BKLogSegmentEntryReader createEntryReader(LogSegmentMetadata segment,\n+                                              long startEntryId,\n+                                              DistributedLogConfiguration conf)\n+            throws Exception {\n+        LedgerHandle lh;\n+        if (segment.isInProgress()) {\n+            lh = bkc.get().openLedgerNoRecovery(\n+                    segment.getLedgerId(),\n+                    BookKeeper.DigestType.CRC32,\n+                    conf.getBKDigestPW().getBytes(UTF_8));\n+        } else {\n+            lh = bkc.get().openLedger(\n+                    segment.getLedgerId(),\n+                    BookKeeper.DigestType.CRC32,\n+                    conf.getBKDigestPW().getBytes(UTF_8));\n+        }\n+        return new BKLogSegmentEntryReader(\n+                segment,\n+                lh,\n+                startEntryId,\n+                bkc.get(),\n+                scheduler,\n+                conf);\n+    }\n+\n+    void generateCompletedLogSegments(DistributedLogManager dlm,\n+                                      DistributedLogConfiguration conf,\n+                                      long numCompletedSegments,\n+                                      long segmentSize) throws Exception {\n+        long txid = 1L;\n+        for (long i = 0; i < numCompletedSegments; i++) {\n+            AsyncLogWriter writer = FutureUtils.result(dlm.openAsyncLogWriter());\n+            for (long j = 1; j <= segmentSize; j++) {\n+                FutureUtils.result(writer.write(DLMTestUtil.getLogRecordInstance(txid++)));\n+                LogRecord ctrlRecord = DLMTestUtil.getLogRecordInstance(txid);\n+                ctrlRecord.setControl();\n+                FutureUtils.result(writer.write(ctrlRecord));\n+            }\n+            Utils.close(writer);\n+        }\n+    }\n+\n+    AsyncLogWriter createInprogressLogSegment(DistributedLogManager dlm,\n+                                              DistributedLogConfiguration conf,\n+                                              long segmentSize) throws Exception {\n+        AsyncLogWriter writer = FutureUtils.result(dlm.openAsyncLogWriter());\n+        for (long i = 1L; i <= segmentSize; i++) {\n+            FutureUtils.result(writer.write(DLMTestUtil.getLogRecordInstance(i)));\n+            LogRecord ctrlRecord = DLMTestUtil.getLogRecordInstance(i);\n+            ctrlRecord.setControl();\n+            FutureUtils.result(writer.write(ctrlRecord));\n+        }\n+        return writer;\n+    }\n+\n+    @Test(timeout = 60000)\n+    public void testReadEntriesFromCompleteLogSegment() throws Exception {\n+        DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n+        confLocal.addConfiguration(conf);\n+        confLocal.setOutputBufferSize(0);\n+        confLocal.setPeriodicFlushFrequencyMilliSeconds(0);\n+        confLocal.setImmediateFlushEnabled(false);\n+        confLocal.setNumPrefetchEntriesPerLogSegment(10);\n+        confLocal.setMaxPrefetchEntriesPerLogSegment(10);\n+        DistributedLogManager dlm = createNewDLM(confLocal, runtime.getMethodName());\n+        generateCompletedLogSegments(dlm, confLocal, 1, 20);\n+        List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+        assertEquals(segments.size() + \" log segments found, expected to be only one\",\n+                1, segments.size());\n+\n+        BKLogSegmentEntryReader reader = createEntryReader(segments.get(0), 0, confLocal);\n+        reader.start();\n+        boolean done = false;\n+        long txId = 1L;\n+        long entryId = 0L;\n+        while (!done) {\n+            Entry.Reader entryReader;\n+            try {\n+                entryReader = FutureUtils.result(reader.readNext(1)).get(0);\n+            } catch (EndOfLogSegmentException eol) {\n+                done = true;\n+                continue;\n+            }\n+            LogRecordWithDLSN record = entryReader.nextRecord();\n+            while (null != record) {\n+                if (!record.isControl()) {\n+                    DLMTestUtil.verifyLogRecord(record);\n+                    assertEquals(txId, record.getTransactionId());\n+                    ++txId;\n+                }\n+                DLSN dlsn = record.getDlsn();\n+                assertEquals(1L, dlsn.getLogSegmentSequenceNo());\n+                assertEquals(entryId, dlsn.getEntryId());\n+                record = entryReader.nextRecord();\n+            }\n+            ++entryId;\n+        }\n+        assertEquals(21, txId);\n+        Utils.close(reader);\n+    }\n+\n+    @Test(timeout = 60000)\n+    public void testCloseReaderToCancelPendingReads() throws Exception {\n+        DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n+        confLocal.addConfiguration(conf);\n+        confLocal.setNumPrefetchEntriesPerLogSegment(10);\n+        confLocal.setMaxPrefetchEntriesPerLogSegment(10);\n+        DistributedLogManager dlm = createNewDLM(confLocal, runtime.getMethodName());\n+        DLMTestUtil.generateCompletedLogSegments(dlm, confLocal, 1, 20);\n+        List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+        assertEquals(segments.size() + \" log segments found, expected to be only one\",\n+                1, segments.size());\n+\n+        BKLogSegmentEntryReader reader = createEntryReader(segments.get(0), 0, confLocal);\n+        List<Future<List<Entry.Reader>>> futures = Lists.newArrayList();\n+        for (int i = 0; i < 5; i++) {\n+            futures.add(reader.readNext(1));\n+        }\n+        assertFalse(\"Reader should not be closed yet\", reader.isClosed());\n+        Utils.close(reader);\n+        for (Future<List<Entry.Reader>> future : futures) {\n+            try {\n+                FutureUtils.result(future);\n+                fail(\"The read request should be cancelled\");\n+            } catch (ReadCancelledException rce) {\n+                // expected\n+            }\n+        }\n+        assertTrue(\"Reader should be closed yet\", reader.isClosed());\n+    }\n+\n+    @Test(timeout = 60000)\n+    public void testMaxPrefetchEntriesSmallBatch() throws Exception {\n+        DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n+        confLocal.addConfiguration(conf);\n+        confLocal.setOutputBufferSize(0);\n+        confLocal.setPeriodicFlushFrequencyMilliSeconds(0);\n+        confLocal.setImmediateFlushEnabled(false);\n+        confLocal.setNumPrefetchEntriesPerLogSegment(2);\n+        confLocal.setMaxPrefetchEntriesPerLogSegment(10);\n+        DistributedLogManager dlm = createNewDLM(confLocal, runtime.getMethodName());\n+        generateCompletedLogSegments(dlm, confLocal, 1, 20);\n+        List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+        assertEquals(segments.size() + \" log segments found, expected to be only one\",\n+                1, segments.size());\n+\n+        BKLogSegmentEntryReader reader = createEntryReader(segments.get(0), 0, confLocal);\n+        reader.start();\n+\n+        // wait for the read ahead entries to become available\n+        while (reader.readAheadEntries.size() < 10) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+\n+        long txId = 1L;\n+        long entryId = 0L;\n+\n+\n+        assertEquals(10, reader.readAheadEntries.size());\n+        assertEquals(10, reader.getNextEntryId());\n+        // read first entry\n+        Entry.Reader entryReader = FutureUtils.result(reader.readNext(1)).get(0);\n+        LogRecordWithDLSN record = entryReader.nextRecord();\n+        while (null != record) {\n+            if (!record.isControl()) {\n+                DLMTestUtil.verifyLogRecord(record);\n+                assertEquals(txId, record.getTransactionId());\n+                ++txId;\n+            }\n+            DLSN dlsn = record.getDlsn();\n+            assertEquals(1L, dlsn.getLogSegmentSequenceNo());\n+            assertEquals(entryId, dlsn.getEntryId());\n+            record = entryReader.nextRecord();\n+        }\n+        ++entryId;\n+        assertEquals(2L, txId);\n+        // wait for the read ahead entries to become 10 again\n+        while (reader.readAheadEntries.size() < 10) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+\n+        assertEquals(10, reader.readAheadEntries.size());\n+        assertEquals(11, reader.getNextEntryId());\n+\n+        Utils.close(reader);\n+    }\n+\n+    @Test(timeout = 60000)\n+    public void testMaxPrefetchEntriesLargeBatch() throws Exception {\n+        DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n+        confLocal.addConfiguration(conf);\n+        confLocal.setOutputBufferSize(0);\n+        confLocal.setPeriodicFlushFrequencyMilliSeconds(0);\n+        confLocal.setImmediateFlushEnabled(false);\n+        confLocal.setNumPrefetchEntriesPerLogSegment(10);\n+        confLocal.setMaxPrefetchEntriesPerLogSegment(5);\n+        DistributedLogManager dlm = createNewDLM(confLocal, runtime.getMethodName());\n+        generateCompletedLogSegments(dlm, confLocal, 1, 20);\n+        List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+        assertEquals(segments.size() + \" log segments found, expected to be only one\",\n+                1, segments.size());\n+\n+        BKLogSegmentEntryReader reader = createEntryReader(segments.get(0), 0, confLocal);\n+        reader.start();\n+\n+        // wait for the read ahead entries to become available\n+        while (reader.readAheadEntries.size() < 5) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+\n+        long txId = 1L;\n+        long entryId = 0L;\n+\n+        assertEquals(5, reader.readAheadEntries.size());\n+        assertEquals(5, reader.getNextEntryId());\n+        // read first entry\n+        Entry.Reader entryReader = FutureUtils.result(reader.readNext(1)).get(0);\n+        LogRecordWithDLSN record = entryReader.nextRecord();\n+        while (null != record) {\n+            if (!record.isControl()) {\n+                DLMTestUtil.verifyLogRecord(record);\n+                assertEquals(txId, record.getTransactionId());\n+                ++txId;\n+            }\n+            DLSN dlsn = record.getDlsn();\n+            assertEquals(1L, dlsn.getLogSegmentSequenceNo());\n+            assertEquals(entryId, dlsn.getEntryId());\n+            record = entryReader.nextRecord();\n+        }\n+        ++entryId;\n+        assertEquals(2L, txId);\n+        // wait for the read ahead entries to become 10 again\n+        while (reader.readAheadEntries.size() < 5) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+\n+        assertEquals(5, reader.readAheadEntries.size());\n+        assertEquals(6, reader.getNextEntryId());\n+\n+        Utils.close(reader);\n+    }\n+\n+    @Test(timeout = 60000)\n+    public void testMaxPrefetchEntriesSmallSegment() throws Exception {\n+        DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n+        confLocal.addConfiguration(conf);\n+        confLocal.setOutputBufferSize(0);\n+        confLocal.setPeriodicFlushFrequencyMilliSeconds(0);\n+        confLocal.setImmediateFlushEnabled(false);\n+        confLocal.setNumPrefetchEntriesPerLogSegment(10);\n+        confLocal.setMaxPrefetchEntriesPerLogSegment(20);\n+        DistributedLogManager dlm = createNewDLM(confLocal, runtime.getMethodName());\n+        generateCompletedLogSegments(dlm, confLocal, 1, 5);\n+        List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+        assertEquals(segments.size() + \" log segments found, expected to be only one\",\n+                1, segments.size());\n+\n+        BKLogSegmentEntryReader reader = createEntryReader(segments.get(0), 0, confLocal);\n+        reader.start();\n+\n+        // wait for the read ahead entries to become available\n+        while (reader.readAheadEntries.size() < (reader.getLastAddConfirmed() + 1)) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+\n+        long txId = 1L;\n+        long entryId = 0L;\n+\n+        assertEquals((reader.getLastAddConfirmed() + 1), reader.readAheadEntries.size());\n+        assertEquals((reader.getLastAddConfirmed() + 1), reader.getNextEntryId());\n+        // read first entry\n+        Entry.Reader entryReader = FutureUtils.result(reader.readNext(1)).get(0);\n+        LogRecordWithDLSN record = entryReader.nextRecord();\n+        while (null != record) {\n+            if (!record.isControl()) {\n+                DLMTestUtil.verifyLogRecord(record);\n+                assertEquals(txId, record.getTransactionId());\n+                ++txId;\n+            }\n+            DLSN dlsn = record.getDlsn();\n+            assertEquals(1L, dlsn.getLogSegmentSequenceNo());\n+            assertEquals(entryId, dlsn.getEntryId());\n+            record = entryReader.nextRecord();\n+        }\n+        ++entryId;\n+        assertEquals(2L, txId);\n+        assertEquals(reader.getLastAddConfirmed(), reader.readAheadEntries.size());\n+        assertEquals((reader.getLastAddConfirmed() + 1), reader.getNextEntryId());\n+\n+        Utils.close(reader);\n+    }\n+\n+    @Test(timeout = 60000)\n+    public void testReadEntriesFromInprogressSegment() throws Exception {\n+        DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n+        confLocal.addConfiguration(conf);\n+        confLocal.setOutputBufferSize(0);\n+        confLocal.setPeriodicFlushFrequencyMilliSeconds(0);\n+        confLocal.setImmediateFlushEnabled(false);\n+        confLocal.setNumPrefetchEntriesPerLogSegment(20);\n+        confLocal.setMaxPrefetchEntriesPerLogSegment(20);\n+        DistributedLogManager dlm = createNewDLM(confLocal, runtime.getMethodName());\n+        AsyncLogWriter writer = createInprogressLogSegment(dlm, confLocal, 5);\n+        List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+        assertEquals(segments.size() + \" log segments found, expected to be only one\",\n+                1, segments.size());\n+\n+        BKLogSegmentEntryReader reader = createEntryReader(segments.get(0), 0, confLocal);\n+        reader.start();\n+\n+        long expectedLastAddConfirmed = 8L;\n+        // wait until sending out all prefetch requests\n+        while (reader.readAheadEntries.size() < expectedLastAddConfirmed + 2) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+        assertEquals(expectedLastAddConfirmed + 2, reader.getNextEntryId());\n+\n+        long txId = 1L;\n+        long entryId = 0L;\n+        while (true) {\n+            Entry.Reader entryReader = FutureUtils.result(reader.readNext(1)).get(0);\n+            LogRecordWithDLSN record = entryReader.nextRecord();\n+            while (null != record) {\n+                if (!record.isControl()) {\n+                    DLMTestUtil.verifyLogRecord(record);\n+                    assertEquals(txId, record.getTransactionId());\n+                    ++txId;\n+                }\n+                DLSN dlsn = record.getDlsn();\n+                assertEquals(1L, dlsn.getLogSegmentSequenceNo());\n+                assertEquals(entryId, dlsn.getEntryId());\n+                record = entryReader.nextRecord();\n+            }\n+            ++entryId;\n+            if (entryId == expectedLastAddConfirmed + 1) {\n+                break;\n+            }\n+        }\n+        assertEquals(6L, txId);\n+\n+        Future<List<Entry.Reader>> nextReadFuture = reader.readNext(1);\n+        // write another record to commit previous writes\n+        FutureUtils.result(writer.write(DLMTestUtil.getLogRecordInstance(txId)));\n+        // the long poll will be satisfied\n+        List<Entry.Reader> nextReadEntries = FutureUtils.result(nextReadFuture);\n+        assertEquals(1, nextReadEntries.size());\n+        Entry.Reader entryReader = nextReadEntries.get(0);\n+        LogRecordWithDLSN record = entryReader.nextRecord();\n+        assertNotNull(record);\n+        assertTrue(record.isControl());\n+        assertNull(entryReader.nextRecord());\n+        // once the read is advanced, we will prefetch next record\n+        while (reader.getNextEntryId() <= entryId) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+        assertEquals(entryId + 2, reader.getNextEntryId());\n+        assertEquals(1, reader.readAheadEntries.size());\n+\n+        Utils.close(reader);\n+        Utils.close(writer);\n+    }\n+\n+    @Test(timeout = 60000)\n+    public void testReadEntriesOnStateChange() throws Exception {\n+        DistributedLogConfiguration confLocal = new DistributedLogConfiguration();\n+        confLocal.addConfiguration(conf);\n+        confLocal.setOutputBufferSize(0);\n+        confLocal.setPeriodicFlushFrequencyMilliSeconds(0);\n+        confLocal.setImmediateFlushEnabled(false);\n+        confLocal.setNumPrefetchEntriesPerLogSegment(20);\n+        confLocal.setMaxPrefetchEntriesPerLogSegment(20);\n+        DistributedLogManager dlm = createNewDLM(confLocal, runtime.getMethodName());\n+        AsyncLogWriter writer = createInprogressLogSegment(dlm, confLocal, 5);\n+        List<LogSegmentMetadata> segments = dlm.getLogSegments();\n+        assertEquals(segments.size() + \" log segments found, expected to be only one\",\n+                1, segments.size());\n+\n+        BKLogSegmentEntryReader reader = createEntryReader(segments.get(0), 0, confLocal);\n+        reader.start();\n+\n+        long expectedLastAddConfirmed = 8L;\n+        // wait until sending out all prefetch requests\n+        while (reader.readAheadEntries.size() < expectedLastAddConfirmed + 2) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+        assertEquals(expectedLastAddConfirmed + 2, reader.getNextEntryId());\n+\n+        long txId = 1L;\n+        long entryId = 0L;\n+        while (true) {\n+            Entry.Reader entryReader = FutureUtils.result(reader.readNext(1)).get(0);\n+            LogRecordWithDLSN record = entryReader.nextRecord();\n+            while (null != record) {\n+                if (!record.isControl()) {\n+                    DLMTestUtil.verifyLogRecord(record);\n+                    assertEquals(txId, record.getTransactionId());\n+                    ++txId;\n+                }\n+                DLSN dlsn = record.getDlsn();\n+                assertEquals(1L, dlsn.getLogSegmentSequenceNo());\n+                assertEquals(entryId, dlsn.getEntryId());\n+                record = entryReader.nextRecord();\n+            }\n+            ++entryId;\n+            if (entryId == expectedLastAddConfirmed + 1) {\n+                break;\n+            }\n+        }\n+        assertEquals(6L, txId);\n+\n+        Future<List<Entry.Reader>> nextReadFuture = reader.readNext(1);\n+        // write another record to commit previous writes\n+        FutureUtils.result(writer.write(DLMTestUtil.getLogRecordInstance(txId)));\n+        // the long poll will be satisfied\n+        List<Entry.Reader> nextReadEntries = FutureUtils.result(nextReadFuture);\n+        assertEquals(1, nextReadEntries.size());\n+        Entry.Reader entryReader = nextReadEntries.get(0);\n+        LogRecordWithDLSN record = entryReader.nextRecord();\n+        assertNotNull(record);\n+        assertTrue(record.isControl());\n+        assertNull(entryReader.nextRecord());\n+        // once the read is advanced, we will prefetch next record\n+        while (reader.getNextEntryId() <= entryId) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+        assertEquals(entryId + 2, reader.getNextEntryId());\n+        assertEquals(1, reader.readAheadEntries.size());\n+\n+        // advance the entry id\n+        ++entryId;\n+        // close the writer, the write will be committed\n+        Utils.close(writer);\n+        entryReader = FutureUtils.result(reader.readNext(1)).get(0);\n+        record = entryReader.nextRecord();\n+        assertNotNull(record);\n+        assertFalse(record.isControl());\n+        assertNull(entryReader.nextRecord());\n+        while (reader.getNextEntryId() <= entryId + 1) {\n+            TimeUnit.MILLISECONDS.sleep(10);\n+        }\n+        assertEquals(entryId + 2, reader.getNextEntryId());\n+        assertEquals(1, reader.readAheadEntries.size());\n+\n+        // get the new log segment\n+        List<LogSegmentMetadata> newSegments = dlm.getLogSegments();\n+        assertEquals(1, newSegments.size());\n+        assertFalse(newSegments.get(0).isInProgress());\n+        reader.onLogSegmentMetadataUpdated(newSegments.get(0));\n+        // when reader received the new log segments. the outstanding long poll\n+        // should be cancelled and end of log segment should be signaled correctly\n+        try {\n+            // when we closed the log segment, another control record will be\n+            // written, so we loop over the reader until we reach end of log segment.\n+            FutureUtils.result(reader.readNext(1));\n+            FutureUtils.result(reader.readNext(1));\n+            fail(\"Should reach end of log segment\");\n+        } catch (EndOfLogSegmentException eol) {\n+            // expected\n+        }\n+        Utils.close(reader);\n+    }\n+\n+}"}]}