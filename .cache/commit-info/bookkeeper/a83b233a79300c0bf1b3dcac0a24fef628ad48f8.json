{"sha":"a83b233a79300c0bf1b3dcac0a24fef628ad48f8","node_id":"MDY6Q29tbWl0NDc4NTkyNTI2OmE4M2IyMzNhNzkzMDBjMGJmMWIzZGNhYzBhMjRmZWY2MjhhZDQ4Zjg=","commit":{"author":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-12-29T01:09:57Z"},"committer":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-12-29T10:13:02Z"},"message":"DL-162: Use log segment entry store interface\n\n- Use log segment entry store interface\n- Delete the old readahead implementation","tree":{"sha":"223a39a8465bc77586e284da4bd1eb8efe6bcbbf","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/trees/223a39a8465bc77586e284da4bd1eb8efe6bcbbf"},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/commits/a83b233a79300c0bf1b3dcac0a24fef628ad48f8","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/a83b233a79300c0bf1b3dcac0a24fef628ad48f8","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/a83b233a79300c0bf1b3dcac0a24fef628ad48f8","comments_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/comments","author":null,"committer":null,"parents":[{"sha":"1166e11904ab83ec64e0147998cebffc653bdbf3","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/1166e11904ab83ec64e0147998cebffc653bdbf3","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/1166e11904ab83ec64e0147998cebffc653bdbf3"}],"stats":{"total":3518,"additions":505,"deletions":3013},"files":[{"sha":"b9d0365e5c759af3aafd3c84925f4efa2ede27d1","filename":"src/main/java/com/twitter/distributedlog/BKAsyncLogReader.java","status":"modified","additions":33,"deletions":35,"changes":68,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReader.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -409,43 +409,39 @@ private synchronized Future<List<LogRecordWithDLSN>> readInternal(int numEntries\n         final PendingReadRequest readRequest = new PendingReadRequest(numEntries, deadlineTime, deadlineTimeUnit);\n \n         if (null == readAheadReader) {\n-            try {\n-                final ReadAheadEntryReader readAheadEntryReader = this.readAheadReader = new ReadAheadEntryReader(\n-                        getStreamName(),\n-                        getStartDLSN(),\n-                        bkDistributedLogManager.getConf(),\n-                        readHandler,\n-                        bkDistributedLogManager.getReaderEntryStore(),\n-                        bkDistributedLogManager.getScheduler(),\n-                        Ticker.systemTicker(),\n-                        bkDistributedLogManager.alertStatsLogger);\n-                readHandler.checkLogStreamExists().addEventListener(new FutureEventListener<Void>() {\n-                    @Override\n-                    public void onSuccess(Void value) {\n-                        try {\n-                            readHandler.registerListener(readAheadEntryReader);\n-                            readHandler.asyncStartFetchLogSegments()\n-                                    .map(new AbstractFunction1<Versioned<List<LogSegmentMetadata>>, BoxedUnit>() {\n-                                        @Override\n-                                        public BoxedUnit apply(Versioned<List<LogSegmentMetadata>> logSegments) {\n-                                            readAheadEntryReader.addStateChangeNotification(BKAsyncLogReader.this);\n-                                            readAheadEntryReader.start(logSegments.getValue());\n-                                            return BoxedUnit.UNIT;\n-                                        }\n-                                    });\n-                        } catch (Exception exc) {\n-                            notifyOnError(exc);\n-                        }\n+            final ReadAheadEntryReader readAheadEntryReader = this.readAheadReader = new ReadAheadEntryReader(\n+                    getStreamName(),\n+                    getStartDLSN(),\n+                    bkDistributedLogManager.getConf(),\n+                    readHandler,\n+                    bkDistributedLogManager.getReaderEntryStore(),\n+                    bkDistributedLogManager.getScheduler(),\n+                    Ticker.systemTicker(),\n+                    bkDistributedLogManager.alertStatsLogger);\n+            readHandler.checkLogStreamExists().addEventListener(new FutureEventListener<Void>() {\n+                @Override\n+                public void onSuccess(Void value) {\n+                    try {\n+                        readHandler.registerListener(readAheadEntryReader);\n+                        readHandler.asyncStartFetchLogSegments()\n+                                .map(new AbstractFunction1<Versioned<List<LogSegmentMetadata>>, BoxedUnit>() {\n+                                    @Override\n+                                    public BoxedUnit apply(Versioned<List<LogSegmentMetadata>> logSegments) {\n+                                        readAheadEntryReader.addStateChangeNotification(BKAsyncLogReader.this);\n+                                        readAheadEntryReader.start(logSegments.getValue());\n+                                        return BoxedUnit.UNIT;\n+                                    }\n+                                });\n+                    } catch (Exception exc) {\n+                        notifyOnError(exc);\n                     }\n+                }\n \n-                    @Override\n-                    public void onFailure(Throwable cause) {\n-                        notifyOnError(cause);\n-                    }\n-                });\n-            } catch (IOException ioe) {\n-                notifyOnError(ioe);\n-            }\n+                @Override\n+                public void onFailure(Throwable cause) {\n+                    notifyOnError(cause);\n+                }\n+            });\n         }\n \n         if (checkClosedOrInError(\"readNext\")) {\n@@ -598,6 +594,8 @@ public void run() {\n                 }\n                 lastProcessTime.reset().start();\n \n+                lastProcessTime.reset().start();\n+\n                 // If the oldest pending promise is interrupted then we must mark\n                 // the reader in error and abort all pending reads since we dont\n                 // know the last consumed read"},{"sha":"d20cc6a87778fec6be6a19b83d16f9957d07d43e","filename":"src/main/java/com/twitter/distributedlog/BKDistributedLogManager.java","status":"modified","additions":24,"deletions":35,"changes":59,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -50,7 +50,6 @@\n import com.twitter.distributedlog.metadata.BKDLConfig;\n import com.twitter.distributedlog.metadata.LogStreamMetadataStore;\n import com.twitter.distributedlog.stats.BroadCastStatsLogger;\n-import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n import com.twitter.distributedlog.subscription.SubscriptionStateStore;\n import com.twitter.distributedlog.subscription.SubscriptionsStore;\n import com.twitter.distributedlog.subscription.ZKSubscriptionStateStore;\n@@ -72,8 +71,8 @@\n import com.twitter.util.FuturePool;\n import com.twitter.util.FutureEventListener;\n import com.twitter.util.Promise;\n-import org.apache.bookkeeper.stats.AlertStatsLogger;\n import org.apache.bookkeeper.feature.FeatureProvider;\n+import org.apache.bookkeeper.stats.AlertStatsLogger;\n import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.bookkeeper.stats.StatsLogger;\n import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n@@ -132,7 +131,6 @@ public DLSN apply(LogRecordWithDLSN record) {\n                 }\n             };\n \n-\n     private final String clientId;\n     private final int regionId;\n     private final String streamIdentifier;\n@@ -160,10 +158,11 @@ public DLSN apply(LogRecordWithDLSN record) {\n     //       instantiating readers or writers.\n     private final BookKeeperClientBuilder writerBKCBuilder;\n     private final BookKeeperClient writerBKC;\n+    private final LogSegmentEntryStore writerEntryStore;\n     private final boolean ownWriterBKC;\n     private final BookKeeperClientBuilder readerBKCBuilder;\n     private final BookKeeperClient readerBKC;\n-    private LogSegmentEntryStore readerEntryStore = null;\n+    private final LogSegmentEntryStore readerEntryStore;\n     private final boolean ownReaderBKC;\n \n     //\n@@ -179,7 +178,6 @@ public DLSN apply(LogRecordWithDLSN record) {\n     private BKLogReadHandler readHandlerForListener = null;\n     private FuturePool readerFuturePool = null;\n     private final PendingReaders pendingReaders;\n-    private final ReadAheadExceptionsLogger readAheadExceptionsLogger;\n \n     // Failure Injector\n     private final AsyncFailureInjector failureInjector;\n@@ -230,7 +228,6 @@ public DLSN apply(LogRecordWithDLSN record) {\n              null,\n              null,\n              null,\n-             new ReadAheadExceptionsLogger(statsLogger),\n              DistributedLogConstants.UNKNOWN_CLIENT_ID,\n              DistributedLogConstants.LOCAL_REGION_ID,\n              null,\n@@ -259,7 +256,6 @@ public DLSN apply(LogRecordWithDLSN record) {\n      * @param readAheadScheduler readAhead scheduler used by readers\n      * @param channelFactory client socket channel factory to build bookkeeper clients\n      * @param requestTimer request timer to build bookkeeper clients\n-     * @param readAheadExceptionsLogger stats logger to record readahead exceptions\n      * @param clientId client id that used to initiate the locks\n      * @param regionId region id that would be encrypted as part of log segment metadata\n      *                 to indicate which region that the log segment will be created\n@@ -287,7 +283,6 @@ public DLSN apply(LogRecordWithDLSN record) {\n                             OrderedScheduler readAheadScheduler,\n                             ClientSocketChannelFactory channelFactory,\n                             HashedWheelTimer requestTimer,\n-                            ReadAheadExceptionsLogger readAheadExceptionsLogger,\n                             String clientId,\n                             Integer regionId,\n                             LedgerAllocator ledgerAllocator,\n@@ -296,7 +291,6 @@ public DLSN apply(LogRecordWithDLSN record) {\n                             StatsLogger statsLogger,\n                             StatsLogger perLogStatsLogger) throws IOException {\n         super(name, conf, uri, writerZKCBuilder, readerZKCBuilder, statsLogger);\n-        Preconditions.checkNotNull(readAheadExceptionsLogger, \"No ReadAhead Stats Logger Provided.\");\n         this.conf = conf;\n         this.dynConf = dynConf;\n         this.scheduler = scheduler;\n@@ -366,6 +360,12 @@ public DLSN apply(LogRecordWithDLSN record) {\n             this.ownWriterBKC = false;\n         }\n         this.writerBKC = this.writerBKCBuilder.build();\n+        this.writerEntryStore = new BKLogSegmentEntryStore(\n+                conf,\n+                writerBKC,\n+                scheduler,\n+                statsLogger,\n+                failureInjector);\n \n         // create the bkc for readers\n         if (null == readerBKCBuilder) {\n@@ -395,13 +395,18 @@ public DLSN apply(LogRecordWithDLSN record) {\n             this.ownReaderBKC = false;\n         }\n         this.readerBKC = this.readerBKCBuilder.build();\n+        this.readerEntryStore = new BKLogSegmentEntryStore(\n+                conf,\n+                readerBKC,\n+                scheduler,\n+                statsLogger,\n+                failureInjector);\n \n         // Feature Provider\n         this.featureProvider = featureProvider;\n \n         // Stats\n         this.alertStatsLogger = new AlertStatsLogger(this.perLogStatsLogger, \"dl_alert\");\n-        this.readAheadExceptionsLogger = readAheadExceptionsLogger;\n     }\n \n     @VisibleForTesting\n@@ -431,15 +436,7 @@ BookKeeperClient getReaderBKC() {\n         return this.readerBKC;\n     }\n \n-    synchronized LogSegmentEntryStore getReaderEntryStore() throws IOException {\n-        if (null == readerEntryStore) {\n-            readerEntryStore = new BKLogSegmentEntryStore(\n-                conf,\n-                readerBKC.get(),\n-                scheduler,\n-                statsLogger,\n-                failureInjector);\n-        }\n+    LogSegmentEntryStore getReaderEntryStore() {\n         return this.readerEntryStore;\n     }\n \n@@ -541,9 +538,9 @@ synchronized BKLogReadHandler createReadHandler(Optional<String> subscriberId,\n                 subscriberId,\n                 conf,\n                 dynConf,\n-                readerBKCBuilder,\n                 readerMetadataStore,\n                 logSegmentMetadataCache,\n+                readerEntryStore,\n                 scheduler,\n                 alertStatsLogger,\n                 statsLogger,\n@@ -622,9 +619,9 @@ private void createWriteHandler(LogMetadataForWriter logMetadata,\n         final BKLogWriteHandler writeHandler = new BKLogWriteHandler(\n                 logMetadata,\n                 conf,\n-                writerBKCBuilder,\n                 writerMetadataStore,\n                 logSegmentMetadataCache,\n+                writerEntryStore,\n                 scheduler,\n                 allocator,\n                 statsLogger,\n@@ -821,33 +818,25 @@ private Future<DLSN> getDLSNNotLessThanTxId(long fromTxnId,\n         if (segmentIdx < 0) {\n             return Future.value(new DLSN(segments.get(0).getLogSegmentSequenceNumber(), 0L, 0L));\n         }\n-        final LedgerHandleCache handleCache =\n-                LedgerHandleCache.newBuilder().bkc(readerBKC).conf(conf).build();\n         return getDLSNNotLessThanTxIdInSegment(\n                 fromTxnId,\n                 segmentIdx,\n                 segments,\n-                handleCache\n-        ).ensure(new AbstractFunction0<BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply() {\n-                handleCache.clear();\n-                return BoxedUnit.UNIT;\n-            }\n-        });\n+                readerEntryStore\n+        );\n     }\n \n     private Future<DLSN> getDLSNNotLessThanTxIdInSegment(final long fromTxnId,\n                                                          final int segmentIdx,\n                                                          final List<LogSegmentMetadata> segments,\n-                                                         final LedgerHandleCache handleCache) {\n+                                                         final LogSegmentEntryStore entryStore) {\n         final LogSegmentMetadata segment = segments.get(segmentIdx);\n         return ReadUtils.getLogRecordNotLessThanTxId(\n                 name,\n                 segment,\n                 fromTxnId,\n                 scheduler,\n-                handleCache,\n+                entryStore,\n                 Math.max(2, dynConf.getReadAheadBatchSize())\n         ).flatMap(new AbstractFunction1<Optional<LogRecordWithDLSN>, Future<DLSN>>() {\n             @Override\n@@ -870,7 +859,7 @@ public DLSN apply(LogRecordWithDLSN record) {\n                             fromTxnId,\n                             segmentIdx + 1,\n                             segments,\n-                            handleCache);\n+                            entryStore);\n                 }\n             }\n         });\n@@ -915,7 +904,7 @@ public AsyncLogReader getAsyncLogReader(long fromTxnId) throws IOException {\n      * </p>\n      *\n      * @see DLUtils#findLogSegmentNotLessThanTxnId(List, long)\n-     * @see ReadUtils#getLogRecordNotLessThanTxId(String, LogSegmentMetadata, long, ExecutorService, LedgerHandleCache, int)\n+     * @see ReadUtils#getLogRecordNotLessThanTxId(String, LogSegmentMetadata, long, ExecutorService, LogSegmentEntryStore, int)\n      * @param fromTxnId\n      *          transaction id to start reading from\n      * @return future representing the open result."},{"sha":"1a23228102b7e920cc94bb63844ed5441565b027","filename":"src/main/java/com/twitter/distributedlog/BKDistributedLogNamespace.java","status":"modified","additions":0,"deletions":10,"changes":10,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -43,7 +43,6 @@\n import com.twitter.distributedlog.metadata.LogMetadataStore;\n import com.twitter.distributedlog.metadata.LogStreamMetadataStore;\n import com.twitter.distributedlog.namespace.DistributedLogNamespace;\n-import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n import com.twitter.distributedlog.util.ConfUtils;\n import com.twitter.distributedlog.util.DLUtils;\n import com.twitter.distributedlog.util.FutureUtils;\n@@ -113,10 +112,6 @@\n  * See {@link PermitLimiter}.\n  * </ul>\n  *\n- * <h4>ReadAhead Exceptions</h4>\n- * Stats about exceptions that encountered in ReadAhead are exposed under <code>`scope`/exceptions</code>.\n- * See {@link ReadAheadExceptionsLogger}.\n- *\n  * <h4>DistributedLogManager</h4>\n  *\n  * All the core stats about reader and writer are exposed under current scope via {@link BKDistributedLogManager}.\n@@ -305,7 +300,6 @@ private static String getHostIpLockClientId() {\n     // Stats Loggers\n     private final StatsLogger statsLogger;\n     private final StatsLogger perLogStatsLogger;\n-    private final ReadAheadExceptionsLogger readAheadExceptionsLogger;\n \n     protected AtomicBoolean closed = new AtomicBoolean(false);\n \n@@ -436,9 +430,6 @@ private BKDistributedLogNamespace(\n             allocator = null;\n         }\n \n-        // Stats Loggers\n-        this.readAheadExceptionsLogger = new ReadAheadExceptionsLogger(statsLogger);\n-\n         // log metadata store\n         if (bkdlConfig.isFederatedNamespace() || conf.isFederatedNamespaceEnabled()) {\n             this.metadataStore = new FederatedZKLogMetadataStore(conf, namespace, sharedReaderZKCForDL, scheduler);\n@@ -895,7 +886,6 @@ protected DistributedLogManager createDistributedLogManager(\n                 readAheadExecutor,                  /* Read Aheader Executor */\n                 channelFactory,                     /* Netty Channel Factory */\n                 requestTimer,                       /* Request Timer */\n-                readAheadExceptionsLogger,          /* ReadAhead Exceptions Logger */\n                 clientId,                           /* Client Id */\n                 regionId,                           /* Region Id */\n                 dlmLedgerAlloctor,                  /* Ledger Allocator */"},{"sha":"0cf8ed5212857d961664acbb76132c3bb6aeacb3","filename":"src/main/java/com/twitter/distributedlog/BKLogHandler.java","status":"modified","additions":7,"deletions":26,"changes":33,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -17,12 +17,12 @@\n  */\n package com.twitter.distributedlog;\n \n-import com.google.common.base.Preconditions;\n import com.google.common.base.Stopwatch;\n import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n import com.twitter.distributedlog.exceptions.LogEmptyException;\n import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.logsegment.LogSegmentEntryStore;\n import com.twitter.distributedlog.metadata.LogMetadata;\n import com.twitter.distributedlog.io.AsyncAbortable;\n import com.twitter.distributedlog.io.AsyncCloseable;\n@@ -45,8 +45,6 @@\n import org.apache.commons.lang3.tuple.Pair;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import scala.runtime.AbstractFunction0;\n-import scala.runtime.BoxedUnit;\n \n import java.io.IOException;\n import java.util.ArrayList;\n@@ -89,10 +87,10 @@ public abstract class BKLogHandler implements AsyncCloseable, AsyncAbortable {\n \n     protected final LogMetadata logMetadata;\n     protected final DistributedLogConfiguration conf;\n-    protected final BookKeeperClient bookKeeperClient;\n     protected final LogStreamMetadataStore streamMetadataStore;\n     protected final LogSegmentMetadataStore metadataStore;\n     protected final LogSegmentMetadataCache metadataCache;\n+    protected final LogSegmentEntryStore entryStore;\n     protected final int firstNumEntriesPerReadLastRecordScan;\n     protected final int maxNumEntriesPerReadLastRecordScan;\n     protected volatile long lastLedgerRollingTimeMillis = -1;\n@@ -122,14 +120,13 @@ public abstract class BKLogHandler implements AsyncCloseable, AsyncAbortable {\n      */\n     BKLogHandler(LogMetadata metadata,\n                  DistributedLogConfiguration conf,\n-                 BookKeeperClientBuilder bkcBuilder,\n                  LogStreamMetadataStore streamMetadataStore,\n                  LogSegmentMetadataCache metadataCache,\n+                 LogSegmentEntryStore entryStore,\n                  OrderedScheduler scheduler,\n                  StatsLogger statsLogger,\n                  AlertStatsLogger alertStatsLogger,\n                  String lockClientId) {\n-        Preconditions.checkNotNull(bkcBuilder);\n         this.logMetadata = metadata;\n         this.conf = conf;\n         this.scheduler = scheduler;\n@@ -140,10 +137,10 @@ public abstract class BKLogHandler implements AsyncCloseable, AsyncAbortable {\n                 conf.isLogSegmentSequenceNumberValidationEnabled());\n         firstNumEntriesPerReadLastRecordScan = conf.getFirstNumEntriesPerReadLastRecordScan();\n         maxNumEntriesPerReadLastRecordScan = conf.getMaxNumEntriesPerReadLastRecordScan();\n-        this.bookKeeperClient = bkcBuilder.build();\n         this.streamMetadataStore = streamMetadataStore;\n         this.metadataStore = streamMetadataStore.getLogSegmentMetadataStore();\n         this.metadataCache = metadataCache;\n+        this.entryStore = entryStore;\n         this.lockClientId = lockClientId;\n \n         // Traces\n@@ -293,24 +290,16 @@ public void onFailure(Throwable cause) {\n     }\n \n     private Future<LogRecordWithDLSN> asyncReadFirstUserRecord(LogSegmentMetadata ledger, DLSN beginDLSN) {\n-        final LedgerHandleCache handleCache =\n-                LedgerHandleCache.newBuilder().bkc(bookKeeperClient).conf(conf).build();\n         return ReadUtils.asyncReadFirstUserRecord(\n                 getFullyQualifiedName(),\n                 ledger,\n                 firstNumEntriesPerReadLastRecordScan,\n                 maxNumEntriesPerReadLastRecordScan,\n                 new AtomicInteger(0),\n                 scheduler,\n-                handleCache,\n+                entryStore,\n                 beginDLSN\n-        ).ensure(new AbstractFunction0<BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply() {\n-                handleCache.clear();\n-                return BoxedUnit.UNIT;\n-            }\n-        });\n+        );\n     }\n \n     /**\n@@ -422,8 +411,6 @@ public Future<LogRecordWithDLSN> asyncReadLastRecord(final LogSegmentMetadata l,\n                                                          final boolean includeEndOfStream) {\n         final AtomicInteger numRecordsScanned = new AtomicInteger(0);\n         final Stopwatch stopwatch = Stopwatch.createStarted();\n-        final LedgerHandleCache handleCache =\n-                LedgerHandleCache.newBuilder().bkc(bookKeeperClient).conf(conf).build();\n         return ReadUtils.asyncReadLastRecord(\n                 getFullyQualifiedName(),\n                 l,\n@@ -434,7 +421,7 @@ public Future<LogRecordWithDLSN> asyncReadLastRecord(final LogSegmentMetadata l,\n                 maxNumEntriesPerReadLastRecordScan,\n                 numRecordsScanned,\n                 scheduler,\n-                handleCache\n+                entryStore\n         ).addEventListener(new FutureEventListener<LogRecordWithDLSN>() {\n             @Override\n             public void onSuccess(LogRecordWithDLSN value) {\n@@ -446,12 +433,6 @@ public void onSuccess(LogRecordWithDLSN value) {\n             public void onFailure(Throwable cause) {\n                 recoverLastEntryStats.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n             }\n-        }).ensure(new AbstractFunction0<BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply() {\n-                handleCache.clear();\n-                return BoxedUnit.UNIT;\n-            }\n         });\n     }\n "},{"sha":"8aa00e7bdb07192f87bab597e85c7b8acf8352c6","filename":"src/main/java/com/twitter/distributedlog/BKLogReadHandler.java","status":"modified","additions":3,"deletions":12,"changes":15,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -34,6 +34,7 @@\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.logsegment.LogSegmentEntryStore;\n import com.twitter.distributedlog.metadata.LogMetadataForReader;\n import com.twitter.distributedlog.lock.DistributedLock;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n@@ -106,7 +107,6 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n     static final Logger LOG = LoggerFactory.getLogger(BKLogReadHandler.class);\n \n     protected final LogMetadataForReader logMetadataForReader;\n-    protected final LedgerHandleCache handleCache;\n \n     protected final DynamicDistributedLogConfiguration dynConf;\n \n@@ -134,9 +134,9 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n                      Optional<String> subscriberId,\n                      DistributedLogConfiguration conf,\n                      DynamicDistributedLogConfiguration dynConf,\n-                     BookKeeperClientBuilder bkcBuilder,\n                      LogStreamMetadataStore streamMetadataStore,\n                      LogSegmentMetadataCache metadataCache,\n+                     LogSegmentEntryStore entryStore,\n                      OrderedScheduler scheduler,\n                      AlertStatsLogger alertStatsLogger,\n                      StatsLogger statsLogger,\n@@ -146,9 +146,9 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n                      boolean isHandleForReading) {\n         super(logMetadata,\n                 conf,\n-                bkcBuilder,\n                 streamMetadataStore,\n                 metadataCache,\n+                entryStore,\n                 scheduler,\n                 statsLogger,\n                 alertStatsLogger,\n@@ -158,12 +158,6 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n         this.perLogStatsLogger =\n                 isHandleForReading ? perLogStatsLogger : NullStatsLogger.INSTANCE;\n         this.readerStateNotification = readerStateNotification;\n-\n-        handleCache = LedgerHandleCache.newBuilder()\n-                .bkc(this.bookKeeperClient)\n-                .conf(conf)\n-                .statsLogger(statsLogger)\n-                .build();\n         this.subscriberId = subscriberId;\n     }\n \n@@ -265,9 +259,6 @@ public Future<Void> asyncClose() {\n                 .flatMap(new AbstractFunction1<Void, Future<Void>>() {\n             @Override\n             public Future<Void> apply(Void result) {\n-                if (null != handleCache) {\n-                    handleCache.clear();\n-                }\n                 // unregister the log segment listener\n                 metadataStore.unregisterLogSegmentListener(logMetadata.getLogSegmentsPath(), BKLogReadHandler.this);\n                 return Future.Void();"},{"sha":"25b25e25dc1348bfb270a9c5528184911e50de73","filename":"src/main/java/com/twitter/distributedlog/BKLogWriteHandler.java","status":"modified","additions":15,"deletions":31,"changes":46,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -30,6 +30,7 @@\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n import com.twitter.distributedlog.function.GetLastTxIdFunction;\n import com.twitter.distributedlog.impl.logsegment.BKLogSegmentEntryWriter;\n+import com.twitter.distributedlog.logsegment.LogSegmentEntryStore;\n import com.twitter.distributedlog.metadata.LogMetadataForWriter;\n import com.twitter.distributedlog.lock.DistributedLock;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n@@ -52,8 +53,6 @@\n import com.twitter.util.Future;\n import com.twitter.util.FutureEventListener;\n import com.twitter.util.Promise;\n-import org.apache.bookkeeper.client.AsyncCallback;\n-import org.apache.bookkeeper.client.BKException;\n import org.apache.bookkeeper.client.LedgerHandle;\n import org.apache.bookkeeper.feature.FeatureProvider;\n import org.apache.bookkeeper.stats.AlertStatsLogger;\n@@ -151,9 +150,9 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n      */\n     BKLogWriteHandler(LogMetadataForWriter logMetadata,\n                       DistributedLogConfiguration conf,\n-                      BookKeeperClientBuilder bkcBuilder,\n                       LogStreamMetadataStore streamMetadataStore,\n                       LogSegmentMetadataCache metadataCache,\n+                      LogSegmentEntryStore entryStore,\n                       OrderedScheduler scheduler,\n                       LedgerAllocator allocator,\n                       StatsLogger statsLogger,\n@@ -167,9 +166,9 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n                       DistributedLock lock /** owned by handler **/) {\n         super(logMetadata,\n                 conf,\n-                bkcBuilder,\n                 streamMetadataStore,\n                 metadataCache,\n+                entryStore,\n                 scheduler,\n                 statsLogger,\n                 alertStatsLogger,\n@@ -1222,33 +1221,18 @@ public void onFailure(Throwable cause) {\n                 deleteOpStats.registerFailedEvent(stopwatch.stop().elapsed(TimeUnit.MICROSECONDS));\n             }\n         });\n-        try {\n-            bookKeeperClient.get().asyncDeleteLedger(ledgerMetadata.getLogSegmentId(), new AsyncCallback.DeleteCallback() {\n-                @Override\n-                public void deleteComplete(int rc, Object ctx) {\n-                    if (BKException.Code.NoSuchLedgerExistsException == rc) {\n-                        LOG.warn(\"No ledger {} found to delete for {} : {}.\",\n-                                new Object[]{ledgerMetadata.getLogSegmentId(), getFullyQualifiedName(),\n-                                        ledgerMetadata});\n-                    } else if (BKException.Code.OK != rc) {\n-                        BKException bke = BKException.create(rc);\n-                        LOG.error(\"Couldn't delete ledger {} from bookkeeper for {} : \",\n-                                new Object[]{ledgerMetadata.getLogSegmentId(), getFullyQualifiedName(), bke});\n-                        promise.setException(bke);\n-                        return;\n-                    }\n-                    // after the ledger is deleted, we delete the metadata znode\n-                    scheduler.submit(new Runnable() {\n-                        @Override\n-                        public void run() {\n-                            deleteLogSegmentMetadata(ledgerMetadata, promise);\n-                        }\n-                    });\n-                }\n-            }, null);\n-        } catch (IOException e) {\n-            promise.setException(BKException.create(BKException.Code.BookieHandleNotAvailableException));\n-        }\n+        entryStore.deleteLogSegment(ledgerMetadata)\n+                .addEventListener(new FutureEventListener<LogSegmentMetadata>() {\n+            @Override\n+            public void onFailure(Throwable cause) {\n+                FutureUtils.setException(promise, cause);\n+            }\n+\n+            @Override\n+            public void onSuccess(LogSegmentMetadata segment) {\n+                deleteLogSegmentMetadata(segment, promise);\n+            }\n+        });\n         return promise;\n     }\n "},{"sha":"5a95e467f3693f0627f887aa0742cc2ea6a1a6a5","filename":"src/main/java/com/twitter/distributedlog/LedgerDescriptor.java","status":"removed","additions":0,"deletions":67,"changes":67,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerDescriptor.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerDescriptor.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerDescriptor.java?ref=1166e11904ab83ec64e0147998cebffc653bdbf3","patch":"@@ -1,67 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.twitter.distributedlog;\n-\n-public class LedgerDescriptor {\n-    private final long ledgerId;\n-    private final long logSegmentSequenceNo;\n-    private final boolean fenced;\n-\n-    public LedgerDescriptor(long ledgerId, long logSegmentSequenceNo, boolean fenced) {\n-        this.ledgerId = ledgerId;\n-        this.logSegmentSequenceNo = logSegmentSequenceNo;\n-        this.fenced = fenced;\n-    }\n-\n-    public long getLedgerId() {\n-        return ledgerId;\n-    }\n-\n-    public long getLogSegmentSequenceNo() {\n-        return logSegmentSequenceNo;\n-    }\n-\n-    public boolean isFenced() {\n-        return fenced;\n-    }\n-\n-    // Only compares the key portion\n-    @Override\n-    public boolean equals(Object other) {\n-        if (!(other instanceof LedgerDescriptor)) {\n-            return false;\n-        }\n-        LedgerDescriptor key = (LedgerDescriptor) other;\n-        return ledgerId == key.ledgerId &&\n-            fenced == key.fenced;\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return (int) (ledgerId * 13 ^ (fenced ? 0xFFFF : 0xF0F0) * 17);\n-    }\n-\n-    @Override\n-    public String toString() {\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(\"(lid=\").append(ledgerId).append(\", lseqno=\").append(logSegmentSequenceNo)\n-                .append(\", fenced=\").append(fenced).append(\")\");\n-        return sb.toString();\n-    }\n-}\n-"},{"sha":"49896fd349da757dbe16d9913c3a79fbb03cc788","filename":"src/main/java/com/twitter/distributedlog/LedgerHandleCache.java","status":"removed","additions":0,"deletions":463,"changes":463,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerHandleCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerHandleCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FLedgerHandleCache.java?ref=1166e11904ab83ec64e0147998cebffc653bdbf3","patch":"@@ -1,463 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.twitter.distributedlog;\n-\n-import com.google.common.base.Preconditions;\n-import com.google.common.base.Stopwatch;\n-import com.twitter.distributedlog.util.FutureUtils;\n-import com.twitter.util.Future;\n-import com.twitter.util.FutureEventListener;\n-import com.twitter.util.Promise;\n-import org.apache.bookkeeper.client.AsyncCallback;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.BookKeeper;\n-import org.apache.bookkeeper.client.LedgerEntry;\n-import org.apache.bookkeeper.client.LedgerHandle;\n-import org.apache.bookkeeper.stats.NullStatsLogger;\n-import org.apache.bookkeeper.stats.OpStatsLogger;\n-import org.apache.bookkeeper.stats.StatsLogger;\n-import org.apache.commons.lang3.tuple.Pair;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.IOException;\n-import java.util.Enumeration;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.atomic.AtomicLong;\n-\n-import static com.google.common.base.Charsets.UTF_8;\n-\n-/**\n- * A central place on managing open ledgers.\n- */\n-public class LedgerHandleCache {\n-    static final Logger LOG = LoggerFactory.getLogger(LedgerHandleCache.class);\n-\n-    public static Builder newBuilder() {\n-        return new Builder();\n-    }\n-\n-    public static class Builder {\n-\n-        private BookKeeperClient bkc;\n-        private String digestpw;\n-        private StatsLogger statsLogger = NullStatsLogger.INSTANCE;\n-\n-        private Builder() {}\n-\n-        public Builder bkc(BookKeeperClient bkc) {\n-            this.bkc = bkc;\n-            return this;\n-        }\n-\n-        public Builder conf(DistributedLogConfiguration conf) {\n-            this.digestpw = conf.getBKDigestPW();\n-            return this;\n-        }\n-\n-        public Builder statsLogger(StatsLogger statsLogger) {\n-            this.statsLogger = statsLogger;\n-            return this;\n-        }\n-\n-        public LedgerHandleCache build() {\n-            Preconditions.checkNotNull(bkc, \"No bookkeeper client is provided\");\n-            Preconditions.checkNotNull(digestpw, \"No bookkeeper digest password is provided\");\n-            Preconditions.checkNotNull(statsLogger, \"No stats logger is provided\");\n-            return new LedgerHandleCache(bkc, digestpw, statsLogger);\n-        }\n-    }\n-\n-    final ConcurrentHashMap<LedgerDescriptor, RefCountedLedgerHandle> handlesMap =\n-        new ConcurrentHashMap<LedgerDescriptor, RefCountedLedgerHandle>();\n-\n-    private final BookKeeperClient bkc;\n-    private final String digestpw;\n-\n-    private final OpStatsLogger openStats;\n-    private final OpStatsLogger openNoRecoveryStats;\n-\n-    private LedgerHandleCache(BookKeeperClient bkc, String digestpw, StatsLogger statsLogger) {\n-        this.bkc = bkc;\n-        this.digestpw = digestpw;\n-        // Stats\n-        openStats = statsLogger.getOpStatsLogger(\"open_ledger\");\n-        openNoRecoveryStats = statsLogger.getOpStatsLogger(\"open_ledger_no_recovery\");\n-    }\n-\n-    /**\n-     * Open the given ledger <i>ledgerDesc</i>.\n-     *\n-     * @param ledgerDesc\n-     *          ledger description\n-     * @param callback\n-     *          open callback.\n-     * @param ctx\n-     *          callback context\n-     */\n-    private void asyncOpenLedger(LedgerDescriptor ledgerDesc, AsyncCallback.OpenCallback callback, Object ctx) {\n-        try {\n-            if (!ledgerDesc.isFenced()) {\n-                bkc.get().asyncOpenLedgerNoRecovery(ledgerDesc.getLedgerId(),\n-                        BookKeeper.DigestType.CRC32, digestpw.getBytes(UTF_8), callback, ctx);\n-            } else {\n-                bkc.get().asyncOpenLedger(ledgerDesc.getLedgerId(),\n-                        BookKeeper.DigestType.CRC32, digestpw.getBytes(UTF_8), callback, ctx);\n-            }\n-        } catch (IOException ace) {\n-            // :) when we can't get bkc, it means bookie handle not available\n-            callback.openComplete(BKException.Code.BookieHandleNotAvailableException, null, ctx);\n-        }\n-    }\n-\n-    /**\n-     * Open the log segment.\n-     *\n-     * @param metadata\n-     *          the log segment metadata\n-     * @param fence\n-     *          whether to fence the log segment during open\n-     * @return a future presenting the open result.\n-     */\n-    public Future<LedgerDescriptor> asyncOpenLedger(LogSegmentMetadata metadata, boolean fence) {\n-        final Stopwatch stopwatch = Stopwatch.createStarted();\n-        final OpStatsLogger openStatsLogger = fence ? openStats : openNoRecoveryStats;\n-        final Promise<LedgerDescriptor> promise = new Promise<LedgerDescriptor>();\n-        final LedgerDescriptor ledgerDesc = new LedgerDescriptor(metadata.getLogSegmentId(), metadata.getLogSegmentSequenceNumber(), fence);\n-        RefCountedLedgerHandle refhandle = handlesMap.get(ledgerDesc);\n-        if (null == refhandle) {\n-            asyncOpenLedger(ledgerDesc, new AsyncCallback.OpenCallback() {\n-                @Override\n-                public void openComplete(int rc, LedgerHandle lh, Object ctx) {\n-                    if (BKException.Code.OK != rc) {\n-                        promise.setException(BKException.create(rc));\n-                        return;\n-                    }\n-                    RefCountedLedgerHandle newRefHandle = new RefCountedLedgerHandle(lh);\n-                    RefCountedLedgerHandle oldRefHandle = handlesMap.putIfAbsent(ledgerDesc, newRefHandle);\n-                    if (null != oldRefHandle) {\n-                        oldRefHandle.addRef();\n-                        if (newRefHandle.removeRef()) {\n-                            newRefHandle.handle.asyncClose(new AsyncCallback.CloseCallback() {\n-                                @Override\n-                                public void closeComplete(int i, LedgerHandle ledgerHandle, Object o) {\n-                                    // No action necessary\n-                                }\n-                            }, null);\n-                        }\n-                    }\n-                    promise.setValue(ledgerDesc);\n-                }\n-            }, null);\n-        } else {\n-            refhandle.addRef();\n-            promise.setValue(ledgerDesc);\n-        }\n-        return promise.addEventListener(new FutureEventListener<LedgerDescriptor>() {\n-            @Override\n-            public void onSuccess(LedgerDescriptor value) {\n-                openStatsLogger.registerSuccessfulEvent(stopwatch.elapsed(TimeUnit.MICROSECONDS));\n-            }\n-\n-            @Override\n-            public void onFailure(Throwable cause) {\n-                openStatsLogger.registerFailedEvent(stopwatch.elapsed(TimeUnit.MICROSECONDS));\n-            }\n-        });\n-    }\n-\n-    /**\n-     * Open a ledger synchronously.\n-     *\n-     * @param metadata\n-     *          log segment metadata\n-     * @param fence\n-     *          whether to fence the log segment during open\n-     * @return ledger descriptor\n-     * @throws BKException\n-     */\n-    public LedgerDescriptor openLedger(LogSegmentMetadata metadata, boolean fence) throws BKException {\n-        return FutureUtils.bkResult(asyncOpenLedger(metadata, fence));\n-    }\n-\n-    private RefCountedLedgerHandle getLedgerHandle(LedgerDescriptor ledgerDescriptor) {\n-        return null == ledgerDescriptor ? null : handlesMap.get(ledgerDescriptor);\n-    }\n-\n-    /**\n-     * Close the ledger asynchronously.\n-     *\n-     * @param ledgerDesc\n-     *          ledger descriptor.\n-     * @return future presenting the closing result.\n-     */\n-    public Future<Void> asyncCloseLedger(LedgerDescriptor ledgerDesc) {\n-        final Promise<Void> promise = new Promise<Void>();\n-\n-        RefCountedLedgerHandle refhandle = getLedgerHandle(ledgerDesc);\n-        if ((null != refhandle) && (refhandle.removeRef())) {\n-            refhandle = handlesMap.remove(ledgerDesc);\n-            if (refhandle.getRefCount() > 0) {\n-                // In the rare race condition that a ref count was added immediately\n-                // after the close de-refed it and the remove was called\n-\n-                // Try to put the handle back in the map\n-                handlesMap.putIfAbsent(ledgerDesc, refhandle);\n-\n-                // ReadOnlyLedgerHandles don't have much overhead, so lets just leave\n-                // the handle open even if it had already been replaced\n-                promise.setValue(null);\n-            } else {\n-                refhandle.handle.asyncClose(new AsyncCallback.CloseCallback() {\n-                    @Override\n-                    public void closeComplete(int rc, LedgerHandle ledgerHandle, Object ctx) {\n-                        if (BKException.Code.OK == rc) {\n-                            promise.setValue(null);\n-                        } else {\n-                            promise.setException(BKException.create(rc));\n-                        }\n-                    }\n-                }, null);\n-            }\n-        } else {\n-            promise.setValue(null);\n-        }\n-        return promise;\n-    }\n-\n-    /**\n-     * Close the ledger synchronously.\n-     *\n-     * @param ledgerDesc\n-     *          ledger descriptor.\n-     * @throws BKException\n-     */\n-    public void closeLedger(LedgerDescriptor ledgerDesc) throws BKException {\n-        FutureUtils.bkResult(asyncCloseLedger(ledgerDesc));\n-    }\n-\n-    /**\n-     * Get the last add confirmed of <code>ledgerDesc</code>.\n-     *\n-     * @param ledgerDesc\n-     *          ledger descriptor.\n-     * @return last add confirmed of <code>ledgerDesc</code>\n-     * @throws BKException\n-     */\n-    public long getLastAddConfirmed(LedgerDescriptor ledgerDesc) throws BKException {\n-        RefCountedLedgerHandle refhandle = getLedgerHandle(ledgerDesc);\n-\n-        if (null == refhandle) {\n-            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n-            throw BKException.create(BKException.Code.UnexpectedConditionException);\n-        }\n-\n-        return refhandle.handle.getLastAddConfirmed();\n-    }\n-\n-    /**\n-     * Whether a ledger is closed or not.\n-     *\n-     * @param ledgerDesc\n-     *          ledger descriptor.\n-     * @return true if a ledger is closed, otherwise false.\n-     * @throws BKException\n-     */\n-    public boolean isLedgerHandleClosed(LedgerDescriptor ledgerDesc) throws BKException {\n-        RefCountedLedgerHandle refhandle = getLedgerHandle(ledgerDesc);\n-\n-        if (null == refhandle) {\n-            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n-            throw BKException.create(BKException.Code.UnexpectedConditionException);\n-        }\n-\n-        return refhandle.handle.isClosed();\n-    }\n-\n-    /**\n-     * Async try read last confirmed.\n-     *\n-     * @param ledgerDesc\n-     *          ledger descriptor\n-     * @return future presenting read last confirmed result.\n-     */\n-    public Future<Long> asyncTryReadLastConfirmed(LedgerDescriptor ledgerDesc) {\n-        RefCountedLedgerHandle refHandle = handlesMap.get(ledgerDesc);\n-        if (null == refHandle) {\n-            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n-            return Future.exception(BKException.create(BKException.Code.UnexpectedConditionException));\n-        }\n-        final Promise<Long> promise = new Promise<Long>();\n-        refHandle.handle.asyncTryReadLastConfirmed(new AsyncCallback.ReadLastConfirmedCallback() {\n-            @Override\n-            public void readLastConfirmedComplete(int rc, long lastAddConfirmed, Object ctx) {\n-                if (BKException.Code.OK == rc) {\n-                    promise.setValue(lastAddConfirmed);\n-                } else {\n-                    promise.setException(BKException.create(rc));\n-                }\n-            }\n-        }, null);\n-        return promise;\n-    }\n-\n-    /**\n-     * Try read last confirmed.\n-     *\n-     * @param ledgerDesc\n-     *          ledger descriptor\n-     * @return last confirmed\n-     * @throws BKException\n-     */\n-    public long tryReadLastConfirmed(LedgerDescriptor ledgerDesc) throws BKException {\n-        return FutureUtils.bkResult(asyncTryReadLastConfirmed(ledgerDesc));\n-    }\n-\n-    /**\n-     * Async read last confirmed and entry\n-     *\n-     * @param ledgerDesc\n-     *          ledger descriptor\n-     * @param entryId\n-     *          entry id to read\n-     * @param timeOutInMillis\n-     *          time out if no newer entry available\n-     * @param parallel\n-     *          whether to read from replicas in parallel\n-     */\n-    public Future<Pair<Long, LedgerEntry>> asyncReadLastConfirmedAndEntry(\n-            LedgerDescriptor ledgerDesc,\n-            long entryId,\n-            long timeOutInMillis,\n-            boolean parallel) {\n-        RefCountedLedgerHandle refHandle = handlesMap.get(ledgerDesc);\n-        if (null == refHandle) {\n-            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n-            return Future.exception(BKException.create(BKException.Code.UnexpectedConditionException));\n-        }\n-        final Promise<Pair<Long, LedgerEntry>> promise = new Promise<Pair<Long, LedgerEntry>>();\n-        refHandle.handle.asyncReadLastConfirmedAndEntry(entryId, timeOutInMillis, parallel,\n-                new AsyncCallback.ReadLastConfirmedAndEntryCallback() {\n-                    @Override\n-                    public void readLastConfirmedAndEntryComplete(int rc, long lac, LedgerEntry ledgerEntry, Object ctx) {\n-                        if (BKException.Code.OK == rc) {\n-                            promise.setValue(Pair.of(lac, ledgerEntry));\n-                        } else {\n-                            promise.setException(BKException.create(rc));\n-                        }\n-                    }\n-                }, null);\n-        return promise;\n-    }\n-\n-    /**\n-     * Async Read Entries\n-     *\n-     * @param ledgerDesc\n-     *          ledger descriptor\n-     * @param first\n-     *          first entry\n-     * @param last\n-     *          second entry\n-     */\n-    public Future<Enumeration<LedgerEntry>> asyncReadEntries(\n-            LedgerDescriptor ledgerDesc, long first, long last) {\n-        RefCountedLedgerHandle refHandle = handlesMap.get(ledgerDesc);\n-        if (null == refHandle) {\n-            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n-            return Future.exception(BKException.create(BKException.Code.UnexpectedConditionException));\n-        }\n-        final Promise<Enumeration<LedgerEntry>> promise = new Promise<Enumeration<LedgerEntry>>();\n-        refHandle.handle.asyncReadEntries(first, last, new AsyncCallback.ReadCallback() {\n-            @Override\n-            public void readComplete(int rc, LedgerHandle lh, Enumeration<LedgerEntry> entries, Object ctx) {\n-                if (BKException.Code.OK == rc) {\n-                    promise.setValue(entries);\n-                } else {\n-                    promise.setException(BKException.create(rc));\n-                }\n-            }\n-        }, null);\n-        return promise;\n-    }\n-\n-    public Enumeration<LedgerEntry> readEntries(LedgerDescriptor ledgerDesc, long first, long last)\n-            throws BKException {\n-        return FutureUtils.bkResult(asyncReadEntries(ledgerDesc, first, last));\n-    }\n-\n-    public long getLength(LedgerDescriptor ledgerDesc) throws BKException {\n-        RefCountedLedgerHandle refhandle = getLedgerHandle(ledgerDesc);\n-\n-        if (null == refhandle) {\n-            LOG.error(\"Accessing ledger {} without opening.\", ledgerDesc);\n-            throw BKException.create(BKException.Code.UnexpectedConditionException);\n-        }\n-\n-        return refhandle.handle.getLength();\n-    }\n-\n-    public void clear() {\n-        if (null != handlesMap) {\n-            Iterator<Map.Entry<LedgerDescriptor, RefCountedLedgerHandle>> handlesMapIter = handlesMap.entrySet().iterator();\n-            while (handlesMapIter.hasNext()) {\n-                Map.Entry<LedgerDescriptor, RefCountedLedgerHandle> entry = handlesMapIter.next();\n-                // Make it inaccessible through the map\n-                handlesMapIter.remove();\n-                // now close the ledger\n-                entry.getValue().forceClose();\n-            }\n-        }\n-    }\n-\n-    static class RefCountedLedgerHandle {\n-        public final LedgerHandle handle;\n-        final AtomicLong refcount = new AtomicLong(0);\n-\n-        RefCountedLedgerHandle(LedgerHandle lh) {\n-            this.handle = lh;\n-            addRef();\n-        }\n-\n-        long getRefCount() {\n-            return refcount.get();\n-        }\n-\n-        public void addRef() {\n-            refcount.incrementAndGet();\n-        }\n-\n-        public boolean removeRef() {\n-            return (refcount.decrementAndGet() == 0);\n-        }\n-\n-        public void forceClose() {\n-            try {\n-                handle.close();\n-            } catch (BKException.BKLedgerClosedException exc) {\n-                // Ignore\n-            } catch (Exception exc) {\n-                LOG.warn(\"Exception while closing ledger {}\", handle, exc);\n-            }\n-        }\n-\n-    }\n-}"},{"sha":"284b3271319f725c78e72235a46e89cf32294b62","filename":"src/main/java/com/twitter/distributedlog/ReadAheadCache.java","status":"removed","additions":0,"deletions":233,"changes":233,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java?ref=1166e11904ab83ec64e0147998cebffc653bdbf3","patch":"@@ -1,233 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.twitter.distributedlog;\n-\n-import java.io.IOException;\n-import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.atomic.AtomicReference;\n-\n-import com.google.common.base.Stopwatch;\n-import com.google.common.base.Ticker;\n-import com.twitter.distributedlog.callback.ReadAheadCallback;\n-import com.twitter.distributedlog.exceptions.DLInterruptedException;\n-import com.twitter.distributedlog.exceptions.InvalidEnvelopedEntryException;\n-import com.twitter.distributedlog.exceptions.LogReadException;\n-import org.apache.bookkeeper.client.LedgerEntry;\n-import org.apache.bookkeeper.stats.AlertStatsLogger;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class ReadAheadCache {\n-    static final Logger LOG = LoggerFactory.getLogger(ReadAheadCache.class);\n-\n-    private final String streamName;\n-    private final LinkedBlockingQueue<Entry.Reader> readAheadEntries;\n-    private final int maxCachedEntries;\n-    private final AtomicReference<IOException> lastException = new AtomicReference<IOException>();\n-    private final boolean deserializeRecordSet;\n-    // callbacks\n-    private final AsyncNotification notification;\n-    private ReadAheadCallback readAheadCallback = null;\n-\n-    // variables for idle reader detection\n-    private final Stopwatch lastEntryProcessTime;\n-\n-    private final AlertStatsLogger alertStatsLogger;\n-\n-    public ReadAheadCache(String streamName,\n-                          AlertStatsLogger alertStatsLogger,\n-                          AsyncNotification notification,\n-                          int maxCachedRecords,\n-                          boolean deserializeRecordSet,\n-                          Ticker ticker) {\n-        this.streamName = streamName;\n-        this.maxCachedEntries = maxCachedRecords;\n-        this.notification = notification;\n-        this.deserializeRecordSet = deserializeRecordSet;\n-\n-        // create the readahead queue\n-        readAheadEntries = new LinkedBlockingQueue<Entry.Reader>();\n-\n-        // start the idle reader detection\n-        lastEntryProcessTime = Stopwatch.createStarted(ticker);\n-\n-        // Stats\n-        this.alertStatsLogger = alertStatsLogger;\n-    }\n-\n-    /**\n-     * Trigger read ahead callback\n-     */\n-    private synchronized void invokeReadAheadCallback() {\n-        if (null != readAheadCallback) {\n-            if (LOG.isTraceEnabled()) {\n-                LOG.trace(\"Cache has space, schedule the read ahead\");\n-            }\n-            readAheadCallback.resumeReadAhead();\n-            readAheadCallback = null;\n-        }\n-    }\n-\n-    /**\n-     * Register a readhead callback.\n-     *\n-     * @param readAheadCallback\n-     *          read ahead callback\n-     */\n-    public synchronized void setReadAheadCallback(ReadAheadCallback readAheadCallback) {\n-        this.readAheadCallback = readAheadCallback;\n-        if (!isCacheFull()) {\n-            invokeReadAheadCallback();\n-        }\n-    }\n-\n-    private void setLastException(IOException exc) {\n-        lastException.set(exc);\n-    }\n-\n-    /**\n-     * Poll next entry from the readahead queue.\n-     *\n-     * @return next entry from readahead queue. null if no entries available in the queue.\n-     * @throws IOException\n-     */\n-    public Entry.Reader getNextReadAheadEntry() throws IOException {\n-        return getNextReadAheadEntry(0L, TimeUnit.MILLISECONDS);\n-    }\n-\n-    public Entry.Reader getNextReadAheadEntry(long waitTime, TimeUnit waitTimeUnit) throws IOException {\n-        if (null != lastException.get()) {\n-            throw lastException.get();\n-        }\n-\n-        Entry.Reader entry = null;\n-        try {\n-            entry = readAheadEntries.poll(waitTime, waitTimeUnit);\n-        } catch (InterruptedException e) {\n-            throw new DLInterruptedException(\"Interrupted on polling readahead entries : \", e);\n-        }\n-\n-        if (null != entry) {\n-            if (!isCacheFull()) {\n-                invokeReadAheadCallback();\n-            }\n-        }\n-\n-        return entry;\n-    }\n-\n-    /**\n-     * Check whether the readahead becomes stall.\n-     *\n-     * @param idleReaderErrorThreshold\n-     *          idle reader error threshold\n-     * @param timeUnit\n-     *          time unit of the idle reader error threshold\n-     * @return true if the readahead becomes stall, otherwise false.\n-     */\n-    public boolean isReadAheadIdle(int idleReaderErrorThreshold, TimeUnit timeUnit) {\n-        return (lastEntryProcessTime.elapsed(timeUnit) > idleReaderErrorThreshold);\n-    }\n-\n-    /**\n-     * Set an ledger entry to readahead cache\n-     *\n-     * @param key\n-     *          read position of the entry\n-     * @param entry\n-     *          the ledger entry\n-     * @param reason\n-     *          the reason to add the entry to readahead (for logging)\n-     * @param envelopeEntries\n-     *          whether this entry an enveloped entries or not\n-     * @param startSequenceId\n-     *          the start sequence id\n-     */\n-    public void set(LedgerReadPosition key,\n-                    LedgerEntry entry,\n-                    String reason,\n-                    boolean envelopeEntries,\n-                    long startSequenceId) {\n-        processNewLedgerEntry(key, entry, reason, envelopeEntries, startSequenceId);\n-        lastEntryProcessTime.reset().start();\n-        AsyncNotification n = notification;\n-        if (null != n) {\n-            n.notifyOnOperationComplete();\n-        }\n-    }\n-\n-    public boolean isCacheFull() {\n-        return getNumCachedEntries() >= maxCachedEntries;\n-    }\n-\n-    /**\n-     * Return number cached records.\n-     *\n-     * @return number cached records.\n-     */\n-    public int getNumCachedEntries() {\n-        return readAheadEntries.size();\n-    }\n-\n-    /**\n-     * Process the new ledger entry and propagate the records into readahead queue.\n-     *\n-     * @param readPosition\n-     *          position of the ledger entry\n-     * @param ledgerEntry\n-     *          ledger entry\n-     * @param reason\n-     *          reason to add this ledger entry\n-     * @param envelopeEntries\n-     *          whether this entry is enveloped\n-     * @param startSequenceId\n-     *          the start sequence id of this log segment\n-     */\n-    private void processNewLedgerEntry(final LedgerReadPosition readPosition,\n-                                       final LedgerEntry ledgerEntry,\n-                                       final String reason,\n-                                       boolean envelopeEntries,\n-                                       long startSequenceId) {\n-        try {\n-            Entry.Reader reader = Entry.newBuilder()\n-                    .setLogSegmentInfo(readPosition.getLogSegmentSequenceNumber(), startSequenceId)\n-                    .setEntryId(ledgerEntry.getEntryId())\n-                    .setEnvelopeEntry(envelopeEntries)\n-                    .deserializeRecordSet(deserializeRecordSet)\n-                    .setInputStream(ledgerEntry.getEntryInputStream())\n-                    .buildReader();\n-            readAheadEntries.add(reader);\n-        } catch (InvalidEnvelopedEntryException ieee) {\n-            alertStatsLogger.raise(\"Found invalid enveloped entry on stream {} : \", streamName, ieee);\n-            setLastException(ieee);\n-        } catch (IOException exc) {\n-            setLastException(exc);\n-        }\n-    }\n-\n-    public void clear() {\n-        readAheadEntries.clear();\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return String.format(\"%s: Num Cached Entries: %d\",\n-            streamName, getNumCachedEntries());\n-    }\n-}"},{"sha":"f4815612aa17d1bd37e1de069939d45f3d19cd07","filename":"src/main/java/com/twitter/distributedlog/ReadUtils.java","status":"modified","additions":76,"deletions":128,"changes":204,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadUtils.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -18,29 +18,25 @@\n package com.twitter.distributedlog;\n \n import java.io.IOException;\n-import java.util.Enumeration;\n import java.util.List;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.atomic.AtomicInteger;\n import java.util.concurrent.atomic.AtomicLong;\n \n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.LedgerEntry;\n-import org.apache.bookkeeper.stats.NullStatsLogger;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n+import com.twitter.distributedlog.logsegment.LogSegmentEntryStore;\n+import com.twitter.distributedlog.logsegment.LogSegmentRandomAccessEntryReader;\n import com.google.common.base.Optional;\n import com.google.common.collect.Lists;\n import com.twitter.distributedlog.selector.FirstDLSNNotLessThanSelector;\n import com.twitter.distributedlog.selector.FirstTxIdNotLessThanSelector;\n import com.twitter.distributedlog.selector.LastRecordSelector;\n import com.twitter.distributedlog.selector.LogRecordSelector;\n-import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.FutureUtils.FutureEventListenerRunnable;\n import com.twitter.util.Future;\n import com.twitter.util.FutureEventListener;\n import com.twitter.util.Promise;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n import scala.runtime.AbstractFunction0;\n import scala.runtime.BoxedUnit;\n \n@@ -58,14 +54,14 @@ public class ReadUtils {\n     //\n \n     /**\n-     * Read last record from a ledger.\n+     * Read last record from a log segment.\n      *\n      * @param streamName\n      *          fully qualified stream name (used for logging)\n      * @param l\n-     *          ledger descriptor.\n+     *          log segment metadata.\n      * @param fence\n-     *          whether to fence the ledger.\n+     *          whether to fence the log segment.\n      * @param includeControl\n      *          whether to include control record.\n      * @param includeEndOfStream\n@@ -78,8 +74,8 @@ public class ReadUtils {\n      *          num of records scanned to get last record\n      * @param executorService\n      *          executor service used for processing entries\n-     * @param handleCache\n-     *          ledger handle cache\n+     * @param entryStore\n+     *          log segment entry store\n      * @return a future with last record.\n      */\n     public static Future<LogRecordWithDLSN> asyncReadLastRecord(\n@@ -92,20 +88,20 @@ public static Future<LogRecordWithDLSN> asyncReadLastRecord(\n             final int scanMaxBatchSize,\n             final AtomicInteger numRecordsScanned,\n             final ExecutorService executorService,\n-            final LedgerHandleCache handleCache) {\n+            final LogSegmentEntryStore entryStore) {\n         final LogRecordSelector selector = new LastRecordSelector();\n         return asyncReadRecord(streamName, l, fence, includeControl, includeEndOfStream, scanStartBatchSize,\n-                               scanMaxBatchSize, numRecordsScanned, executorService, handleCache,\n+                               scanMaxBatchSize, numRecordsScanned, executorService, entryStore,\n                                selector, true /* backward */, 0L);\n     }\n \n     /**\n-     * Read first record from a ledger with a DLSN larger than that given.\n+     * Read first record from a log segment with a DLSN larger than that given.\n      *\n      * @param streamName\n      *          fully qualified stream name (used for logging)\n      * @param l\n-     *          ledger descriptor.\n+     *          log segment metadata.\n      * @param scanStartBatchSize\n      *          first num entries used for read last record scan\n      * @param scanMaxBatchSize\n@@ -114,6 +110,8 @@ public static Future<LogRecordWithDLSN> asyncReadLastRecord(\n      *          num of records scanned to get last record\n      * @param executorService\n      *          executor service used for processing entries\n+     * @param entryStore\n+     *          log segment entry store\n      * @param dlsn\n      *          threshold dlsn\n      * @return a future with last record.\n@@ -125,15 +123,15 @@ public static Future<LogRecordWithDLSN> asyncReadFirstUserRecord(\n             final int scanMaxBatchSize,\n             final AtomicInteger numRecordsScanned,\n             final ExecutorService executorService,\n-            final LedgerHandleCache handleCache,\n+            final LogSegmentEntryStore entryStore,\n             final DLSN dlsn) {\n         long startEntryId = 0L;\n         if (l.getLogSegmentSequenceNumber() == dlsn.getLogSegmentSequenceNo()) {\n             startEntryId = dlsn.getEntryId();\n         }\n         final LogRecordSelector selector = new FirstDLSNNotLessThanSelector(dlsn);\n         return asyncReadRecord(streamName, l, false, false, false, scanStartBatchSize,\n-                               scanMaxBatchSize, numRecordsScanned, executorService, handleCache,\n+                               scanMaxBatchSize, numRecordsScanned, executorService, entryStore,\n                                selector, false /* backward */, startEntryId);\n     }\n \n@@ -233,14 +231,12 @@ private static class SingleEntryScanContext extends ScanContext {\n     }\n \n     /**\n-     * Read record from a given range of ledger entries.\n+     * Read record from a given range of log segment entries.\n      *\n      * @param streamName\n      *          fully qualified stream name (used for logging)\n-     * @param ledgerDescriptor\n-     *          ledger descriptor.\n-     * @param handleCache\n-     *          ledger handle cache.\n+     * @param reader\n+     *          log segment random access reader\n      * @param executorService\n      *          executor service used for processing entries\n      * @param context\n@@ -249,8 +245,7 @@ private static class SingleEntryScanContext extends ScanContext {\n      */\n     private static Future<LogRecordWithDLSN> asyncReadRecordFromEntries(\n             final String streamName,\n-            final LedgerDescriptor ledgerDescriptor,\n-            LedgerHandleCache handleCache,\n+            final LogSegmentRandomAccessEntryReader reader,\n             final LogSegmentMetadata metadata,\n             final ExecutorService executorService,\n             final ScanContext context,\n@@ -260,22 +255,19 @@ private static Future<LogRecordWithDLSN> asyncReadRecordFromEntries(\n         final long endEntryId = context.curEndEntryId.get();\n         if (LOG.isDebugEnabled()) {\n             LOG.debug(\"{} reading entries [{} - {}] from {}.\",\n-                    new Object[] { streamName, startEntryId, endEntryId, ledgerDescriptor });\n+                    new Object[] { streamName, startEntryId, endEntryId, metadata});\n         }\n-        FutureEventListener<Enumeration<LedgerEntry>> readEntriesListener =\n-            new FutureEventListener<Enumeration<LedgerEntry>>() {\n+        FutureEventListener<List<Entry.Reader>> readEntriesListener =\n+            new FutureEventListener<List<Entry.Reader>>() {\n                 @Override\n-                public void onSuccess(final Enumeration<LedgerEntry> entries) {\n+                public void onSuccess(final List<Entry.Reader> entries) {\n                     if (LOG.isDebugEnabled()) {\n                         LOG.debug(\"{} finished reading entries [{} - {}] from {}\",\n-                                new Object[]{ streamName, startEntryId, endEntryId, ledgerDescriptor });\n+                                new Object[]{ streamName, startEntryId, endEntryId, metadata});\n                     }\n-                    LogRecordWithDLSN record = null;\n-                    while (entries.hasMoreElements()) {\n-                        LedgerEntry entry = entries.nextElement();\n+                    for (Entry.Reader entry : entries) {\n                         try {\n-                            visitEntryRecords(\n-                                    streamName, metadata, ledgerDescriptor.getLogSegmentSequenceNo(), entry, context, selector);\n+                            visitEntryRecords(entry, context, selector);\n                         } catch (IOException ioe) {\n                             // exception is only thrown due to bad ledger entry, so it might be corrupted\n                             // we shouldn't do anything beyond this point. throw the exception to application\n@@ -284,35 +276,28 @@ public void onSuccess(final Enumeration<LedgerEntry> entries) {\n                         }\n                     }\n \n-                    record = selector.result();\n+                    LogRecordWithDLSN record = selector.result();\n                     if (LOG.isDebugEnabled()) {\n                         LOG.debug(\"{} got record from entries [{} - {}] of {} : {}\",\n                                 new Object[]{streamName, startEntryId, endEntryId,\n-                                        ledgerDescriptor, record});\n+                                        metadata, record});\n                     }\n                     promise.setValue(record);\n                 }\n \n                 @Override\n                 public void onFailure(final Throwable cause) {\n-                    String errMsg = \"Error reading entries [\" + startEntryId + \"-\" + endEntryId\n-                                + \"] for reading record of \" + streamName;\n-                    promise.setException(new IOException(errMsg,\n-                            BKException.create(FutureUtils.bkResultCode(cause))));\n+                    promise.setException(cause);\n                 }\n             };\n-        handleCache.asyncReadEntries(ledgerDescriptor, startEntryId, endEntryId)\n+        reader.readEntries(startEntryId, endEntryId)\n                 .addEventListener(FutureEventListenerRunnable.of(readEntriesListener, executorService));\n         return promise;\n     }\n \n     /**\n      * Process each record using LogRecordSelector.\n      *\n-     * @param streamName\n-     *          fully qualified stream name (used for logging)\n-     * @param logSegmentSeqNo\n-     *          ledger sequence number\n      * @param entry\n      *          ledger entry\n      * @param context\n@@ -321,22 +306,13 @@ public void onFailure(final Throwable cause) {\n      * @throws IOException\n      */\n     private static void visitEntryRecords(\n-            String streamName,\n-            LogSegmentMetadata metadata,\n-            long logSegmentSeqNo,\n-            LedgerEntry entry,\n+            Entry.Reader entry,\n             ScanContext context,\n             LogRecordSelector selector) throws IOException {\n-        Entry.Reader reader = Entry.newBuilder()\n-                .setLogSegmentInfo(logSegmentSeqNo, metadata.getStartSequenceId())\n-                .setEntryId(entry.getEntryId())\n-                .setEnvelopeEntry(metadata.getEnvelopeEntries())\n-                .setInputStream(entry.getEntryInputStream())\n-                .buildReader();\n-        LogRecordWithDLSN nextRecord = reader.nextRecord();\n+        LogRecordWithDLSN nextRecord = entry.nextRecord();\n         while (nextRecord != null) {\n             LogRecordWithDLSN record = nextRecord;\n-            nextRecord = reader.nextRecord();\n+            nextRecord = entry.nextRecord();\n             context.numRecordsScanned.incrementAndGet();\n             if (!context.includeControl && record.isControl()) {\n                 continue;\n@@ -353,10 +329,8 @@ private static void visitEntryRecords(\n      *\n      * @param streamName\n      *          fully qualified stream name (used for logging)\n-     * @param ledgerDescriptor\n-     *          ledger descriptor.\n-     * @param handleCache\n-     *          ledger handle cache.\n+     * @param reader\n+     *          log segment random access reader\n      * @param executorService\n      *          executor service used for processing entries\n      * @param promise\n@@ -366,8 +340,7 @@ private static void visitEntryRecords(\n      */\n     private static void asyncReadRecordFromEntries(\n             final String streamName,\n-            final LedgerDescriptor ledgerDescriptor,\n-            final LedgerHandleCache handleCache,\n+            final LogSegmentRandomAccessEntryReader reader,\n             final LogSegmentMetadata metadata,\n             final ExecutorService executorService,\n             final Promise<LogRecordWithDLSN> promise,\n@@ -380,7 +353,7 @@ public void onSuccess(LogRecordWithDLSN value) {\n                     if (LOG.isDebugEnabled()) {\n                         LOG.debug(\"{} read record from [{} - {}] of {} : {}\",\n                                 new Object[]{streamName, context.curStartEntryId.get(), context.curEndEntryId.get(),\n-                                        ledgerDescriptor, value});\n+                                        metadata, value});\n                     }\n                     if (null != value) {\n                         promise.setValue(value);\n@@ -393,8 +366,7 @@ public void onSuccess(LogRecordWithDLSN value) {\n                     }\n                     // scan next range\n                     asyncReadRecordFromEntries(streamName,\n-                            ledgerDescriptor,\n-                            handleCache,\n+                            reader,\n                             metadata,\n                             executorService,\n                             promise,\n@@ -407,14 +379,13 @@ public void onFailure(Throwable cause) {\n                     promise.setException(cause);\n                 }\n             };\n-        asyncReadRecordFromEntries(streamName, ledgerDescriptor, handleCache, metadata, executorService, context, selector)\n+        asyncReadRecordFromEntries(streamName, reader, metadata, executorService, context, selector)\n                 .addEventListener(FutureEventListenerRunnable.of(readEntriesListener, executorService));\n     }\n \n     private static void asyncReadRecordFromLogSegment(\n             final String streamName,\n-            final LedgerDescriptor ledgerDescriptor,\n-            final LedgerHandleCache handleCache,\n+            final LogSegmentRandomAccessEntryReader reader,\n             final LogSegmentMetadata metadata,\n             final ExecutorService executorService,\n             final int scanStartBatchSize,\n@@ -426,16 +397,10 @@ private static void asyncReadRecordFromLogSegment(\n             final LogRecordSelector selector,\n             final boolean backward,\n             final long startEntryId) {\n-        final long lastAddConfirmed;\n-        try {\n-            lastAddConfirmed = handleCache.getLastAddConfirmed(ledgerDescriptor);\n-        } catch (BKException e) {\n-            promise.setException(e);\n-            return;\n-        }\n+        final long lastAddConfirmed = reader.getLastAddConfirmed();\n         if (lastAddConfirmed < 0) {\n             if (LOG.isDebugEnabled()) {\n-                LOG.debug(\"Ledger {} is empty for {}.\", new Object[] { ledgerDescriptor, streamName });\n+                LOG.debug(\"Log segment {} is empty for {}.\", new Object[] { metadata, streamName });\n             }\n             promise.setValue(null);\n             return;\n@@ -444,7 +409,7 @@ private static void asyncReadRecordFromLogSegment(\n                 startEntryId, lastAddConfirmed,\n                 scanStartBatchSize, scanMaxBatchSize,\n                 includeControl, includeEndOfStream, backward, numRecordsScanned);\n-        asyncReadRecordFromEntries(streamName, ledgerDescriptor, handleCache, metadata, executorService,\n+        asyncReadRecordFromEntries(streamName, reader, metadata, executorService,\n                                    promise, context, selector);\n     }\n \n@@ -458,25 +423,25 @@ private static Future<LogRecordWithDLSN> asyncReadRecord(\n             final int scanMaxBatchSize,\n             final AtomicInteger numRecordsScanned,\n             final ExecutorService executorService,\n-            final LedgerHandleCache handleCache,\n+            final LogSegmentEntryStore entryStore,\n             final LogRecordSelector selector,\n             final boolean backward,\n             final long startEntryId) {\n \n         final Promise<LogRecordWithDLSN> promise = new Promise<LogRecordWithDLSN>();\n \n-        FutureEventListener<LedgerDescriptor> openLedgerListener =\n-            new FutureEventListener<LedgerDescriptor>() {\n+        FutureEventListener<LogSegmentRandomAccessEntryReader> openReaderListener =\n+            new FutureEventListener<LogSegmentRandomAccessEntryReader>() {\n                 @Override\n-                public void onSuccess(final LedgerDescriptor ledgerDescriptor) {\n+                public void onSuccess(final LogSegmentRandomAccessEntryReader reader) {\n                     if (LOG.isDebugEnabled()) {\n-                        LOG.debug(\"{} Opened logsegment {} for reading record\",\n+                        LOG.debug(\"{} Opened log segment {} for reading record\",\n                                 streamName, l);\n                     }\n                     promise.ensure(new AbstractFunction0<BoxedUnit>() {\n                         @Override\n                         public BoxedUnit apply() {\n-                            handleCache.asyncCloseLedger(ledgerDescriptor);\n+                            reader.asyncClose();\n                             return BoxedUnit.UNIT;\n                         }\n                     });\n@@ -485,21 +450,19 @@ public BoxedUnit apply() {\n                                 (backward ? \"backward\" : \"forward\"), streamName, l});\n                     }\n                     asyncReadRecordFromLogSegment(\n-                            streamName, ledgerDescriptor, handleCache, l, executorService,\n+                            streamName, reader, l, executorService,\n                             scanStartBatchSize, scanMaxBatchSize,\n                             includeControl, includeEndOfStream,\n                             promise, numRecordsScanned, selector, backward, startEntryId);\n                 }\n \n                 @Override\n                 public void onFailure(final Throwable cause) {\n-                    String errMsg = \"Error opening log segment [\" + l + \"] for reading record of \" + streamName;\n-                    promise.setException(new IOException(errMsg,\n-                            BKException.create(FutureUtils.bkResultCode(cause))));\n+                    promise.setException(cause);\n                 }\n             };\n-        handleCache.asyncOpenLedger(l, fence)\n-                .addEventListener(FutureEventListenerRunnable.of(openLedgerListener, executorService));\n+        entryStore.openRandomAccessReader(l, fence)\n+                .addEventListener(FutureEventListenerRunnable.of(openReaderListener, executorService));\n         return promise;\n     }\n \n@@ -530,8 +493,8 @@ public void onFailure(final Throwable cause) {\n      *          transaction id\n      * @param executorService\n      *          executor service used for processing entries\n-     * @param handleCache\n-     *          ledger handle cache\n+     * @param entryStore\n+     *          log segment entry store\n      * @param nWays\n      *          how many number of entries to search in parallel\n      * @return found log record. none if all transaction ids are less than provided <code>transactionId</code>.\n@@ -541,7 +504,7 @@ public static Future<Optional<LogRecordWithDLSN>> getLogRecordNotLessThanTxId(\n             final LogSegmentMetadata segment,\n             final long transactionId,\n             final ExecutorService executorService,\n-            final LedgerHandleCache handleCache,\n+            final LogSegmentEntryStore entryStore,\n             final int nWays) {\n         if (!segment.isInProgress()) {\n             if (segment.getLastTxId() < transactionId) {\n@@ -554,25 +517,19 @@ public static Future<Optional<LogRecordWithDLSN>> getLogRecordNotLessThanTxId(\n \n         final Promise<Optional<LogRecordWithDLSN>> promise =\n                 new Promise<Optional<LogRecordWithDLSN>>();\n-        final FutureEventListener<LedgerDescriptor> openLedgerListener =\n-            new FutureEventListener<LedgerDescriptor>() {\n+        final FutureEventListener<LogSegmentRandomAccessEntryReader> openReaderListener =\n+            new FutureEventListener<LogSegmentRandomAccessEntryReader>() {\n                 @Override\n-                public void onSuccess(final LedgerDescriptor ld) {\n+                public void onSuccess(final LogSegmentRandomAccessEntryReader reader) {\n                     promise.ensure(new AbstractFunction0<BoxedUnit>() {\n                         @Override\n                         public BoxedUnit apply() {\n-                            handleCache.asyncCloseLedger(ld);\n+                            reader.asyncClose();\n                             return BoxedUnit.UNIT;\n                         }\n \n                     });\n-                    long lastEntryId;\n-                    try {\n-                        lastEntryId = handleCache.getLastAddConfirmed(ld);\n-                    } catch (BKException e) {\n-                        promise.setException(e);\n-                        return;\n-                    }\n+                    long lastEntryId = reader.getLastAddConfirmed();\n                     if (lastEntryId < 0) {\n                         // it means that the log segment is created but not written yet or an empty log segment.\n                         // it is equivalent to 'all log records whose transaction id is less than provided transactionId'\n@@ -586,8 +543,7 @@ public BoxedUnit apply() {\n                                 new FirstTxIdNotLessThanSelector(transactionId);\n                         asyncReadRecordFromEntries(\n                                 logName,\n-                                ld,\n-                                handleCache,\n+                                reader,\n                                 segment,\n                                 executorService,\n                                 new SingleEntryScanContext(0L),\n@@ -608,11 +564,10 @@ public void onFailure(Throwable cause) {\n                     }\n                     getLogRecordNotLessThanTxIdFromEntries(\n                             logName,\n-                            ld,\n                             segment,\n                             transactionId,\n                             executorService,\n-                            handleCache,\n+                            reader,\n                             Lists.newArrayList(0L, lastEntryId),\n                             nWays,\n                             Optional.<LogRecordWithDLSN>absent(),\n@@ -621,14 +576,12 @@ public void onFailure(Throwable cause) {\n \n                 @Override\n                 public void onFailure(final Throwable cause) {\n-                    String errMsg = \"Error opening log segment [\" + segment\n-                            + \"] for find record from \" + logName;\n-                    promise.setException(new IOException(errMsg,\n-                            BKException.create(FutureUtils.bkResultCode(cause))));\n+                    promise.setException(cause);\n                 }\n             };\n-        handleCache.asyncOpenLedger(segment, false)\n-                .addEventListener(FutureEventListenerRunnable.of(openLedgerListener, executorService));\n+\n+        entryStore.openRandomAccessReader(segment, false)\n+                .addEventListener(FutureEventListenerRunnable.of(openReaderListener, executorService));\n         return promise;\n     }\n \n@@ -644,8 +597,8 @@ public void onFailure(final Throwable cause) {\n      *          provided transaction id to search\n      * @param executorService\n      *          executor service\n-     * @param handleCache\n-     *          handle cache\n+     * @param reader\n+     *          log segment random access reader\n      * @param entriesToSearch\n      *          list of entries to search\n      * @param nWays\n@@ -657,11 +610,10 @@ public void onFailure(final Throwable cause) {\n      */\n     private static void getLogRecordNotLessThanTxIdFromEntries(\n             final String logName,\n-            final LedgerDescriptor ld,\n             final LogSegmentMetadata segment,\n             final long transactionId,\n             final ExecutorService executorService,\n-            final LedgerHandleCache handleCache,\n+            final LogSegmentRandomAccessEntryReader reader,\n             final List<Long> entriesToSearch,\n             final int nWays,\n             final Optional<LogRecordWithDLSN> prevFoundRecord,\n@@ -672,8 +624,7 @@ private static void getLogRecordNotLessThanTxIdFromEntries(\n             LogRecordSelector selector = new FirstTxIdNotLessThanSelector(transactionId);\n             Future<LogRecordWithDLSN> searchResult = asyncReadRecordFromEntries(\n                     logName,\n-                    ld,\n-                    handleCache,\n+                    reader,\n                     segment,\n                     executorService,\n                     new SingleEntryScanContext(entryId),\n@@ -686,11 +637,10 @@ private static void getLogRecordNotLessThanTxIdFromEntries(\n                     public void onSuccess(List<LogRecordWithDLSN> resultList) {\n                         processSearchResults(\n                                 logName,\n-                                ld,\n                                 segment,\n                                 transactionId,\n                                 executorService,\n-                                handleCache,\n+                                reader,\n                                 resultList,\n                                 nWays,\n                                 prevFoundRecord,\n@@ -711,11 +661,10 @@ public void onFailure(Throwable cause) {\n      */\n     static void processSearchResults(\n             final String logName,\n-            final LedgerDescriptor ld,\n             final LogSegmentMetadata segment,\n             final long transactionId,\n             final ExecutorService executorService,\n-            final LedgerHandleCache handleCache,\n+            final LogSegmentRandomAccessEntryReader reader,\n             final List<LogRecordWithDLSN> searchResults,\n             final int nWays,\n             final Optional<LogRecordWithDLSN> prevFoundRecord,\n@@ -758,11 +707,10 @@ static void processSearchResults(\n         }\n         getLogRecordNotLessThanTxIdFromEntries(\n                 logName,\n-                ld,\n                 segment,\n                 transactionId,\n                 executorService,\n-                handleCache,\n+                reader,\n                 nextSearchBatch,\n                 nWays,\n                 Optional.of(foundRecord),"},{"sha":"0a3fdb05241d960a9e31ddb5362f518b2f4442b1","filename":"src/main/java/com/twitter/distributedlog/admin/DistributedLogAdmin.java","status":"modified","additions":27,"deletions":25,"changes":52,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FDistributedLogAdmin.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FDistributedLogAdmin.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FDistributedLogAdmin.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -21,7 +21,6 @@\n import com.twitter.distributedlog.BookKeeperClient;\n import com.twitter.distributedlog.DistributedLogConfiguration;\n import com.twitter.distributedlog.DistributedLogManager;\n-import com.twitter.distributedlog.LedgerHandleCache;\n import com.twitter.distributedlog.LogRecordWithDLSN;\n import com.twitter.distributedlog.LogSegmentMetadata;\n import com.twitter.distributedlog.ReadUtils;\n@@ -30,6 +29,9 @@\n import com.twitter.distributedlog.acl.ZKAccessControl;\n import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n import com.twitter.distributedlog.impl.federated.FederatedZKLogMetadataStore;\n+import com.twitter.distributedlog.impl.logsegment.BKLogSegmentEntryStore;\n+import com.twitter.distributedlog.injector.AsyncFailureInjector;\n+import com.twitter.distributedlog.logsegment.LogSegmentEntryStore;\n import com.twitter.distributedlog.metadata.BKDLConfig;\n import com.twitter.distributedlog.metadata.DLMetadata;\n import com.twitter.distributedlog.metadata.DryrunLogSegmentMetadataStoreUpdater;\n@@ -39,19 +41,19 @@\n import com.twitter.distributedlog.tools.DistributedLogTool;\n import com.twitter.distributedlog.util.DLUtils;\n import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.distributedlog.util.SchedulerUtils;\n import com.twitter.util.Await;\n import com.twitter.util.Function;\n import com.twitter.util.Future;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.bookkeeper.util.IOUtils;\n import org.apache.commons.cli.CommandLine;\n import org.apache.commons.cli.Options;\n import org.apache.commons.cli.ParseException;\n import org.apache.zookeeper.KeeperException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import scala.runtime.AbstractFunction0;\n-import scala.runtime.BoxedUnit;\n \n import java.io.IOException;\n import java.net.URI;\n@@ -194,18 +196,18 @@ public String toString() {\n     public static void checkAndRepairDLNamespace(final URI uri,\n                                                  final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n                                                  final MetadataUpdater metadataUpdater,\n-                                                 final ExecutorService executorService,\n+                                                 final OrderedScheduler scheduler,\n                                                  final BookKeeperClient bkc,\n                                                  final String digestpw,\n                                                  final boolean verbose,\n                                                  final boolean interactive) throws IOException {\n-        checkAndRepairDLNamespace(uri, factory, metadataUpdater, executorService, bkc, digestpw, verbose, interactive, 1);\n+        checkAndRepairDLNamespace(uri, factory, metadataUpdater, scheduler, bkc, digestpw, verbose, interactive, 1);\n     }\n \n     public static void checkAndRepairDLNamespace(final URI uri,\n                                                  final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n                                                  final MetadataUpdater metadataUpdater,\n-                                                 final ExecutorService executorService,\n+                                                 final OrderedScheduler scheduler,\n                                                  final BookKeeperClient bkc,\n                                                  final String digestpw,\n                                                  final boolean verbose,\n@@ -222,7 +224,7 @@ public static void checkAndRepairDLNamespace(final URI uri,\n             return;\n         }\n         Map<String, StreamCandidate> streamCandidates =\n-                checkStreams(factory, streams, executorService, bkc, digestpw, concurrency);\n+                checkStreams(factory, streams, scheduler, bkc, digestpw, concurrency);\n         if (verbose) {\n             System.out.println(\"+ 0. \" + streamCandidates.size() + \" corrupted streams found.\");\n         }\n@@ -248,7 +250,7 @@ public static void checkAndRepairDLNamespace(final URI uri,\n     private static Map<String, StreamCandidate> checkStreams(\n             final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n             final Collection<String> streams,\n-            final ExecutorService executorService,\n+            final OrderedScheduler scheduler,\n             final BookKeeperClient bkc,\n             final String digestpw,\n             final int concurrency) throws IOException {\n@@ -273,7 +275,7 @@ public void run() {\n                     StreamCandidate candidate;\n                     try {\n                         LOG.info(\"Checking stream {}.\", stream);\n-                        candidate = checkStream(factory, stream, executorService, bkc, digestpw);\n+                        candidate = checkStream(factory, stream, scheduler, bkc, digestpw);\n                         LOG.info(\"Checked stream {} - {}.\", stream, candidate);\n                     } catch (IOException e) {\n                         LOG.error(\"Error on checking stream {} : \", stream, e);\n@@ -316,7 +318,7 @@ public void run() {\n     private static StreamCandidate checkStream(\n             final com.twitter.distributedlog.DistributedLogManagerFactory factory,\n             final String streamName,\n-            final ExecutorService executorService,\n+            final OrderedScheduler scheduler,\n             final BookKeeperClient bkc,\n             String digestpw) throws IOException {\n         DistributedLogManager dlm = factory.createDistributedLogManagerWithSharedClients(streamName);\n@@ -328,7 +330,7 @@ private static StreamCandidate checkStream(\n             List<Future<LogSegmentCandidate>> futures =\n                     new ArrayList<Future<LogSegmentCandidate>>(segments.size());\n             for (LogSegmentMetadata segment : segments) {\n-                futures.add(checkLogSegment(streamName, segment, executorService, bkc, digestpw));\n+                futures.add(checkLogSegment(streamName, segment, scheduler, bkc, digestpw));\n             }\n             List<LogSegmentCandidate> segmentCandidates;\n             try {\n@@ -354,17 +356,19 @@ private static StreamCandidate checkStream(\n     private static Future<LogSegmentCandidate> checkLogSegment(\n             final String streamName,\n             final LogSegmentMetadata metadata,\n-            final ExecutorService executorService,\n+            final OrderedScheduler scheduler,\n             final BookKeeperClient bkc,\n             final String digestpw) {\n         if (metadata.isInProgress()) {\n             return Future.value(null);\n         }\n \n-        final LedgerHandleCache handleCache = LedgerHandleCache.newBuilder()\n-                .bkc(bkc)\n-                .conf(new DistributedLogConfiguration().setBKDigestPW(digestpw))\n-                .build();\n+        final LogSegmentEntryStore entryStore = new BKLogSegmentEntryStore(\n+                new DistributedLogConfiguration().setBKDigestPW(digestpw),\n+                bkc,\n+                scheduler,\n+                NullStatsLogger.INSTANCE,\n+                AsyncFailureInjector.NULL);\n         return ReadUtils.asyncReadLastRecord(\n                 streamName,\n                 metadata,\n@@ -374,8 +378,8 @@ private static Future<LogSegmentCandidate> checkLogSegment(\n                 4,\n                 16,\n                 new AtomicInteger(0),\n-                executorService,\n-                handleCache\n+                scheduler,\n+                entryStore\n         ).map(new Function<LogRecordWithDLSN, LogSegmentCandidate>() {\n             @Override\n             public LogSegmentCandidate apply(LogRecordWithDLSN record) {\n@@ -388,12 +392,6 @@ public LogSegmentCandidate apply(LogRecordWithDLSN record) {\n                     return null;\n                 }\n             }\n-        }).ensure(new AbstractFunction0<BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply() {\n-                handleCache.clear();\n-                return BoxedUnit.UNIT;\n-            }\n         });\n     }\n \n@@ -736,10 +734,14 @@ protected int runCmd() throws Exception {\n                             getLogSegmentMetadataStore()) :\n                     LogSegmentMetadataStoreUpdater.createMetadataUpdater(getConf(),\n                             getLogSegmentMetadataStore());\n+            OrderedScheduler scheduler = OrderedScheduler.newBuilder()\n+                    .name(\"dlck-scheduler\")\n+                    .corePoolSize(Runtime.getRuntime().availableProcessors())\n+                    .build();\n             ExecutorService executorService = Executors.newCachedThreadPool();\n             BookKeeperClient bkc = getBookKeeperClient();\n             try {\n-                checkAndRepairDLNamespace(getUri(), getFactory(), metadataUpdater, executorService,\n+                checkAndRepairDLNamespace(getUri(), getFactory(), metadataUpdater, scheduler,\n                                           bkc, getConf().getBKDigestPW(), verbose, !getForce(), concurrency);\n             } finally {\n                 SchedulerUtils.shutdownScheduler(executorService, 5, TimeUnit.MINUTES);"},{"sha":"f7f4acf21bbe179f01105b878a6c139dc40f5668","filename":"src/main/java/com/twitter/distributedlog/impl/logsegment/BKLogSegmentEntryStore.java","status":"modified","additions":122,"deletions":14,"changes":136,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentEntryStore.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -17,13 +17,15 @@\n  */\n package com.twitter.distributedlog.impl.logsegment;\n \n+import com.twitter.distributedlog.BookKeeperClient;\n import com.twitter.distributedlog.DistributedLogConfiguration;\n import com.twitter.distributedlog.LogSegmentMetadata;\n import com.twitter.distributedlog.exceptions.BKTransmitException;\n import com.twitter.distributedlog.injector.AsyncFailureInjector;\n import com.twitter.distributedlog.logsegment.LogSegmentEntryReader;\n import com.twitter.distributedlog.logsegment.LogSegmentEntryStore;\n import com.twitter.distributedlog.logsegment.LogSegmentEntryWriter;\n+import com.twitter.distributedlog.logsegment.LogSegmentRandomAccessEntryReader;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.util.Future;\n@@ -33,13 +35,22 @@\n import org.apache.bookkeeper.client.BookKeeper;\n import org.apache.bookkeeper.client.LedgerHandle;\n import org.apache.bookkeeper.stats.StatsLogger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n \n import static com.google.common.base.Charsets.UTF_8;\n \n /**\n  * BookKeeper Based Entry Store\n  */\n-public class BKLogSegmentEntryStore implements LogSegmentEntryStore, AsyncCallback.OpenCallback {\n+public class BKLogSegmentEntryStore implements\n+        LogSegmentEntryStore,\n+        AsyncCallback.OpenCallback,\n+        AsyncCallback.DeleteCallback {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(BKLogSegmentEntryReader.class);\n \n     private static class OpenReaderRequest {\n \n@@ -56,26 +67,68 @@ private static class OpenReaderRequest {\n \n     }\n \n+    private static class DeleteLogSegmentRequest {\n+\n+        private final LogSegmentMetadata segment;\n+        private final Promise<LogSegmentMetadata> deletePromise;\n+\n+        DeleteLogSegmentRequest(LogSegmentMetadata segment) {\n+            this.segment = segment;\n+            this.deletePromise = new Promise<LogSegmentMetadata>();\n+        }\n+\n+    }\n+\n     private final byte[] passwd;\n-    private final BookKeeper bk;\n+    private final BookKeeperClient bkc;\n     private final OrderedScheduler scheduler;\n     private final DistributedLogConfiguration conf;\n     private final StatsLogger statsLogger;\n     private final AsyncFailureInjector failureInjector;\n \n     public BKLogSegmentEntryStore(DistributedLogConfiguration conf,\n-                                  BookKeeper bk,\n+                                  BookKeeperClient bkc,\n                                   OrderedScheduler scheduler,\n                                   StatsLogger statsLogger,\n                                   AsyncFailureInjector failureInjector) {\n         this.conf = conf;\n-        this.bk = bk;\n+        this.bkc = bkc;\n         this.passwd = conf.getBKDigestPW().getBytes(UTF_8);\n         this.scheduler = scheduler;\n         this.statsLogger = statsLogger;\n         this.failureInjector = failureInjector;\n     }\n \n+    @Override\n+    public Future<LogSegmentMetadata> deleteLogSegment(LogSegmentMetadata segment) {\n+        DeleteLogSegmentRequest request = new DeleteLogSegmentRequest(segment);\n+        BookKeeper bk;\n+        try {\n+            bk = this.bkc.get();\n+        } catch (IOException e) {\n+            return Future.exception(e);\n+        }\n+        bk.asyncDeleteLedger(segment.getLogSegmentId(), this, request);\n+        return request.deletePromise;\n+    }\n+\n+    @Override\n+    public void deleteComplete(int rc, Object ctx) {\n+        DeleteLogSegmentRequest deleteRequest = (DeleteLogSegmentRequest) ctx;\n+        if (BKException.Code.NoSuchLedgerExistsException == rc) {\n+            logger.warn(\"No ledger {} found to delete for {}.\",\n+                    deleteRequest.segment.getLogSegmentId(), deleteRequest.segment);\n+        } else if (BKException.Code.OK != rc) {\n+            logger.error(\"Couldn't delete ledger {} from bookkeeper for {} : {}\",\n+                    new Object[]{ deleteRequest.segment.getLogSegmentId(), deleteRequest.segment,\n+                            BKException.getMessage(rc) });\n+            FutureUtils.setException(deleteRequest.deletePromise,\n+                    new BKTransmitException(\"Couldn't delete log segment \" + deleteRequest.segment, rc));\n+            return;\n+        }\n+        FutureUtils.setValue(deleteRequest.deletePromise, deleteRequest.segment);\n+    }\n+\n     @Override\n     public Future<LogSegmentEntryWriter> openWriter(LogSegmentMetadata segment) {\n         throw new UnsupportedOperationException(\"Not supported yet\");\n@@ -84,6 +137,12 @@ public Future<LogSegmentEntryWriter> openWriter(LogSegmentMetadata segment) {\n     @Override\n     public Future<LogSegmentEntryReader> openReader(LogSegmentMetadata segment,\n                                                     long startEntryId) {\n+        BookKeeper bk;\n+        try {\n+            bk = this.bkc.get();\n+        } catch (IOException e) {\n+            return Future.exception(e);\n+        }\n         OpenReaderRequest request = new OpenReaderRequest(segment, startEntryId);\n         if (segment.isInProgress()) {\n             bk.asyncOpenLedgerNoRecovery(\n@@ -113,15 +172,64 @@ public void openComplete(int rc, LedgerHandle lh, Object ctx) {\n             return;\n         }\n         // successfully open a ledger\n-        LogSegmentEntryReader reader = new BKLogSegmentEntryReader(\n-                request.segment,\n-                lh,\n-                request.startEntryId,\n-                bk,\n-                scheduler,\n-                conf,\n-                statsLogger,\n-                failureInjector);\n-        FutureUtils.setValue(request.openPromise, reader);\n+        try {\n+            LogSegmentEntryReader reader = new BKLogSegmentEntryReader(\n+                    request.segment,\n+                    lh,\n+                    request.startEntryId,\n+                    bkc.get(),\n+                    scheduler,\n+                    conf,\n+                    statsLogger,\n+                    failureInjector);\n+            FutureUtils.setValue(request.openPromise, reader);\n+        } catch (IOException e) {\n+            FutureUtils.setException(request.openPromise, e);\n+        }\n+\n+    }\n+\n+    @Override\n+    public Future<LogSegmentRandomAccessEntryReader> openRandomAccessReader(final LogSegmentMetadata segment,\n+                                                                            final boolean fence) {\n+        final BookKeeper bk;\n+        try {\n+            bk = this.bkc.get();\n+        } catch (IOException e) {\n+            return Future.exception(e);\n+        }\n+        final Promise<LogSegmentRandomAccessEntryReader> openPromise = new Promise<LogSegmentRandomAccessEntryReader>();\n+        AsyncCallback.OpenCallback openCallback = new AsyncCallback.OpenCallback() {\n+            @Override\n+            public void openComplete(int rc, LedgerHandle lh, Object ctx) {\n+                if (BKException.Code.OK != rc) {\n+                    FutureUtils.setException(\n+                            openPromise,\n+                            new BKTransmitException(\"Failed to open ledger handle for log segment \" + segment, rc));\n+                    return;\n+                }\n+                LogSegmentRandomAccessEntryReader reader = new BKLogSegmentRandomAccessEntryReader(\n+                        segment,\n+                        lh,\n+                        conf);\n+                FutureUtils.setValue(openPromise, reader);\n+            }\n+        };\n+        if (segment.isInProgress() && !fence) {\n+            bk.asyncOpenLedgerNoRecovery(\n+                    segment.getLogSegmentId(),\n+                    BookKeeper.DigestType.CRC32,\n+                    passwd,\n+                    this,\n+                    openCallback);\n+        } else {\n+            bk.asyncOpenLedger(\n+                    segment.getLogSegmentId(),\n+                    BookKeeper.DigestType.CRC32,\n+                    passwd,\n+                    this,\n+                    openCallback);\n+        }\n+        return openPromise;\n     }\n }"},{"sha":"9cec80c081d801c16d62075e9af1556da4dedf28","filename":"src/main/java/com/twitter/distributedlog/impl/logsegment/BKLogSegmentRandomAccessEntryReader.java","status":"added","additions":119,"deletions":0,"changes":119,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentRandomAccessEntryReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentRandomAccessEntryReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FBKLogSegmentRandomAccessEntryReader.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -0,0 +1,119 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.impl.logsegment;\n+\n+import com.google.common.collect.Lists;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n+import com.twitter.distributedlog.Entry;\n+import com.twitter.distributedlog.LogSegmentMetadata;\n+import com.twitter.distributedlog.exceptions.BKTransmitException;\n+import com.twitter.distributedlog.logsegment.LogSegmentRandomAccessEntryReader;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.util.Future;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.client.AsyncCallback.ReadCallback;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.LedgerEntry;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+\n+import java.io.IOException;\n+import java.util.Enumeration;\n+import java.util.List;\n+\n+/**\n+ * BookKeeper ledger based random access entry reader.\n+ */\n+class BKLogSegmentRandomAccessEntryReader implements\n+        LogSegmentRandomAccessEntryReader,\n+        ReadCallback {\n+\n+    private final long lssn;\n+    private final long startSequenceId;\n+    private final boolean envelopeEntries;\n+    private final boolean deserializeRecordSet;\n+    // state\n+    private final LogSegmentMetadata metadata;\n+    private final LedgerHandle lh;\n+    private Promise<Void> closePromise = null;\n+\n+    BKLogSegmentRandomAccessEntryReader(LogSegmentMetadata metadata,\n+                                        LedgerHandle lh,\n+                                        DistributedLogConfiguration conf) {\n+        this.metadata = metadata;\n+        this.lssn = metadata.getLogSegmentSequenceNumber();\n+        this.startSequenceId = metadata.getStartSequenceId();\n+        this.envelopeEntries = metadata.getEnvelopeEntries();\n+        this.deserializeRecordSet = conf.getDeserializeRecordSetOnReads();\n+        this.lh = lh;\n+    }\n+\n+    @Override\n+    public long getLastAddConfirmed() {\n+        return lh.getLastAddConfirmed();\n+    }\n+\n+    @Override\n+    public Future<List<Entry.Reader>> readEntries(long startEntryId, long endEntryId) {\n+        Promise<List<Entry.Reader>> promise = new Promise<List<Entry.Reader>>();\n+        lh.asyncReadEntries(startEntryId, endEntryId, this, promise);\n+        return promise;\n+    }\n+\n+    Entry.Reader processReadEntry(LedgerEntry entry) throws IOException {\n+        return Entry.newBuilder()\n+                .setLogSegmentInfo(lssn, startSequenceId)\n+                .setEntryId(entry.getEntryId())\n+                .setEnvelopeEntry(envelopeEntries)\n+                .deserializeRecordSet(deserializeRecordSet)\n+                .setInputStream(entry.getEntryInputStream())\n+                .buildReader();\n+    }\n+\n+    @Override\n+    public void readComplete(int rc, LedgerHandle lh, Enumeration<LedgerEntry> entries, Object ctx) {\n+        Promise<List<Entry.Reader>> promise = (Promise<List<Entry.Reader>>) ctx;\n+        if (BKException.Code.OK == rc) {\n+            List<Entry.Reader> entryList = Lists.newArrayList();\n+            while (entries.hasMoreElements()) {\n+                try {\n+                    entryList.add(processReadEntry(entries.nextElement()));\n+                } catch (IOException ioe) {\n+                    FutureUtils.setException(promise, ioe);\n+                    return;\n+                }\n+            }\n+            FutureUtils.setValue(promise, entryList);\n+        } else {\n+            FutureUtils.setException(promise,\n+                    new BKTransmitException(\"Failed to read entries :\", rc));\n+        }\n+    }\n+\n+    @Override\n+    public Future<Void> asyncClose() {\n+        final Promise<Void> closeFuture;\n+        synchronized (this) {\n+            if (null != closePromise) {\n+                return closePromise;\n+            }\n+            closeFuture = closePromise = new Promise<Void>();\n+        }\n+        BKUtils.closeLedgers(lh).proxyTo(closeFuture);\n+        return closeFuture;\n+    }\n+}"},{"sha":"850f9c86ae7b93fbb2aea9a01af75027d0f59465","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentEntryStore.java","status":"modified","additions":17,"deletions":0,"changes":17,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentEntryStore.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -27,6 +27,14 @@\n @Beta\n public interface LogSegmentEntryStore {\n \n+    /**\n+     * Delete the actual log segment from the entry store.\n+     *\n+     * @param segment log segment metadata\n+     * @return future represent the delete result\n+     */\n+    Future<LogSegmentMetadata> deleteLogSegment(LogSegmentMetadata segment);\n+\n     /**\n      * Open the writer for writing data to the log <i>segment</i>.\n      *\n@@ -45,4 +53,13 @@ public interface LogSegmentEntryStore {\n     Future<LogSegmentEntryReader> openReader(LogSegmentMetadata segment,\n                                              long startEntryId);\n \n+    /**\n+     * Open the reader for reading entries from a random access log <i>segment</i>.\n+     *\n+     * @param segment the log <i>segment</i> to read entries from\n+     * @param fence the flag to fence log segment\n+     * @return future represent the opened random access reader\n+     */\n+    Future<LogSegmentRandomAccessEntryReader> openRandomAccessReader(LogSegmentMetadata segment,\n+                                                                     boolean fence);\n }"},{"sha":"70472ca3c2d7eda5c036c1d426ceed318298e180","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentRandomAccessEntryReader.java","status":"added","additions":47,"deletions":0,"changes":47,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentRandomAccessEntryReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentRandomAccessEntryReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentRandomAccessEntryReader.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -0,0 +1,47 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.logsegment;\n+\n+import com.twitter.distributedlog.Entry;\n+import com.twitter.distributedlog.io.AsyncCloseable;\n+import com.twitter.util.Future;\n+\n+import java.util.List;\n+\n+/**\n+ * An interface class to read entries {@link com.twitter.distributedlog.Entry}\n+ * from a random access log segment.\n+ */\n+public interface LogSegmentRandomAccessEntryReader extends AsyncCloseable {\n+\n+    /**\n+     * Read entries [startEntryId, endEntryId] from a random access log segment.\n+     *\n+     * @param startEntryId start entry id\n+     * @param endEntryId end entry id\n+     * @return A promise that when satisfied will contain a list of entries of [startEntryId, endEntryId].\n+     */\n+    Future<List<Entry.Reader>> readEntries(long startEntryId, long endEntryId);\n+\n+    /**\n+     * Return the last add confirmed entry id (LAC).\n+     *\n+     * @return the last add confirmed entry id.\n+     */\n+    long getLastAddConfirmed();\n+}"},{"sha":"1f152211fe895ded6a58240d66187581220faad8","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadPhase.java","status":"removed","additions":0,"deletions":45,"changes":45,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadPhase.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadPhase.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadPhase.java?ref=1166e11904ab83ec64e0147998cebffc653bdbf3","patch":"@@ -1,45 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.twitter.distributedlog.readahead;\n-\n-/**\n- * Enum code represents readahead phases\n- */\n-public enum ReadAheadPhase {\n-    ERROR(-5),\n-    TRUNCATED(-4),\n-    INTERRUPTED(-3),\n-    STOPPED(-2),\n-    EXCEPTION_HANDLING(-1),\n-    SCHEDULE_READAHEAD(0),\n-    GET_LEDGERS(1),\n-    OPEN_LEDGER(2),\n-    CLOSE_LEDGER(3),\n-    READ_LAST_CONFIRMED(4),\n-    READ_ENTRIES(5);\n-\n-    int code;\n-\n-    ReadAheadPhase(int code) {\n-        this.code = code;\n-    }\n-\n-    int getCode() {\n-        return this.code;\n-    }\n-}"},{"sha":"a58218be9885cb69bde17159be10c8bb73f4851b","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadTracker.java","status":"removed","additions":0,"deletions":104,"changes":104,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java?ref=1166e11904ab83ec64e0147998cebffc653bdbf3","patch":"@@ -1,104 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.twitter.distributedlog.readahead;\n-\n-import com.twitter.distributedlog.ReadAheadCache;\n-import org.apache.bookkeeper.stats.Gauge;\n-import org.apache.bookkeeper.stats.StatsLogger;\n-\n-import java.util.concurrent.atomic.AtomicLong;\n-\n-/**\n- * ReadAheadTracker is tracking the progress of readahead worker. so we could use it to investigate where\n- * the readahead worker is.\n- */\n-public class ReadAheadTracker {\n-    // ticks is used to differentiate that the worker enter same phase in different time.\n-    final AtomicLong ticks = new AtomicLong(0);\n-    // which phase that the worker is in.\n-    ReadAheadPhase phase;\n-    private final StatsLogger statsLogger;\n-    // Gauges and their labels\n-    private static final String phaseGaugeLabel = \"phase\";\n-    private final Gauge<Number> phaseGauge;\n-    private static final String ticksGaugeLabel = \"ticks\";\n-    private final Gauge<Number> ticksGauge;\n-    private static final String cachEntriesGaugeLabel = \"cache_entries\";\n-    private final Gauge<Number> cacheEntriesGauge;\n-\n-    ReadAheadTracker(String streamName,\n-                     final ReadAheadCache cache,\n-                     ReadAheadPhase initialPhase,\n-                     StatsLogger statsLogger) {\n-        this.statsLogger = statsLogger;\n-        this.phase = initialPhase;\n-        phaseGauge = new Gauge<Number>() {\n-            @Override\n-            public Number getDefaultValue() {\n-                return ReadAheadPhase.SCHEDULE_READAHEAD.getCode();\n-            }\n-\n-            @Override\n-            public Number getSample() {\n-                return phase.getCode();\n-            }\n-        };\n-        this.statsLogger.registerGauge(phaseGaugeLabel, phaseGauge);\n-\n-        ticksGauge = new Gauge<Number>() {\n-            @Override\n-            public Number getDefaultValue() {\n-                return 0;\n-            }\n-\n-            @Override\n-            public Number getSample() {\n-                return ticks.get();\n-            }\n-        };\n-        this.statsLogger.registerGauge(ticksGaugeLabel, ticksGauge);\n-\n-        cacheEntriesGauge = new Gauge<Number>() {\n-            @Override\n-            public Number getDefaultValue() {\n-                return 0;\n-            }\n-\n-            @Override\n-            public Number getSample() {\n-                return cache.getNumCachedEntries();\n-            }\n-        };\n-        this.statsLogger.registerGauge(cachEntriesGaugeLabel, cacheEntriesGauge);\n-    }\n-\n-    ReadAheadPhase getPhase() {\n-        return this.phase;\n-    }\n-\n-    public void enterPhase(ReadAheadPhase readAheadPhase) {\n-        this.ticks.incrementAndGet();\n-        this.phase = readAheadPhase;\n-    }\n-\n-    public void unregisterGauge() {\n-        this.statsLogger.unregisterGauge(phaseGaugeLabel, phaseGauge);\n-        this.statsLogger.unregisterGauge(ticksGaugeLabel, ticksGauge);\n-        this.statsLogger.unregisterGauge(cachEntriesGaugeLabel, cacheEntriesGauge);\n-    }\n-}"},{"sha":"8529281bf18d1947d6baa17954c446914d2de264","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadWorker.java","status":"removed","additions":0,"deletions":1503,"changes":1503,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java?ref=1166e11904ab83ec64e0147998cebffc653bdbf3","patch":"@@ -1,1503 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.twitter.distributedlog.readahead;\n-\n-import com.google.common.annotations.VisibleForTesting;\n-import com.google.common.base.Stopwatch;\n-import com.twitter.distributedlog.exceptions.AlreadyTruncatedTransactionException;\n-import com.twitter.distributedlog.AsyncNotification;\n-import com.twitter.distributedlog.BKLogHandler;\n-import com.twitter.distributedlog.DLSN;\n-import com.twitter.distributedlog.DistributedLogConfiguration;\n-import com.twitter.distributedlog.LedgerDescriptor;\n-import com.twitter.distributedlog.LedgerHandleCache;\n-import com.twitter.distributedlog.LedgerReadPosition;\n-import com.twitter.distributedlog.exceptions.LogNotFoundException;\n-import com.twitter.distributedlog.exceptions.LogReadException;\n-import com.twitter.distributedlog.LogSegmentMetadata;\n-import com.twitter.distributedlog.ReadAheadCache;\n-import com.twitter.distributedlog.callback.LogSegmentListener;\n-import com.twitter.distributedlog.callback.ReadAheadCallback;\n-import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n-import com.twitter.distributedlog.exceptions.DLInterruptedException;\n-import com.twitter.distributedlog.exceptions.UnexpectedException;\n-import com.twitter.distributedlog.metadata.LogMetadataForReader;\n-import com.twitter.distributedlog.injector.AsyncFailureInjector;\n-import com.twitter.distributedlog.io.AsyncCloseable;\n-import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n-import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n-import com.twitter.distributedlog.util.FutureUtils;\n-import com.twitter.distributedlog.util.OrderedScheduler;\n-import com.twitter.util.Future;\n-import com.twitter.util.FutureEventListener;\n-import com.twitter.util.Promise;\n-import org.apache.bookkeeper.client.AsyncCallback;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.LedgerEntry;\n-import org.apache.bookkeeper.client.LedgerHandle;\n-import org.apache.bookkeeper.proto.BookkeeperInternalCallbacks;\n-import org.apache.bookkeeper.stats.AlertStatsLogger;\n-import org.apache.bookkeeper.stats.Counter;\n-import org.apache.bookkeeper.stats.OpStatsLogger;\n-import org.apache.bookkeeper.stats.StatsLogger;\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.commons.lang3.tuple.Pair;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import scala.Function1;\n-import scala.runtime.AbstractFunction1;\n-import scala.runtime.BoxedUnit;\n-\n-import java.util.Enumeration;\n-import java.util.List;\n-import java.util.concurrent.RejectedExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.concurrent.atomic.AtomicInteger;\n-\n-/**\n- * ReadAhead Worker process readahead in asynchronous way. The whole readahead process are chained into\n- * different phases:\n- *\n- * <p>\n- * ScheduleReadAheadPhase: Schedule the readahead request based on previous state (e.g. whether to backoff).\n- * After the readahead request was scheduled, the worker enters ReadAhead phase.\n- * </p>\n- * <p>\n- * ReadAhead Phase: This phase is divided into several sub-phases. All the sub-phases are chained into the\n- * execution flow. If errors happened during execution, the worker enters Exceptions Handling Phase.\n- * <br>\n- * CheckInProgressChangedPhase: check whether there is in progress ledgers changed and updated the metadata.\n- * <br>\n- * OpenLedgerPhase: open ledgers if necessary for following read requests.\n- * <br>\n- * ReadEntriesPhase: read entries from bookkeeper and fill the readahead cache.\n- * <br>\n- * After that, the worker goes back to Schedule Phase to schedule next readahead request.\n- * </p>\n- * <p>\n- * Exceptions Handling Phase: Handle all the exceptions and properly schedule next readahead request.\n- * </p>\n- */\n-public class ReadAheadWorker implements ReadAheadCallback, Runnable, AsyncCloseable, LogSegmentListener {\n-\n-    private static final Logger LOG = LoggerFactory.getLogger(ReadAheadWorker.class);\n-\n-    private static final int BKC_ZK_EXCEPTION_THRESHOLD_IN_SECONDS = 30;\n-    private static final int BKC_UNEXPECTED_EXCEPTION_THRESHOLD = 3;\n-\n-    // Stream information\n-    private final String fullyQualifiedName;\n-    private final DistributedLogConfiguration conf;\n-    private final DynamicDistributedLogConfiguration dynConf;\n-    private final LogMetadataForReader logMetadata;\n-    private final BKLogHandler bkLedgerManager;\n-    private final boolean isHandleForReading;\n-    // Notification to notify readahead status\n-    protected final AsyncNotification notification;\n-\n-    // resources\n-    protected final OrderedScheduler scheduler;\n-    private final LedgerHandleCache handleCache;\n-    private final ReadAheadCache readAheadCache;\n-\n-    // ReadAhead Status\n-    volatile boolean running = true;\n-    Promise<Void> stopPromise = null;\n-    private volatile boolean isCatchingUp = true;\n-    private volatile boolean logDeleted = false;\n-    private volatile boolean readAheadError = false;\n-    private volatile boolean readAheadInterrupted = false;\n-    private volatile boolean readingFromTruncated = false;\n-\n-    // Exceptions Handling\n-    volatile boolean encounteredException = false;\n-    private final AtomicInteger bkcZkExceptions = new AtomicInteger(0);\n-    private final AtomicInteger bkcUnExpectedExceptions = new AtomicInteger(0);\n-    private final int noLedgerExceptionOnReadLACThreshold;\n-    private final AtomicInteger bkcNoLedgerExceptionsOnReadLAC = new AtomicInteger(0);\n-\n-    // Read Ahead Positions\n-    private final LedgerReadPosition startReadPosition;\n-    protected LedgerReadPosition nextReadAheadPosition;\n-\n-    //\n-    // LogSegments & Metadata Notification\n-    //\n-\n-    // variables related to zookeeper watcher notification to interrupt long poll waits\n-    final Object notificationLock = new Object();\n-    AsyncNotification metadataNotification = null;\n-    volatile long metadataNotificationTimeMillis = -1L;\n-\n-    // variables related to log segments\n-    private volatile boolean reInitializeMetadata = true;\n-    private volatile boolean forceReadLogSegments = false;\n-    volatile boolean inProgressChanged = false;\n-    private LogSegmentMetadata currentMetadata = null;\n-    private int currentMetadataIndex;\n-    protected LedgerDescriptor currentLH;\n-    private volatile List<LogSegmentMetadata> logSegmentListNotified;\n-    private volatile List<LogSegmentMetadata> logSegmentList;\n-\n-    //\n-    // ReadAhead Phases\n-    //\n-\n-    final Phase schedulePhase = new ScheduleReadAheadPhase();\n-    final Phase exceptionHandler = new ExceptionHandlePhase(schedulePhase);\n-    final Phase readAheadPhase =\n-            new StoppablePhase(\n-                    new CheckInProgressChangedPhase(\n-                            new OpenLedgerPhase(\n-                                    new ReadEntriesPhase(schedulePhase))));\n-\n-    //\n-    // Stats, Tracing and Failure Injection\n-    //\n-\n-    // failure injector\n-    private final AsyncFailureInjector failureInjector;\n-    // trace\n-    protected final long metadataLatencyWarnThresholdMillis;\n-    final ReadAheadTracker tracker;\n-    final Stopwatch resumeStopWatch;\n-    final Stopwatch LACNotAdvancedStopWatch = Stopwatch.createUnstarted();\n-    // Misc\n-    private final boolean readAheadSkipBrokenEntries;\n-    // Stats\n-    private final AlertStatsLogger alertStatsLogger;\n-    private final StatsLogger readAheadPerStreamStatsLogger;\n-    private final Counter readAheadWorkerWaits;\n-    private final Counter readAheadEntryPiggyBackHits;\n-    private final Counter readAheadEntryPiggyBackMisses;\n-    private final Counter readAheadReadLACAndEntryCounter;\n-    private final Counter readAheadCacheFullCounter;\n-    private final Counter readAheadSkippedBrokenEntries;\n-    private final Counter idleReaderWarn;\n-    private final OpStatsLogger readAheadReadEntriesStat;\n-    private final OpStatsLogger readAheadCacheResumeStat;\n-    private final OpStatsLogger readAheadLacLagStats;\n-    private final OpStatsLogger longPollInterruptionStat;\n-    private final OpStatsLogger metadataReinitializationStat;\n-    private final OpStatsLogger notificationExecutionStat;\n-    private final ReadAheadExceptionsLogger readAheadExceptionsLogger;\n-\n-    public ReadAheadWorker(DistributedLogConfiguration conf,\n-                           DynamicDistributedLogConfiguration dynConf,\n-                           LogMetadataForReader logMetadata,\n-                           BKLogHandler ledgerManager,\n-                           OrderedScheduler scheduler,\n-                           LedgerHandleCache handleCache,\n-                           LedgerReadPosition startPosition,\n-                           ReadAheadCache readAheadCache,\n-                           boolean isHandleForReading,\n-                           ReadAheadExceptionsLogger readAheadExceptionsLogger,\n-                           StatsLogger handlerStatsLogger,\n-                           StatsLogger readAheadPerStreamStatsLogger,\n-                           AlertStatsLogger alertStatsLogger,\n-                           AsyncFailureInjector failureInjector,\n-                           AsyncNotification notification) {\n-        // Log information\n-        this.fullyQualifiedName = logMetadata.getFullyQualifiedName();\n-        this.conf = conf;\n-        this.dynConf = dynConf;\n-        this.logMetadata = logMetadata;\n-        this.bkLedgerManager = ledgerManager;\n-        this.isHandleForReading = isHandleForReading;\n-        this.notification = notification;\n-        // Resources\n-        this.scheduler = scheduler;\n-        this.handleCache = handleCache;\n-        this.readAheadCache = readAheadCache;\n-        // Readahead status\n-        this.startReadPosition = new LedgerReadPosition(startPosition);\n-        this.nextReadAheadPosition = new LedgerReadPosition(startPosition);\n-        // LogSegments\n-\n-        // Failure Detection\n-        this.failureInjector = failureInjector;\n-        // Tracing\n-        this.metadataLatencyWarnThresholdMillis = conf.getMetadataLatencyWarnThresholdMillis();\n-        this.noLedgerExceptionOnReadLACThreshold =\n-                conf.getReadAheadNoSuchLedgerExceptionOnReadLACErrorThresholdMillis() / conf.getReadAheadWaitTime();\n-        this.tracker = new ReadAheadTracker(logMetadata.getLogName(), readAheadCache,\n-                ReadAheadPhase.SCHEDULE_READAHEAD, readAheadPerStreamStatsLogger);\n-        this.resumeStopWatch = Stopwatch.createUnstarted();\n-        // Misc\n-        this.readAheadSkipBrokenEntries = conf.getReadAheadSkipBrokenEntries();\n-        // Stats\n-        this.alertStatsLogger = alertStatsLogger;\n-        this.readAheadPerStreamStatsLogger = readAheadPerStreamStatsLogger;\n-        StatsLogger readAheadStatsLogger = handlerStatsLogger.scope(\"readahead_worker\");\n-        readAheadWorkerWaits = readAheadStatsLogger.getCounter(\"wait\");\n-        readAheadEntryPiggyBackHits = readAheadStatsLogger.getCounter(\"entry_piggy_back_hits\");\n-        readAheadEntryPiggyBackMisses = readAheadStatsLogger.getCounter(\"entry_piggy_back_misses\");\n-        readAheadReadEntriesStat = readAheadStatsLogger.getOpStatsLogger(\"read_entries\");\n-        readAheadReadLACAndEntryCounter = readAheadStatsLogger.getCounter(\"read_lac_and_entry_counter\");\n-        readAheadCacheFullCounter = readAheadStatsLogger.getCounter(\"cache_full\");\n-        readAheadSkippedBrokenEntries = readAheadStatsLogger.getCounter(\"skipped_broken_entries\");\n-        readAheadCacheResumeStat = readAheadStatsLogger.getOpStatsLogger(\"resume\");\n-        readAheadLacLagStats = readAheadStatsLogger.getOpStatsLogger(\"read_lac_lag\");\n-        longPollInterruptionStat = readAheadStatsLogger.getOpStatsLogger(\"long_poll_interruption\");\n-        notificationExecutionStat = readAheadStatsLogger.getOpStatsLogger(\"notification_execution\");\n-        metadataReinitializationStat = readAheadStatsLogger.getOpStatsLogger(\"metadata_reinitialization\");\n-        idleReaderWarn = readAheadStatsLogger.getCounter(\"idle_reader_warn\");\n-        this.readAheadExceptionsLogger = readAheadExceptionsLogger;\n-    }\n-\n-    @VisibleForTesting\n-    public LedgerReadPosition getNextReadAheadPosition() {\n-        return nextReadAheadPosition;\n-    }\n-\n-    public LedgerDescriptor getCurrentLedgerDescriptor() {\n-        return currentLH;\n-    }\n-\n-    //\n-    // ReadAhead Status\n-    //\n-\n-    void setReadAheadError(ReadAheadTracker tracker, Throwable cause) {\n-        LOG.error(\"Read Ahead for {} is set to error.\", logMetadata.getFullyQualifiedName());\n-        readAheadError = true;\n-        tracker.enterPhase(ReadAheadPhase.ERROR);\n-        if (null != notification) {\n-            notification.notifyOnError(cause);\n-        }\n-        if (null != stopPromise) {\n-            FutureUtils.setValue(stopPromise, null);\n-        }\n-    }\n-\n-    void setReadAheadInterrupted(ReadAheadTracker tracker) {\n-        readAheadInterrupted = true;\n-        tracker.enterPhase(ReadAheadPhase.INTERRUPTED);\n-        if (null != notification) {\n-            notification.notifyOnError(new DLInterruptedException(\"ReadAhead worker for \"\n-                    + bkLedgerManager.getFullyQualifiedName() + \" is interrupted.\"));\n-        }\n-        if (null != stopPromise) {\n-            FutureUtils.setValue(stopPromise, null);\n-        }\n-    }\n-\n-    void setReadingFromTruncated(ReadAheadTracker tracker) {\n-        readingFromTruncated = true;\n-        tracker.enterPhase(ReadAheadPhase.TRUNCATED);\n-        if (null != notification) {\n-            notification.notifyOnError(\n-                    new AlreadyTruncatedTransactionException(logMetadata.getFullyQualifiedName()\n-                            + \": Trying to position read ahead to a segment that is marked truncated\"));\n-        }\n-        if (null != stopPromise) {\n-            FutureUtils.setValue(stopPromise, null);\n-        }\n-    }\n-\n-    private void setReadAheadStopped() {\n-        tracker.enterPhase(ReadAheadPhase.STOPPED);\n-        if (null != stopPromise) {\n-            FutureUtils.setValue(stopPromise, null);\n-        }\n-        LOG.info(\"Stopped ReadAheadWorker for {}\", fullyQualifiedName);\n-    }\n-\n-    public void checkClosedOrInError()\n-            throws LogNotFoundException, LogReadException, DLInterruptedException,\n-            AlreadyTruncatedTransactionException {\n-        if (logDeleted) {\n-            throw new LogNotFoundException(logMetadata.getFullyQualifiedName() + \" is already deleted.\");\n-        } else if (readingFromTruncated) {\n-            throw new AlreadyTruncatedTransactionException(\n-                String.format(\"%s: Trying to position read ahead a segment that is marked truncated\",\n-                    logMetadata.getFullyQualifiedName()));\n-        } else if (readAheadInterrupted) {\n-            throw new DLInterruptedException(String.format(\"%s: ReadAhead Thread was interrupted\",\n-                logMetadata.getFullyQualifiedName()));\n-        } else if (readAheadError) {\n-            throw new LogReadException(String.format(\"%s: ReadAhead Thread encountered exceptions\",\n-                logMetadata.getFullyQualifiedName()));\n-        }\n-    }\n-\n-    public boolean isCaughtUp() {\n-        return !isCatchingUp;\n-    }\n-\n-    public void start(List<LogSegmentMetadata> segmentList) {\n-        LOG.debug(\"Starting ReadAhead Worker for {} : segments = {}\",\n-                fullyQualifiedName, segmentList);\n-        running = true;\n-        logSegmentListNotified = segmentList;\n-        schedulePhase.process(BKException.Code.OK);\n-    }\n-\n-    @Override\n-    public Future<Void> asyncClose() {\n-        LOG.info(\"Stopping Readahead worker for {}\", fullyQualifiedName);\n-        running = false;\n-        // Unregister associated gauages to prevent GC spiral\n-        this.tracker.unregisterGauge();\n-\n-        // Aside from unfortunate naming of variables, this allows\n-        // the currently active long poll to be interrupted and completed\n-        AsyncNotification notification;\n-        synchronized (notificationLock) {\n-            notification = metadataNotification;\n-            metadataNotification = null;\n-        }\n-        if (null != notification) {\n-            notification.notifyOnOperationComplete();\n-        }\n-        if (null == stopPromise) {\n-            return Future.Void();\n-        }\n-        return FutureUtils.ignore(FutureUtils.within(\n-                stopPromise,\n-                2 * conf.getReadAheadWaitTime(),\n-                TimeUnit.MILLISECONDS,\n-                new TimeoutException(\"Timeout on waiting for ReadAhead worker to stop \" + fullyQualifiedName),\n-                scheduler,\n-                fullyQualifiedName));\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return \"Running:\" + running +\n-            \", NextReadAheadPosition:\" + nextReadAheadPosition +\n-            \", BKZKExceptions:\" + bkcZkExceptions.get() +\n-            \", BKUnexpectedExceptions:\" + bkcUnExpectedExceptions.get() +\n-            \", EncounteredException:\" + encounteredException +\n-            \", readAheadError:\" + readAheadError +\n-            \", readAheadInterrupted\" + readAheadInterrupted +\n-            \", CurrentMetadata:\" + ((null != currentMetadata) ? currentMetadata : \"NONE\") +\n-            \", FailureInjector:\" + failureInjector;\n-    }\n-\n-    @Override\n-    public void resumeReadAhead() {\n-        try {\n-            long cacheResumeLatency = resumeStopWatch.stop().elapsed(TimeUnit.MICROSECONDS);\n-            readAheadCacheResumeStat.registerSuccessfulEvent(cacheResumeLatency);\n-        } catch (IllegalStateException ise) {\n-            LOG.error(\"Encountered illegal state when stopping resume stop watch for {} : \",\n-                    logMetadata.getFullyQualifiedName(), ise);\n-        }\n-        submit(this);\n-    }\n-\n-    Runnable addRTEHandler(final Runnable runnable) {\n-        return new Runnable() {\n-            @Override\n-            public void run() {\n-                try {\n-                    runnable.run();\n-                } catch (RuntimeException rte) {\n-                    LOG.error(\"ReadAhead on stream {} encountered runtime exception\",\n-                            logMetadata.getFullyQualifiedName(), rte);\n-                    setReadAheadError(tracker, rte);\n-                    throw rte;\n-                }\n-            }\n-        };\n-    }\n-\n-    <T> Function1<T, BoxedUnit> submit(final Function1<T, BoxedUnit> function) {\n-        return new AbstractFunction1<T, BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply(final T input) {\n-                submit(new Runnable() {\n-                    @Override\n-                    public void run() {\n-                        function.apply(input);\n-                    }\n-                });\n-                return BoxedUnit.UNIT;\n-            }\n-        };\n-    }\n-\n-    void submit(Runnable runnable) {\n-        if (failureInjector.shouldInjectStops()) {\n-            LOG.warn(\"Error injected: read ahead for stream {} is going to stall.\",\n-                    logMetadata.getFullyQualifiedName());\n-            return;\n-        }\n-\n-        if (failureInjector.shouldInjectDelays()) {\n-            int delayMs = failureInjector.getInjectedDelayMs();\n-            schedule(runnable, delayMs);\n-            return;\n-        }\n-\n-        try {\n-            scheduler.submit(addRTEHandler(runnable));\n-        } catch (RejectedExecutionException ree) {\n-            setReadAheadError(tracker, ree);\n-        }\n-    }\n-\n-    private void schedule(Runnable runnable, long timeInMillis) {\n-        try {\n-            InterruptibleScheduledRunnable task = new InterruptibleScheduledRunnable(runnable);\n-            boolean executeImmediately = setMetadataNotification(task);\n-            if (executeImmediately) {\n-                scheduler.submit(addRTEHandler(task));\n-                return;\n-            }\n-            scheduler.schedule(addRTEHandler(task), timeInMillis, TimeUnit.MILLISECONDS);\n-            readAheadWorkerWaits.inc();\n-        } catch (RejectedExecutionException ree) {\n-            setReadAheadError(tracker, ree);\n-        }\n-    }\n-\n-    private void handleException(ReadAheadPhase phase, int returnCode) {\n-        readAheadExceptionsLogger.getBKExceptionStatsLogger(phase.name()).getExceptionCounter(returnCode).inc();\n-        exceptionHandler.process(returnCode);\n-    }\n-\n-    private boolean closeCurrentLedgerHandle() {\n-        if (currentLH == null) {\n-            return true;\n-        }\n-        boolean retVal = false;\n-        LedgerDescriptor ld = currentLH;\n-        try {\n-            handleCache.closeLedger(ld);\n-            currentLH = null;\n-            retVal = true;\n-        } catch (BKException bke) {\n-            LOG.debug(\"BK Exception during closing {} : \", ld, bke);\n-            handleException(ReadAheadPhase.CLOSE_LEDGER, bke.getCode());\n-        }\n-\n-        return retVal;\n-    }\n-\n-    abstract class Phase {\n-\n-        final Phase next;\n-\n-        Phase(Phase next) {\n-            this.next = next;\n-        }\n-\n-        abstract void process(int rc);\n-    }\n-\n-    /**\n-     * Schedule next readahead request. If we need to backoff, schedule in a backoff delay.\n-     */\n-    final class ScheduleReadAheadPhase extends Phase {\n-\n-        ScheduleReadAheadPhase() {\n-            super(null);\n-        }\n-\n-        @Override\n-        void process(int rc) {\n-            if (!running) {\n-                setReadAheadStopped();\n-                return;\n-            }\n-            tracker.enterPhase(ReadAheadPhase.SCHEDULE_READAHEAD);\n-\n-            boolean injectErrors = failureInjector.shouldInjectErrors();\n-            if (encounteredException || injectErrors) {\n-                int zkErrorThreshold = BKC_ZK_EXCEPTION_THRESHOLD_IN_SECONDS * 1000 * 4 / conf.getReadAheadWaitTime();\n-\n-                if ((bkcZkExceptions.get() > zkErrorThreshold) || injectErrors) {\n-                    LOG.error(\"{} : BookKeeper Client used by the ReadAhead Thread has encountered {} zookeeper exceptions : simulate = {}\",\n-                              new Object[] { fullyQualifiedName, bkcZkExceptions.get(), injectErrors });\n-                    running = false;\n-                    setReadAheadError(tracker, new LogReadException(\n-                            \"Encountered too many zookeeper issues on read ahead for \" + bkLedgerManager.getFullyQualifiedName()));\n-                } else if (bkcUnExpectedExceptions.get() > BKC_UNEXPECTED_EXCEPTION_THRESHOLD) {\n-                    LOG.error(\"{} : ReadAhead Thread has encountered {} unexpected BK exceptions.\",\n-                              fullyQualifiedName, bkcUnExpectedExceptions.get());\n-                    running = false;\n-                    setReadAheadError(tracker, new LogReadException(\n-                            \"Encountered too many unexpected bookkeeper issues on read ahead for \" + bkLedgerManager.getFullyQualifiedName()));\n-                } else {\n-                    // We must always reinitialize metadata if the last attempt to read failed.\n-                    reInitializeMetadata = true;\n-                    encounteredException = false;\n-                    // Backoff before resuming\n-                    if (LOG.isTraceEnabled()) {\n-                        LOG.trace(\"Scheduling read ahead for {} after {} ms.\", fullyQualifiedName, conf.getReadAheadWaitTime() / 4);\n-                    }\n-                    schedule(ReadAheadWorker.this, conf.getReadAheadWaitTime() / 4);\n-                }\n-            } else {\n-                if (LOG.isTraceEnabled()) {\n-                    LOG.trace(\"Scheduling read ahead for {} now.\", fullyQualifiedName);\n-                }\n-                submit(ReadAheadWorker.this);\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * Phase on handling exceptions.\n-     */\n-    final class ExceptionHandlePhase extends Phase {\n-\n-        ExceptionHandlePhase(Phase next) {\n-            super(next);\n-        }\n-\n-        @Override\n-        void process(int rc) {\n-            tracker.enterPhase(ReadAheadPhase.EXCEPTION_HANDLING);\n-\n-            if (BKException.Code.InterruptedException == rc) {\n-                LOG.trace(\"ReadAhead Worker for {} is interrupted.\", fullyQualifiedName);\n-                running = false;\n-                setReadAheadInterrupted(tracker);\n-                return;\n-            } else if (BKException.Code.ZKException == rc) {\n-                encounteredException = true;\n-                int numExceptions = bkcZkExceptions.incrementAndGet();\n-                LOG.debug(\"ReadAhead Worker for {} encountered zookeeper exception : total exceptions are {}.\",\n-                        fullyQualifiedName, numExceptions);\n-            } else if (BKException.Code.OK != rc) {\n-                encounteredException = true;\n-                switch(rc) {\n-                    case BKException.Code.NoSuchEntryException:\n-                    case BKException.Code.LedgerRecoveryException:\n-                    case BKException.Code.NoSuchLedgerExistsException:\n-                        break;\n-                    default:\n-                        bkcUnExpectedExceptions.incrementAndGet();\n-                }\n-                LOG.info(\"ReadAhead Worker for {} encountered exception : {}\",\n-                        fullyQualifiedName, BKException.create(rc));\n-            }\n-            // schedule next read ahead\n-            next.process(BKException.Code.OK);\n-        }\n-    }\n-\n-    /**\n-     * A phase that could be stopped by a stopPromise\n-     */\n-    final class StoppablePhase extends Phase {\n-\n-        StoppablePhase(Phase next) {\n-            super(next);\n-        }\n-\n-        @Override\n-        void process(int rc) {\n-            if (!running) {\n-                setReadAheadStopped();\n-                return;\n-            }\n-\n-            if (null == stopPromise) {\n-                stopPromise = new Promise<Void>();\n-            }\n-\n-            // proceed the readahead request\n-            next.process(BKException.Code.OK);\n-        }\n-    }\n-\n-    /**\n-     * Phase on checking in progress changed.\n-     */\n-    final class CheckInProgressChangedPhase extends Phase\n-            implements FutureEventListener<Versioned<List<LogSegmentMetadata>>> {\n-\n-        CheckInProgressChangedPhase(Phase next) {\n-            super(next);\n-        }\n-\n-        void processLogSegments(final List<LogSegmentMetadata> segments) {\n-            // submit callback execution to dlg executor to avoid deadlock.\n-            submit(new Runnable() {\n-                @Override\n-                public void run() {\n-                    logSegmentList = segments;\n-                    boolean isInitialPositioning = nextReadAheadPosition.definitelyLessThanOrEqualTo(startReadPosition);\n-                    for (int i = 0; i < logSegmentList.size(); i++) {\n-                        LogSegmentMetadata l = logSegmentList.get(i);\n-                        // By default we should skip truncated segments during initial positioning\n-                        if (l.isTruncated() &&\n-                            isInitialPositioning &&\n-                            !conf.getIgnoreTruncationStatus()) {\n-                            continue;\n-                        }\n-\n-                        DLSN nextReadDLSN = new DLSN(nextReadAheadPosition.getLogSegmentSequenceNumber(),\n-                                nextReadAheadPosition.getEntryId(), -1);\n-\n-                        // next read position still inside a log segment\n-                        final boolean hasDataToRead = (l.getLastDLSN().compareTo(nextReadDLSN) >= 0);\n-\n-                        // either there is data to read in current log segment or we are moving over a log segment that is\n-                        // still inprogress or was inprogress, we have check (or maybe close) this log segment.\n-                        final boolean checkOrCloseLedger = hasDataToRead ||\n-                            // next read position move over a log segment, if l is still inprogress or it was inprogress\n-                            ((l.isInProgress() || (null != currentMetadata && currentMetadata.isInProgress())) &&\n-                                    l.getLogSegmentSequenceNumber() == nextReadAheadPosition.getLogSegmentSequenceNumber());\n-\n-                        // If we are positioning on a partially truncated log segment then the truncation point should\n-                        // be before the nextReadPosition\n-                        if (l.isPartiallyTruncated() &&\n-                            !isInitialPositioning &&\n-                            (l.getMinActiveDLSN().compareTo(nextReadDLSN) > 0)) {\n-                            if (conf.getAlertWhenPositioningOnTruncated()) {\n-                                alertStatsLogger.raise(\"Trying to position reader on {} when {} is marked partially truncated\",\n-                                    nextReadAheadPosition, l);\n-                            }\n-\n-                            if (!conf.getIgnoreTruncationStatus()) {\n-                                LOG.error(\"{}: Trying to position reader on {} when {} is marked partially truncated\",\n-                                    new Object[]{ logMetadata.getFullyQualifiedName(), nextReadAheadPosition, l});\n-                                setReadingFromTruncated(tracker);\n-                                return;\n-                            }\n-                        }\n-\n-\n-                        if (LOG.isTraceEnabled()) {\n-                            LOG.trace(\"CheckLogSegment : newMetadata = {}, currentMetadata = {}, nextReadAheadPosition = {}\",\n-                                      new Object[] { l, currentMetadata, nextReadAheadPosition});\n-                        }\n-\n-                        if (checkOrCloseLedger) {\n-                            long startBKEntry = 0;\n-                            if (l.isPartiallyTruncated() && !conf.getIgnoreTruncationStatus()) {\n-                                startBKEntry = l.getMinActiveDLSN().getEntryId();\n-                            }\n-\n-                            if(l.getLogSegmentSequenceNumber() == nextReadAheadPosition.getLogSegmentSequenceNumber()) {\n-                                startBKEntry = Math.max(startBKEntry, nextReadAheadPosition.getEntryId());\n-                                if (currentMetadata != null) {\n-                                    inProgressChanged = currentMetadata.isInProgress() && !l.isInProgress();\n-                                }\n-                            } else {\n-                                // We are positioning on a new ledger => reset the current ledger handle\n-                                LOG.trace(\"Positioning {} on a new ledger {}\", fullyQualifiedName, l);\n-\n-                                if (!closeCurrentLedgerHandle()) {\n-                                    return;\n-                                }\n-                            }\n-\n-                            nextReadAheadPosition = new LedgerReadPosition(l.getLogSegmentId(), l.getLogSegmentSequenceNumber(), startBKEntry);\n-                            if (conf.getTraceReadAheadMetadataChanges()) {\n-                                LOG.info(\"Moved read position to {} for stream {} at {}.\",\n-                                         new Object[] {nextReadAheadPosition, logMetadata.getFullyQualifiedName(), System.currentTimeMillis() });\n-                            }\n-\n-                            if (l.isTruncated()) {\n-                                if (conf.getAlertWhenPositioningOnTruncated()) {\n-                                    alertStatsLogger.raise(\"Trying to position reader on {} when {} is marked truncated\",\n-                                        nextReadAheadPosition, l);\n-                                }\n-\n-                                if (!conf.getIgnoreTruncationStatus()) {\n-                                    LOG.error(\"{}: Trying to position reader on {} when {} is marked truncated\",\n-                                        new Object[]{ logMetadata.getFullyQualifiedName(), nextReadAheadPosition, l});\n-                                    setReadingFromTruncated(tracker);\n-                                    return;\n-                                }\n-                            }\n-\n-                            currentMetadata = l;\n-                            currentMetadataIndex = i;\n-                            break;\n-                        }\n-\n-                        // Handle multiple in progress => stop at the first in progress\n-                        if (l.isInProgress()) {\n-                            break;\n-                        }\n-                    }\n-\n-                    if (null == currentMetadata) {\n-                        if (isCatchingUp) {\n-                            isCatchingUp = false;\n-                            if (isHandleForReading) {\n-                                LOG.info(\"{} caught up at {}: position = {} and no log segment to position on at this point.\",\n-                                         new Object[] { fullyQualifiedName, System.currentTimeMillis(), nextReadAheadPosition });\n-                            }\n-                        }\n-                        schedule(ReadAheadWorker.this, conf.getReadAheadWaitTimeOnEndOfStream());\n-                        if (LOG.isDebugEnabled()) {\n-                            LOG.debug(\"No log segment to position on for {}. Backing off for {} millseconds\",\n-                                    fullyQualifiedName, conf.getReadAheadWaitTimeOnEndOfStream());\n-                        }\n-                    } else  {\n-                        if (LOG.isDebugEnabled()) {\n-                            LOG.debug(\"Initialized metadata for {}, starting reading ahead from {} : {}.\",\n-                                    new Object[] { fullyQualifiedName, currentMetadataIndex, currentMetadata });\n-                        }\n-                        next.process(BKException.Code.OK);\n-                    }\n-\n-                    // Once we have read the ledger list for the first time, subsequent segments\n-                    // should be read in a streaming manner and we should get the new ledgers as\n-                    // they close in ZK through watchers.\n-                    // So lets start observing the latency\n-                    bkLedgerManager.reportGetSegmentStats(true);\n-                }\n-            });\n-        }\n-\n-        @Override\n-        void process(int rc) {\n-            if (!running) {\n-                setReadAheadStopped();\n-                return;\n-            }\n-\n-            tracker.enterPhase(ReadAheadPhase.GET_LEDGERS);\n-\n-            inProgressChanged = false;\n-            if (LOG.isTraceEnabled()) {\n-                LOG.trace(\"Checking {} if InProgress changed.\", fullyQualifiedName);\n-            }\n-\n-            if (reInitializeMetadata || null == currentMetadata) {\n-                reInitializeMetadata = false;\n-                if (LOG.isTraceEnabled()) {\n-                    LOG.trace(\"Reinitializing metadata for {}.\", fullyQualifiedName);\n-                }\n-                if (metadataNotificationTimeMillis > 0) {\n-                    long metadataReinitializeTimeMillis = System.currentTimeMillis();\n-                    long elapsedMillisSinceMetadataChanged = metadataReinitializeTimeMillis - metadataNotificationTimeMillis;\n-                    if (elapsedMillisSinceMetadataChanged >= metadataLatencyWarnThresholdMillis) {\n-                        LOG.warn(\"{} reinitialize metadata at {}, which is {} millis after receiving notification at {}.\",\n-                                 new Object[] { logMetadata.getFullyQualifiedName(), metadataReinitializeTimeMillis,\n-                                                elapsedMillisSinceMetadataChanged, metadataNotificationTimeMillis});\n-                    }\n-                    metadataReinitializationStat.registerSuccessfulEvent(\n-                            TimeUnit.MILLISECONDS.toMicros(elapsedMillisSinceMetadataChanged));\n-                    metadataNotificationTimeMillis = -1L;\n-                }\n-                if (forceReadLogSegments) {\n-                    forceReadLogSegments = false;\n-                    bkLedgerManager.readLogSegmentsFromStore(\n-                            LogSegmentMetadata.COMPARATOR,\n-                            LogSegmentFilter.DEFAULT_FILTER,\n-                            null\n-                    ).addEventListener(this);\n-                } else {\n-                    processLogSegments(logSegmentListNotified);\n-                }\n-            } else {\n-                next.process(BKException.Code.OK);\n-            }\n-        }\n-\n-        @Override\n-        public void onSuccess(Versioned<List<LogSegmentMetadata>> segments) {\n-            processLogSegments(segments.getValue());\n-        }\n-\n-        @Override\n-        public void onFailure(Throwable cause) {\n-            LOG.info(\"Encountered metadata exception while reading log segments of {} : {}. Retrying ...\",\n-                    bkLedgerManager.getFullyQualifiedName(), cause.getMessage());\n-            reInitializeMetadata = true;\n-            forceReadLogSegments = true;\n-            handleException(ReadAheadPhase.GET_LEDGERS, BKException.Code.ZKException);\n-        }\n-    }\n-\n-    final class OpenLedgerPhase extends Phase\n-            implements BookkeeperInternalCallbacks.GenericCallback<LedgerDescriptor>,\n-                        AsyncCallback.ReadLastConfirmedAndEntryCallback {\n-\n-        OpenLedgerPhase(Phase next) {\n-            super(next);\n-        }\n-\n-        private void issueReadLastConfirmedAndEntry(final boolean parallel,\n-                                                    final long lastAddConfirmed) {\n-            final String ctx = String.format(\"ReadLastConfirmedAndEntry(%s, %d)\", parallel? \"Parallel\":\"Sequential\", lastAddConfirmed);\n-            final ReadLastConfirmedAndEntryCallbackWithNotification callback =\n-                new ReadLastConfirmedAndEntryCallbackWithNotification(lastAddConfirmed, this, ctx);\n-            boolean callbackImmediately = setMetadataNotification(callback);\n-            handleCache.asyncReadLastConfirmedAndEntry(\n-                    currentLH,\n-                    nextReadAheadPosition.getEntryId(),\n-                    conf.getReadLACLongPollTimeout(),\n-                    parallel\n-            ).addEventListener(new FutureEventListener<Pair<Long, LedgerEntry>>() {\n-                @Override\n-                public void onSuccess(Pair<Long, LedgerEntry> lacAndEntry) {\n-                    callback.readLastConfirmedAndEntryComplete(\n-                            BKException.Code.OK,\n-                            lacAndEntry.getLeft(),\n-                            lacAndEntry.getRight(),\n-                            ctx);\n-                }\n-\n-                @Override\n-                public void onFailure(Throwable cause) {\n-                    callback.readLastConfirmedAndEntryComplete(\n-                            FutureUtils.bkResultCode(cause),\n-                            lastAddConfirmed,\n-                            null,\n-                            ctx);\n-                }\n-            });\n-            callback.callbackImmediately(callbackImmediately);\n-            readAheadReadLACAndEntryCounter.inc();\n-        }\n-\n-        @Override\n-        void process(int rc) {\n-            if (!running) {\n-                setReadAheadStopped();\n-                return;\n-            }\n-\n-            tracker.enterPhase(ReadAheadPhase.OPEN_LEDGER);\n-\n-            if (currentMetadata.isInProgress()) { // we don't want to fence the current journal\n-                if (null == currentLH) {\n-                    if (conf.getTraceReadAheadMetadataChanges()) {\n-                        LOG.info(\"Opening inprogress ledger of {} for {} at {}.\",\n-                                 new Object[] { currentMetadata, fullyQualifiedName, System.currentTimeMillis() });\n-                    }\n-                    handleCache.asyncOpenLedger(currentMetadata, false)\n-                            .addEventListener(new FutureEventListener<LedgerDescriptor>() {\n-                                @Override\n-                                public void onSuccess(LedgerDescriptor ld) {\n-                                    operationComplete(BKException.Code.OK, ld);\n-                                }\n-\n-                                @Override\n-                                public void onFailure(Throwable cause) {\n-                                    operationComplete(FutureUtils.bkResultCode(cause), null);\n-                                }\n-                            });\n-                } else {\n-                    final long lastAddConfirmed;\n-                    try {\n-                        lastAddConfirmed = handleCache.getLastAddConfirmed(currentLH);\n-                    } catch (BKException ie) {\n-                        // Exception is thrown due to no ledger handle\n-                        handleException(ReadAheadPhase.OPEN_LEDGER, ie.getCode());\n-                        return;\n-                    }\n-\n-                    if (lastAddConfirmed < nextReadAheadPosition.getEntryId()) {\n-                        // This indicates that the currentMetadata is still marked in\n-                        // progress while we have already read all the entries. It might\n-                        // indicate a failure to detect metadata change. So we\n-                        // should probably try force read log segments if the reader has\n-                        // been idle for after a while.\n-                        if (LACNotAdvancedStopWatch.isRunning()) {\n-                            if (LACNotAdvancedStopWatch.elapsed(TimeUnit.MILLISECONDS)\n-                                > conf.getReaderIdleWarnThresholdMillis()) {\n-                                idleReaderWarn.inc();\n-                                LOG.info(\"{} Ledger {} for inprogress segment {}, reader has been idle for warn threshold {}\",\n-                                    new Object[] { fullyQualifiedName, currentMetadata, currentLH, conf.getReaderIdleWarnThresholdMillis() });\n-                                reInitializeMetadata = true;\n-                                forceReadLogSegments = true;\n-                            }\n-                        } else {\n-                            LACNotAdvancedStopWatch.reset().start();\n-                            if (conf.getTraceReadAheadMetadataChanges()) {\n-                                LOG.info(\"{} Ledger {} for inprogress segment {} closed\",\n-                                    new Object[] { fullyQualifiedName, currentMetadata, currentLH });\n-                            }\n-                        }\n-\n-                        tracker.enterPhase(ReadAheadPhase.READ_LAST_CONFIRMED);\n-\n-                        // the readahead is caught up if current ledger is in progress and read position moves over last add confirmed\n-                        if (isCatchingUp) {\n-                            isCatchingUp = false;\n-                            if (isHandleForReading) {\n-                                LOG.info(\"{} caught up at {}: lac = {}, position = {}.\",\n-                                         new Object[] { fullyQualifiedName, System.currentTimeMillis(), lastAddConfirmed, nextReadAheadPosition });\n-                            }\n-                        }\n-\n-                        LOG.trace(\"Reading last add confirmed of {} for {}, as read poistion has moved over {} : {}\",\n-                                new Object[] { currentMetadata, fullyQualifiedName, lastAddConfirmed, nextReadAheadPosition });\n-\n-                        if (nextReadAheadPosition.getEntryId() == 0 && conf.getTraceReadAheadMetadataChanges()) {\n-                            // we are waiting for first entry to arrive\n-                            LOG.info(\"Reading last add confirmed for {} at {}: lac = {}, position = {}.\",\n-                                     new Object[] { fullyQualifiedName, System.currentTimeMillis(), lastAddConfirmed, nextReadAheadPosition});\n-                        } else {\n-                            LOG.trace(\"Reading last add confirmed for {} at {}: lac = {}, position = {}.\",\n-                                      new Object[] { fullyQualifiedName, System.currentTimeMillis(), lastAddConfirmed, nextReadAheadPosition});\n-                        }\n-                        issueReadLastConfirmedAndEntry(false, lastAddConfirmed);\n-                    } else {\n-                        next.process(BKException.Code.OK);\n-                    }\n-                }\n-            } else {\n-                LACNotAdvancedStopWatch.reset();\n-                if (null != currentLH) {\n-                    try {\n-                        if (inProgressChanged) {\n-                            LOG.trace(\"Closing completed ledger of {} for {}.\", currentMetadata, fullyQualifiedName);\n-                            if (!closeCurrentLedgerHandle()) {\n-                                return;\n-                            }\n-                            inProgressChanged = false;\n-                        } else {\n-                            long lastAddConfirmed = handleCache.getLastAddConfirmed(currentLH);\n-                            if (nextReadAheadPosition.getEntryId() > lastAddConfirmed) {\n-                                // Its possible that the last entryId does not account for the control\n-                                // log record, but the lastAddConfirmed should never be short of the\n-                                // last entry id; else we maybe missing an entry\n-                                boolean gapDetected = false;\n-                                if (lastAddConfirmed < currentMetadata.getLastEntryId()) {\n-                                    alertStatsLogger.raise(\"Unexpected last entry id during read ahead; {} , {}\",\n-                                        currentMetadata, lastAddConfirmed);\n-                                    gapDetected = true;\n-                                }\n-\n-                                if (conf.getPositionGapDetectionEnabled() && gapDetected) {\n-                                    setReadAheadError(tracker, new UnexpectedException(\n-                                            \"Unexpected last entry id during read ahead : \" + currentMetadata\n-                                                    + \", lac = \" + lastAddConfirmed));\n-                                } else {\n-                                    // This disconnect will only surface during repositioning and\n-                                    // will not silently miss records; therefore its safe to not halt\n-                                    // reading, but we should print a warning for easy diagnosis\n-                                    if (conf.getTraceReadAheadMetadataChanges() && lastAddConfirmed > (currentMetadata.getLastEntryId() + 1)) {\n-                                        LOG.warn(\"Potential Metadata Corruption {} for stream {}, lastAddConfirmed {}\",\n-                                                new Object[] {currentMetadata, logMetadata.getFullyQualifiedName(), lastAddConfirmed});\n-                                    }\n-\n-                                    LOG.trace(\"Past the last Add Confirmed {} in ledger {} for {}\",\n-                                              new Object[] { lastAddConfirmed, currentMetadata, fullyQualifiedName });\n-                                    if (!closeCurrentLedgerHandle()) {\n-                                        return;\n-                                    }\n-                                    LogSegmentMetadata oldMetadata = currentMetadata;\n-                                    currentMetadata = null;\n-                                    if (currentMetadataIndex + 1 < logSegmentList.size()) {\n-                                        currentMetadata = logSegmentList.get(++currentMetadataIndex);\n-                                        if (currentMetadata.getLogSegmentSequenceNumber() != (oldMetadata.getLogSegmentSequenceNumber() + 1)) {\n-                                            // We should never get here as we should have exited the loop if\n-                                            // pendingRequests were empty\n-                                            alertStatsLogger.raise(\"Unexpected condition during read ahead; {} , {}\",\n-                                                currentMetadata, oldMetadata);\n-                                            setReadAheadError(tracker, new UnexpectedException(\n-                                                    \"Unexpected condition during read ahead : current metadata \"\n-                                                            + currentMetadata + \", old metadata \" + oldMetadata));\n-                                        } else {\n-                                            if (currentMetadata.isTruncated()) {\n-                                                if (conf.getAlertWhenPositioningOnTruncated()) {\n-                                                    alertStatsLogger.raise(\"Trying to position reader on the log segment that is marked truncated : {}\",\n-                                                        currentMetadata);\n-                                                }\n-\n-                                                if (!conf.getIgnoreTruncationStatus()) {\n-                                                    LOG.error(\"{}: Trying to position reader on the log segment that is marked truncated : {}\",\n-                                                            logMetadata.getFullyQualifiedName(), currentMetadata);\n-                                                    setReadingFromTruncated(tracker);\n-                                                }\n-                                            } else {\n-                                                if (LOG.isTraceEnabled()) {\n-                                                    LOG.trace(\"Moving read position to a new ledger {} for {}.\",\n-                                                        currentMetadata, fullyQualifiedName);\n-                                                }\n-                                                nextReadAheadPosition.positionOnNewLogSegment(currentMetadata.getLogSegmentId(), currentMetadata.getLogSegmentSequenceNumber());\n-                                            }\n-                                        }\n-                                    }\n-                                }\n-                            }\n-                        }\n-                        if (!readAheadError) {\n-                            next.process(BKException.Code.OK);\n-                        }\n-                    } catch (BKException bke) {\n-                        LOG.debug(\"Exception while repositioning\", bke);\n-                        handleException(ReadAheadPhase.CLOSE_LEDGER, bke.getCode());\n-                    }\n-                } else {\n-                    LOG.trace(\"Opening completed ledger of {} for {}.\", currentMetadata, fullyQualifiedName);\n-                    handleCache.asyncOpenLedger(currentMetadata, true)\n-                            .addEventListener(new FutureEventListener<LedgerDescriptor>() {\n-                                @Override\n-                                public void onSuccess(LedgerDescriptor ld) {\n-                                    operationComplete(BKException.Code.OK, ld);\n-                                }\n-\n-                                @Override\n-                                public void onFailure(Throwable cause) {\n-                                    operationComplete(FutureUtils.bkResultCode(cause), null);\n-                                }\n-                            });\n-                }\n-            }\n-\n-        }\n-\n-        @Override\n-        public void operationComplete(final int rc, final LedgerDescriptor result) {\n-            // submit callback execution to dlg executor to avoid deadlock.\n-            submit(new Runnable() {\n-                @Override\n-                public void run() {\n-                    if (BKException.Code.OK != rc) {\n-                        LOG.debug(\"BK Exception {} while opening ledger\", rc);\n-                        handleException(ReadAheadPhase.OPEN_LEDGER, rc);\n-                        return;\n-                    }\n-                    currentLH = result;\n-                    if (conf.getTraceReadAheadMetadataChanges()) {\n-                        LOG.info(\"Opened ledger of {} for {} at {}.\",\n-                                new Object[]{currentMetadata, fullyQualifiedName, System.currentTimeMillis()});\n-                    }\n-                    bkcZkExceptions.set(0);\n-                    bkcUnExpectedExceptions.set(0);\n-                    bkcNoLedgerExceptionsOnReadLAC.set(0);\n-                    next.process(rc);\n-                }\n-            });\n-        }\n-\n-        /**\n-         * Handle the result of reading last add confirmed.\n-         *\n-         * @param rc\n-         *          result of reading last add confirmed\n-         */\n-        private void handleReadLastConfirmedError(int rc) {\n-            if (BKException.Code.NoSuchLedgerExistsException == rc) {\n-                if (bkcNoLedgerExceptionsOnReadLAC.incrementAndGet() > noLedgerExceptionOnReadLACThreshold) {\n-                    LOG.info(\"{} No entries published to ledger {} yet for {} millis.\",\n-                            new Object[] { fullyQualifiedName, currentLH, conf.getReadAheadNoSuchLedgerExceptionOnReadLACErrorThresholdMillis() });\n-                    bkcNoLedgerExceptionsOnReadLAC.set(0);\n-                    // set current ledger handle to null, so it would be re-opened again.\n-                    // if the ledger does disappear, it would trigger re-initialize log segments on handling openLedger exceptions\n-                    if (closeCurrentLedgerHandle()) {\n-                        next.process(BKException.Code.OK);\n-                    }\n-                    return;\n-                } else {\n-                    if (LOG.isTraceEnabled()) {\n-                        LOG.info(\"{} No entries published to ledger {} yet. Backoff reading ahead for {} ms.\",\n-                                new Object[]{fullyQualifiedName, currentLH, conf.getReadAheadWaitTime()});\n-                    }\n-                    // Backoff before resuming\n-                    schedule(ReadAheadWorker.this, conf.getReadAheadWaitTime());\n-                    return;\n-                }\n-            } else if (BKException.Code.OK != rc) {\n-                handleException(ReadAheadPhase.READ_LAST_CONFIRMED, rc);\n-                return;\n-            }\n-        }\n-\n-        public void readLastConfirmedAndEntryComplete(final int rc, final long lastConfirmed, final LedgerEntry entry,\n-                                                      final Object ctx) {\n-            // submit callback execution to dlg executor to avoid deadlock.\n-            submit(new Runnable() {\n-                @Override\n-                public void run() {\n-                    if (BKException.Code.OK != rc) {\n-                        handleReadLastConfirmedError(rc);\n-                        return;\n-                    }\n-                    bkcZkExceptions.set(0);\n-                    bkcUnExpectedExceptions.set(0);\n-                    bkcNoLedgerExceptionsOnReadLAC.set(0);\n-                    if (LOG.isTraceEnabled()) {\n-                        try {\n-                            LOG.trace(\"Advancing Last Add Confirmed of {} for {} : {}, {}\",\n-                                      new Object[] { currentMetadata, fullyQualifiedName, lastConfirmed,\n-                                                     handleCache.getLastAddConfirmed(currentLH) });\n-                        } catch (BKException exc) {\n-                            // Ignore\n-                        }\n-                    }\n-\n-                    if ((null != entry)\n-                        && (nextReadAheadPosition.getEntryId() == entry.getEntryId())\n-                        && (nextReadAheadPosition.getLedgerId() == entry.getLedgerId())) {\n-                        if (lastConfirmed <= 4 && conf.getTraceReadAheadMetadataChanges()) {\n-                            LOG.info(\"Hit readLastConfirmedAndEntry for {} at {} : entry = {}, lac = {}, position = {}.\",\n-                                    new Object[] { fullyQualifiedName, System.currentTimeMillis(),\n-                                            entry.getEntryId(), lastConfirmed, nextReadAheadPosition });\n-                        }\n-\n-                        if (!isCatchingUp) {\n-                            long lac = lastConfirmed - nextReadAheadPosition.getEntryId();\n-                            if (lac > 0) {\n-                                readAheadLacLagStats.registerSuccessfulEvent(lac);\n-                            }\n-                        }\n-\n-                        nextReadAheadPosition.advance();\n-\n-                        readAheadCache.set(new LedgerReadPosition(entry.getLedgerId(), currentLH.getLogSegmentSequenceNo(), entry.getEntryId()),\n-                                               entry, null != ctx ? ctx.toString() : \"\",\n-                                               currentMetadata.getEnvelopeEntries(), currentMetadata.getStartSequenceId());\n-\n-                        if (LOG.isTraceEnabled()) {\n-                            LOG.trace(\"Reading the value received {} for {} : entryId {}\",\n-                                new Object[] { currentMetadata, fullyQualifiedName, entry.getEntryId() });\n-                        }\n-                        readAheadEntryPiggyBackHits.inc();\n-                    } else {\n-                        if (lastConfirmed > nextReadAheadPosition.getEntryId()) {\n-                            LOG.info(\"{} : entry {} isn't piggybacked but last add confirmed already moves to {}.\",\n-                                     new Object[] { logMetadata.getFullyQualifiedName(), nextReadAheadPosition.getEntryId(), lastConfirmed });\n-                        }\n-                        readAheadEntryPiggyBackMisses.inc();\n-                    }\n-                    next.process(rc);\n-                }\n-            });\n-        }\n-    }\n-\n-    final class ReadEntriesPhase extends Phase implements Runnable {\n-\n-        boolean cacheFull = false;\n-        long lastAddConfirmed = -1;\n-\n-        ReadEntriesPhase(Phase next) {\n-            super(next);\n-        }\n-\n-        @Override\n-        void process(int rc) {\n-            if (!running) {\n-                setReadAheadStopped();\n-                return;\n-            }\n-\n-            tracker.enterPhase(ReadAheadPhase.READ_ENTRIES);\n-\n-            cacheFull = false;\n-            lastAddConfirmed = -1;\n-            if (null != currentLH) {\n-                try {\n-                    lastAddConfirmed = handleCache.getLastAddConfirmed(currentLH);\n-                } catch (BKException bke) {\n-                    handleException(ReadAheadPhase.READ_LAST_CONFIRMED, bke.getCode());\n-                    return;\n-                }\n-                read();\n-            } else {\n-                complete();\n-            }\n-        }\n-\n-        private void read() {\n-            if (lastAddConfirmed < nextReadAheadPosition.getEntryId()) {\n-                if (LOG.isTraceEnabled()) {\n-                    LOG.trace(\"Nothing to read for {} of {} : lastAddConfirmed = {}, nextReadAheadPosition = {}\",\n-                            new Object[] { currentMetadata, fullyQualifiedName, lastAddConfirmed, nextReadAheadPosition});\n-                }\n-                complete();\n-                return;\n-            }\n-            if (LOG.isTraceEnabled()) {\n-                LOG.trace(\"Reading entry {} for {} of {}.\",\n-                        new Object[] {nextReadAheadPosition, currentMetadata, fullyQualifiedName });\n-            }\n-            int readAheadBatchSize = dynConf.getReadAheadBatchSize();\n-            final long startEntryId = nextReadAheadPosition.getEntryId();\n-            final long endEntryId = Math.min(lastAddConfirmed, (nextReadAheadPosition.getEntryId() + readAheadBatchSize - 1));\n-\n-            if (endEntryId <= readAheadBatchSize && conf.getTraceReadAheadMetadataChanges()) {\n-                // trace first read batch\n-                LOG.info(\"Reading entries ({} - {}) for {} at {} : lac = {}, nextReadAheadPosition = {}.\",\n-                         new Object[] { startEntryId, endEntryId, fullyQualifiedName, System.currentTimeMillis(), lastAddConfirmed, nextReadAheadPosition});\n-            }\n-\n-            final String readCtx = String.format(\"ReadEntries(%d-%d)\", startEntryId, endEntryId);\n-            handleCache.asyncReadEntries(currentLH, startEntryId, endEntryId)\n-                    .addEventListener(new FutureEventListener<Enumeration<LedgerEntry>>() {\n-\n-                        @Override\n-                        public void onSuccess(Enumeration<LedgerEntry> entries) {\n-                            int rc = BKException.Code.OK;\n-\n-                            if (failureInjector.shouldInjectCorruption(startEntryId, endEntryId)) {\n-                                rc = BKException.Code.DigestMatchException;\n-                            }\n-                            readComplete(rc, null, entries, readCtx, startEntryId, endEntryId);\n-                        }\n-\n-                        @Override\n-                        public void onFailure(Throwable cause) {\n-                            readComplete(FutureUtils.bkResultCode(cause), null, null, readCtx, startEntryId, endEntryId);\n-                        }\n-                    });\n-        }\n-\n-        public void readComplete(final int rc, final LedgerHandle lh,\n-                                 final Enumeration<LedgerEntry> seq, final Object ctx,\n-                                 final long startEntryId, final long endEntryId) {\n-            // submit callback execution to dlg executor to avoid deadlock.\n-            submit(new Runnable() {\n-                @Override\n-                public void run() {\n-                    // If readAheadSkipBrokenEntries is enabled and we hit a corrupt entry, log and\n-                    // stat the issue and move forward.\n-                    if (BKException.Code.DigestMatchException == rc && readAheadSkipBrokenEntries) {\n-                        readAheadReadEntriesStat.registerFailedEvent(0);\n-                        LOG.error(\"BK DigestMatchException while reading entries {}-{} in stream {}, entry {} discarded\",\n-                                new Object[] { startEntryId, endEntryId, fullyQualifiedName, startEntryId });\n-                        bkcZkExceptions.set(0);\n-                        bkcUnExpectedExceptions.set(0);\n-                        readAheadSkippedBrokenEntries.inc();\n-                        nextReadAheadPosition.advance();\n-                    } else if (BKException.Code.OK != rc) {\n-                        readAheadReadEntriesStat.registerFailedEvent(0);\n-                        LOG.debug(\"BK Exception {} while reading entry\", rc);\n-                        handleException(ReadAheadPhase.READ_ENTRIES, rc);\n-                        return;\n-                    } else {\n-                        int numReads = 0;\n-                        while (seq.hasMoreElements()) {\n-                            bkcZkExceptions.set(0);\n-                            bkcUnExpectedExceptions.set(0);\n-                            nextReadAheadPosition.advance();\n-                            LedgerEntry e = seq.nextElement();\n-                            LedgerReadPosition readPosition = new LedgerReadPosition(e.getLedgerId(), currentMetadata.getLogSegmentSequenceNumber(), e.getEntryId());\n-                            readAheadCache.set(readPosition, e, null != ctx ? ctx.toString() : \"\",\n-                                    currentMetadata.getEnvelopeEntries(), currentMetadata.getStartSequenceId());\n-                            ++numReads;\n-                            if (LOG.isDebugEnabled()) {\n-                                LOG.debug(\"Read entry {} of {}.\", readPosition, fullyQualifiedName);\n-                            }\n-                        }\n-                        readAheadReadEntriesStat.registerSuccessfulEvent(numReads);\n-                    }\n-                    if (readAheadCache.isCacheFull()) {\n-                        cacheFull = true;\n-                        complete();\n-                    } else {\n-                        read();\n-                    }\n-                }\n-            });\n-        }\n-\n-        private void complete() {\n-            if (cacheFull) {\n-                LOG.trace(\"Cache for {} is full. Backoff reading until notified\", fullyQualifiedName);\n-                readAheadCacheFullCounter.inc();\n-                resumeStopWatch.reset().start();\n-                stopPromise = null;\n-                readAheadCache.setReadAheadCallback(ReadAheadWorker.this);\n-            } else {\n-                run();\n-            }\n-        }\n-\n-        @Override\n-        public void run() {\n-            next.process(BKException.Code.OK);\n-        }\n-    }\n-\n-    @Override\n-    public void run() {\n-        if (!running) {\n-            setReadAheadStopped();\n-            return;\n-        }\n-        readAheadPhase.process(BKException.Code.OK);\n-    }\n-\n-    @Override\n-    public void onSegmentsUpdated(List<LogSegmentMetadata> segments) {\n-        AsyncNotification notification;\n-        synchronized (notificationLock) {\n-            logSegmentListNotified = segments;\n-            reInitializeMetadata = true;\n-            LOG.debug(\"{} Read ahead node changed\", fullyQualifiedName);\n-            notification = metadataNotification;\n-            metadataNotification = null;\n-        }\n-        metadataNotificationTimeMillis = System.currentTimeMillis();\n-        if (null != notification) {\n-            notification.notifyOnOperationComplete();\n-        }\n-    }\n-\n-    @Override\n-    public void onLogStreamDeleted() {\n-        logDeleted = true;\n-        setReadAheadError(tracker, new LogNotFoundException(\"Log stream \"\n-                + bkLedgerManager.getFullyQualifiedName() + \" is deleted.\"));\n-    }\n-\n-    /**\n-     * Set metadata notification and return the flag indicating whether to reinitialize metadata.\n-     *\n-     * @param notification\n-     *          metadata notification\n-     * @return flag indicating whether to reinitialize metadata.\n-     */\n-    private boolean setMetadataNotification(AsyncNotification notification) {\n-        synchronized (notificationLock) {\n-            this.metadataNotification = notification;\n-            return reInitializeMetadata;\n-        }\n-    }\n-\n-    @VisibleForTesting\n-    public AsyncNotification getMetadataNotification() {\n-        synchronized (notificationLock) {\n-            return metadataNotification;\n-        }\n-    }\n-\n-    /**\n-     * A scheduled runnable that could be waken and executed immediately when notification arrives.\n-     *\n-     * E.g\n-     * <p>\n-     * The reader reaches end of stream, it backs off to schedule next read in 2 seconds.\n-     * <br/>\n-     * if a new log segment is created, without this change, reader has to wait 2 seconds to read\n-     * entries in new log segment, which means delivery latency of entries in new log segment could\n-     * be up to 2 seconds. but with this change, the task would be executed immediately, which reader\n-     * would be waken up from backoff, which would reduce the delivery latency.\n-     * </p>\n-     */\n-    class InterruptibleScheduledRunnable implements AsyncNotification, Runnable {\n-\n-        final Runnable task;\n-        final AtomicBoolean called = new AtomicBoolean(false);\n-        final long startNanos;\n-\n-        InterruptibleScheduledRunnable(Runnable task) {\n-            this.task = task;\n-            this.startNanos = MathUtils.nowInNano();\n-        }\n-\n-        @Override\n-        public void notifyOnError(Throwable t) {\n-            longPollInterruptionStat.registerFailedEvent(MathUtils.elapsedMicroSec(startNanos));\n-            execute();\n-        }\n-\n-        @Override\n-        public void notifyOnOperationComplete() {\n-            longPollInterruptionStat.registerSuccessfulEvent(MathUtils.elapsedMicroSec(startNanos));\n-            execute();\n-        }\n-\n-        @Override\n-        public void run() {\n-            if (called.compareAndSet(false, true)) {\n-                task.run();\n-            }\n-        }\n-\n-        void execute() {\n-            if (called.compareAndSet(false, true)) {\n-                submit(task);\n-            }\n-        }\n-    }\n-\n-    abstract class LongPollNotification<T> implements AsyncNotification {\n-\n-        final long lac;\n-        final T cb;\n-        final Object ctx;\n-        final AtomicBoolean called = new AtomicBoolean(false);\n-        final long startNanos;\n-\n-        LongPollNotification(long lac, T cb, Object ctx) {\n-            this.lac = lac;\n-            this.cb = cb;\n-            this.ctx = ctx;\n-            this.startNanos = MathUtils.nowInNano();\n-        }\n-\n-        void complete(boolean success) {\n-            long startTime = MathUtils.nowInNano();\n-            doComplete(success);\n-            if (success) {\n-                notificationExecutionStat.registerSuccessfulEvent(MathUtils.elapsedMicroSec(startTime));\n-            } else {\n-                notificationExecutionStat.registerFailedEvent(MathUtils.elapsedMicroSec(startTime));\n-            }\n-        }\n-\n-        abstract void doComplete(boolean success);\n-\n-        @Override\n-        public void notifyOnError(Throwable cause) {\n-            longPollInterruptionStat.registerFailedEvent(MathUtils.elapsedMicroSec(startNanos));\n-            complete(false);\n-        }\n-\n-        @Override\n-        public void notifyOnOperationComplete() {\n-            longPollInterruptionStat.registerSuccessfulEvent(MathUtils.elapsedMicroSec(startNanos));\n-            complete(true);\n-        }\n-\n-        void callbackImmediately(boolean immediate) {\n-            if (immediate) {\n-                complete(true);\n-            }\n-        }\n-    }\n-\n-    class ReadLastConfirmedAndEntryCallbackWithNotification\n-            extends LongPollNotification<AsyncCallback.ReadLastConfirmedAndEntryCallback>\n-            implements AsyncCallback.ReadLastConfirmedAndEntryCallback {\n-\n-        ReadLastConfirmedAndEntryCallbackWithNotification(\n-                long lac, AsyncCallback.ReadLastConfirmedAndEntryCallback cb, Object ctx) {\n-            super(lac, cb, ctx);\n-        }\n-\n-        @Override\n-        public void readLastConfirmedAndEntryComplete(int rc, long lac, LedgerEntry entry, Object ctx) {\n-            if (called.compareAndSet(false, true)) {\n-                // clear the notification when callback\n-                synchronized (notificationLock) {\n-                    metadataNotification = null;\n-                }\n-                this.cb.readLastConfirmedAndEntryComplete(rc, lac, entry, ctx);\n-            }\n-        }\n-\n-        @Override\n-        void doComplete(boolean success) {\n-            readLastConfirmedAndEntryComplete(BKException.Code.OK, lac, null, ctx);\n-        }\n-\n-    }\n-}"},{"sha":"326f92b581c277c42eb23f1d389a1f1931cf90c9","filename":"src/main/java/com/twitter/distributedlog/stats/ReadAheadExceptionsLogger.java","status":"removed","additions":0,"deletions":60,"changes":60,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FReadAheadExceptionsLogger.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FReadAheadExceptionsLogger.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fstats%2FReadAheadExceptionsLogger.java?ref=1166e11904ab83ec64e0147998cebffc653bdbf3","patch":"@@ -1,60 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.twitter.distributedlog.stats;\n-\n-import org.apache.bookkeeper.stats.StatsLogger;\n-\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n-\n-/**\n- * Stats logger to log exceptions happened in {@link com.twitter.distributedlog.readahead.ReadAheadWorker}.\n- * They are counters of exceptions happened on each read ahead phase:\n- * <code>`scope`/exceptions/`phase`/`code`</code>. `scope` is the current scope of\n- * stats logger, `phase` is the read ahead phase, while `code` is the exception code. Check\n- * {@link com.twitter.distributedlog.readahead.ReadAheadPhase} for details about phases and\n- * {@link BKExceptionStatsLogger} for details about `code`.\n- */\n-public class ReadAheadExceptionsLogger {\n-\n-    private final StatsLogger statsLogger;\n-    private StatsLogger parentExceptionStatsLogger;\n-    private final ConcurrentMap<String, BKExceptionStatsLogger> exceptionStatsLoggers =\n-            new ConcurrentHashMap<String, BKExceptionStatsLogger>();\n-\n-    public ReadAheadExceptionsLogger(StatsLogger statsLogger) {\n-        this.statsLogger = statsLogger;\n-    }\n-\n-    public BKExceptionStatsLogger getBKExceptionStatsLogger(String phase) {\n-        // initialize the parent exception stats logger lazily\n-        if (null == parentExceptionStatsLogger) {\n-            parentExceptionStatsLogger = statsLogger.scope(\"exceptions\");\n-        }\n-        BKExceptionStatsLogger exceptionStatsLogger = exceptionStatsLoggers.get(phase);\n-        if (null == exceptionStatsLogger) {\n-            exceptionStatsLogger = new BKExceptionStatsLogger(parentExceptionStatsLogger.scope(phase));\n-            BKExceptionStatsLogger oldExceptionStatsLogger =\n-                    exceptionStatsLoggers.putIfAbsent(phase, exceptionStatsLogger);\n-            if (null != oldExceptionStatsLogger) {\n-                exceptionStatsLogger = oldExceptionStatsLogger;\n-            }\n-        }\n-        return exceptionStatsLogger;\n-    }\n-}"},{"sha":"1829e5414662ade4f646bc5699ede27f7f52b0ab","filename":"src/test/java/com/twitter/distributedlog/TestLedgerHandleCache.java","status":"removed","additions":0,"deletions":180,"changes":180,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLedgerHandleCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/1166e11904ab83ec64e0147998cebffc653bdbf3/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLedgerHandleCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestLedgerHandleCache.java?ref=1166e11904ab83ec64e0147998cebffc653bdbf3","patch":"@@ -1,180 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.twitter.distributedlog;\n-\n-import com.twitter.distributedlog.util.FutureUtils;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.BookKeeper;\n-import org.apache.bookkeeper.client.LedgerHandle;\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.Test;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import static com.google.common.base.Charsets.UTF_8;\n-import static org.junit.Assert.*;\n-\n-/**\n- * Test {@link LedgerHandleCache}\n- */\n-public class TestLedgerHandleCache extends TestDistributedLogBase {\n-    static final Logger LOG = LoggerFactory.getLogger(TestLedgerHandleCache.class);\n-\n-    protected static String ledgersPath = \"/ledgers\";\n-\n-    private ZooKeeperClient zkc;\n-    private BookKeeperClient bkc;\n-\n-    @Before\n-    public void setup() throws Exception {\n-        zkc = TestZooKeeperClientBuilder.newBuilder()\n-                .zkServers(zkServers)\n-                .build();\n-        bkc = BookKeeperClientBuilder.newBuilder()\n-                .name(\"bkc\")\n-                .zkc(zkc)\n-                .ledgersPath(ledgersPath)\n-                .dlConfig(conf)\n-                .build();\n-    }\n-\n-    @After\n-    public void teardown() throws Exception {\n-        bkc.close();\n-        zkc.close();\n-    }\n-\n-    @Test(timeout = 60000, expected = NullPointerException.class)\n-    public void testBuilderWithoutBKC() throws Exception {\n-        LedgerHandleCache.newBuilder().build();\n-    }\n-\n-    @Test(timeout = 60000, expected = NullPointerException.class)\n-    public void testBuilderWithoutStatsLogger() throws Exception {\n-        LedgerHandleCache.newBuilder().bkc(bkc).conf(conf).statsLogger(null).build();\n-    }\n-\n-    @Test(timeout = 60000, expected = BKException.BKBookieHandleNotAvailableException.class)\n-    public void testOpenLedgerWhenBkcClosed() throws Exception {\n-        BookKeeperClient newBkc = BookKeeperClientBuilder.newBuilder().name(\"newBkc\")\n-                .zkc(zkc).ledgersPath(ledgersPath).dlConfig(conf).build();\n-        LedgerHandleCache cache =\n-                LedgerHandleCache.newBuilder().bkc(newBkc).conf(conf).build();\n-        // closed the bkc\n-        newBkc.close();\n-        // open ledger after bkc closed.\n-        cache.openLedger(new LogSegmentMetadata.LogSegmentMetadataBuilder(\"\", 2, 1, 1).setRegionId(1).build(), false);\n-    }\n-\n-    @Test(timeout = 60000, expected = BKException.ZKException.class)\n-    public void testOpenLedgerWhenZkClosed() throws Exception {\n-        ZooKeeperClient newZkc = TestZooKeeperClientBuilder.newBuilder()\n-                .name(\"zkc-openledger-when-zk-closed\")\n-                .zkServers(zkServers)\n-                .build();\n-        BookKeeperClient newBkc = BookKeeperClientBuilder.newBuilder()\n-                .name(\"bkc-openledger-when-zk-closed\")\n-                .zkc(newZkc)\n-                .ledgersPath(ledgersPath)\n-                .dlConfig(conf)\n-                .build();\n-        try {\n-            LedgerHandle lh = newBkc.get().createLedger(BookKeeper.DigestType.CRC32, \"zkcClosed\".getBytes(UTF_8));\n-            lh.close();\n-            newZkc.close();\n-            LedgerHandleCache cache =\n-                    LedgerHandleCache.newBuilder().bkc(newBkc).conf(conf).build();\n-            // open ledger after zkc closed\n-            cache.openLedger(new LogSegmentMetadata.LogSegmentMetadataBuilder(\"\",\n-                    2, lh.getId(), 1).setLogSegmentSequenceNo(lh.getId()).build(), false);\n-        } finally {\n-            newBkc.close();\n-        }\n-    }\n-\n-    @Test(timeout = 60000, expected = BKException.BKUnexpectedConditionException.class)\n-    public void testReadLastConfirmedWithoutOpeningLedger() throws Exception {\n-        LedgerDescriptor desc = new LedgerDescriptor(9999, 9999, false);\n-        LedgerHandleCache cache =\n-                LedgerHandleCache.newBuilder().bkc(bkc).conf(conf).build();\n-        // read last confirmed\n-        cache.tryReadLastConfirmed(desc);\n-    }\n-\n-    @Test(timeout = 60000, expected = BKException.BKUnexpectedConditionException.class)\n-    public void testReadEntriesWithoutOpeningLedger() throws Exception {\n-        LedgerDescriptor desc = new LedgerDescriptor(9999, 9999, false);\n-        LedgerHandleCache cache =\n-                LedgerHandleCache.newBuilder().bkc(bkc).conf(conf).build();\n-        // read entries\n-        cache.readEntries(desc, 0, 10);\n-    }\n-\n-    @Test(timeout = 60000, expected = BKException.BKUnexpectedConditionException.class)\n-    public void testGetLastConfirmedWithoutOpeningLedger() throws Exception {\n-        LedgerDescriptor desc = new LedgerDescriptor(9999, 9999, false);\n-        LedgerHandleCache cache =\n-                LedgerHandleCache.newBuilder().bkc(bkc).conf(conf).build();\n-        // read entries\n-        cache.getLastAddConfirmed(desc);\n-    }\n-\n-    @Test(timeout = 60000, expected = BKException.BKUnexpectedConditionException.class)\n-    public void testReadLastConfirmedAndEntryWithoutOpeningLedger() throws Exception {\n-        LedgerDescriptor desc = new LedgerDescriptor(9999, 9999, false);\n-        LedgerHandleCache cache =\n-                LedgerHandleCache.newBuilder().bkc(bkc).conf(conf).build();\n-        // read entries\n-        FutureUtils.bkResult(cache.asyncReadLastConfirmedAndEntry(desc, 1L, 200L, false));\n-    }\n-\n-    @Test(timeout = 60000, expected = BKException.BKUnexpectedConditionException.class)\n-    public void testGetLengthWithoutOpeningLedger() throws Exception {\n-        LedgerDescriptor desc = new LedgerDescriptor(9999, 9999, false);\n-        LedgerHandleCache cache =\n-                LedgerHandleCache.newBuilder().bkc(bkc).conf(conf).build();\n-        // read entries\n-        cache.getLength(desc);\n-    }\n-\n-    @Test(timeout = 60000)\n-    public void testOpenAndCloseLedger() throws Exception {\n-        LedgerHandle lh = bkc.get().createLedger(1, 1, 1,\n-                BookKeeper.DigestType.CRC32, conf.getBKDigestPW().getBytes(UTF_8));\n-        LedgerHandleCache cache =\n-                LedgerHandleCache.newBuilder().bkc(bkc).conf(conf).build();\n-        LogSegmentMetadata segment = new LogSegmentMetadata.LogSegmentMetadataBuilder(\n-                \"/data\", LogSegmentMetadata.LogSegmentMetadataVersion.VERSION_V5_SEQUENCE_ID, lh.getId(), 0L)\n-                .build();\n-        LedgerDescriptor desc1 = cache.openLedger(segment, false);\n-        assertTrue(cache.handlesMap.containsKey(desc1));\n-        LedgerHandleCache.RefCountedLedgerHandle refLh = cache.handlesMap.get(desc1);\n-        assertEquals(1, refLh.getRefCount());\n-        cache.openLedger(segment, false);\n-        assertTrue(cache.handlesMap.containsKey(desc1));\n-        assertEquals(2, refLh.getRefCount());\n-        // close the ledger\n-        cache.closeLedger(desc1);\n-        assertTrue(cache.handlesMap.containsKey(desc1));\n-        assertEquals(1, refLh.getRefCount());\n-        cache.closeLedger(desc1);\n-        assertFalse(cache.handlesMap.containsKey(desc1));\n-        assertEquals(0, refLh.getRefCount());\n-    }\n-}"},{"sha":"74a52317a4b877911f5c4a53d7573c48ae5a9b9f","filename":"src/test/java/com/twitter/distributedlog/TestReadAheadEntryReader.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAheadEntryReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAheadEntryReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadAheadEntryReader.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -99,7 +99,7 @@ private ReadAheadEntryReader createEntryReader(String streamName,\n                 true);\n         LogSegmentEntryStore entryStore = new BKLogSegmentEntryStore(\n                 conf,\n-                bkc.get(),\n+                bkc,\n                 scheduler,\n                 NullStatsLogger.INSTANCE,\n                 AsyncFailureInjector.NULL);"},{"sha":"4358a8e3ef2bcc2ab1825f9f3a139f4ab751a894","filename":"src/test/java/com/twitter/distributedlog/TestReadUtils.java","status":"modified","additions":6,"deletions":38,"changes":44,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestReadUtils.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -34,8 +34,6 @@\n import org.junit.rules.TestName;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import scala.runtime.AbstractFunction0;\n-import scala.runtime.BoxedUnit;\n \n import static org.junit.Assert.*;\n \n@@ -52,42 +50,22 @@ public class TestReadUtils extends TestDistributedLogBase {\n     private Future<Optional<LogRecordWithDLSN>> getLogRecordNotLessThanTxId(\n             BKDistributedLogManager bkdlm, int logsegmentIdx, long transactionId) throws Exception {\n         List<LogSegmentMetadata> logSegments = bkdlm.getLogSegments();\n-        final LedgerHandleCache handleCache = LedgerHandleCache.newBuilder()\n-                .bkc(bkdlm.getWriterBKC())\n-                .conf(conf)\n-                .build();\n         return ReadUtils.getLogRecordNotLessThanTxId(\n                 bkdlm.getStreamName(),\n                 logSegments.get(logsegmentIdx),\n                 transactionId,\n                 Executors.newSingleThreadExecutor(),\n-                handleCache,\n+                bkdlm.getReaderEntryStore(),\n                 10\n-        ).ensure(new AbstractFunction0<BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply() {\n-                handleCache.clear();\n-                return BoxedUnit.UNIT;\n-            }\n-        });\n+        );\n     }\n \n     private Future<LogRecordWithDLSN> getFirstGreaterThanRecord(BKDistributedLogManager bkdlm, int ledgerNo, DLSN dlsn) throws Exception {\n         List<LogSegmentMetadata> ledgerList = bkdlm.getLogSegments();\n-        final LedgerHandleCache handleCache = LedgerHandleCache.newBuilder()\n-                .bkc(bkdlm.getWriterBKC())\n-                .conf(conf)\n-                .build();\n         return ReadUtils.asyncReadFirstUserRecord(\n                 bkdlm.getStreamName(), ledgerList.get(ledgerNo), 2, 16, new AtomicInteger(0), Executors.newFixedThreadPool(1),\n-                handleCache, dlsn\n-        ).ensure(new AbstractFunction0<BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply() {\n-                handleCache.clear();\n-                return BoxedUnit.UNIT;\n-            }\n-        });\n+                bkdlm.getReaderEntryStore(), dlsn\n+        );\n     }\n \n     private Future<LogRecordWithDLSN> getLastUserRecord(BKDistributedLogManager bkdlm, int ledgerNo) throws Exception {\n@@ -98,20 +76,10 @@ private Future<LogRecordWithDLSN> getLastUserRecord(BKDistributedLogManager bkdl\n                         LogSegmentFilter.DEFAULT_FILTER,\n                         null)\n         ).getValue();\n-        final LedgerHandleCache handleCache = LedgerHandleCache.newBuilder()\n-                .bkc(bkdlm.getWriterBKC())\n-                .conf(conf)\n-                .build();\n         return ReadUtils.asyncReadLastRecord(\n                 bkdlm.getStreamName(), ledgerList.get(ledgerNo), false, false, false, 2, 16, new AtomicInteger(0), Executors.newFixedThreadPool(1),\n-                handleCache\n-        ).ensure(new AbstractFunction0<BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply() {\n-                handleCache.clear();\n-                return BoxedUnit.UNIT;\n-            }\n-        });\n+                bkdlm.getReaderEntryStore()\n+        );\n     }\n \n     @Test(timeout = 60000)"},{"sha":"d1069c3dd2b3675d42eac70af96ed91bb2659abc","filename":"src/test/java/com/twitter/distributedlog/admin/TestDLCK.java","status":"modified","additions":7,"deletions":2,"changes":9,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fadmin%2FTestDLCK.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -28,6 +28,7 @@\n import com.twitter.distributedlog.ZooKeeperClient;\n import com.twitter.distributedlog.metadata.DryrunLogSegmentMetadataStoreUpdater;\n import com.twitter.distributedlog.metadata.LogSegmentMetadataStoreUpdater;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.distributedlog.util.SchedulerUtils;\n import org.apache.zookeeper.CreateMode;\n import org.apache.zookeeper.ZooDefs;\n@@ -104,6 +105,10 @@ public void testCheckAndRepairDLNamespace() throws Exception {\n         zkc.get().create(uri.getPath(), new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n         com.twitter.distributedlog.DistributedLogManagerFactory factory =\n                 new com.twitter.distributedlog.DistributedLogManagerFactory(confLocal, uri);\n+        OrderedScheduler scheduler = OrderedScheduler.newBuilder()\n+                .name(\"dlck-tool\")\n+                .corePoolSize(1)\n+                .build();\n         ExecutorService executorService = Executors.newCachedThreadPool();\n \n         String streamName = \"check-and-repair-dl-namespace\";\n@@ -119,7 +124,7 @@ public void testCheckAndRepairDLNamespace() throws Exception {\n         BookKeeperClient bkc = getBookKeeperClient(factory);\n         DistributedLogAdmin.checkAndRepairDLNamespace(uri, factory,\n                 new DryrunLogSegmentMetadataStoreUpdater(confLocal, getLogSegmentMetadataStore(factory)),\n-                executorService, bkc, confLocal.getBKDigestPW(), false, false);\n+                scheduler, bkc, confLocal.getBKDigestPW(), false, false);\n \n         Map<Long, LogSegmentMetadata> segments = getLogSegments(dlm);\n         LOG.info(\"segments after drynrun {}\", segments);\n@@ -132,7 +137,7 @@ public void testCheckAndRepairDLNamespace() throws Exception {\n         bkc = getBookKeeperClient(factory);\n         DistributedLogAdmin.checkAndRepairDLNamespace(uri, factory,\n                 LogSegmentMetadataStoreUpdater.createMetadataUpdater(confLocal, getLogSegmentMetadataStore(factory)),\n-                executorService, bkc, confLocal.getBKDigestPW(), false, false);\n+                scheduler, bkc, confLocal.getBKDigestPW(), false, false);\n \n         segments = getLogSegments(dlm);\n         LOG.info(\"segments after repair {}\", segments);"},{"sha":"4cf86face4216802c2261dcf76b31cfffe7544ce","filename":"src/test/java/com/twitter/distributedlog/impl/logsegment/TestBKLogSegmentEntryReader.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FTestBKLogSegmentEntryReader.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/a83b233a79300c0bf1b3dcac0a24fef628ad48f8/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FTestBKLogSegmentEntryReader.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Flogsegment%2FTestBKLogSegmentEntryReader.java?ref=a83b233a79300c0bf1b3dcac0a24fef628ad48f8","patch":"@@ -91,7 +91,7 @@ BKLogSegmentEntryReader createEntryReader(LogSegmentMetadata segment,\n                                               DistributedLogConfiguration conf)\n             throws Exception {\n         LogSegmentEntryStore store = new BKLogSegmentEntryStore(\n-                conf, bkc.get(), scheduler, NullStatsLogger.INSTANCE, AsyncFailureInjector.NULL);\n+                conf, bkc, scheduler, NullStatsLogger.INSTANCE, AsyncFailureInjector.NULL);\n         return (BKLogSegmentEntryReader) FutureUtils.result(store.openReader(segment, startEntryId));\n     }\n "}]}