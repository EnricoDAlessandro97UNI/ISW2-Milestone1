{"sha":"ee117235dc1a6fa76093c315c0fed4239831cd63","node_id":"MDY6Q29tbWl0NDc4NTkyNTI2OmVlMTE3MjM1ZGMxYTZmYTc2MDkzYzMxNWMwZmVkNDIzOTgzMWNkNjM=","commit":{"author":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-11-22T01:30:13Z"},"committer":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-12-28T00:49:29Z"},"message":"DL-111: ReadAhead Cache should cache entries rather than records\n\nCurrent readahead cache cache records. So it will be a lot of callbacks (function calls) when polling a record off the readahead cache. Most of the cpu cycles are unnecessarily spent\non function calls on polling records off the readahead cache. It is the throughput bottleneck for a DL reader.\n\nThis change is to change ReadAhead cache to cache entries rather than records. Defer the deserilization of records later on when the reader wants to access the records. It also make\nthe cache more efficient to reduce the memory footprint.","tree":{"sha":"cf5d8fc47615d5d9ede194babfb82229c53f6777","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/trees/cf5d8fc47615d5d9ede194babfb82229c53f6777"},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/commits/ee117235dc1a6fa76093c315c0fed4239831cd63","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/ee117235dc1a6fa76093c315c0fed4239831cd63","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/ee117235dc1a6fa76093c315c0fed4239831cd63","comments_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/ee117235dc1a6fa76093c315c0fed4239831cd63/comments","author":null,"committer":null,"parents":[{"sha":"b90cce8bbffa23f348058f8977a740b97f39dee2","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/b90cce8bbffa23f348058f8977a740b97f39dee2","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/b90cce8bbffa23f348058f8977a740b97f39dee2"}],"stats":{"total":210,"additions":78,"deletions":132},"files":[{"sha":"e11d7a302bc1d6c5890dd24c3ced2f040f4b38e0","filename":"src/main/java/com/twitter/distributedlog/BKAsyncLogReaderDLSN.java","status":"modified","additions":53,"deletions":3,"changes":56,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java?ref=ee117235dc1a6fa76093c315c0fed4239831cd63","patch":"@@ -118,6 +118,10 @@ public void run() {\n         }\n     };\n \n+    // State\n+    private Entry.Reader currentEntry = null;\n+    private LogRecordWithDLSN nextRecord = null;\n+\n     // Failure Injector\n     private final AsyncFailureInjector failureInjector;\n     private boolean disableProcessingReadRequests = false;\n@@ -281,8 +285,14 @@ public void run() {\n                     //     that means notification was missed between readahead and reader.\n                     //   - cache is empty and readahead is idle (no records added for a long time)\n                     idleReaderCheckIdleReadAheadCount.inc();\n-                    if (cache.getNumCachedRecords() <= 0\n-                            && !cache.isReadAheadIdle(idleErrorThresholdMillis, TimeUnit.MILLISECONDS)) {\n+                    try {\n+                        if (!hasMoreRecords(cache)\n+                                && !cache.isReadAheadIdle(idleErrorThresholdMillis, TimeUnit.MILLISECONDS)) {\n+                            return;\n+                        }\n+                    } catch (IOException e) {\n+                        // we encountered exceptions on checking more records\n+                        setLastException(e);\n                         return;\n                     }\n \n@@ -488,6 +498,46 @@ private void cancelAllPendingReads(Throwable throwExc) {\n         pendingRequests.clear();\n     }\n \n+    boolean hasMoreRecords() throws IOException {\n+        return hasMoreRecords(bkLedgerManager.readAheadCache);\n+    }\n+\n+    private synchronized boolean hasMoreRecords(ReadAheadCache cache) throws IOException {\n+        if (cache.getNumCachedEntries() > 0 || null != nextRecord) {\n+            return true;\n+        } else if (null != currentEntry) {\n+            nextRecord = currentEntry.nextRecord();\n+            return null != nextRecord;\n+        } else {\n+            return false;\n+        }\n+    }\n+\n+    private synchronized LogRecordWithDLSN readNextRecord() throws IOException {\n+        if (null == currentEntry) {\n+            currentEntry = bkLedgerManager.getNextReadAheadEntry();\n+            // no current entry after reading from read head then return null\n+            if (null == currentEntry) {\n+                return null;\n+            }\n+        }\n+\n+        LogRecordWithDLSN recordToReturn;\n+        if (null == nextRecord) {\n+            nextRecord = currentEntry.nextRecord();\n+            // no more records in current entry\n+            if (null == nextRecord) {\n+                currentEntry = null;\n+                return readNextRecord();\n+            }\n+        }\n+\n+        // found a record to return and prefetch the next one\n+        recordToReturn = nextRecord;\n+        nextRecord = currentEntry.nextRecord();\n+        return recordToReturn;\n+    }\n+\n     @Override\n     public void run() {\n         synchronized(scheduleLock) {\n@@ -549,7 +599,7 @@ public void run() {\n                     while (!nextRequest.hasReadEnoughRecords()) {\n                         // read single record\n                         do {\n-                            record = bkLedgerManager.getNextReadAheadRecord();\n+                            record = readNextRecord();\n                         } while (null != record && (record.isControl() || (record.getDlsn().compareTo(getStartDLSN()) < 0)));\n                         if (null == record) {\n                             break;"},{"sha":"faa47fcc2c2dd36c45da99ffe03948b3c094135a","filename":"src/main/java/com/twitter/distributedlog/BKLogReadHandler.java","status":"modified","additions":2,"deletions":5,"changes":7,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java?ref=ee117235dc1a6fa76093c315c0fed4239831cd63","patch":"@@ -199,13 +199,10 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n                 .build();\n         readAheadCache = new ReadAheadCache(\n                 getFullyQualifiedName(),\n-                handlerStatsLogger,\n                 alertStatsLogger,\n                 readerStateNotification,\n                 dynConf.getReadAheadMaxRecords(),\n                 deserializeRecordSet,\n-                conf.getTraceReadAheadDeliveryLatency(),\n-                conf.getDataLatencyWarnThresholdMillis(),\n                 Ticker.systemTicker());\n \n         this.subscriberId = subscriberId;\n@@ -481,8 +478,8 @@ public void run() {\n         return promise;\n     }\n \n-    public LogRecordWithDLSN getNextReadAheadRecord() throws IOException {\n-        return readAheadCache.getNextReadAheadRecord();\n+    public Entry.Reader getNextReadAheadEntry() throws IOException {\n+        return readAheadCache.getNextReadAheadEntry();\n     }\n \n     public ReadAheadCache getReadAheadCache() {"},{"sha":"bce12b6bb698009503273311c5115d69cfce7c27","filename":"src/main/java/com/twitter/distributedlog/BKSyncLogReaderDLSN.java","status":"modified","additions":1,"deletions":11,"changes":12,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java?ref=ee117235dc1a6fa76093c315c0fed4239831cd63","patch":"@@ -51,7 +51,6 @@ class BKSyncLogReaderDLSN implements LogReader, Runnable, FutureEventListener<Lo\n     private Promise<Void> closeFuture;\n     private final Optional<Long> startTransactionId;\n     private final DLSN startDLSN;\n-    private volatile DLSN lastSeenDLSN = DLSN.InvalidDLSN;\n     // lock on variables that would be accessed by both background threads and foreground threads\n     private final Object sharedLock = new Object();\n \n@@ -110,7 +109,6 @@ public void resumeReadAhead() {\n \n     @Override\n     public void onSuccess(LogRecordWithDLSN record) {\n-        this.lastSeenDLSN = record.getDlsn();\n         if (!startTransactionId.isPresent() || record.getTransactionId() >= startTransactionId.get()) {\n             readAheadRecords.add(record);\n         }\n@@ -167,15 +165,7 @@ public synchronized LogRecordWithDLSN readNext(boolean nonBlocking)\n                     if (null != record) {\n                         break;\n                     }\n-                    DLSN lastDLSNSeenByReadAhead =\n-                            reader.bkLedgerManager.readAheadCache.getLastReadAheadUserDLSN();\n-\n-                    // if last seen DLSN by reader is same as the one seen by ReadAhead\n-                    // that means that reader is caught up with ReadAhead and ReadAhead\n-                    // is caught up with stream\n-                    shallWait = DLSN.InitialDLSN != lastDLSNSeenByReadAhead\n-                            && lastSeenDLSN.compareTo(lastDLSNSeenByReadAhead) < 0\n-                            && startDLSN.compareTo(lastDLSNSeenByReadAhead) <= 0;\n+                    shallWait = reader.hasMoreRecords();\n                 }\n             } catch (InterruptedException e) {\n                 throw new DLInterruptedException(\"Interrupted on waiting next available log record for stream \""},{"sha":"d6051f6616ecda6ffb571fff284be2dd2a7a45ca","filename":"src/main/java/com/twitter/distributedlog/ReadAheadCache.java","status":"modified","additions":17,"deletions":105,"changes":122,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FReadAheadCache.java?ref=ee117235dc1a6fa76093c315c0fed4239831cd63","patch":"@@ -20,7 +20,6 @@\n import java.io.IOException;\n import java.util.concurrent.LinkedBlockingQueue;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.atomic.AtomicLong;\n import java.util.concurrent.atomic.AtomicReference;\n \n import com.google.common.base.Stopwatch;\n@@ -30,20 +29,15 @@\n import com.twitter.distributedlog.exceptions.LogReadException;\n import org.apache.bookkeeper.client.LedgerEntry;\n import org.apache.bookkeeper.stats.AlertStatsLogger;\n-import org.apache.bookkeeper.stats.OpStatsLogger;\n-import org.apache.bookkeeper.stats.StatsLogger;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n public class ReadAheadCache {\n     static final Logger LOG = LoggerFactory.getLogger(ReadAheadCache.class);\n \n     private final String streamName;\n-    private final LinkedBlockingQueue<LogRecordWithDLSN> readAheadRecords;\n-    private final int maxCachedRecords;\n-    private final AtomicReference<DLSN> minActiveDLSN = new AtomicReference<DLSN>(DLSN.NonInclusiveLowerBound);\n-    private DLSN lastReadAheadDLSN = DLSN.InvalidDLSN;\n-    private DLSN lastReadAheadUserDLSN = DLSN.InvalidDLSN;\n+    private final LinkedBlockingQueue<Entry.Reader> readAheadEntries;\n+    private final int maxCachedEntries;\n     private final AtomicReference<IOException> lastException = new AtomicReference<IOException>();\n     private final boolean deserializeRecordSet;\n     // callbacks\n@@ -53,53 +47,27 @@ public class ReadAheadCache {\n     // variables for idle reader detection\n     private final Stopwatch lastEntryProcessTime;\n \n-    // Stats\n-    private final AtomicLong cacheBytes = new AtomicLong(0);\n-\n     private final AlertStatsLogger alertStatsLogger;\n-    private final StatsLogger statsLogger;\n-    private final OpStatsLogger readAheadDeliveryLatencyStat;\n-    private final OpStatsLogger negativeReadAheadDeliveryLatencyStat;\n-    // Flags on controlling delivery latency stats collection\n-    private final boolean traceDeliveryLatencyEnabled;\n-    private volatile boolean suppressDeliveryLatency = true;\n-    private final long deliveryLatencyWarnThresholdMillis;\n \n     public ReadAheadCache(String streamName,\n-                          StatsLogger statsLogger,\n                           AlertStatsLogger alertStatsLogger,\n                           AsyncNotification notification,\n                           int maxCachedRecords,\n                           boolean deserializeRecordSet,\n-                          boolean traceDeliveryLatencyEnabled,\n-                          long deliveryLatencyWarnThresholdMillis,\n                           Ticker ticker) {\n         this.streamName = streamName;\n-        this.maxCachedRecords = maxCachedRecords;\n+        this.maxCachedEntries = maxCachedRecords;\n         this.notification = notification;\n         this.deserializeRecordSet = deserializeRecordSet;\n \n         // create the readahead queue\n-        readAheadRecords = new LinkedBlockingQueue<LogRecordWithDLSN>();\n+        readAheadEntries = new LinkedBlockingQueue<Entry.Reader>();\n \n         // start the idle reader detection\n         lastEntryProcessTime = Stopwatch.createStarted(ticker);\n \n-        // Flags to control delivery latency tracing\n-        this.traceDeliveryLatencyEnabled = traceDeliveryLatencyEnabled;\n-        this.deliveryLatencyWarnThresholdMillis = deliveryLatencyWarnThresholdMillis;\n         // Stats\n-        StatsLogger readAheadStatsLogger = statsLogger.scope(\"readahead\");\n-        this.statsLogger = readAheadStatsLogger;\n         this.alertStatsLogger = alertStatsLogger;\n-        this.readAheadDeliveryLatencyStat =\n-                readAheadStatsLogger.getOpStatsLogger(\"delivery_latency\");\n-        this.negativeReadAheadDeliveryLatencyStat =\n-                readAheadStatsLogger.getOpStatsLogger(\"negative_delivery_latency\");\n-    }\n-\n-    DLSN getLastReadAheadUserDLSN() {\n-        return lastReadAheadUserDLSN;\n     }\n \n     /**\n@@ -133,26 +101,25 @@ private void setLastException(IOException exc) {\n     }\n \n     /**\n-     * Poll next record from the readahead queue.\n+     * Poll next entry from the readahead queue.\n      *\n-     * @return next record from readahead queue. null if no records available in the queue.\n+     * @return next entry from readahead queue. null if no entries available in the queue.\n      * @throws IOException\n      */\n-    public LogRecordWithDLSN getNextReadAheadRecord() throws IOException {\n+    public Entry.Reader getNextReadAheadEntry() throws IOException {\n         if (null != lastException.get()) {\n             throw lastException.get();\n         }\n \n-        LogRecordWithDLSN record = readAheadRecords.poll();\n+        Entry.Reader entry = readAheadEntries.poll();\n \n-        if (null != record) {\n-            cacheBytes.addAndGet(-record.getPayload().length);\n+        if (null != entry) {\n             if (!isCacheFull()) {\n                 invokeReadAheadCallback();\n             }\n         }\n \n-        return record;\n+        return entry;\n     }\n \n     /**\n@@ -196,33 +163,16 @@ public void set(LedgerReadPosition key,\n     }\n \n     public boolean isCacheFull() {\n-        return getNumCachedRecords() >= maxCachedRecords;\n+        return getNumCachedEntries() >= maxCachedEntries;\n     }\n \n     /**\n      * Return number cached records.\n      *\n      * @return number cached records.\n      */\n-    public int getNumCachedRecords() {\n-        return readAheadRecords.size();\n-    }\n-\n-    /**\n-     * Return number cached bytes.\n-     *\n-     * @return number cached bytes.\n-     */\n-    public long getNumCachedBytes() {\n-        return cacheBytes.get();\n-    }\n-\n-    public void setSuppressDeliveryLatency(boolean suppressed) {\n-        this.suppressDeliveryLatency = suppressed;\n-    }\n-\n-    public void setMinActiveDLSN(DLSN minActiveDLSN) {\n-        this.minActiveDLSN.set(minActiveDLSN);\n+    public int getNumCachedEntries() {\n+        return readAheadEntries.size();\n     }\n \n     /**\n@@ -252,44 +202,7 @@ private void processNewLedgerEntry(final LedgerReadPosition readPosition,\n                     .deserializeRecordSet(deserializeRecordSet)\n                     .setInputStream(ledgerEntry.getEntryInputStream())\n                     .buildReader();\n-            while(true) {\n-                LogRecordWithDLSN record = reader.nextRecord();\n-\n-                if (null == record) {\n-                    break;\n-                }\n-\n-                if (lastReadAheadDLSN.compareTo(record.getDlsn()) >= 0) {\n-                    LOG.error(\"Out of order reads last {} : curr {}\", lastReadAheadDLSN, record.getDlsn());\n-                    throw new LogReadException(\"Out of order reads\");\n-                }\n-                lastReadAheadDLSN = record.getDlsn();\n-\n-                if (record.isControl()) {\n-                    continue;\n-                }\n-                lastReadAheadUserDLSN = lastReadAheadDLSN;\n-\n-                if (minActiveDLSN.get().compareTo(record.getDlsn()) > 0) {\n-                    continue;\n-                }\n-\n-                if (traceDeliveryLatencyEnabled && !suppressDeliveryLatency) {\n-                    long currentMs = System.currentTimeMillis();\n-                    long deliveryMs = currentMs - record.getTransactionId();\n-                    if (deliveryMs >= 0) {\n-                        readAheadDeliveryLatencyStat.registerSuccessfulEvent(deliveryMs);\n-                    } else {\n-                        negativeReadAheadDeliveryLatencyStat.registerSuccessfulEvent(-deliveryMs);\n-                    }\n-                    if (deliveryMs > deliveryLatencyWarnThresholdMillis) {\n-                        LOG.warn(\"Record {} for stream {} took long time to deliver : publish time = {}, available time = {}, delivery time = {}, reason = {}.\",\n-                                 new Object[] { record.getDlsn(), streamName, record.getTransactionId(), currentMs, deliveryMs, reason });\n-                    }\n-                }\n-                readAheadRecords.add(record);\n-                cacheBytes.addAndGet(record.getPayload().length);\n-            }\n+            readAheadEntries.add(reader);\n         } catch (InvalidEnvelopedEntryException ieee) {\n             alertStatsLogger.raise(\"Found invalid enveloped entry on stream {} : \", streamName, ieee);\n             setLastException(ieee);\n@@ -299,13 +212,12 @@ private void processNewLedgerEntry(final LedgerReadPosition readPosition,\n     }\n \n     public void clear() {\n-        readAheadRecords.clear();\n-        cacheBytes.set(0L);\n+        readAheadEntries.clear();\n     }\n \n     @Override\n     public String toString() {\n-        return String.format(\"%s: Cache Bytes: %d, Num Cached Records: %d\",\n-            streamName, cacheBytes.get(), getNumCachedRecords());\n+        return String.format(\"%s: Num Cached Entries: %d\",\n+            streamName, getNumCachedEntries());\n     }\n }"},{"sha":"a58218be9885cb69bde17159be10c8bb73f4851b","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadTracker.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadTracker.java?ref=ee117235dc1a6fa76093c315c0fed4239831cd63","patch":"@@ -81,7 +81,7 @@ public Number getDefaultValue() {\n \n             @Override\n             public Number getSample() {\n-                return cache.getNumCachedRecords();\n+                return cache.getNumCachedEntries();\n             }\n         };\n         this.statsLogger.registerGauge(cachEntriesGaugeLabel, cacheEntriesGauge);"},{"sha":"9a1911ed5aa8314d0718a31473136e64ddfd845e","filename":"src/main/java/com/twitter/distributedlog/readahead/ReadAheadWorker.java","status":"modified","additions":0,"deletions":3,"changes":3,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Freadahead%2FReadAheadWorker.java?ref=ee117235dc1a6fa76093c315c0fed4239831cd63","patch":"@@ -692,7 +692,6 @@ public void run() {\n                             long startBKEntry = 0;\n                             if (l.isPartiallyTruncated() && !conf.getIgnoreTruncationStatus()) {\n                                 startBKEntry = l.getMinActiveDLSN().getEntryId();\n-                                readAheadCache.setMinActiveDLSN(l.getMinActiveDLSN());\n                             }\n \n                             if(l.getLogSegmentSequenceNumber() == nextReadAheadPosition.getLogSegmentSequenceNumber()) {\n@@ -743,7 +742,6 @@ public void run() {\n                     if (null == currentMetadata) {\n                         if (isCatchingUp) {\n                             isCatchingUp = false;\n-                            readAheadCache.setSuppressDeliveryLatency(false);\n                             if (isHandleForReading) {\n                                 LOG.info(\"{} caught up at {}: position = {} and no log segment to position on at this point.\",\n                                          new Object[] { fullyQualifiedName, System.currentTimeMillis(), nextReadAheadPosition });\n@@ -945,7 +943,6 @@ public void onFailure(Throwable cause) {\n                         // the readahead is caught up if current ledger is in progress and read position moves over last add confirmed\n                         if (isCatchingUp) {\n                             isCatchingUp = false;\n-                            readAheadCache.setSuppressDeliveryLatency(false);\n                             if (isHandleForReading) {\n                                 LOG.info(\"{} caught up at {}: lac = {}, position = {}.\",\n                                          new Object[] { fullyQualifiedName, System.currentTimeMillis(), lastAddConfirmed, nextReadAheadPosition });"},{"sha":"28f7a74702e61dccbc0977e0da976906db18fa84","filename":"src/test/java/com/twitter/distributedlog/TestAsyncReaderWriter.java","status":"modified","additions":4,"deletions":4,"changes":8,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/ee117235dc1a6fa76093c315c0fed4239831cd63/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAsyncReaderWriter.java?ref=ee117235dc1a6fa76093c315c0fed4239831cd63","patch":"@@ -1618,17 +1618,17 @@ public void testMaxReadAheadRecords() throws Exception {\n         assertEquals(1L, record.getTransactionId());\n \n         assertNotNull(reader.bkLedgerManager.readAheadWorker);\n-        assertTrue(reader.bkLedgerManager.readAheadCache.getNumCachedRecords() <= maxAllowedCachedRecords);\n+        assertTrue(reader.bkLedgerManager.readAheadCache.getNumCachedEntries() <= maxAllowedCachedRecords);\n \n         for (int i = 2; i <= numRecords; i++) {\n             record = Await.result(reader.readNext());\n             LOG.info(\"Read record {}\", record);\n             assertEquals((long) i, record.getTransactionId());\n             TimeUnit.MILLISECONDS.sleep(20);\n-            int numCachedRecords = reader.bkLedgerManager.readAheadCache.getNumCachedRecords();\n+            int numCachedEntries = reader.bkLedgerManager.readAheadCache.getNumCachedEntries();\n             assertTrue(\"Should cache less than \" + batchSize + \" records but already found \"\n-                    + numCachedRecords + \" records when reading \" + i + \"th record\",\n-                    numCachedRecords <= maxAllowedCachedRecords);\n+                    + numCachedEntries + \" records when reading \" + i + \"th record\",\n+                    numCachedEntries <= maxAllowedCachedRecords);\n         }\n     }\n "}]}