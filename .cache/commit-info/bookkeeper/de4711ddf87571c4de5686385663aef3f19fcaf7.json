{"sha":"de4711ddf87571c4de5686385663aef3f19fcaf7","node_id":"MDY6Q29tbWl0NDc4NTkyNTI2OmRlNDcxMWRkZjg3NTcxYzRkZTU2ODYzODU2NjNhZWYzZjE5ZmNhZjc=","commit":{"author":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-12-01T01:14:05Z"},"committer":{"name":"Sijie Guo","email":"sijieg@twitter.com","date":"2016-12-29T10:08:33Z"},"message":"DL-117: Stream metadata store\n\nThis change is to abstract the zookeeper operations into a stream metadata store, so we can replace zookeeper with other metadata store easily.\n\nSo the metadata operations in distributedlog now are managed by 3 classes:\n\n- LogMetadataStore : it is the namespace metadata store : it manages the location (uri) mapping for streams and handle namespace operations.\n- LogStreamMetadataStore: it is the stream metadata store : it manages the metadata for a single stream, such as managing read/write lock, retriving/creating stream metadata, deleting metadata and such.\n- LogSegmentMetadataStore: it is the segment metadata store : it manages the log segment metadata for individual log segment.\n\nLogMetadataStore and LogSegmentMetadataStore are already there. This change focus on LogStreamMetadataStore\n\nChanged:\n\n* abstract all the zookeeper metadata operation in log handlers to LogStreamMetadataStore\n* remove disabling max tx id santify check, as maxTxId update is part of the metadata update transaction\n\nNot changed:\n\nthe name of ZKLogMetadataForReader and ZKLogMetadataForWriter are not changed. I will send out a change to rename these two classes as they are not related to zookeeper anymore.","tree":{"sha":"71efddc72d1edb15012af9f92a34b9e0394b0dff","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/trees/71efddc72d1edb15012af9f92a34b9e0394b0dff"},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/git/commits/de4711ddf87571c4de5686385663aef3f19fcaf7","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/de4711ddf87571c4de5686385663aef3f19fcaf7","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/de4711ddf87571c4de5686385663aef3f19fcaf7","comments_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/de4711ddf87571c4de5686385663aef3f19fcaf7/comments","author":null,"committer":null,"parents":[{"sha":"68f796019ce771a44ba20548046a444177143be0","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/commits/68f796019ce771a44ba20548046a444177143be0","html_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/commit/68f796019ce771a44ba20548046a444177143be0"}],"stats":{"total":2286,"additions":1180,"deletions":1106},"files":[{"sha":"2ca064c148002ad938ecd60ee1a1fd1ed8fbe98a","filename":"src/main/java/com/twitter/distributedlog/BKAsyncLogReaderDLSN.java","status":"modified","additions":2,"deletions":4,"changes":6,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKAsyncLogReaderDLSN.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -30,7 +30,6 @@\n import com.twitter.distributedlog.injector.AsyncFailureInjector;\n import com.twitter.distributedlog.injector.AsyncRandomFailureInjector;\n import com.twitter.distributedlog.util.FutureUtils;\n-import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.util.Future;\n import com.twitter.util.FutureEventListener;\n import com.twitter.util.Promise;\n@@ -210,7 +209,6 @@ void complete() {\n \n     BKAsyncLogReaderDLSN(BKDistributedLogManager bkdlm,\n                          ScheduledExecutorService executorService,\n-                         OrderedScheduler lockStateExecutor,\n                          DLSN startDLSN,\n                          Optional<String> subscriberId,\n                          boolean returnEndOfStreamRecord,\n@@ -219,7 +217,7 @@ void complete() {\n         this.bkDistributedLogManager = bkdlm;\n         this.executorService = executorService;\n         this.bkLedgerManager = bkDistributedLogManager.createReadHandler(subscriberId,\n-                lockStateExecutor, this, deserializeRecordSet, true);\n+                this, deserializeRecordSet, true);\n         LOG.debug(\"Starting async reader at {}\", startDLSN);\n         this.startDLSN = startDLSN;\n         this.scheduleDelayStopwatch = Stopwatch.createUnstarted();\n@@ -414,7 +412,7 @@ private synchronized Future<List<LogRecordWithDLSN>> readInternal(int numEntries\n         final PendingReadRequest readRequest = new PendingReadRequest(numEntries, deadlineTime, deadlineTimeUnit);\n \n         if (!readAheadStarted) {\n-            bkLedgerManager.checkLogStreamExistsAsync().addEventListener(new FutureEventListener<Void>() {\n+            bkLedgerManager.checkLogStreamExists().addEventListener(new FutureEventListener<Void>() {\n                 @Override\n                 public void onSuccess(Void value) {\n                     try {"},{"sha":"0a34caab116534f4bb55e31fb0fc38a901c09779","filename":"src/main/java/com/twitter/distributedlog/BKDistributedLogManager.java","status":"modified","additions":43,"deletions":137,"changes":180,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogManager.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -29,25 +29,22 @@\n import com.twitter.distributedlog.callback.LogSegmentListener;\n import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n import com.twitter.distributedlog.exceptions.AlreadyClosedException;\n-import com.twitter.distributedlog.exceptions.DLInterruptedException;\n import com.twitter.distributedlog.exceptions.LogEmptyException;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n import com.twitter.distributedlog.function.CloseAsyncCloseableFunction;\n import com.twitter.distributedlog.function.GetVersionedValueFunction;\n-import com.twitter.distributedlog.impl.ZKLogSegmentMetadataStore;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForReader;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n+import com.twitter.distributedlog.impl.metadata.ZKLogStreamMetadataStore;\n import com.twitter.distributedlog.io.AsyncCloseable;\n import com.twitter.distributedlog.lock.DistributedLock;\n import com.twitter.distributedlog.lock.NopDistributedLock;\n-import com.twitter.distributedlog.lock.SessionLockFactory;\n import com.twitter.distributedlog.lock.ZKDistributedLock;\n-import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n-import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.metadata.BKDLConfig;\n+import com.twitter.distributedlog.metadata.LogStreamMetadataStore;\n import com.twitter.distributedlog.stats.BroadCastStatsLogger;\n import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n import com.twitter.distributedlog.subscription.SubscriptionStateStore;\n@@ -75,10 +72,6 @@\n import org.apache.bookkeeper.feature.FeatureProvider;\n import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.bookkeeper.stats.StatsLogger;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.Watcher;\n-import org.apache.zookeeper.ZKUtil;\n-import org.apache.zookeeper.ZooKeeper;\n import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n import org.jboss.netty.util.HashedWheelTimer;\n import org.slf4j.Logger;\n@@ -93,7 +86,6 @@\n import java.util.List;\n import java.util.Set;\n import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.RejectedExecutionException;\n import java.util.concurrent.TimeUnit;\n \n /**\n@@ -120,13 +112,6 @@\n class BKDistributedLogManager extends ZKMetadataAccessor implements DistributedLogManager {\n     static final Logger LOG = LoggerFactory.getLogger(BKDistributedLogManager.class);\n \n-    static void createLog(DistributedLogConfiguration conf, ZooKeeperClient zkc, URI uri, String streamName)\n-            throws IOException, InterruptedException {\n-        Future<ZKLogMetadataForWriter> createFuture = ZKLogMetadataForWriter.of(\n-                        uri, streamName, conf.getUnpartitionedStreamName(), zkc.get(), zkc.getDefaultACL(), true, true);\n-        FutureUtils.result(createFuture);\n-    }\n-\n     static final Function<LogRecordWithDLSN, Long> RECORD_2_TXID_FUNCTION =\n             new Function<LogRecordWithDLSN, Long>() {\n                 @Override\n@@ -158,12 +143,10 @@ public DLSN apply(LogRecordWithDLSN record) {\n     private final StatsLogger perLogStatsLogger;\n     private final AlertStatsLogger alertStatsLogger;\n \n-    // lock factory\n-    private SessionLockFactory lockFactory = null;\n-\n-    // log segment metadata stores\n-    private final LogSegmentMetadataStore writerMetadataStore;\n-    private final LogSegmentMetadataStore readerMetadataStore;\n+    // log stream metadata stores\n+    private final LogStreamMetadataStore writerMetadataStore;\n+    private final LogStreamMetadataStore readerMetadataStore;\n+    // log segment metadata cache\n     private final LogSegmentMetadataCache logSegmentMetadataCache;\n \n     // bookkeeper clients\n@@ -183,9 +166,6 @@ public DLSN apply(LogRecordWithDLSN record) {\n     //\n     private final LedgerAllocator ledgerAllocator;\n     private final PermitLimiter writeLimiter;\n-    // Log Segment Rolling Manager to control rolling speed\n-    private final PermitManager logSegmentRollingPermitManager;\n-    private OrderedScheduler lockStateExecutor = null;\n \n     //\n     // Reader Related Variables\n@@ -237,19 +217,16 @@ public DLSN apply(LogRecordWithDLSN record) {\n              readerBKCBuilder,\n              null,\n              null,\n-             null,\n              new LogSegmentMetadataCache(conf, Ticker.systemTicker()),\n              OrderedScheduler.newBuilder().name(\"BKDL-\" + name).corePoolSize(1).build(),\n              null,\n              null,\n              null,\n-             null,\n              new ReadAheadExceptionsLogger(statsLogger),\n              DistributedLogConstants.UNKNOWN_CLIENT_ID,\n              DistributedLogConstants.LOCAL_REGION_ID,\n              null,\n              writeLimiter,\n-             PermitManager.UNLIMITED_PERMIT_MANAGER,\n              featureProvider,\n              statsLogger,\n              NullStatsLogger.INSTANCE);\n@@ -268,12 +245,10 @@ public DLSN apply(LogRecordWithDLSN record) {\n      * @param zkcForReaderBKC zookeeper builder for bookkeeper shared by readers\n      * @param writerBKCBuilder bookkeeper builder for writers\n      * @param readerBKCBuilder bookkeeper builder for readers\n-     * @param lockFactory distributed lock factory\n      * @param writerMetadataStore writer metadata store\n      * @param readerMetadataStore reader metadata store\n      * @param scheduler ordered scheduled used by readers and writers\n      * @param readAheadScheduler readAhead scheduler used by readers\n-     * @param lockStateExecutor ordered scheduled used by locks to execute lock actions\n      * @param channelFactory client socket channel factory to build bookkeeper clients\n      * @param requestTimer request timer to build bookkeeper clients\n      * @param readAheadExceptionsLogger stats logger to record readahead exceptions\n@@ -297,21 +272,18 @@ public DLSN apply(LogRecordWithDLSN record) {\n                             ZooKeeperClient zkcForReaderBKC,\n                             BookKeeperClientBuilder writerBKCBuilder,\n                             BookKeeperClientBuilder readerBKCBuilder,\n-                            SessionLockFactory lockFactory,\n-                            LogSegmentMetadataStore writerMetadataStore,\n-                            LogSegmentMetadataStore readerMetadataStore,\n+                            LogStreamMetadataStore writerMetadataStore,\n+                            LogStreamMetadataStore readerMetadataStore,\n                             LogSegmentMetadataCache logSegmentMetadataCache,\n                             OrderedScheduler scheduler,\n                             OrderedScheduler readAheadScheduler,\n-                            OrderedScheduler lockStateExecutor,\n                             ClientSocketChannelFactory channelFactory,\n                             HashedWheelTimer requestTimer,\n                             ReadAheadExceptionsLogger readAheadExceptionsLogger,\n                             String clientId,\n                             Integer regionId,\n                             LedgerAllocator ledgerAllocator,\n                             PermitLimiter writeLimiter,\n-                            PermitManager logSegmentRollingPermitManager,\n                             FeatureProvider featureProvider,\n                             StatsLogger statsLogger,\n                             StatsLogger perLogStatsLogger) throws IOException {\n@@ -320,8 +292,6 @@ public DLSN apply(LogRecordWithDLSN record) {\n         this.conf = conf;\n         this.dynConf = dynConf;\n         this.scheduler = scheduler;\n-        this.lockFactory = lockFactory;\n-        this.lockStateExecutor = lockStateExecutor;\n         this.readAheadScheduler = null == readAheadScheduler ? scheduler : readAheadScheduler;\n         this.statsLogger = statsLogger;\n         this.perLogStatsLogger = BroadCastStatsLogger.masterslave(perLogStatsLogger, statsLogger);\n@@ -332,15 +302,24 @@ public DLSN apply(LogRecordWithDLSN record) {\n         this.streamIdentifier = conf.getUnpartitionedStreamName();\n         this.ledgerAllocator = ledgerAllocator;\n         this.writeLimiter = writeLimiter;\n-        this.logSegmentRollingPermitManager = logSegmentRollingPermitManager;\n \n         if (null == writerMetadataStore) {\n-            this.writerMetadataStore = new ZKLogSegmentMetadataStore(conf, writerZKC, scheduler);\n+            this.writerMetadataStore = new ZKLogStreamMetadataStore(\n+                    clientId,\n+                    conf,\n+                    writerZKC,\n+                    scheduler,\n+                    statsLogger);\n         } else {\n             this.writerMetadataStore = writerMetadataStore;\n         }\n         if (null == readerMetadataStore) {\n-            this.readerMetadataStore = new ZKLogSegmentMetadataStore(conf, readerZKC, scheduler);\n+            this.readerMetadataStore = new ZKLogStreamMetadataStore(\n+                    clientId,\n+                    conf,\n+                    readerZKC,\n+                    scheduler,\n+                    statsLogger);\n         } else {\n             this.readerMetadataStore = readerMetadataStore;\n         }\n@@ -407,26 +386,13 @@ public DLSN apply(LogRecordWithDLSN record) {\n         this.readAheadExceptionsLogger = readAheadExceptionsLogger;\n     }\n \n-    synchronized OrderedScheduler getLockStateExecutor(boolean createIfNull) {\n-        if (createIfNull && null == lockStateExecutor && ownExecutor) {\n-            lockStateExecutor = OrderedScheduler.newBuilder()\n-                    .corePoolSize(1).name(\"BKDL-LockState\").build();\n-        }\n-        return lockStateExecutor;\n+    @VisibleForTesting\n+    LogStreamMetadataStore getWriterMetadataStore() {\n+        return writerMetadataStore;\n     }\n \n-    private synchronized SessionLockFactory getLockFactory(boolean createIfNull) {\n-        if (createIfNull && null == lockFactory) {\n-            lockFactory = new ZKSessionLockFactory(\n-                    writerZKC,\n-                    clientId,\n-                    getLockStateExecutor(createIfNull),\n-                    conf.getZKNumRetries(),\n-                    conf.getLockTimeoutMilliSeconds(),\n-                    conf.getZKRetryBackoffStartMillis(),\n-                    statsLogger);\n-        }\n-        return lockFactory;\n+    URI getUri() {\n+        return uri;\n     }\n \n     DistributedLogConfiguration getConf() {\n@@ -457,12 +423,16 @@ FeatureProvider getFeatureProvider() {\n         return this.featureProvider;\n     }\n \n-    private synchronized BKLogReadHandler getReadHandlerForListener(boolean create) {\n+    private synchronized BKLogReadHandler getReadHandlerAndRegisterListener(\n+            boolean create, LogSegmentListener listener) {\n         if (null == readHandlerForListener && create) {\n             readHandlerForListener = createReadHandler();\n-            // start fetch the log segments\n+            readHandlerForListener.registerListener(listener);\n+            // start fetch the log segments after created the listener\n             readHandlerForListener.asyncStartFetchLogSegments();\n+            return readHandlerForListener;\n         }\n+        readHandlerForListener.registerListener(listener);\n         return readHandlerForListener;\n     }\n \n@@ -483,8 +453,7 @@ protected Future<List<LogSegmentMetadata>> getLogSegmentsAsync() {\n \n     @Override\n     public void registerListener(LogSegmentListener listener) throws IOException {\n-        BKLogReadHandler readHandler = getReadHandlerForListener(true);\n-        readHandler.registerListener(listener);\n+        getReadHandlerAndRegisterListener(true, listener);\n     }\n \n     @Override\n@@ -523,14 +492,12 @@ synchronized BKLogReadHandler createReadHandler(Optional<String> subscriberId,\n                                                     boolean isHandleForReading) {\n         return createReadHandler(\n                 subscriberId,\n-                getLockStateExecutor(true),\n                 null,\n                 true, /* deserialize record set */\n                 isHandleForReading);\n     }\n \n     synchronized BKLogReadHandler createReadHandler(Optional<String> subscriberId,\n-                                                    OrderedScheduler lockExecutor,\n                                                     AsyncNotification notification,\n                                                     boolean deserializeRecordSet,\n                                                     boolean isHandleForReading) {\n@@ -540,12 +507,10 @@ synchronized BKLogReadHandler createReadHandler(Optional<String> subscriberId,\n                 subscriberId,\n                 conf,\n                 dynConf,\n-                readerZKCBuilder,\n                 readerBKCBuilder,\n                 readerMetadataStore,\n                 logSegmentMetadataCache,\n                 scheduler,\n-                lockExecutor,\n                 readAheadScheduler,\n                 alertStatsLogger,\n                 readAheadExceptionsLogger,\n@@ -585,24 +550,15 @@ public BKLogWriteHandler createWriteHandler(boolean lockHandler)\n     }\n \n     Future<BKLogWriteHandler> asyncCreateWriteHandler(final boolean lockHandler) {\n-        final ZooKeeper zk;\n-        try {\n-            zk = writerZKC.get();\n-        } catch (InterruptedException e) {\n-            LOG.error(\"Failed to initialize zookeeper client : \", e);\n-            return Future.exception(new DLInterruptedException(\"Failed to initialize zookeeper client\", e));\n-        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n-            return Future.exception(FutureUtils.zkException(e, uri.getPath()));\n-        }\n-\n         boolean ownAllocator = null == ledgerAllocator;\n \n-        // Fetching Log Metadata\n-        Future<ZKLogMetadataForWriter> metadataFuture =\n-                ZKLogMetadataForWriter.of(uri, name, streamIdentifier,\n-                        zk, writerZKC.getDefaultACL(),\n-                        ownAllocator, conf.getCreateStreamIfNotExists() || ownAllocator);\n-        return metadataFuture.flatMap(new AbstractFunction1<ZKLogMetadataForWriter, Future<BKLogWriteHandler>>() {\n+        // Fetching Log Metadata (create if not exists)\n+        return writerMetadataStore.getLog(\n+                uri,\n+                name,\n+                ownAllocator,\n+                conf.getCreateStreamIfNotExists() || ownAllocator\n+        ).flatMap(new AbstractFunction1<ZKLogMetadataForWriter, Future<BKLogWriteHandler>>() {\n             @Override\n             public Future<BKLogWriteHandler> apply(ZKLogMetadataForWriter logMetadata) {\n                 Promise<BKLogWriteHandler> createPromise = new Promise<BKLogWriteHandler>();\n@@ -615,16 +571,10 @@ public Future<BKLogWriteHandler> apply(ZKLogMetadataForWriter logMetadata) {\n     private void createWriteHandler(ZKLogMetadataForWriter logMetadata,\n                                     boolean lockHandler,\n                                     final Promise<BKLogWriteHandler> createPromise) {\n-        OrderedScheduler lockStateExecutor = getLockStateExecutor(true);\n         // Build the locks\n         DistributedLock lock;\n         if (conf.isWriteLockEnabled()) {\n-            lock = new ZKDistributedLock(\n-                    lockStateExecutor,\n-                    getLockFactory(true),\n-                    logMetadata.getLockPath(),\n-                    conf.getLockTimeoutMilliSeconds(),\n-                    statsLogger);\n+            lock = writerMetadataStore.createWriteLock(logMetadata);\n         } else {\n             lock = NopDistributedLock.INSTANCE;\n         }\n@@ -641,7 +591,6 @@ private void createWriteHandler(ZKLogMetadataForWriter logMetadata,\n         final BKLogWriteHandler writeHandler = new BKLogWriteHandler(\n                 logMetadata,\n                 conf,\n-                writerZKCBuilder,\n                 writerBKCBuilder,\n                 writerMetadataStore,\n                 logSegmentMetadataCache,\n@@ -656,10 +605,6 @@ private void createWriteHandler(ZKLogMetadataForWriter logMetadata,\n                 featureProvider,\n                 dynConf,\n                 lock);\n-        PermitManager manager = getLogSegmentRollingPermitManager();\n-        if (manager instanceof Watcher) {\n-            writeHandler.register((Watcher) manager);\n-        }\n         if (lockHandler) {\n             writeHandler.lockHandler().addEventListener(new FutureEventListener<DistributedLock>() {\n                 @Override\n@@ -684,15 +629,15 @@ public BoxedUnit apply() {\n     }\n \n     PermitManager getLogSegmentRollingPermitManager() {\n-        return logSegmentRollingPermitManager;\n+        return writerMetadataStore.getPermitManager();\n     }\n \n     <T> Future<T> processReaderOperation(final Function<BKLogReadHandler, Future<T>> func) {\n         initializeFuturePool(false);\n         return readerFuturePool.apply(new ExceptionalFunction0<BKLogReadHandler>() {\n             @Override\n             public BKLogReadHandler applyE() throws Throwable {\n-                return getReadHandlerForListener(true);\n+                return getReadHandlerAndRegisterListener(true, null);\n             }\n         }).flatMap(new ExceptionalFunction<BKLogReadHandler, Future<T>>() {\n             @Override\n@@ -982,7 +927,6 @@ public Future<AsyncLogReader> openAsyncLogReader(DLSN fromDLSN) {\n         AsyncLogReader reader = new BKAsyncLogReaderDLSN(\n                 this,\n                 scheduler,\n-                getLockStateExecutor(true),\n                 fromDLSN,\n                 subscriberId,\n                 false,\n@@ -1022,7 +966,6 @@ protected Future<AsyncLogReader> getAsyncLogReaderWithLock(final Optional<DLSN>\n         final BKAsyncLogReaderDLSN reader = new BKAsyncLogReaderDLSN(\n                 BKDistributedLogManager.this,\n                 scheduler,\n-                getLockStateExecutor(true),\n                 fromDLSN.isPresent() ? fromDLSN.get() : DLSN.InitialDLSN,\n                 subscriberId,\n                 false,\n@@ -1266,33 +1209,9 @@ private void recoverInternal(String streamIdentifier) throws IOException {\n      */\n     @Override\n     public void delete() throws IOException {\n-        BKLogWriteHandler ledgerHandler = createWriteHandler(true);\n-        try {\n-            ledgerHandler.deleteLog();\n-        } finally {\n-            Utils.closeQuietly(ledgerHandler);\n-        }\n-\n-        // Delete the ZK path associated with the log stream\n-        String zkPath = getZKPath();\n-        // Safety check when we are using the shared zookeeper\n-        if (zkPath.toLowerCase().contains(\"distributedlog\")) {\n-            try {\n-                LOG.info(\"Delete the path associated with the log {}, ZK Path {}\", name, zkPath);\n-                ZKUtil.deleteRecursive(writerZKC.get(), zkPath);\n-            } catch (InterruptedException ie) {\n-                LOG.error(\"Interrupted while accessing ZK\", ie);\n-                throw new DLInterruptedException(\"Error initializing zk\", ie);\n-            } catch (KeeperException ke) {\n-                LOG.error(\"Error accessing entry in zookeeper\", ke);\n-                throw new IOException(\"Error initializing zk\", ke);\n-            }\n-        } else {\n-            LOG.warn(\"Skip deletion of unrecognized ZK Path {}\", zkPath);\n-        }\n+        FutureUtils.result(writerMetadataStore.deleteLog(uri, getStreamName()));\n     }\n \n-\n     /**\n      * The DistributedLogManager may archive/purge any logs for transactionId\n      * less than or equal to minImageTxId.\n@@ -1377,9 +1296,6 @@ public Future<Void> asyncClose() {\n                         SchedulerUtils.shutdownScheduler(readAheadScheduler, schedTimeout, TimeUnit.MILLISECONDS);\n                         LOG.info(\"Stopped BKDL ReadAhead Executor Service for {}.\", name);\n                     }\n-\n-                    SchedulerUtils.shutdownScheduler(getLockStateExecutor(false), schedTimeout, TimeUnit.MILLISECONDS);\n-                    LOG.info(\"Stopped BKDL Lock State Executor for {}.\", name);\n                 }\n                 if (ownWriterBKC) {\n                     writerBKC.close();\n@@ -1410,16 +1326,6 @@ public void close() throws IOException {\n         FutureUtils.result(asyncClose());\n     }\n \n-    public boolean scheduleTask(Runnable task) {\n-        try {\n-            scheduler.submit(task);\n-            return true;\n-        } catch (RejectedExecutionException ree) {\n-            LOG.error(\"Task {} is rejected : \", task, ree);\n-            return false;\n-        }\n-    }\n-\n     private FuturePool buildFuturePool(ExecutorService executorService,\n                                        StatsLogger statsLogger) {\n         FuturePool futurePool = new ExecutorServiceFuturePool(executorService);"},{"sha":"2c9fe449713dcf4fe24d42496b84735f684a8815","filename":"src/main/java/com/twitter/distributedlog/BKDistributedLogNamespace.java","status":"modified","additions":38,"deletions":99,"changes":137,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKDistributedLogNamespace.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -21,7 +21,6 @@\n import com.google.common.base.Optional;\n import com.google.common.base.Preconditions;\n import com.google.common.base.Ticker;\n-import com.google.common.collect.Lists;\n import com.google.common.collect.Sets;\n import com.google.common.util.concurrent.ThreadFactoryBuilder;\n import com.twitter.distributedlog.DistributedLogManagerFactory.ClientSharingOption;\n@@ -33,30 +32,24 @@\n import com.twitter.distributedlog.callback.NamespaceListener;\n import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n import com.twitter.distributedlog.exceptions.AlreadyClosedException;\n-import com.twitter.distributedlog.exceptions.DLInterruptedException;\n import com.twitter.distributedlog.exceptions.InvalidStreamNameException;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n-import com.twitter.distributedlog.exceptions.ZKException;\n import com.twitter.distributedlog.feature.CoreFeatureKeys;\n import com.twitter.distributedlog.impl.ZKLogMetadataStore;\n-import com.twitter.distributedlog.impl.ZKLogSegmentMetadataStore;\n import com.twitter.distributedlog.impl.federated.FederatedZKLogMetadataStore;\n-import com.twitter.distributedlog.lock.SessionLockFactory;\n-import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n+import com.twitter.distributedlog.impl.metadata.ZKLogStreamMetadataStore;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n-import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.metadata.BKDLConfig;\n import com.twitter.distributedlog.metadata.LogMetadataStore;\n+import com.twitter.distributedlog.metadata.LogStreamMetadataStore;\n import com.twitter.distributedlog.namespace.DistributedLogNamespace;\n import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n import com.twitter.distributedlog.util.ConfUtils;\n import com.twitter.distributedlog.util.DLUtils;\n import com.twitter.distributedlog.util.FutureUtils;\n-import com.twitter.distributedlog.util.LimitedPermitManager;\n import com.twitter.distributedlog.util.MonitoredScheduledThreadPoolExecutor;\n import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.distributedlog.util.PermitLimiter;\n-import com.twitter.distributedlog.util.PermitManager;\n import com.twitter.distributedlog.util.SchedulerUtils;\n import com.twitter.distributedlog.util.SimplePermitLimiter;\n import com.twitter.distributedlog.util.Utils;\n@@ -272,7 +265,6 @@ private static String getHostIpLockClientId() {\n     private final BKDLConfig bkdlConfig;\n     private final OrderedScheduler scheduler;\n     private final OrderedScheduler readAheadExecutor;\n-    private final OrderedScheduler lockStateExecutor;\n     private final ClientSocketChannelFactory channelFactory;\n     private final HashedWheelTimer requestTimer;\n     // zookeeper clients\n@@ -300,16 +292,12 @@ private static String getHostIpLockClientId() {\n     private final LedgerAllocator allocator;\n     // access control manager\n     private AccessControlManager accessControlManager;\n-    // log segment rolling permit manager\n-    private final PermitManager logSegmentRollingPermitManager;\n     // log metadata store\n     private final LogMetadataStore metadataStore;\n     // log segment metadata store\n     private final LogSegmentMetadataCache logSegmentMetadataCache;\n-    private final LogSegmentMetadataStore writerSegmentMetadataStore;\n-    private final LogSegmentMetadataStore readerSegmentMetadataStore;\n-    // lock factory\n-    private final SessionLockFactory lockFactory;\n+    private final LogStreamMetadataStore writerStreamMetadataStore;\n+    private final LogStreamMetadataStore readerStreamMetadataStore;\n \n     // feature provider\n     private final FeatureProvider featureProvider;\n@@ -371,15 +359,7 @@ private BKDistributedLogNamespace(\n             this.readAheadExecutor = this.scheduler;\n             LOG.info(\"Used shared executor for readahead.\");\n         }\n-        StatsLogger lockStateStatsLogger = statsLogger.scope(\"factory\").scope(\"lock_scheduler\");\n-        this.lockStateExecutor = OrderedScheduler.newBuilder()\n-                .name(\"DLM-LockState\")\n-                .corePoolSize(conf.getNumLockStateThreads())\n-                .statsLogger(lockStateStatsLogger)\n-                .perExecutorStatsLogger(lockStateStatsLogger)\n-                .traceTaskExecution(conf.getEnableTaskExecutionStats())\n-                .traceTaskExecutionWarnTimeUs(conf.getTaskExecutionWarnTimeMicros())\n-                .build();\n+\n         this.channelFactory = new NioClientSocketChannelFactory(\n             Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat(\"DL-netty-boss-%d\").build()),\n             Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat(\"DL-netty-worker-%d\").build()),\n@@ -427,9 +407,6 @@ private BKDistributedLogNamespace(\n         }\n         this.readerBKC = this.sharedReaderBKCBuilder.build();\n \n-        this.logSegmentRollingPermitManager = new LimitedPermitManager(\n-                conf.getLogSegmentRollingConcurrency(), 1, TimeUnit.MINUTES, scheduler);\n-\n         if (conf.getGlobalOutstandingWriteLimit() < 0) {\n             this.writeLimiter = PermitLimiter.NULL_PERMIT_LIMITER;\n         } else {\n@@ -458,15 +435,6 @@ private BKDistributedLogNamespace(\n         } else {\n             allocator = null;\n         }\n-        // Build the lock factory\n-        this.lockFactory = new ZKSessionLockFactory(\n-                sharedWriterZKCForDL,\n-                clientId,\n-                lockStateExecutor,\n-                conf.getZKNumRetries(),\n-                conf.getLockTimeoutMilliSeconds(),\n-                conf.getZKRetryBackoffStartMillis(),\n-                statsLogger);\n \n         // Stats Loggers\n         this.readAheadExceptionsLogger = new ReadAheadExceptionsLogger(statsLogger);\n@@ -478,11 +446,22 @@ private BKDistributedLogNamespace(\n             this.metadataStore = new ZKLogMetadataStore(conf, namespace, sharedReaderZKCForDL, scheduler);\n         }\n \n-        // create log segment metadata store\n-        this.writerSegmentMetadataStore =\n-                new ZKLogSegmentMetadataStore(conf, sharedWriterZKCForDL, scheduler);\n-        this.readerSegmentMetadataStore =\n-                new ZKLogSegmentMetadataStore(conf, sharedReaderZKCForDL, scheduler);\n+        // create log stream metadata store\n+        this.writerStreamMetadataStore =\n+                new ZKLogStreamMetadataStore(\n+                        clientId,\n+                        conf,\n+                        sharedWriterZKCForDL,\n+                        scheduler,\n+                        statsLogger);\n+        this.readerStreamMetadataStore =\n+                new ZKLogStreamMetadataStore(\n+                        clientId,\n+                        conf,\n+                        sharedReaderZKCForDL,\n+                        scheduler,\n+                        statsLogger);\n+        // create a log segment metadata cache\n         this.logSegmentMetadataCache = new LogSegmentMetadataCache(conf, Ticker.systemTicker());\n \n         LOG.info(\"Constructed BK DistributedLogNamespace : clientId = {}, regionId = {}, federated = {}.\",\n@@ -499,7 +478,7 @@ public void createLog(String logName)\n         checkState();\n         validateName(logName);\n         URI uri = FutureUtils.result(metadataStore.createLog(logName));\n-        createUnpartitionedStreams(conf, uri, Lists.newArrayList(logName));\n+        FutureUtils.result(writerStreamMetadataStore.getLog(uri, logName, true, true));\n     }\n \n     @Override\n@@ -556,7 +535,16 @@ public boolean logExists(String logName)\n         throws IOException, IllegalArgumentException {\n         checkState();\n         Optional<URI> uri = FutureUtils.result(metadataStore.getLogLocation(logName));\n-        return uri.isPresent() && checkIfLogExists(conf, uri.get(), logName);\n+        if (uri.isPresent()) {\n+            try {\n+                FutureUtils.result(writerStreamMetadataStore.logExists(uri.get(), logName));\n+                return true;\n+            } catch (LogNotFoundException lnfe) {\n+                return false;\n+            }\n+        } else {\n+            return false;\n+        }\n     }\n \n     @Override\n@@ -701,8 +689,8 @@ public BookKeeperClient getReaderBKC() {\n     }\n \n     @VisibleForTesting\n-    public LogSegmentMetadataStore getWriterSegmentMetadataStore() {\n-        return writerSegmentMetadataStore;\n+    public LogStreamMetadataStore getWriterStreamMetadataStore() {\n+        return writerStreamMetadataStore;\n     }\n \n     @VisibleForTesting\n@@ -883,10 +871,8 @@ protected DistributedLogManager createDistributedLogManager(\n         }\n \n         LedgerAllocator dlmLedgerAlloctor = null;\n-        PermitManager dlmLogSegmentRollingPermitManager = PermitManager.UNLIMITED_PERMIT_MANAGER;\n         if (ClientSharingOption.SharedClients == clientSharingOption) {\n             dlmLedgerAlloctor = this.allocator;\n-            dlmLogSegmentRollingPermitManager = this.logSegmentRollingPermitManager;\n         }\n         // if there's a specified perStreamStatsLogger, user it, otherwise use the default one.\n         StatsLogger perLogStatsLogger = perStreamStatsLogger.or(this.perLogStatsLogger);\n@@ -902,21 +888,18 @@ protected DistributedLogManager createDistributedLogManager(\n                 readerZKCForBK,                     /* ZKC for BookKeeper for DL Readers */\n                 writerBKCBuilder,                   /* BookKeeper Builder for DL Writers */\n                 readerBKCBuilder,                   /* BookKeeper Builder for DL Readers */\n-                lockFactory,                        /* Lock Factory */\n-                writerSegmentMetadataStore,         /* Log Segment Metadata Store for DL Writers */\n-                readerSegmentMetadataStore,         /* Log Segment Metadata Store for DL Readers */\n+                writerStreamMetadataStore,         /* Log Segment Metadata Store for DL Writers */\n+                readerStreamMetadataStore,         /* Log Segment Metadata Store for DL Readers */\n                 logSegmentMetadataCache,            /* Log Segment Metadata Cache */\n                 scheduler,                          /* DL scheduler */\n                 readAheadExecutor,                  /* Read Aheader Executor */\n-                lockStateExecutor,                  /* Lock State Executor */\n                 channelFactory,                     /* Netty Channel Factory */\n                 requestTimer,                       /* Request Timer */\n                 readAheadExceptionsLogger,          /* ReadAhead Exceptions Logger */\n                 clientId,                           /* Client Id */\n                 regionId,                           /* Region Id */\n                 dlmLedgerAlloctor,                  /* Ledger Allocator */\n                 writeLimiter,                       /* Write Limiter */\n-                dlmLogSegmentRollingPermitManager,  /* Log segment rolling limiter */\n                 featureProvider.scope(\"dl\"),        /* Feature Provider */\n                 statsLogger,                        /* Stats Logger */\n                 perLogStatsLogger                   /* Per Log Stats Logger */\n@@ -961,25 +944,6 @@ private static void validateInput(DistributedLogConfiguration conf, URI uri, Str\n         validateName(nameOfStream);\n     }\n \n-    private static boolean checkIfLogExists(DistributedLogConfiguration conf, URI uri, String name)\n-        throws IOException, IllegalArgumentException {\n-        validateInput(conf, uri, name);\n-        final String logRootPath = uri.getPath() + String.format(\"/%s\", name);\n-        return withZooKeeperClient(new ZooKeeperClientHandler<Boolean>() {\n-            @Override\n-            public Boolean handle(ZooKeeperClient zkc) throws IOException {\n-                // check existence after syncing\n-                try {\n-                    return null != Utils.sync(zkc, logRootPath).exists(logRootPath, false);\n-                } catch (KeeperException e) {\n-                    throw new ZKException(\"Error on checking if log \" + logRootPath + \" exists\", e.code());\n-                } catch (InterruptedException e) {\n-                    throw new DLInterruptedException(\"Interrupted on checking if log \" + logRootPath + \" exists\", e);\n-                }\n-            }\n-        }, conf, uri);\n-    }\n-\n     public static Map<String, byte[]> enumerateLogsWithMetadataInNamespace(final DistributedLogConfiguration conf, final URI uri)\n         throws IOException, IllegalArgumentException {\n         return withZooKeeperClient(new ZooKeeperClientHandler<Map<String, byte[]>>() {\n@@ -1025,27 +989,6 @@ private static Map<String, byte[]> enumerateLogsWithMetadataInternal(ZooKeeperCl\n         return result;\n     }\n \n-    private static void createUnpartitionedStreams(\n-            final DistributedLogConfiguration conf,\n-            final URI uri,\n-            final List<String> streamNames)\n-        throws IOException, IllegalArgumentException {\n-        withZooKeeperClient(new ZooKeeperClientHandler<Void>() {\n-            @Override\n-            public Void handle(ZooKeeperClient zkc) throws IOException {\n-                for (String s : streamNames) {\n-                    try {\n-                        BKDistributedLogManager.createLog(conf, zkc, uri, s);\n-                    } catch (InterruptedException e) {\n-                        LOG.error(\"Interrupted on creating unpartitioned stream {} : \", s, e);\n-                        return null;\n-                    }\n-                }\n-                return null;\n-            }\n-        }, conf, uri);\n-    }\n-\n     private void checkState() throws IOException {\n         if (closed.get()) {\n             LOG.error(\"BKDistributedLogNamespace {} is already closed\", namespace);\n@@ -1079,13 +1022,11 @@ public void close() {\n             LOG.info(\"Ledger Allocator stopped.\");\n         }\n \n-        // Unregister gauge to avoid GC spiral\n-        this.logSegmentRollingPermitManager.close();\n         this.writeLimiter.close();\n \n         // Shutdown log segment metadata stores\n-        Utils.close(writerSegmentMetadataStore);\n-        Utils.close(readerSegmentMetadataStore);\n+        Utils.close(writerStreamMetadataStore);\n+        Utils.close(readerStreamMetadataStore);\n \n         // Shutdown the schedulers\n         SchedulerUtils.shutdownScheduler(scheduler, conf.getSchedulerShutdownTimeoutMs(),\n@@ -1113,7 +1054,5 @@ public void close() {\n         LOG.info(\"Release external resources used by channel factory.\");\n         requestTimer.stop();\n         LOG.info(\"Stopped request timer\");\n-        SchedulerUtils.shutdownScheduler(lockStateExecutor, 5000, TimeUnit.MILLISECONDS);\n-        LOG.info(\"Stopped lock state executor\");\n     }\n }"},{"sha":"4f138f2a7aa94d517790d4e2923fcdd986cbd6dc","filename":"src/main/java/com/twitter/distributedlog/BKLogHandler.java","status":"modified","additions":11,"deletions":63,"changes":74,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogHandler.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -20,19 +20,17 @@\n import com.google.common.base.Preconditions;\n import com.google.common.base.Stopwatch;\n import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n-import com.twitter.distributedlog.exceptions.DLInterruptedException;\n import com.twitter.distributedlog.exceptions.LogEmptyException;\n-import com.twitter.distributedlog.exceptions.LogNotFoundException;\n import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n-import com.twitter.distributedlog.exceptions.ZKException;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadata;\n import com.twitter.distributedlog.io.AsyncAbortable;\n import com.twitter.distributedlog.io.AsyncCloseable;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n import com.twitter.distributedlog.logsegment.PerStreamLogSegmentCache;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.metadata.LogStreamMetadataStore;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.util.Function;\n@@ -45,10 +43,6 @@\n import org.apache.bookkeeper.versioning.Version;\n import org.apache.bookkeeper.versioning.Versioned;\n import org.apache.commons.lang3.tuple.Pair;\n-import org.apache.zookeeper.AsyncCallback;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.ZooKeeper;\n-import org.apache.zookeeper.data.Stat;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import scala.runtime.AbstractFunction0;\n@@ -95,8 +89,8 @@ public abstract class BKLogHandler implements AsyncCloseable, AsyncAbortable {\n \n     protected final ZKLogMetadata logMetadata;\n     protected final DistributedLogConfiguration conf;\n-    protected final ZooKeeperClient zooKeeperClient;\n     protected final BookKeeperClient bookKeeperClient;\n+    protected final LogStreamMetadataStore streamMetadataStore;\n     protected final LogSegmentMetadataStore metadataStore;\n     protected final LogSegmentMetadataCache metadataCache;\n     protected final int firstNumEntriesPerReadLastRecordScan;\n@@ -112,8 +106,6 @@ public abstract class BKLogHandler implements AsyncCloseable, AsyncAbortable {\n     // Maintain the list of log segments per stream\n     protected final PerStreamLogSegmentCache logSegmentCache;\n \n-\n-\n     // trace\n     protected final long metadataLatencyWarnThresholdMillis;\n \n@@ -130,15 +122,13 @@ public abstract class BKLogHandler implements AsyncCloseable, AsyncAbortable {\n      */\n     BKLogHandler(ZKLogMetadata metadata,\n                  DistributedLogConfiguration conf,\n-                 ZooKeeperClientBuilder zkcBuilder,\n                  BookKeeperClientBuilder bkcBuilder,\n-                 LogSegmentMetadataStore metadataStore,\n+                 LogStreamMetadataStore streamMetadataStore,\n                  LogSegmentMetadataCache metadataCache,\n                  OrderedScheduler scheduler,\n                  StatsLogger statsLogger,\n                  AlertStatsLogger alertStatsLogger,\n                  String lockClientId) {\n-        Preconditions.checkNotNull(zkcBuilder);\n         Preconditions.checkNotNull(bkcBuilder);\n         this.logMetadata = metadata;\n         this.conf = conf;\n@@ -148,13 +138,11 @@ public abstract class BKLogHandler implements AsyncCloseable, AsyncAbortable {\n         this.logSegmentCache = new PerStreamLogSegmentCache(\n                 metadata.getLogName(),\n                 conf.isLogSegmentSequenceNumberValidationEnabled());\n-\n         firstNumEntriesPerReadLastRecordScan = conf.getFirstNumEntriesPerReadLastRecordScan();\n         maxNumEntriesPerReadLastRecordScan = conf.getMaxNumEntriesPerReadLastRecordScan();\n-        this.zooKeeperClient = zkcBuilder.build();\n-        LOG.debug(\"Using ZK Path {}\", logMetadata.getLogRootPath());\n         this.bookKeeperClient = bkcBuilder.build();\n-        this.metadataStore = metadataStore;\n+        this.streamMetadataStore = streamMetadataStore;\n+        this.metadataStore = streamMetadataStore.getLogSegmentMetadataStore();\n         this.metadataCache = metadataCache;\n         this.lockClientId = lockClientId;\n \n@@ -188,7 +176,8 @@ public String getLockClientId() {\n \n     public Future<LogRecordWithDLSN> asyncGetFirstLogRecord() {\n         final Promise<LogRecordWithDLSN> promise = new Promise<LogRecordWithDLSN>();\n-        checkLogStreamExistsAsync().addEventListener(new FutureEventListener<Void>() {\n+        streamMetadataStore.logExists(logMetadata.getUri(), logMetadata.getLogName())\n+                .addEventListener(new FutureEventListener<Void>() {\n             @Override\n             public void onSuccess(Void value) {\n                 readLogSegmentsFromStore(\n@@ -234,7 +223,8 @@ public void onFailure(Throwable cause) {\n \n     public Future<LogRecordWithDLSN> getLastLogRecordAsync(final boolean recover, final boolean includeEndOfStream) {\n         final Promise<LogRecordWithDLSN> promise = new Promise<LogRecordWithDLSN>();\n-        checkLogStreamExistsAsync().addEventListener(new FutureEventListener<Void>() {\n+        streamMetadataStore.logExists(logMetadata.getUri(), logMetadata.getLogName())\n+                .addEventListener(new FutureEventListener<Void>() {\n             @Override\n             public void onSuccess(Void value) {\n                 readLogSegmentsFromStore(\n@@ -381,8 +371,8 @@ public Long apply(final LogRecordWithDLSN endRecord) {\n      * @return the count of records present in the range\n      */\n     public Future<Long> asyncGetLogRecordCount(final DLSN beginDLSN) {\n-\n-        return checkLogStreamExistsAsync().flatMap(new Function<Void, Future<Long>>() {\n+        return streamMetadataStore.logExists(logMetadata.getUri(), logMetadata.getLogName())\n+                .flatMap(new Function<Void, Future<Long>>() {\n             public Future<Long> apply(Void done) {\n \n                 return readLogSegmentsFromStore(\n@@ -417,48 +407,6 @@ private Long sum(List<Long> values) {\n         return sum;\n     }\n \n-    Future<Void> checkLogStreamExistsAsync() {\n-        final Promise<Void> promise = new Promise<Void>();\n-        try {\n-            final ZooKeeper zk = zooKeeperClient.get();\n-            zk.sync(logMetadata.getLogSegmentsPath(), new AsyncCallback.VoidCallback() {\n-                @Override\n-                public void processResult(int syncRc, String path, Object syncCtx) {\n-                    if (KeeperException.Code.NONODE.intValue() == syncRc) {\n-                        promise.setException(new LogNotFoundException(\n-                                String.format(\"Log %s does not exist or has been deleted\", getFullyQualifiedName())));\n-                        return;\n-                    } else if (KeeperException.Code.OK.intValue() != syncRc){\n-                        promise.setException(new ZKException(\"Error on checking log existence for \" + getFullyQualifiedName(),\n-                                KeeperException.create(KeeperException.Code.get(syncRc))));\n-                        return;\n-                    }\n-                    zk.exists(logMetadata.getLogSegmentsPath(), false, new AsyncCallback.StatCallback() {\n-                        @Override\n-                        public void processResult(int rc, String path, Object ctx, Stat stat) {\n-                            if (KeeperException.Code.OK.intValue() == rc) {\n-                                promise.setValue(null);\n-                            } else if (KeeperException.Code.NONODE.intValue() == rc) {\n-                                promise.setException(new LogNotFoundException(String.format(\"Log %s does not exist or has been deleted\", getFullyQualifiedName())));\n-                            } else {\n-                                promise.setException(new ZKException(\"Error on checking log existence for \" + getFullyQualifiedName(),\n-                                        KeeperException.create(KeeperException.Code.get(rc))));\n-                            }\n-                        }\n-                    }, null);\n-                }\n-            }, null);\n-\n-        } catch (InterruptedException ie) {\n-            LOG.error(\"Interrupted while reading {}\", logMetadata.getLogSegmentsPath(), ie);\n-            promise.setException(new DLInterruptedException(\"Interrupted while checking \"\n-                    + logMetadata.getLogSegmentsPath(), ie));\n-        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n-            promise.setException(e);\n-        }\n-        return promise;\n-    }\n-\n     @Override\n     public Future<Void> asyncAbort() {\n         return asyncClose();"},{"sha":"196317291361ea708de95014d91e9307fa9067dc","filename":"src/main/java/com/twitter/distributedlog/BKLogReadHandler.java","status":"modified","additions":26,"deletions":100,"changes":126,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogReadHandler.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -31,29 +31,23 @@\n import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n-import com.twitter.distributedlog.exceptions.DLInterruptedException;\n-import com.twitter.distributedlog.exceptions.LockCancelledException;\n import com.twitter.distributedlog.exceptions.LockingException;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForReader;\n import com.twitter.distributedlog.injector.AsyncFailureInjector;\n import com.twitter.distributedlog.lock.DistributedLock;\n-import com.twitter.distributedlog.lock.SessionLockFactory;\n-import com.twitter.distributedlog.lock.ZKDistributedLock;\n-import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n-import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.metadata.LogStreamMetadataStore;\n import com.twitter.distributedlog.readahead.ReadAheadWorker;\n import com.twitter.distributedlog.stats.BroadCastStatsLogger;\n import com.twitter.distributedlog.stats.ReadAheadExceptionsLogger;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.distributedlog.util.Utils;\n import com.twitter.util.ExceptionalFunction;\n-import com.twitter.util.ExceptionalFunction0;\n import com.twitter.util.Function;\n import com.twitter.util.Future;\n import com.twitter.util.FutureEventListener;\n@@ -67,14 +61,13 @@\n import org.apache.bookkeeper.util.SafeRunnable;\n import org.apache.bookkeeper.versioning.Version;\n import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.zookeeper.CreateMode;\n-import org.apache.zookeeper.KeeperException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import scala.Function0;\n import scala.runtime.AbstractFunction1;\n import scala.runtime.BoxedUnit;\n \n+import javax.annotation.Nullable;\n+\n /**\n  * Log Handler for Readers.\n  * <h3>Metrics</h3>\n@@ -111,7 +104,7 @@\n  * becoming idle.\n  * </ul>\n  * <h4>Read Lock</h4>\n- * All read lock related stats are exposed under scope `read_lock`. See {@link ZKDistributedLock}\n+ * All read lock related stats are exposed under scope `read_lock`.\n  * for detail stats.\n  */\n class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n@@ -126,10 +119,7 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n     protected ReadAheadWorker readAheadWorker = null;\n     private final boolean isHandleForReading;\n \n-    private final SessionLockFactory lockFactory;\n-    private final OrderedScheduler lockStateExecutor;\n     private final Optional<String> subscriberId;\n-    private final String readLockPath;\n     private DistributedLock readLock;\n     private Future<Void> lockAcquireFuture;\n \n@@ -156,12 +146,10 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n                      Optional<String> subscriberId,\n                      DistributedLogConfiguration conf,\n                      DynamicDistributedLogConfiguration dynConf,\n-                     ZooKeeperClientBuilder zkcBuilder,\n                      BookKeeperClientBuilder bkcBuilder,\n-                     LogSegmentMetadataStore metadataStore,\n+                     LogStreamMetadataStore streamMetadataStore,\n                      LogSegmentMetadataCache metadataCache,\n                      OrderedScheduler scheduler,\n-                     OrderedScheduler lockStateExecutor,\n                      OrderedScheduler readAheadExecutor,\n                      AlertStatsLogger alertStatsLogger,\n                      ReadAheadExceptionsLogger readAheadExceptionsLogger,\n@@ -173,9 +161,8 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n                      boolean deserializeRecordSet) {\n         super(logMetadata,\n                 conf,\n-                zkcBuilder,\n                 bkcBuilder,\n-                metadataStore,\n+                streamMetadataStore,\n                 metadataCache,\n                 scheduler,\n                 statsLogger,\n@@ -206,23 +193,12 @@ class BKLogReadHandler extends BKLogHandler implements LogSegmentNamesListener {\n                 Ticker.systemTicker());\n \n         this.subscriberId = subscriberId;\n-        this.readLockPath = logMetadata.getReadLockPath(subscriberId);\n-        this.lockStateExecutor = lockStateExecutor;\n-        this.lockFactory = new ZKSessionLockFactory(\n-                zooKeeperClient,\n-                getLockClientId(),\n-                lockStateExecutor,\n-                conf.getZKNumRetries(),\n-                conf.getLockTimeoutMilliSeconds(),\n-                conf.getZKRetryBackoffStartMillis(),\n-                statsLogger.scope(\"read_lock\"));\n-\n         this.isHandleForReading = isHandleForReading;\n     }\n \n     @VisibleForTesting\n     String getReadLockPath() {\n-        return readLockPath;\n+        return logMetadataForReader.getReadLockPath(subscriberId);\n     }\n \n     <T> void satisfyPromiseAsync(final Promise<T> promise, final Try<T> result) {\n@@ -234,38 +210,24 @@ public void safeRun() {\n         });\n     }\n \n+    Future<Void> checkLogStreamExists() {\n+        return streamMetadataStore.logExists(logMetadata.getUri(), logMetadata.getLogName());\n+    }\n+\n     /**\n      * Elective stream lock--readers are not required to acquire the lock before using the stream.\n      */\n     synchronized Future<Void> lockStream() {\n         if (null == lockAcquireFuture) {\n-            final Function0<DistributedLock> lockFunction =  new ExceptionalFunction0<DistributedLock>() {\n-                @Override\n-                public DistributedLock applyE() throws IOException {\n-                    // Unfortunately this has a blocking call which we should not execute on the\n-                    // ZK completion thread\n-                    BKLogReadHandler.this.readLock = new ZKDistributedLock(\n-                            lockStateExecutor,\n-                            lockFactory,\n-                            readLockPath,\n-                            conf.getLockTimeoutMilliSeconds(),\n-                            statsLogger.scope(\"read_lock\"));\n-\n-                    LOG.info(\"acquiring readlock {} at {}\", getLockClientId(), readLockPath);\n-                    return BKLogReadHandler.this.readLock;\n-                }\n-            };\n-            lockAcquireFuture = ensureReadLockPathExist().flatMap(new ExceptionalFunction<Void, Future<Void>>() {\n-                @Override\n-                public Future<Void> applyE(Void in) throws Throwable {\n-                    return scheduler.apply(lockFunction).flatMap(new ExceptionalFunction<DistributedLock, Future<Void>>() {\n+            lockAcquireFuture = streamMetadataStore.createReadLock(logMetadataForReader, subscriberId)\n+                    .flatMap(new ExceptionalFunction<DistributedLock, Future<Void>>() {\n                         @Override\n-                        public Future<Void> applyE(DistributedLock lock) throws IOException {\n+                        public Future<Void> applyE(DistributedLock lock) throws Throwable {\n+                            BKLogReadHandler.this.readLock = lock;\n+                            LOG.info(\"acquiring readlock {} at {}\", getLockClientId(), getReadLockPath());\n                             return acquireLockOnExecutorThread(lock);\n                         }\n                     });\n-                }\n-            });\n         }\n         return lockAcquireFuture;\n     }\n@@ -292,14 +254,14 @@ public BoxedUnit apply(Throwable t) {\n         acquireFuture.addEventListener(new FutureEventListener<DistributedLock>() {\n             @Override\n             public void onSuccess(DistributedLock lock) {\n-                LOG.info(\"acquired readlock {} at {}\", getLockClientId(), readLockPath);\n+                LOG.info(\"acquired readlock {} at {}\", getLockClientId(), getReadLockPath());\n                 satisfyPromiseAsync(threadAcquirePromise, new Return<Void>(null));\n             }\n \n             @Override\n             public void onFailure(Throwable cause) {\n                 LOG.info(\"failed to acquire readlock {} at {}\",\n-                        new Object[]{getLockClientId(), readLockPath, cause});\n+                        new Object[]{ getLockClientId(), getReadLockPath(), cause });\n                 satisfyPromiseAsync(threadAcquirePromise, new Throw<Void>(cause));\n             }\n         });\n@@ -438,46 +400,6 @@ public LedgerHandleCache getHandleCache() {\n         return handleCache;\n     }\n \n-    private Future<Void> ensureReadLockPathExist() {\n-        final Promise<Void> promise = new Promise<Void>();\n-        promise.setInterruptHandler(new com.twitter.util.Function<Throwable, BoxedUnit>() {\n-            @Override\n-            public BoxedUnit apply(Throwable t) {\n-                FutureUtils.setException(promise, new LockCancelledException(readLockPath, \"Could not ensure read lock path\", t));\n-                return null;\n-            }\n-        });\n-        Optional<String> parentPathShouldNotCreate = Optional.of(logMetadata.getLogRootPath());\n-        Utils.zkAsyncCreateFullPathOptimisticRecursive(zooKeeperClient, readLockPath, parentPathShouldNotCreate,\n-                new byte[0], zooKeeperClient.getDefaultACL(), CreateMode.PERSISTENT,\n-                new org.apache.zookeeper.AsyncCallback.StringCallback() {\n-                    @Override\n-                    public void processResult(final int rc, final String path, Object ctx, String name) {\n-                        scheduler.submit(new Runnable() {\n-                            @Override\n-                            public void run() {\n-                                if (KeeperException.Code.NONODE.intValue() == rc) {\n-                                    FutureUtils.setException(promise, new LogNotFoundException(String.format(\"Log %s does not exist or has been deleted\", getFullyQualifiedName())));\n-                                } else if (KeeperException.Code.OK.intValue() == rc) {\n-                                    FutureUtils.setValue(promise, null);\n-                                    LOG.trace(\"Created path {}.\", path);\n-                                } else if (KeeperException.Code.NODEEXISTS.intValue() == rc) {\n-                                    FutureUtils.setValue(promise, null);\n-                                    LOG.trace(\"Path {} is already existed.\", path);\n-                                } else if (DistributedLogConstants.ZK_CONNECTION_EXCEPTION_RESULT_CODE == rc) {\n-                                    FutureUtils.setException(promise, new ZooKeeperClient.ZooKeeperConnectionException(path));\n-                                } else if (DistributedLogConstants.DL_INTERRUPTED_EXCEPTION_RESULT_CODE == rc) {\n-                                    FutureUtils.setException(promise, new DLInterruptedException(path));\n-                                } else {\n-                                    FutureUtils.setException(promise, KeeperException.create(KeeperException.Code.get(rc)));\n-                                }\n-                            }\n-                        });\n-                    }\n-                }, null);\n-        return promise;\n-    }\n-\n     public Entry.Reader getNextReadAheadEntry() throws IOException {\n         return readAheadCache.getNextReadAheadEntry();\n     }\n@@ -560,12 +482,16 @@ public void onLogStreamDeleted() {\n     // Listener for log segments\n     //\n \n-    protected void registerListener(LogSegmentListener listener) {\n-        listeners.add(listener);\n+    protected void registerListener(@Nullable LogSegmentListener listener) {\n+        if (null != listener) {\n+            listeners.add(listener);\n+        }\n     }\n \n-    protected void unregisterListener(LogSegmentListener listener) {\n-        listeners.remove(listener);\n+    protected void unregisterListener(@Nullable LogSegmentListener listener) {\n+        if (null != listener) {\n+            listeners.remove(listener);\n+        }\n     }\n \n     protected void notifyUpdatedLogSegments(List<LogSegmentMetadata> segments) {"},{"sha":"f2e30ce0eb74503f1c40eedde21b5bb78104d70f","filename":"src/main/java/com/twitter/distributedlog/BKLogWriteHandler.java","status":"modified","additions":71,"deletions":140,"changes":211,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKLogWriteHandler.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -23,22 +23,21 @@\n import com.twitter.distributedlog.bk.LedgerAllocator;\n import com.twitter.distributedlog.config.DynamicDistributedLogConfiguration;\n import com.twitter.distributedlog.exceptions.DLIllegalStateException;\n-import com.twitter.distributedlog.exceptions.DLInterruptedException;\n import com.twitter.distributedlog.exceptions.EndOfStreamException;\n import com.twitter.distributedlog.exceptions.LockingException;\n+import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n import com.twitter.distributedlog.exceptions.TransactionIdOutOfOrderException;\n import com.twitter.distributedlog.exceptions.UnexpectedException;\n-import com.twitter.distributedlog.exceptions.ZKException;\n import com.twitter.distributedlog.function.GetLastTxIdFunction;\n import com.twitter.distributedlog.impl.BKLogSegmentEntryWriter;\n import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n import com.twitter.distributedlog.lock.DistributedLock;\n import com.twitter.distributedlog.logsegment.LogSegmentFilter;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataCache;\n-import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.logsegment.RollingPolicy;\n import com.twitter.distributedlog.logsegment.SizeBasedRollingPolicy;\n import com.twitter.distributedlog.logsegment.TimeBasedRollingPolicy;\n+import com.twitter.distributedlog.metadata.LogStreamMetadataStore;\n import com.twitter.distributedlog.metadata.MetadataUpdater;\n import com.twitter.distributedlog.metadata.LogSegmentMetadataStoreUpdater;\n import com.twitter.distributedlog.util.DLUtils;\n@@ -49,9 +48,6 @@\n import com.twitter.distributedlog.util.Transaction;\n import com.twitter.distributedlog.util.PermitLimiter;\n import com.twitter.distributedlog.util.Utils;\n-import com.twitter.distributedlog.zk.ZKOp;\n-import com.twitter.distributedlog.zk.ZKTransaction;\n-import com.twitter.distributedlog.zk.ZKVersionedSetOp;\n import com.twitter.util.Function;\n import com.twitter.util.Future;\n import com.twitter.util.FutureEventListener;\n@@ -60,19 +56,11 @@\n import org.apache.bookkeeper.client.BKException;\n import org.apache.bookkeeper.client.LedgerHandle;\n import org.apache.bookkeeper.feature.FeatureProvider;\n-import org.apache.bookkeeper.meta.ZkVersion;\n import org.apache.bookkeeper.stats.AlertStatsLogger;\n import org.apache.bookkeeper.stats.OpStatsLogger;\n import org.apache.bookkeeper.stats.StatsLogger;\n import org.apache.bookkeeper.versioning.Version;\n import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.zookeeper.CreateMode;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.Op;\n-import org.apache.zookeeper.OpResult;\n-import org.apache.zookeeper.Watcher;\n-import org.apache.zookeeper.ZKUtil;\n-import org.apache.zookeeper.data.ACL;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import scala.runtime.AbstractFunction1;\n@@ -84,7 +72,6 @@\n import java.util.List;\n import java.util.concurrent.TimeUnit;\n \n-import static com.google.common.base.Charsets.UTF_8;\n import static com.twitter.distributedlog.impl.ZKLogSegmentFilters.WRITE_HANDLE_FILTER;\n \n /**\n@@ -102,11 +89,11 @@\n class BKLogWriteHandler extends BKLogHandler {\n     static final Logger LOG = LoggerFactory.getLogger(BKLogReadHandler.class);\n \n+    protected final ZKLogMetadataForWriter logMetadataForWriter;\n     protected final DistributedLock lock;\n     protected final LedgerAllocator ledgerAllocator;\n     protected final MaxTxId maxTxId;\n     protected final MaxLogSegmentSequenceNo maxLogSegmentSequenceNo;\n-    protected final boolean sanityCheckTxnId;\n     protected final boolean validateLogSegmentSequenceNumber;\n     protected final int regionId;\n     protected final RollingPolicy rollingPolicy;\n@@ -164,9 +151,8 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n      */\n     BKLogWriteHandler(ZKLogMetadataForWriter logMetadata,\n                       DistributedLogConfiguration conf,\n-                      ZooKeeperClientBuilder zkcBuilder,\n                       BookKeeperClientBuilder bkcBuilder,\n-                      LogSegmentMetadataStore metadataStore,\n+                      LogStreamMetadataStore streamMetadataStore,\n                       LogSegmentMetadataCache metadataCache,\n                       OrderedScheduler scheduler,\n                       LedgerAllocator allocator,\n@@ -181,14 +167,14 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n                       DistributedLock lock /** owned by handler **/) {\n         super(logMetadata,\n                 conf,\n-                zkcBuilder,\n                 bkcBuilder,\n-                metadataStore,\n+                streamMetadataStore,\n                 metadataCache,\n                 scheduler,\n                 statsLogger,\n                 alertStatsLogger,\n                 clientId);\n+        this.logMetadataForWriter = logMetadata;\n         this.perLogStatsLogger = perLogStatsLogger;\n         this.writeLimiter = writeLimiter;\n         this.featureProvider = featureProvider;\n@@ -202,15 +188,13 @@ public Future<Long> apply(List<LogSegmentMetadata> segmentList) {\n         } else {\n             this.regionId = DistributedLogConstants.LOCAL_REGION_ID;\n         }\n-        this.sanityCheckTxnId = conf.getSanityCheckTxnID();\n         this.validateLogSegmentSequenceNumber = conf.isLogSegmentSequenceNumberValidationEnabled();\n \n         // Construct the max sequence no\n         maxLogSegmentSequenceNo = new MaxLogSegmentSequenceNo(logMetadata.getMaxLSSNData());\n         inprogressLSSNs = new LinkedList<Long>();\n         // Construct the max txn id.\n-        maxTxId = new MaxTxId(zooKeeperClient, logMetadata.getMaxTxIdPath(),\n-                conf.getSanityCheckTxnID(), logMetadata.getMaxTxIdData());\n+        maxTxId = new MaxTxId(logMetadata.getMaxTxIdData());\n \n         // Schedule fetching log segment list in background before we access it.\n         // We don't need to watch the log segment list changes for writer, as it manages log segment list.\n@@ -291,13 +275,12 @@ public void onSuccess(Versioned<List<LogSegmentMetadata>> result) {\n     }\n \n     // Transactional operations for MaxLogSegmentSequenceNo\n-    void storeMaxSequenceNumber(final Transaction txn,\n+    void storeMaxSequenceNumber(final Transaction<Object> txn,\n                                 final MaxLogSegmentSequenceNo maxSeqNo,\n                                 final long seqNo,\n                                 final boolean isInprogress) {\n-        byte[] data = DLUtils.serializeLogSegmentSequenceNumber(seqNo);\n-        Op zkOp = Op.setData(logMetadata.getLogSegmentsPath(), data, maxSeqNo.getZkVersion());\n-        txn.addOp(new ZKVersionedSetOp(zkOp, new Transaction.OpListener<Version>() {\n+        metadataStore.storeMaxLogSegmentSequenceNumber(txn, logMetadata, maxSeqNo.getVersionedData(seqNo),\n+                new Transaction.OpListener<Version>() {\n             @Override\n             public void onCommit(Version version) {\n                 if (validateLogSegmentSequenceNumber) {\n@@ -309,69 +292,60 @@ public void onCommit(Version version) {\n                         }\n                     }\n                 }\n-                maxSeqNo.update((ZkVersion) version, seqNo);\n+                maxSeqNo.update(version, seqNo);\n             }\n \n             @Override\n             public void onAbort(Throwable t) {\n                 // no-op\n             }\n-        }));\n+        });\n     }\n \n     // Transactional operations for MaxTxId\n-    void storeMaxTxId(final ZKTransaction txn,\n+    void storeMaxTxId(final Transaction<Object> txn,\n                       final MaxTxId maxTxId,\n                       final long txId) {\n-        byte[] data = maxTxId.couldStore(txId);\n-        if (null != data) {\n-            Op zkOp = Op.setData(maxTxId.getZkPath(), data, -1);\n-            txn.addOp(new ZKVersionedSetOp(zkOp, new Transaction.OpListener<Version>() {\n-                @Override\n-                public void onCommit(Version version) {\n-                    maxTxId.setMaxTxId(txId);\n-                }\n-\n-                @Override\n-                public void onAbort(Throwable t) {\n+        metadataStore.storeMaxTxnId(txn, logMetadataForWriter, maxTxId.getVersionedData(txId),\n+                new Transaction.OpListener<Version>() {\n+                    @Override\n+                    public void onCommit(Version version) {\n+                                                        maxTxId.update(version, txId);\n+                                                                                      }\n \n-                }\n-            }));\n-        }\n+                    @Override\n+                    public void onAbort(Throwable t) {\n+                        // no-op\n+                    }\n+                });\n     }\n \n     // Transactional operations for logsegment\n-    void writeLogSegment(final ZKTransaction txn,\n-                         final List<ACL> acl,\n-                         final String inprogressSegmentName,\n-                         final LogSegmentMetadata metadata,\n-                         final String path) {\n-        byte[] finalisedData = metadata.getFinalisedData().getBytes(UTF_8);\n-        Op zkOp = Op.create(path, finalisedData, acl, CreateMode.PERSISTENT);\n-        txn.addOp(new ZKOp(zkOp) {\n+    void writeLogSegment(final Transaction<Object> txn,\n+                         final LogSegmentMetadata metadata) {\n+        metadataStore.createLogSegment(txn, metadata, new Transaction.OpListener<Void>() {\n             @Override\n-            protected void commitOpResult(OpResult opResult) {\n-                addLogSegmentToCache(inprogressSegmentName, metadata);\n+            public void onCommit(Void r) {\n+                addLogSegmentToCache(metadata.getSegmentName(), metadata);\n             }\n \n             @Override\n-            protected void abortOpResult(Throwable t, OpResult opResult) {\n+            public void onAbort(Throwable t) {\n                 // no-op\n             }\n         });\n     }\n \n-    void deleteLogSegment(final ZKTransaction txn,\n-                          final String logSegmentName,\n-                          final String logSegmentPath) {\n-        Op zkOp = Op.delete(logSegmentPath, -1);\n-        txn.addOp(new ZKOp(zkOp) {\n+    void deleteLogSegment(final Transaction<Object> txn,\n+                          final LogSegmentMetadata metadata) {\n+        metadataStore.deleteLogSegment(txn, metadata, new Transaction.OpListener<Void>() {\n             @Override\n-            protected void commitOpResult(OpResult opResult) {\n-                removeLogSegmentFromCache(logSegmentName);\n+            public void onCommit(Void r) {\n+                removeLogSegmentFromCache(metadata.getSegmentName());\n             }\n+\n             @Override\n-            protected void abortOpResult(Throwable t, OpResult opResult) {\n+            public void onAbort(Throwable t) {\n                 // no-op\n             }\n         });\n@@ -405,10 +379,6 @@ Future<Void> unlockHandler() {\n         }\n     }\n \n-    void register(Watcher watcher) {\n-        this.zooKeeperClient.register(watcher);\n-    }\n-\n     /**\n      * Start a new log segment in a BookKeeper ledger.\n      * First ensure that we have the write lock for this journal.\n@@ -539,19 +509,17 @@ protected void doStartLogSegment(final long txId,\n             FutureUtils.setException(promise, new IOException(\"Invalid Transaction Id \" + txId));\n             return;\n         }\n-        if (this.sanityCheckTxnId) {\n-            long highestTxIdWritten = maxTxId.get();\n-            if (txId < highestTxIdWritten) {\n-                if (highestTxIdWritten == DistributedLogConstants.MAX_TXID) {\n-                    LOG.error(\"We've already marked the stream as ended and attempting to start a new log segment\");\n-                    FutureUtils.setException(promise, new EndOfStreamException(\"Writing to a stream after it has been marked as completed\"));\n-                    return;\n-                }\n-                else {\n-                    LOG.error(\"We've already seen TxId {} the max TXId is {}\", txId, highestTxIdWritten);\n-                    FutureUtils.setException(promise, new TransactionIdOutOfOrderException(txId, highestTxIdWritten));\n-                    return;\n-                }\n+\n+        long highestTxIdWritten = maxTxId.get();\n+        if (txId < highestTxIdWritten) {\n+            if (highestTxIdWritten == DistributedLogConstants.MAX_TXID) {\n+                LOG.error(\"We've already marked the stream as ended and attempting to start a new log segment\");\n+                FutureUtils.setException(promise, new EndOfStreamException(\"Writing to a stream after it has been marked as completed\"));\n+                return;\n+            } else {\n+                LOG.error(\"We've already seen TxId {} the max TXId is {}\", txId, highestTxIdWritten);\n+                FutureUtils.setException(promise, new TransactionIdOutOfOrderException(txId, highestTxIdWritten));\n+                return;\n             }\n         }\n \n@@ -564,7 +532,7 @@ protected void doStartLogSegment(final long txId,\n         }\n \n         // start the transaction from zookeeper\n-        final ZKTransaction txn = new ZKTransaction(zooKeeperClient);\n+        final Transaction<Object> txn = streamMetadataStore.newTransaction();\n \n         // failpoint injected before creating ledger\n         try {\n@@ -617,7 +585,7 @@ private void failStartLogSegment(Promise<BKLogSegmentWriter> promise,\n     // once the ledger handle is obtained from allocator, this function should guarantee\n     // either the transaction is executed or aborted. Otherwise, the ledger handle will\n     // just leak from the allocation pool - hence cause \"No Ledger Allocator\"\n-    private void createInprogressLogSegment(ZKTransaction txn,\n+    private void createInprogressLogSegment(Transaction<Object> txn,\n                                             final long txId,\n                                             final LedgerHandle lh,\n                                             boolean bestEffort,\n@@ -634,7 +602,6 @@ private void createInprogressLogSegment(ZKTransaction txn,\n             return;\n         }\n \n-        final String inprogressZnodeName = inprogressZNodeName(lh.getId(), txId, logSegmentSeqNo);\n         final String inprogressZnodePath = inprogressZNode(lh.getId(), txId, logSegmentSeqNo);\n         final LogSegmentMetadata l =\n             new LogSegmentMetadata.LogSegmentMetadataBuilder(inprogressZnodePath,\n@@ -645,12 +612,7 @@ private void createInprogressLogSegment(ZKTransaction txn,\n                     .build();\n \n         // Create an inprogress segment\n-        writeLogSegment(\n-                txn,\n-                zooKeeperClient.getDefaultACL(),\n-                inprogressZnodeName,\n-                l,\n-                inprogressZnodePath);\n+        writeLogSegment(txn, l);\n \n         // Try storing max sequence number.\n         LOG.debug(\"Try storing max sequence number in startLogSegment {} : {}\", inprogressZnodePath, logSegmentSeqNo);\n@@ -667,7 +629,7 @@ public void onSuccess(Void value) {\n                 try {\n                     FutureUtils.setValue(promise, new BKLogSegmentWriter(\n                             getFullyQualifiedName(),\n-                            inprogressZnodeName,\n+                            l.getSegmentName(),\n                             conf,\n                             conf.getDLLedgerMetadataLayoutVersion(),\n                             new BKLogSegmentEntryWriter(lh),\n@@ -888,7 +850,6 @@ private void doCompleteAndCloseLogSegmentAfterLogSegmentListFetched(\n         }\n \n         LOG.debug(\"Completing and Closing Log Segment {} {}\", firstTxId, lastTxId);\n-        final String inprogressZnodePath = inprogressZNode(inprogressZnodeName);\n         LogSegmentMetadata inprogressLogSegment = readLogSegmentFromCache(inprogressZnodeName);\n \n         // validate log segment\n@@ -936,7 +897,7 @@ private void doCompleteAndCloseLogSegmentAfterLogSegmentListFetched(\n             // ignore the case that a new inprogress log segment is pre-allocated\n             // before completing current inprogress one\n             LOG.info(\"Try storing max sequence number {} in completing {}.\",\n-                    new Object[] { logSegmentSeqNo, inprogressZnodePath });\n+                    new Object[] { logSegmentSeqNo, inprogressLogSegment.getZkPath() });\n         } else {\n             LOG.warn(\"Unexpected max ledger sequence number {} found while completing log segment {} for {}\",\n                     new Object[] { maxLogSegmentSequenceNo.getSequenceNumber(), logSegmentSeqNo, getFullyQualifiedName() });\n@@ -949,7 +910,6 @@ private void doCompleteAndCloseLogSegmentAfterLogSegmentListFetched(\n         }\n \n         // Prepare the completion\n-        final String nameForCompletedLedger = completedLedgerZNodeName(firstTxId, lastTxId, logSegmentSeqNo);\n         final String pathForCompletedLedger = completedLedgerZNode(firstTxId, lastTxId, logSegmentSeqNo);\n         long startSequenceId;\n         try {\n@@ -970,17 +930,12 @@ private void doCompleteAndCloseLogSegmentAfterLogSegmentListFetched(\n         setLastLedgerRollingTimeMillis(completedLogSegment.getCompletionTime());\n \n         // prepare the transaction\n-        ZKTransaction txn = new ZKTransaction(zooKeeperClient);\n+        Transaction<Object> txn = streamMetadataStore.newTransaction();\n \n         // create completed log segment\n-        writeLogSegment(\n-                txn,\n-                zooKeeperClient.getDefaultACL(),\n-                nameForCompletedLedger,\n-                completedLogSegment,\n-                pathForCompletedLedger);\n+        writeLogSegment(txn, completedLogSegment);\n         // delete inprogress log segment\n-        deleteLogSegment(txn, inprogressZnodeName, inprogressZnodePath);\n+        deleteLogSegment(txn, inprogressLogSegment);\n         // store max sequence number\n         storeMaxSequenceNumber(txn, maxLogSegmentSequenceNo, maxSeqNo, false);\n         // update max txn id.\n@@ -991,7 +946,8 @@ private void doCompleteAndCloseLogSegmentAfterLogSegmentListFetched(\n             @Override\n             public void onSuccess(Void value) {\n                 LOG.info(\"Completed {} to {} for {} : {}\",\n-                        new Object[] { inprogressZnodeName, nameForCompletedLedger, getFullyQualifiedName(), completedLogSegment });\n+                        new Object[] { inprogressZnodeName, completedLogSegment.getSegmentName(),\n+                                getFullyQualifiedName(), completedLogSegment });\n                 FutureUtils.setValue(promise, completedLogSegment);\n             }\n \n@@ -1072,27 +1028,6 @@ private Future<LogSegmentMetadata> completeLogSegment(LogSegmentMetadata l,\n \n     }\n \n-    public void deleteLog() throws IOException {\n-        lock.checkOwnershipAndReacquire();\n-        FutureUtils.result(purgeLogSegmentsOlderThanTxnId(-1));\n-\n-        try {\n-            Utils.closeQuietly(lock);\n-            zooKeeperClient.get().exists(logMetadata.getLogSegmentsPath(), false);\n-            zooKeeperClient.get().exists(logMetadata.getMaxTxIdPath(), false);\n-            if (logMetadata.getLogRootPath().toLowerCase().contains(\"distributedlog\")) {\n-                ZKUtil.deleteRecursive(zooKeeperClient.get(), logMetadata.getLogRootPath());\n-            } else {\n-                LOG.warn(\"Skip deletion of unrecognized ZK Path {}\", logMetadata.getLogRootPath());\n-            }\n-        } catch (InterruptedException ie) {\n-            LOG.error(\"Interrupted while deleting log znodes\", ie);\n-            throw new DLInterruptedException(\"Interrupted while deleting \" + logMetadata.getLogRootPath(), ie);\n-        } catch (KeeperException ke) {\n-            LOG.error(\"Error deleting\" + logMetadata.getLogRootPath() + \" in zookeeper\", ke);\n-        }\n-    }\n-\n     Future<List<LogSegmentMetadata>> setLogSegmentsOlderThanDLSNTruncated(final DLSN dlsn) {\n         if (DLSN.InvalidDLSN == dlsn) {\n             List<LogSegmentMetadata> emptyList = new ArrayList<LogSegmentMetadata>(0);\n@@ -1321,33 +1256,29 @@ public void run() {\n     private void deleteLogSegmentMetadata(final LogSegmentMetadata segmentMetadata,\n                                           final Promise<LogSegmentMetadata> promise) {\n         Transaction<Object> deleteTxn = metadataStore.transaction();\n-        metadataStore.deleteLogSegment(deleteTxn, segmentMetadata);\n-        deleteTxn.execute().addEventListener(new FutureEventListener<Void>() {\n+        metadataStore.deleteLogSegment(deleteTxn, segmentMetadata, new Transaction.OpListener<Void>() {\n             @Override\n-            public void onSuccess(Void result) {\n+            public void onCommit(Void r) {\n                 // purge log segment\n                 removeLogSegmentFromCache(segmentMetadata.getZNodeName());\n                 promise.setValue(segmentMetadata);\n             }\n \n             @Override\n-            public void onFailure(Throwable cause) {\n-                if (cause instanceof ZKException) {\n-                    ZKException zke = (ZKException) cause;\n-                    if (KeeperException.Code.NONODE == zke.getKeeperExceptionCode()) {\n-                        LOG.error(\"No log segment {} found for {}.\",\n-                                segmentMetadata, getFullyQualifiedName());\n-                        // purge log segment\n-                        removeLogSegmentFromCache(segmentMetadata.getZNodeName());\n-                        promise.setValue(segmentMetadata);\n-                        return;\n-                    }\n+            public void onAbort(Throwable t) {\n+                if (t instanceof LogSegmentNotFoundException) {\n+                    // purge log segment\n+                    removeLogSegmentFromCache(segmentMetadata.getZNodeName());\n+                    promise.setValue(segmentMetadata);\n+                    return;\n+                } else {\n+                    LOG.error(\"Couldn't purge {} for {}: with error {}\",\n+                            new Object[]{ segmentMetadata, getFullyQualifiedName(), t });\n+                    promise.setException(t);\n                 }\n-                LOG.error(\"Couldn't purge {} for {}: with error {}\",\n-                        new Object[]{ segmentMetadata, getFullyQualifiedName(), cause });\n-                promise.setException(cause);\n             }\n         });\n+        deleteTxn.execute();\n     }\n \n     @Override"},{"sha":"0f6db75d3b01bed7e2814588d23df135891e4b1a","filename":"src/main/java/com/twitter/distributedlog/BKSyncLogReaderDLSN.java","status":"modified","additions":0,"deletions":1,"changes":1,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FBKSyncLogReaderDLSN.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -62,7 +62,6 @@ class BKSyncLogReaderDLSN implements LogReader, AsyncNotification {\n                         StatsLogger statsLogger) {\n         this.readHandler = bkdlm.createReadHandler(\n                 Optional.<String>absent(),\n-                bkdlm.getLockStateExecutor(true),\n                 this,\n                 conf.getDeserializeRecordSetOnReads(),\n                 true);"},{"sha":"6f37a59457274cf34ecbd6e360b62a2cf9f33a3b","filename":"src/main/java/com/twitter/distributedlog/DistributedLogConfiguration.java","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDistributedLogConfiguration.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -1557,6 +1557,7 @@ public DistributedLogConfiguration setEnableRecordCounts(boolean enableRecordCou\n      *\n      * @return true if should check txn id with max txn id, otherwise false.\n      */\n+    @Deprecated\n     public boolean getSanityCheckTxnID() {\n         return getBoolean(BKDL_MAXID_SANITYCHECK, BKDL_MAXID_SANITYCHECK_DEFAULT);\n     }\n@@ -1569,6 +1570,7 @@ public boolean getSanityCheckTxnID() {\n      * @return configuration.\n      * @see #getSanityCheckTxnID()\n      */\n+    @Deprecated\n     public DistributedLogConfiguration setSanityCheckTxnID(boolean enabled) {\n         setProperty(BKDL_MAXID_SANITYCHECK, enabled);\n         return this;"},{"sha":"9bfaabacc1c14843d92539f92d04fcbcac697733","filename":"src/main/java/com/twitter/distributedlog/MaxLogSegmentSequenceNo.java","status":"modified","additions":6,"deletions":34,"changes":40,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxLogSegmentSequenceNo.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxLogSegmentSequenceNo.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxLogSegmentSequenceNo.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -17,26 +17,15 @@\n  */\n package com.twitter.distributedlog;\n \n-import com.twitter.distributedlog.exceptions.DLInterruptedException;\n-import com.twitter.distributedlog.exceptions.ZKException;\n import com.twitter.distributedlog.util.DLUtils;\n-import org.apache.bookkeeper.meta.ZkVersion;\n import org.apache.bookkeeper.versioning.Version;\n import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.data.Stat;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.IOException;\n \n /**\n  * Utility class for storing and reading max ledger sequence number\n  */\n class MaxLogSegmentSequenceNo {\n \n-    static final Logger LOG = LoggerFactory.getLogger(MaxLogSegmentSequenceNo.class);\n-\n     Version version;\n     long maxSeqNo;\n \n@@ -55,46 +44,29 @@ class MaxLogSegmentSequenceNo {\n             if (null != logSegmentsData && null != logSegmentsData.getVersion()) {\n                 version = logSegmentsData.getVersion();\n             } else {\n-                version = new ZkVersion(-1);\n+                throw new IllegalStateException(\"Invalid MaxLogSegmentSequenceNo found - \" + logSegmentsData);\n             }\n         }\n     }\n \n-    synchronized int getZkVersion() {\n-        return ((ZkVersion) version).getZnodeVersion();\n+    synchronized Version getVersion() {\n+        return version;\n     }\n \n     synchronized long getSequenceNumber() {\n         return maxSeqNo;\n     }\n \n-    synchronized MaxLogSegmentSequenceNo update(int zkVersion, long logSegmentSeqNo) {\n-        return update(new ZkVersion(zkVersion), logSegmentSeqNo);\n-    }\n-\n-    synchronized MaxLogSegmentSequenceNo update(ZkVersion version, long logSegmentSeqNo) {\n+    synchronized MaxLogSegmentSequenceNo update(Version version, long logSegmentSeqNo) {\n         if (version.compare(this.version) == Version.Occurred.AFTER) {\n             this.version = version;\n             this.maxSeqNo = logSegmentSeqNo;\n         }\n         return this;\n     }\n \n-    synchronized void store(ZooKeeperClient zkc, String path, long logSegmentSeqNo) throws IOException {\n-        try {\n-            Stat stat = zkc.get().setData(path,\n-                    DLUtils.serializeLogSegmentSequenceNumber(logSegmentSeqNo), getZkVersion());\n-            update(stat.getVersion(), logSegmentSeqNo);\n-        } catch (KeeperException ke) {\n-            throw new ZKException(\"Error writing max ledger sequence number \" + logSegmentSeqNo + \" to \"\n-                                  + path + \" : \", ke);\n-        } catch (ZooKeeperClient.ZooKeeperConnectionException zce) {\n-            throw new IOException(\"Error writing max ledger sequence number \" + logSegmentSeqNo + \" to \"\n-                    + path + \" : \", zce);\n-        } catch (InterruptedException e) {\n-            throw new DLInterruptedException(\"Error writing max ledger sequence number \" + logSegmentSeqNo + \" to \"\n-                    + path + \" : \", e);\n-        }\n+    public synchronized Versioned<Long> getVersionedData(long seqNo) {\n+        return new Versioned<Long>(seqNo, version);\n     }\n \n }"},{"sha":"ed7218e1b70aaff4297db43ffe5c1489f493f2a1","filename":"src/main/java/com/twitter/distributedlog/MaxTxId.java","status":"modified","additions":22,"deletions":54,"changes":76,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxTxId.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxTxId.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FMaxTxId.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -18,87 +18,55 @@\n package com.twitter.distributedlog;\n \n import com.twitter.distributedlog.util.DLUtils;\n+import org.apache.bookkeeper.versioning.Version;\n import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.zookeeper.data.Stat;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.io.IOException;\n-\n /**\n  * Utility class for storing and reading\n  * the max seen txid in zookeeper\n  */\n class MaxTxId {\n     static final Logger LOG = LoggerFactory.getLogger(MaxTxId.class);\n \n-    private final ZooKeeperClient zkc;\n-    private final String path;\n-    private final boolean enabled;\n-\n+    private Version version;\n     private long currentMax;\n \n-    MaxTxId(ZooKeeperClient zkc, String path, boolean enabled,\n-            Versioned<byte[]> maxTxIdData) {\n-        this.zkc = zkc;\n-        this.path = path;\n-        this.enabled = enabled && null != maxTxIdData && null != maxTxIdData.getVersion()\n-                && null != maxTxIdData.getValue();\n-        if (this.enabled) {\n+    MaxTxId(Versioned<byte[]> maxTxIdData) {\n+        if (null != maxTxIdData\n+                && null != maxTxIdData.getValue()\n+                && null != maxTxIdData.getVersion()) {\n+            this.version = maxTxIdData.getVersion();\n             try {\n                 this.currentMax = DLUtils.deserializeTransactionId(maxTxIdData.getValue());\n             } catch (NumberFormatException e) {\n-                LOG.warn(\"Invalid txn id stored in {}\", path, e);\n-                this.currentMax = 0L;\n+                LOG.warn(\"Invalid txn id stored in {}\", e);\n+                this.currentMax = DistributedLogConstants.INVALID_TXID;\n             }\n         } else {\n-            this.currentMax = -1L;\n+            this.currentMax = DistributedLogConstants.INVALID_TXID;\n+            if (null != maxTxIdData && null != maxTxIdData.getVersion()) {\n+                this.version = maxTxIdData.getVersion();\n+            } else {\n+                throw new IllegalStateException(\"Invalid MaxTxId found - \" + maxTxIdData);\n+            }\n         }\n     }\n \n-    String getZkPath() {\n-        return path;\n-    }\n-\n-    synchronized void setMaxTxId(long txId) {\n-        if (enabled && this.currentMax < txId) {\n+    synchronized void update(Version version, long txId) {\n+        if (version.compare(this.version) == Version.Occurred.AFTER) {\n+            this.version = version;\n             this.currentMax = txId;\n         }\n     }\n \n-    synchronized byte[] couldStore(long maxTxId) {\n-        if (enabled && currentMax < maxTxId) {\n-            return DLUtils.serializeTransactionId(maxTxId);\n-        } else {\n-            return null;\n-        }\n-    }\n-\n-    /**\n-     * Store the highest TxID encountered so far so that we\n-     * can enforce the monotonically non-decreasing property\n-     * This is best effort as this enforcement is only done\n-     *\n-     * @param maxTxId - the maximum transaction id seen so far\n-     * @throws IOException\n-     */\n-    synchronized void store(long maxTxId) throws IOException {\n-        if (enabled && currentMax < maxTxId) {\n-            if (LOG.isTraceEnabled()) {\n-                LOG.trace(\"Setting maxTxId to \" + maxTxId);\n-            }\n-            String txidStr = Long.toString(maxTxId);\n-            try {\n-                zkc.get().setData(path, txidStr.getBytes(\"UTF-8\"), -1);\n-                currentMax = maxTxId;\n-            } catch (Exception e) {\n-                LOG.error(\"Error writing new MaxTxId value {}\", maxTxId, e);\n-            }\n-        }\n-    }\n-\n     synchronized long get() {\n         return currentMax;\n     }\n \n+    public Versioned<Long> getVersionedData(long txId) {\n+        return new Versioned<Long>(Math.max(txId, currentMax), version);\n+    }\n+\n }"},{"sha":"1b831ea89d48ad4fb4b52649db5de37cb847845c","filename":"src/main/java/com/twitter/distributedlog/impl/ZKLogSegmentMetadataStore.java","status":"modified","additions":50,"deletions":13,"changes":63,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FZKLogSegmentMetadataStore.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -23,12 +23,16 @@\n import com.twitter.distributedlog.ZooKeeperClient;\n import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.exceptions.LogSegmentNotFoundException;\n import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadata;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n import com.twitter.distributedlog.util.DLUtils;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.OrderedScheduler;\n import com.twitter.distributedlog.util.Transaction;\n+import com.twitter.distributedlog.util.Transaction.OpListener;\n import com.twitter.distributedlog.zk.DefaultZKOp;\n import com.twitter.distributedlog.zk.ZKOp;\n import com.twitter.distributedlog.zk.ZKTransaction;\n@@ -48,10 +52,8 @@\n import org.apache.zookeeper.data.Stat;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import scala.runtime.AbstractFunction1;\n \n import java.io.IOException;\n-import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n@@ -220,30 +222,28 @@ protected void submitTask(Object key, Runnable r) {\n \n     @Override\n     public void storeMaxLogSegmentSequenceNumber(Transaction<Object> txn,\n-                                                 String path,\n+                                                 ZKLogMetadata logMetadata,\n                                                  Versioned<Long> lssn,\n                                                  Transaction.OpListener<Version> listener) {\n         Version version = lssn.getVersion();\n         assert(version instanceof ZkVersion);\n-\n         ZkVersion zkVersion = (ZkVersion) version;\n         byte[] data = DLUtils.serializeLogSegmentSequenceNumber(lssn.getValue());\n-        Op setDataOp = Op.setData(path, data, zkVersion.getZnodeVersion());\n+        Op setDataOp = Op.setData(logMetadata.getLogSegmentsPath(), data, zkVersion.getZnodeVersion());\n         ZKOp zkOp = new ZKVersionedSetOp(setDataOp, listener);\n         txn.addOp(zkOp);\n     }\n \n     @Override\n     public void storeMaxTxnId(Transaction<Object> txn,\n-                              String path,\n+                              ZKLogMetadataForWriter logMetadata,\n                               Versioned<Long> transactionId,\n                               Transaction.OpListener<Version> listener) {\n         Version version = transactionId.getVersion();\n         assert(version instanceof ZkVersion);\n-\n         ZkVersion zkVersion = (ZkVersion) version;\n         byte[] data = DLUtils.serializeTransactionId(transactionId.getValue());\n-        Op setDataOp = Op.setData(path, data, zkVersion.getZnodeVersion());\n+        Op setDataOp = Op.setData(logMetadata.getMaxTxIdPath(), data, zkVersion.getZnodeVersion());\n         ZKOp zkOp = new ZKVersionedSetOp(setDataOp, listener);\n         txn.addOp(zkOp);\n     }\n@@ -256,29 +256,66 @@ public Transaction<Object> transaction() {\n     }\n \n     @Override\n-    public void createLogSegment(Transaction<Object> txn, LogSegmentMetadata segment) {\n+    public void createLogSegment(Transaction<Object> txn,\n+                                 LogSegmentMetadata segment,\n+                                 OpListener<Void> listener) {\n         byte[] finalisedData = segment.getFinalisedData().getBytes(UTF_8);\n         Op createOp = Op.create(\n                 segment.getZkPath(),\n                 finalisedData,\n                 zkc.getDefaultACL(),\n                 CreateMode.PERSISTENT);\n-        txn.addOp(DefaultZKOp.of(createOp));\n+        txn.addOp(DefaultZKOp.of(createOp, listener));\n     }\n \n     @Override\n-    public void deleteLogSegment(Transaction<Object> txn, LogSegmentMetadata segment) {\n+    public void deleteLogSegment(Transaction<Object> txn,\n+                                 final LogSegmentMetadata segment,\n+                                 final OpListener<Void> listener) {\n         Op deleteOp = Op.delete(\n                 segment.getZkPath(),\n                 -1);\n-        txn.addOp(DefaultZKOp.of(deleteOp));\n+        logger.info(\"Delete segment : {}\", segment);\n+        txn.addOp(DefaultZKOp.of(deleteOp, new OpListener<Void>() {\n+            @Override\n+            public void onCommit(Void r) {\n+                if (null != listener) {\n+                    listener.onCommit(r);\n+                }\n+            }\n+\n+            @Override\n+            public void onAbort(Throwable t) {\n+                logger.info(\"Aborted transaction on deleting segment {}\", segment);\n+                KeeperException.Code kc;\n+                if (t instanceof KeeperException) {\n+                    kc = ((KeeperException) t).code();\n+                } else if (t instanceof ZKException) {\n+                    kc = ((ZKException) t).getKeeperExceptionCode();\n+                } else {\n+                    abortListener(t);\n+                    return;\n+                }\n+                if (KeeperException.Code.NONODE == kc) {\n+                    abortListener(new LogSegmentNotFoundException(segment.getZkPath()));\n+                    return;\n+                }\n+                abortListener(t);\n+            }\n+\n+            private void abortListener(Throwable t) {\n+                if (null != listener) {\n+                    listener.onAbort(t);\n+                }\n+            }\n+        }));\n     }\n \n     @Override\n     public void updateLogSegment(Transaction<Object> txn, LogSegmentMetadata segment) {\n         byte[] finalisedData = segment.getFinalisedData().getBytes(UTF_8);\n         Op updateOp = Op.setData(segment.getZkPath(), finalisedData, -1);\n-        txn.addOp(DefaultZKOp.of(updateOp));\n+        txn.addOp(DefaultZKOp.of(updateOp, null));\n     }\n \n     // reads"},{"sha":"37beb16c5dc78d3a607362bf286d22c8cf9f6081","filename":"src/main/java/com/twitter/distributedlog/impl/metadata/ZKLogMetadata.java","status":"modified","additions":17,"deletions":6,"changes":23,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadata.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadata.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadata.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -28,6 +28,17 @@ protected static String getLogComponentPath(URI uri, String logName, String logI\n         return String.format(\"%s/%s/%s%s\", uri.getPath(), logName, logIdentifier, component);\n     }\n \n+    /**\n+     * Get the top stream path for a given log.\n+     *\n+     * @param uri namespace to store the log\n+     * @param logName name of the log\n+     * @return top stream path\n+     */\n+    public static String getLogStreamPath(URI uri, String logName) {\n+        return String.format(\"%s/%s\", uri.getPath(), logName);\n+    }\n+\n     /**\n      * Get the log root path for a given log.\n      *\n@@ -59,14 +70,14 @@ public static String getLogSegmentsPath(URI uri, String logName, String logIdent\n     }\n \n     protected static final int LAYOUT_VERSION = -1;\n-    protected final static String LOGSEGMENTS_PATH = \"/ledgers\";\n-    protected final static String VERSION_PATH = \"/version\";\n+    public final static String LOGSEGMENTS_PATH = \"/ledgers\";\n+    public final static String VERSION_PATH = \"/version\";\n     // writer znodes\n-    protected final static String MAX_TXID_PATH = \"/maxtxid\";\n-    protected final static String LOCK_PATH = \"/lock\";\n-    protected final static String ALLOCATION_PATH = \"/allocation\";\n+    public final static String MAX_TXID_PATH = \"/maxtxid\";\n+    public final static String LOCK_PATH = \"/lock\";\n+    public final static String ALLOCATION_PATH = \"/allocation\";\n     // reader znodes\n-    protected final static String READ_LOCK_PATH = \"/readLock\";\n+    public final static String READ_LOCK_PATH = \"/readLock\";\n \n     protected final URI uri;\n     protected final String logName;"},{"sha":"9a1548cf6f0cbb4b8b4ca29778f7b73befd9df77","filename":"src/main/java/com/twitter/distributedlog/impl/metadata/ZKLogMetadataForWriter.java","status":"modified","additions":6,"deletions":303,"changes":309,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogMetadataForWriter.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -17,312 +17,15 @@\n  */\n package com.twitter.distributedlog.impl.metadata;\n \n-import com.google.common.base.Preconditions;\n-import com.google.common.collect.Lists;\n-import com.twitter.distributedlog.DistributedLogConstants;\n-import com.twitter.distributedlog.exceptions.LogNotFoundException;\n-import com.twitter.distributedlog.exceptions.DLException;\n-import com.twitter.distributedlog.exceptions.InvalidStreamNameException;\n-import com.twitter.distributedlog.exceptions.LogExistsException;\n-import com.twitter.distributedlog.exceptions.UnexpectedException;\n-import com.twitter.distributedlog.exceptions.ZKException;\n-import com.twitter.distributedlog.util.DLUtils;\n-import com.twitter.distributedlog.util.Utils;\n-import com.twitter.util.ExceptionalFunction;\n-import com.twitter.util.Future;\n-import com.twitter.util.Promise;\n-import org.apache.bookkeeper.meta.ZkVersion;\n import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.zookeeper.AsyncCallback;\n-import org.apache.zookeeper.CreateMode;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.Op;\n-import org.apache.zookeeper.OpResult;\n-import org.apache.zookeeper.ZooKeeper;\n-import org.apache.zookeeper.common.PathUtils;\n-import org.apache.zookeeper.data.ACL;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import scala.runtime.AbstractFunction1;\n \n-import java.io.File;\n import java.net.URI;\n-import java.util.List;\n \n /**\n  * Log Metadata for writer\n  */\n public class ZKLogMetadataForWriter extends ZKLogMetadata {\n \n-    static final Logger LOG = LoggerFactory.getLogger(ZKLogMetadataForWriter.class);\n-\n-    static class MetadataIndex {\n-        static final int LOG_ROOT_PARENT = 0;\n-        static final int LOG_ROOT = 1;\n-        static final int MAX_TXID = 2;\n-        static final int VERSION = 3;\n-        static final int LOCK = 4;\n-        static final int READ_LOCK = 5;\n-        static final int LOGSEGMENTS = 6;\n-        static final int ALLOCATION = 7;\n-    }\n-\n-    static int bytesToInt(byte[] b) {\n-        assert b.length >= 4;\n-        return b[0] << 24 | b[1] << 16 | b[2] << 8 | b[3];\n-    }\n-\n-    static byte[] intToBytes(int i) {\n-        return new byte[]{\n-            (byte) (i >> 24),\n-            (byte) (i >> 16),\n-            (byte) (i >> 8),\n-            (byte) (i)};\n-    }\n-\n-    static boolean pathExists(Versioned<byte[]> metadata) {\n-        return null != metadata.getValue() && null != metadata.getVersion();\n-    }\n-\n-    static void ensureMetadataExist(Versioned<byte[]> metadata) {\n-        Preconditions.checkNotNull(metadata.getValue());\n-        Preconditions.checkNotNull(metadata.getVersion());\n-    }\n-\n-    public static Future<ZKLogMetadataForWriter> of(\n-            final URI uri,\n-            final String logName,\n-            final String logIdentifier,\n-            final ZooKeeper zk,\n-            final List<ACL> acl,\n-            final boolean ownAllocator,\n-            final boolean createIfNotExists) {\n-        final String logRootPath = ZKLogMetadata.getLogRootPath(uri, logName, logIdentifier);\n-        try {\n-            PathUtils.validatePath(logRootPath);\n-        } catch (IllegalArgumentException e) {\n-            LOG.error(\"Illegal path value {} for stream {}\", new Object[]{logRootPath, logName, e});\n-            return Future.exception(new InvalidStreamNameException(logName, \"Log name is invalid\"));\n-        }\n-\n-        return checkLogMetadataPaths(zk, logRootPath, ownAllocator)\n-                .flatMap(new AbstractFunction1<List<Versioned<byte[]>>, Future<List<Versioned<byte[]>>>>() {\n-                    @Override\n-                    public Future<List<Versioned<byte[]>>> apply(List<Versioned<byte[]>> metadatas) {\n-                        Promise<List<Versioned<byte[]>>> promise =\n-                                new Promise<List<Versioned<byte[]>>>();\n-                        createMissingMetadata(zk, logRootPath, metadatas, acl,\n-                                ownAllocator, createIfNotExists, promise);\n-                        return promise;\n-                    }\n-                }).map(new ExceptionalFunction<List<Versioned<byte[]>>, ZKLogMetadataForWriter>() {\n-                    @Override\n-                    public ZKLogMetadataForWriter applyE(List<Versioned<byte[]>> metadatas) throws DLException {\n-                        return processLogMetadatas(uri, logName, logIdentifier, metadatas, ownAllocator);\n-                    }\n-                });\n-    }\n-\n-    static Future<List<Versioned<byte[]>>> checkLogMetadataPaths(ZooKeeper zk,\n-                                                                 String logRootPath,\n-                                                                 boolean ownAllocator) {\n-        // Note re. persistent lock state initialization: the read lock persistent state (path) is\n-        // initialized here but only used in the read handler. The reason is its more convenient and\n-        // less error prone to manage all stream structure in one place.\n-        final String logRootParentPath = new File(logRootPath).getParent();\n-        final String logSegmentsPath = logRootPath + LOGSEGMENTS_PATH;\n-        final String maxTxIdPath = logRootPath + MAX_TXID_PATH;\n-        final String lockPath = logRootPath + LOCK_PATH;\n-        final String readLockPath = logRootPath + READ_LOCK_PATH;\n-        final String versionPath = logRootPath + VERSION_PATH;\n-        final String allocationPath = logRootPath + ALLOCATION_PATH;\n-\n-        int numPaths = ownAllocator ? MetadataIndex.ALLOCATION + 1 : MetadataIndex.LOGSEGMENTS + 1;\n-        List<Future<Versioned<byte[]>>> checkFutures = Lists.newArrayListWithExpectedSize(numPaths);\n-        checkFutures.add(Utils.zkGetData(zk, logRootParentPath, false));\n-        checkFutures.add(Utils.zkGetData(zk, logRootPath, false));\n-        checkFutures.add(Utils.zkGetData(zk, maxTxIdPath, false));\n-        checkFutures.add(Utils.zkGetData(zk, versionPath, false));\n-        checkFutures.add(Utils.zkGetData(zk, lockPath, false));\n-        checkFutures.add(Utils.zkGetData(zk, readLockPath, false));\n-        checkFutures.add(Utils.zkGetData(zk, logSegmentsPath, false));\n-        if (ownAllocator) {\n-            checkFutures.add(Utils.zkGetData(zk, allocationPath, false));\n-        }\n-\n-        return Future.collect(checkFutures);\n-    }\n-\n-    static void createMissingMetadata(final ZooKeeper zk,\n-                                      final String logRootPath,\n-                                      final List<Versioned<byte[]>> metadatas,\n-                                      final List<ACL> acl,\n-                                      final boolean ownAllocator,\n-                                      final boolean createIfNotExists,\n-                                      final Promise<List<Versioned<byte[]>>> promise) {\n-        final List<byte[]> pathsToCreate = Lists.newArrayListWithExpectedSize(metadatas.size());\n-        final List<Op> zkOps = Lists.newArrayListWithExpectedSize(metadatas.size());\n-        CreateMode createMode = CreateMode.PERSISTENT;\n-\n-        // log root parent path\n-        if (pathExists(metadatas.get(MetadataIndex.LOG_ROOT_PARENT))) {\n-            pathsToCreate.add(null);\n-        } else {\n-            String logRootParentPath = new File(logRootPath).getParent();\n-            pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n-            zkOps.add(Op.create(logRootParentPath, DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n-        }\n-\n-        // log root path\n-        if (pathExists(metadatas.get(MetadataIndex.LOG_ROOT))) {\n-            pathsToCreate.add(null);\n-        } else {\n-            pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n-            zkOps.add(Op.create(logRootPath, DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n-        }\n-\n-        // max id\n-        if (pathExists(metadatas.get(MetadataIndex.MAX_TXID))) {\n-            pathsToCreate.add(null);\n-        } else {\n-            byte[] zeroTxnIdData = DLUtils.serializeTransactionId(0L);\n-            pathsToCreate.add(zeroTxnIdData);\n-            zkOps.add(Op.create(logRootPath + MAX_TXID_PATH, zeroTxnIdData, acl, createMode));\n-        }\n-        // version\n-        if (pathExists(metadatas.get(MetadataIndex.VERSION))) {\n-            pathsToCreate.add(null);\n-        } else {\n-            byte[] versionData = intToBytes(LAYOUT_VERSION);\n-            pathsToCreate.add(versionData);\n-            zkOps.add(Op.create(logRootPath + VERSION_PATH, versionData, acl, createMode));\n-        }\n-        // lock path\n-        if (pathExists(metadatas.get(MetadataIndex.LOCK))) {\n-            pathsToCreate.add(null);\n-        } else {\n-            pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n-            zkOps.add(Op.create(logRootPath + LOCK_PATH, DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n-        }\n-        // read lock path\n-        if (pathExists(metadatas.get(MetadataIndex.READ_LOCK))) {\n-            pathsToCreate.add(null);\n-        } else {\n-            pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n-            zkOps.add(Op.create(logRootPath + READ_LOCK_PATH, DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n-        }\n-        // log segments path\n-        if (pathExists(metadatas.get(MetadataIndex.LOGSEGMENTS))) {\n-            pathsToCreate.add(null);\n-        } else {\n-            byte[] logSegmentsData = DLUtils.serializeLogSegmentSequenceNumber(\n-                    DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO);\n-            pathsToCreate.add(logSegmentsData);\n-            zkOps.add(Op.create(logRootPath + LOGSEGMENTS_PATH, logSegmentsData, acl, createMode));\n-        }\n-        // allocation path\n-        if (ownAllocator) {\n-            if (pathExists(metadatas.get(MetadataIndex.ALLOCATION))) {\n-                pathsToCreate.add(null);\n-            } else {\n-                pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n-                zkOps.add(Op.create(logRootPath + ALLOCATION_PATH,\n-                        DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n-            }\n-        }\n-        if (zkOps.isEmpty()) {\n-            // nothing missed\n-            promise.setValue(metadatas);\n-            return;\n-        }\n-        if (!createIfNotExists) {\n-            promise.setException(new LogNotFoundException(\"Log \" + logRootPath + \" not found\"));\n-            return;\n-        }\n-\n-        zk.multi(zkOps, new AsyncCallback.MultiCallback() {\n-            @Override\n-            public void processResult(int rc, String path, Object ctx, List<OpResult> resultList) {\n-                if (KeeperException.Code.OK.intValue() == rc) {\n-                    List<Versioned<byte[]>> finalMetadatas =\n-                            Lists.newArrayListWithExpectedSize(metadatas.size());\n-                    for (int i = 0; i < pathsToCreate.size(); i++) {\n-                        byte[] dataCreated = pathsToCreate.get(i);\n-                        if (null == dataCreated) {\n-                            finalMetadatas.add(metadatas.get(i));\n-                        } else {\n-                            finalMetadatas.add(new Versioned<byte[]>(dataCreated, new ZkVersion(0)));\n-                        }\n-                    }\n-                    promise.setValue(finalMetadatas);\n-                } else if (KeeperException.Code.NODEEXISTS.intValue() == rc) {\n-                    promise.setException(new LogExistsException(\"Someone just created log \"\n-                            + logRootPath));\n-                } else {\n-                    if (LOG.isDebugEnabled()) {\n-                        StringBuilder builder = new StringBuilder();\n-                        for (OpResult result : resultList) {\n-                            if (result instanceof OpResult.ErrorResult) {\n-                                OpResult.ErrorResult errorResult = (OpResult.ErrorResult) result;\n-                                builder.append(errorResult.getErr()).append(\",\");\n-                            } else {\n-                                builder.append(0).append(\",\");\n-                            }\n-                        }\n-                        String resultCodeList = builder.substring(0, builder.length() - 1);\n-                        LOG.debug(\"Failed to create log, full rc list = {}\", resultCodeList);\n-                    }\n-\n-                    promise.setException(new ZKException(\"Failed to create log \" + logRootPath,\n-                            KeeperException.Code.get(rc)));\n-                }\n-            }\n-        }, null);\n-    }\n-\n-    static ZKLogMetadataForWriter processLogMetadatas(URI uri,\n-                                                      String logName,\n-                                                      String logIdentifier,\n-                                                      List<Versioned<byte[]>> metadatas,\n-                                                      boolean ownAllocator)\n-            throws UnexpectedException {\n-        try {\n-            // max id\n-            Versioned<byte[]> maxTxnIdData = metadatas.get(MetadataIndex.MAX_TXID);\n-            ensureMetadataExist(maxTxnIdData);\n-            // version\n-            Versioned<byte[]> versionData = metadatas.get(MetadataIndex.VERSION);\n-            ensureMetadataExist(maxTxnIdData);\n-            Preconditions.checkArgument(LAYOUT_VERSION == bytesToInt(versionData.getValue()));\n-            // lock path\n-            ensureMetadataExist(metadatas.get(MetadataIndex.LOCK));\n-            // read lock path\n-            ensureMetadataExist(metadatas.get(MetadataIndex.READ_LOCK));\n-            // max lssn\n-            Versioned<byte[]> maxLSSNData = metadatas.get(MetadataIndex.LOGSEGMENTS);\n-            ensureMetadataExist(maxLSSNData);\n-            try {\n-                DLUtils.deserializeLogSegmentSequenceNumber(maxLSSNData.getValue());\n-            } catch (NumberFormatException nfe) {\n-                throw new UnexpectedException(\"Invalid max sequence number found in log \" + logName, nfe);\n-            }\n-            // allocation path\n-            Versioned<byte[]>  allocationData;\n-            if (ownAllocator) {\n-                allocationData = metadatas.get(MetadataIndex.ALLOCATION);\n-                ensureMetadataExist(allocationData);\n-            } else {\n-                allocationData = new Versioned<byte[]>(null, null);\n-            }\n-            return new ZKLogMetadataForWriter(uri, logName, logIdentifier,\n-                    maxLSSNData, maxTxnIdData, allocationData);\n-        } catch (IllegalArgumentException iae) {\n-            throw new UnexpectedException(\"Invalid log \" + logName, iae);\n-        } catch (NullPointerException npe) {\n-            throw new UnexpectedException(\"Invalid log \" + logName, npe);\n-        }\n-    }\n-\n     private final Versioned<byte[]> maxLSSNData;\n     private final Versioned<byte[]> maxTxIdData;\n     private final Versioned<byte[]> allocationData;\n@@ -334,12 +37,12 @@ static ZKLogMetadataForWriter processLogMetadatas(URI uri,\n      * @param logName       name of the log\n      * @param logIdentifier identifier of the log\n      */\n-    private ZKLogMetadataForWriter(URI uri,\n-                                   String logName,\n-                                   String logIdentifier,\n-                                   Versioned<byte[]> maxLSSNData,\n-                                   Versioned<byte[]> maxTxIdData,\n-                                   Versioned<byte[]> allocationData) {\n+    public ZKLogMetadataForWriter(URI uri,\n+                                  String logName,\n+                                  String logIdentifier,\n+                                  Versioned<byte[]> maxLSSNData,\n+                                  Versioned<byte[]> maxTxIdData,\n+                                  Versioned<byte[]> allocationData) {\n         super(uri, logName, logIdentifier);\n         this.maxLSSNData = maxLSSNData;\n         this.maxTxIdData = maxTxIdData;"},{"sha":"d89dddb7a586ebc912e7b5e10547b9c874021c4b","filename":"src/main/java/com/twitter/distributedlog/impl/metadata/ZKLogStreamMetadataStore.java","status":"added","additions":630,"deletions":0,"changes":630,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogStreamMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogStreamMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FZKLogStreamMetadataStore.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -0,0 +1,630 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.impl.metadata;\n+\n+import com.google.common.base.Optional;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.twitter.distributedlog.DistributedLogConfiguration;\n+import com.twitter.distributedlog.DistributedLogConstants;\n+import com.twitter.distributedlog.ZooKeeperClient;\n+import com.twitter.distributedlog.exceptions.DLException;\n+import com.twitter.distributedlog.exceptions.DLInterruptedException;\n+import com.twitter.distributedlog.exceptions.InvalidStreamNameException;\n+import com.twitter.distributedlog.exceptions.LockCancelledException;\n+import com.twitter.distributedlog.exceptions.LogExistsException;\n+import com.twitter.distributedlog.exceptions.LogNotFoundException;\n+import com.twitter.distributedlog.exceptions.UnexpectedException;\n+import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.impl.ZKLogSegmentMetadataStore;\n+import com.twitter.distributedlog.lock.DistributedLock;\n+import com.twitter.distributedlog.lock.SessionLockFactory;\n+import com.twitter.distributedlog.lock.ZKDistributedLock;\n+import com.twitter.distributedlog.lock.ZKSessionLockFactory;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.metadata.LogStreamMetadataStore;\n+import com.twitter.distributedlog.util.DLUtils;\n+import com.twitter.distributedlog.util.FutureUtils;\n+import com.twitter.distributedlog.util.SchedulerUtils;\n+import com.twitter.distributedlog.zk.LimitedPermitManager;\n+import com.twitter.distributedlog.util.OrderedScheduler;\n+import com.twitter.distributedlog.util.PermitManager;\n+import com.twitter.distributedlog.util.Transaction;\n+import com.twitter.distributedlog.util.Utils;\n+import com.twitter.distributedlog.zk.ZKTransaction;\n+import com.twitter.util.ExceptionalFunction;\n+import com.twitter.util.ExceptionalFunction0;\n+import com.twitter.util.Future;\n+import com.twitter.util.Promise;\n+import org.apache.bookkeeper.meta.ZkVersion;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.versioning.Versioned;\n+import org.apache.zookeeper.AsyncCallback;\n+import org.apache.zookeeper.CreateMode;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.Op;\n+import org.apache.zookeeper.OpResult;\n+import org.apache.zookeeper.ZKUtil;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.apache.zookeeper.common.PathUtils;\n+import org.apache.zookeeper.data.ACL;\n+import org.apache.zookeeper.data.Stat;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.runtime.AbstractFunction1;\n+import scala.runtime.BoxedUnit;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.twitter.distributedlog.impl.metadata.ZKLogMetadata.*;\n+\n+/**\n+ * zookeeper based {@link LogStreamMetadataStore}\n+ */\n+public class ZKLogStreamMetadataStore implements LogStreamMetadataStore {\n+\n+    private final static Logger LOG = LoggerFactory.getLogger(ZKLogStreamMetadataStore.class);\n+\n+    private final String clientId;\n+    private final DistributedLogConfiguration conf;\n+    private final ZooKeeperClient zooKeeperClient;\n+    private final OrderedScheduler scheduler;\n+    private final StatsLogger statsLogger;\n+    private final LogSegmentMetadataStore logSegmentStore;\n+    private final LimitedPermitManager permitManager;\n+    // lock\n+    private SessionLockFactory lockFactory;\n+    private OrderedScheduler lockStateExecutor;\n+\n+    public ZKLogStreamMetadataStore(String clientId,\n+                                    DistributedLogConfiguration conf,\n+                                    ZooKeeperClient zkc,\n+                                    OrderedScheduler scheduler,\n+                                    StatsLogger statsLogger) {\n+        this.clientId = clientId;\n+        this.conf = conf;\n+        this.zooKeeperClient = zkc;\n+        this.scheduler = scheduler;\n+        this.statsLogger = statsLogger;\n+        // create the log segment metadata store and the permit manager (used for log segment rolling)\n+        this.logSegmentStore = new ZKLogSegmentMetadataStore(conf, zooKeeperClient, scheduler);\n+        this.permitManager = new LimitedPermitManager(\n+                conf.getLogSegmentRollingConcurrency(),\n+                1,\n+                TimeUnit.MINUTES,\n+                scheduler);\n+        this.zooKeeperClient.register(permitManager);\n+    }\n+\n+    private synchronized OrderedScheduler getLockStateExecutor(boolean createIfNull) {\n+        if (createIfNull && null == lockStateExecutor) {\n+            StatsLogger lockStateStatsLogger = statsLogger.scope(\"lock_scheduler\");\n+            lockStateExecutor = OrderedScheduler.newBuilder()\n+                    .name(\"DLM-LockState\")\n+                    .corePoolSize(conf.getNumLockStateThreads())\n+                    .statsLogger(lockStateStatsLogger)\n+                    .perExecutorStatsLogger(lockStateStatsLogger)\n+                    .traceTaskExecution(conf.getEnableTaskExecutionStats())\n+                    .traceTaskExecutionWarnTimeUs(conf.getTaskExecutionWarnTimeMicros())\n+                    .build();\n+        }\n+        return lockStateExecutor;\n+    }\n+\n+    private synchronized SessionLockFactory getLockFactory(boolean createIfNull) {\n+        if (createIfNull && null == lockFactory) {\n+            lockFactory = new ZKSessionLockFactory(\n+                    zooKeeperClient,\n+                    clientId,\n+                    getLockStateExecutor(createIfNull),\n+                    conf.getZKNumRetries(),\n+                    conf.getLockTimeoutMilliSeconds(),\n+                    conf.getZKRetryBackoffStartMillis(),\n+                    statsLogger);\n+        }\n+        return lockFactory;\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        this.zooKeeperClient.unregister(permitManager);\n+        this.permitManager.close();\n+        this.logSegmentStore.close();\n+        SchedulerUtils.shutdownScheduler(\n+                getLockStateExecutor(false),\n+                conf.getSchedulerShutdownTimeoutMs(),\n+                TimeUnit.MILLISECONDS);\n+    }\n+\n+    @Override\n+    public LogSegmentMetadataStore getLogSegmentMetadataStore() {\n+        return logSegmentStore;\n+    }\n+\n+    @Override\n+    public PermitManager getPermitManager() {\n+        return this.permitManager;\n+    }\n+\n+    @Override\n+    public Transaction<Object> newTransaction() {\n+        return new ZKTransaction(zooKeeperClient);\n+    }\n+\n+    @Override\n+    public Future<Void> logExists(URI uri, final String logName) {\n+        final String logSegmentsPath = ZKLogMetadata.getLogSegmentsPath(\n+                uri, logName, conf.getUnpartitionedStreamName());\n+        final Promise<Void> promise = new Promise<Void>();\n+        try {\n+            final ZooKeeper zk = zooKeeperClient.get();\n+            zk.sync(logSegmentsPath, new AsyncCallback.VoidCallback() {\n+                @Override\n+                public void processResult(int syncRc, String path, Object syncCtx) {\n+                    if (KeeperException.Code.NONODE.intValue() == syncRc) {\n+                        promise.setException(new LogNotFoundException(\n+                                String.format(\"Log %s does not exist or has been deleted\", logName)));\n+                        return;\n+                    } else if (KeeperException.Code.OK.intValue() != syncRc){\n+                        promise.setException(new ZKException(\"Error on checking log existence for \" + logName,\n+                                KeeperException.create(KeeperException.Code.get(syncRc))));\n+                        return;\n+                    }\n+                    zk.exists(logSegmentsPath, false, new AsyncCallback.StatCallback() {\n+                        @Override\n+                        public void processResult(int rc, String path, Object ctx, Stat stat) {\n+                            if (KeeperException.Code.OK.intValue() == rc) {\n+                                promise.setValue(null);\n+                            } else if (KeeperException.Code.NONODE.intValue() == rc) {\n+                                promise.setException(new LogNotFoundException(\n+                                        String.format(\"Log %s does not exist or has been deleted\", logName)));\n+                            } else {\n+                                promise.setException(new ZKException(\"Error on checking log existence for \" + logName,\n+                                        KeeperException.create(KeeperException.Code.get(rc))));\n+                            }\n+                        }\n+                    }, null);\n+                }\n+            }, null);\n+\n+        } catch (InterruptedException ie) {\n+            LOG.error(\"Interrupted while reading {}\", logSegmentsPath, ie);\n+            promise.setException(new DLInterruptedException(\"Interrupted while checking \"\n+                    + logSegmentsPath, ie));\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            promise.setException(e);\n+        }\n+        return promise;\n+    }\n+\n+    //\n+    // Create Write Lock\n+    //\n+\n+    @Override\n+    public DistributedLock createWriteLock(ZKLogMetadataForWriter metadata) {\n+        return new ZKDistributedLock(\n+                getLockStateExecutor(true),\n+                getLockFactory(true),\n+                metadata.getLockPath(),\n+                conf.getLockTimeoutMilliSeconds(),\n+                statsLogger);\n+    }\n+\n+    //\n+    // Create Read Lock\n+    //\n+\n+    private Future<Void> ensureReadLockPathExist(final ZKLogMetadata logMetadata,\n+                                                 final String readLockPath) {\n+        final Promise<Void> promise = new Promise<Void>();\n+        promise.setInterruptHandler(new com.twitter.util.Function<Throwable, BoxedUnit>() {\n+            @Override\n+            public BoxedUnit apply(Throwable t) {\n+                FutureUtils.setException(promise, new LockCancelledException(readLockPath,\n+                        \"Could not ensure read lock path\", t));\n+                return null;\n+            }\n+        });\n+        Optional<String> parentPathShouldNotCreate = Optional.of(logMetadata.getLogRootPath());\n+        Utils.zkAsyncCreateFullPathOptimisticRecursive(zooKeeperClient, readLockPath, parentPathShouldNotCreate,\n+                new byte[0], zooKeeperClient.getDefaultACL(), CreateMode.PERSISTENT,\n+                new org.apache.zookeeper.AsyncCallback.StringCallback() {\n+                    @Override\n+                    public void processResult(final int rc, final String path, Object ctx, String name) {\n+                        if (KeeperException.Code.NONODE.intValue() == rc) {\n+                            FutureUtils.setException(promise, new LogNotFoundException(\n+                                    String.format(\"Log %s does not exist or has been deleted\",\n+                                            logMetadata.getFullyQualifiedName())));\n+                        } else if (KeeperException.Code.OK.intValue() == rc) {\n+                            FutureUtils.setValue(promise, null);\n+                            LOG.trace(\"Created path {}.\", path);\n+                        } else if (KeeperException.Code.NODEEXISTS.intValue() == rc) {\n+                            FutureUtils.setValue(promise, null);\n+                            LOG.trace(\"Path {} is already existed.\", path);\n+                        } else if (DistributedLogConstants.ZK_CONNECTION_EXCEPTION_RESULT_CODE == rc) {\n+                            FutureUtils.setException(promise, new ZooKeeperClient.ZooKeeperConnectionException(path));\n+                        } else if (DistributedLogConstants.DL_INTERRUPTED_EXCEPTION_RESULT_CODE == rc) {\n+                            FutureUtils.setException(promise, new DLInterruptedException(path));\n+                        } else {\n+                            FutureUtils.setException(promise, KeeperException.create(KeeperException.Code.get(rc)));\n+                        }\n+                    }\n+                }, null);\n+        return promise;\n+    }\n+\n+    @Override\n+    public Future<DistributedLock> createReadLock(final ZKLogMetadataForReader metadata,\n+                                                  Optional<String> readerId) {\n+        final String readLockPath = metadata.getReadLockPath(readerId);\n+        return ensureReadLockPathExist(metadata, readLockPath).flatMap(\n+                new ExceptionalFunction<Void, Future<DistributedLock>>() {\n+            @Override\n+            public Future<DistributedLock> applyE(Void value) throws Throwable {\n+                // Unfortunately this has a blocking call which we should not execute on the\n+                // ZK completion thread\n+                return scheduler.apply(new ExceptionalFunction0<DistributedLock>() {\n+                    @Override\n+                    public DistributedLock applyE() throws Throwable {\n+                        return new ZKDistributedLock(\n+                            getLockStateExecutor(true),\n+                            getLockFactory(true),\n+                            readLockPath,\n+                            conf.getLockTimeoutMilliSeconds(),\n+                            statsLogger.scope(\"read_lock\"));\n+                    }\n+                });\n+            }\n+        });\n+    }\n+\n+    //\n+    // Create Log\n+    //\n+\n+    static class MetadataIndex {\n+        static final int LOG_ROOT_PARENT = 0;\n+        static final int LOG_ROOT = 1;\n+        static final int MAX_TXID = 2;\n+        static final int VERSION = 3;\n+        static final int LOCK = 4;\n+        static final int READ_LOCK = 5;\n+        static final int LOGSEGMENTS = 6;\n+        static final int ALLOCATION = 7;\n+    }\n+\n+    static int bytesToInt(byte[] b) {\n+        assert b.length >= 4;\n+        return b[0] << 24 | b[1] << 16 | b[2] << 8 | b[3];\n+    }\n+\n+    static byte[] intToBytes(int i) {\n+        return new byte[]{\n+            (byte) (i >> 24),\n+            (byte) (i >> 16),\n+            (byte) (i >> 8),\n+            (byte) (i)};\n+    }\n+\n+    static Future<List<Versioned<byte[]>>> checkLogMetadataPaths(ZooKeeper zk,\n+                                                                 String logRootPath,\n+                                                                 boolean ownAllocator) {\n+        // Note re. persistent lock state initialization: the read lock persistent state (path) is\n+        // initialized here but only used in the read handler. The reason is its more convenient and\n+        // less error prone to manage all stream structure in one place.\n+        final String logRootParentPath = new File(logRootPath).getParent();\n+        final String logSegmentsPath = logRootPath + LOGSEGMENTS_PATH;\n+        final String maxTxIdPath = logRootPath + MAX_TXID_PATH;\n+        final String lockPath = logRootPath + LOCK_PATH;\n+        final String readLockPath = logRootPath + READ_LOCK_PATH;\n+        final String versionPath = logRootPath + VERSION_PATH;\n+        final String allocationPath = logRootPath + ALLOCATION_PATH;\n+\n+        int numPaths = ownAllocator ? MetadataIndex.ALLOCATION + 1 : MetadataIndex.LOGSEGMENTS + 1;\n+        List<Future<Versioned<byte[]>>> checkFutures = Lists.newArrayListWithExpectedSize(numPaths);\n+        checkFutures.add(Utils.zkGetData(zk, logRootParentPath, false));\n+        checkFutures.add(Utils.zkGetData(zk, logRootPath, false));\n+        checkFutures.add(Utils.zkGetData(zk, maxTxIdPath, false));\n+        checkFutures.add(Utils.zkGetData(zk, versionPath, false));\n+        checkFutures.add(Utils.zkGetData(zk, lockPath, false));\n+        checkFutures.add(Utils.zkGetData(zk, readLockPath, false));\n+        checkFutures.add(Utils.zkGetData(zk, logSegmentsPath, false));\n+        if (ownAllocator) {\n+            checkFutures.add(Utils.zkGetData(zk, allocationPath, false));\n+        }\n+\n+        return Future.collect(checkFutures);\n+    }\n+\n+    static boolean pathExists(Versioned<byte[]> metadata) {\n+        return null != metadata.getValue() && null != metadata.getVersion();\n+    }\n+\n+    static void ensureMetadataExist(Versioned<byte[]> metadata) {\n+        Preconditions.checkNotNull(metadata.getValue());\n+        Preconditions.checkNotNull(metadata.getVersion());\n+    }\n+\n+    static void createMissingMetadata(final ZooKeeper zk,\n+                                      final String logRootPath,\n+                                      final List<Versioned<byte[]>> metadatas,\n+                                      final List<ACL> acl,\n+                                      final boolean ownAllocator,\n+                                      final boolean createIfNotExists,\n+                                      final Promise<List<Versioned<byte[]>>> promise) {\n+        final List<byte[]> pathsToCreate = Lists.newArrayListWithExpectedSize(metadatas.size());\n+        final List<Op> zkOps = Lists.newArrayListWithExpectedSize(metadatas.size());\n+        CreateMode createMode = CreateMode.PERSISTENT;\n+\n+        // log root parent path\n+        if (pathExists(metadatas.get(MetadataIndex.LOG_ROOT_PARENT))) {\n+            pathsToCreate.add(null);\n+        } else {\n+            String logRootParentPath = new File(logRootPath).getParent();\n+            pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n+            zkOps.add(Op.create(logRootParentPath, DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n+        }\n+\n+        // log root path\n+        if (pathExists(metadatas.get(MetadataIndex.LOG_ROOT))) {\n+            pathsToCreate.add(null);\n+        } else {\n+            pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n+            zkOps.add(Op.create(logRootPath, DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n+        }\n+\n+        // max id\n+        if (pathExists(metadatas.get(MetadataIndex.MAX_TXID))) {\n+            pathsToCreate.add(null);\n+        } else {\n+            byte[] zeroTxnIdData = DLUtils.serializeTransactionId(0L);\n+            pathsToCreate.add(zeroTxnIdData);\n+            zkOps.add(Op.create(logRootPath + MAX_TXID_PATH, zeroTxnIdData, acl, createMode));\n+        }\n+        // version\n+        if (pathExists(metadatas.get(MetadataIndex.VERSION))) {\n+            pathsToCreate.add(null);\n+        } else {\n+            byte[] versionData = intToBytes(LAYOUT_VERSION);\n+            pathsToCreate.add(versionData);\n+            zkOps.add(Op.create(logRootPath + VERSION_PATH, versionData, acl, createMode));\n+        }\n+        // lock path\n+        if (pathExists(metadatas.get(MetadataIndex.LOCK))) {\n+            pathsToCreate.add(null);\n+        } else {\n+            pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n+            zkOps.add(Op.create(logRootPath + LOCK_PATH, DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n+        }\n+        // read lock path\n+        if (pathExists(metadatas.get(MetadataIndex.READ_LOCK))) {\n+            pathsToCreate.add(null);\n+        } else {\n+            pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n+            zkOps.add(Op.create(logRootPath + READ_LOCK_PATH, DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n+        }\n+        // log segments path\n+        if (pathExists(metadatas.get(MetadataIndex.LOGSEGMENTS))) {\n+            pathsToCreate.add(null);\n+        } else {\n+            byte[] logSegmentsData = DLUtils.serializeLogSegmentSequenceNumber(\n+                    DistributedLogConstants.UNASSIGNED_LOGSEGMENT_SEQNO);\n+            pathsToCreate.add(logSegmentsData);\n+            zkOps.add(Op.create(logRootPath + LOGSEGMENTS_PATH, logSegmentsData, acl, createMode));\n+        }\n+        // allocation path\n+        if (ownAllocator) {\n+            if (pathExists(metadatas.get(MetadataIndex.ALLOCATION))) {\n+                pathsToCreate.add(null);\n+            } else {\n+                pathsToCreate.add(DistributedLogConstants.EMPTY_BYTES);\n+                zkOps.add(Op.create(logRootPath + ALLOCATION_PATH,\n+                        DistributedLogConstants.EMPTY_BYTES, acl, createMode));\n+            }\n+        }\n+        if (zkOps.isEmpty()) {\n+            // nothing missed\n+            promise.setValue(metadatas);\n+            return;\n+        }\n+        if (!createIfNotExists) {\n+            promise.setException(new LogNotFoundException(\"Log \" + logRootPath + \" not found\"));\n+            return;\n+        }\n+\n+        zk.multi(zkOps, new AsyncCallback.MultiCallback() {\n+            @Override\n+            public void processResult(int rc, String path, Object ctx, List<OpResult> resultList) {\n+                if (KeeperException.Code.OK.intValue() == rc) {\n+                    List<Versioned<byte[]>> finalMetadatas =\n+                            Lists.newArrayListWithExpectedSize(metadatas.size());\n+                    for (int i = 0; i < pathsToCreate.size(); i++) {\n+                        byte[] dataCreated = pathsToCreate.get(i);\n+                        if (null == dataCreated) {\n+                            finalMetadatas.add(metadatas.get(i));\n+                        } else {\n+                            finalMetadatas.add(new Versioned<byte[]>(dataCreated, new ZkVersion(0)));\n+                        }\n+                    }\n+                    promise.setValue(finalMetadatas);\n+                } else if (KeeperException.Code.NODEEXISTS.intValue() == rc) {\n+                    promise.setException(new LogExistsException(\"Someone just created log \"\n+                            + logRootPath));\n+                } else {\n+                    if (LOG.isDebugEnabled()) {\n+                        StringBuilder builder = new StringBuilder();\n+                        for (OpResult result : resultList) {\n+                            if (result instanceof OpResult.ErrorResult) {\n+                                OpResult.ErrorResult errorResult = (OpResult.ErrorResult) result;\n+                                builder.append(errorResult.getErr()).append(\",\");\n+                            } else {\n+                                builder.append(0).append(\",\");\n+                            }\n+                        }\n+                        String resultCodeList = builder.substring(0, builder.length() - 1);\n+                        LOG.debug(\"Failed to create log, full rc list = {}\", resultCodeList);\n+                    }\n+\n+                    promise.setException(new ZKException(\"Failed to create log \" + logRootPath,\n+                            KeeperException.Code.get(rc)));\n+                }\n+            }\n+        }, null);\n+    }\n+\n+    static ZKLogMetadataForWriter processLogMetadatas(URI uri,\n+                                                      String logName,\n+                                                      String logIdentifier,\n+                                                      List<Versioned<byte[]>> metadatas,\n+                                                      boolean ownAllocator)\n+            throws UnexpectedException {\n+        try {\n+            // max id\n+            Versioned<byte[]> maxTxnIdData = metadatas.get(MetadataIndex.MAX_TXID);\n+            ensureMetadataExist(maxTxnIdData);\n+            // version\n+            Versioned<byte[]> versionData = metadatas.get(MetadataIndex.VERSION);\n+            ensureMetadataExist(maxTxnIdData);\n+            Preconditions.checkArgument(LAYOUT_VERSION == bytesToInt(versionData.getValue()));\n+            // lock path\n+            ensureMetadataExist(metadatas.get(MetadataIndex.LOCK));\n+            // read lock path\n+            ensureMetadataExist(metadatas.get(MetadataIndex.READ_LOCK));\n+            // max lssn\n+            Versioned<byte[]> maxLSSNData = metadatas.get(MetadataIndex.LOGSEGMENTS);\n+            ensureMetadataExist(maxLSSNData);\n+            try {\n+                DLUtils.deserializeLogSegmentSequenceNumber(maxLSSNData.getValue());\n+            } catch (NumberFormatException nfe) {\n+                throw new UnexpectedException(\"Invalid max sequence number found in log \" + logName, nfe);\n+            }\n+            // allocation path\n+            Versioned<byte[]>  allocationData;\n+            if (ownAllocator) {\n+                allocationData = metadatas.get(MetadataIndex.ALLOCATION);\n+                ensureMetadataExist(allocationData);\n+            } else {\n+                allocationData = new Versioned<byte[]>(null, null);\n+            }\n+            return new ZKLogMetadataForWriter(uri, logName, logIdentifier,\n+                    maxLSSNData, maxTxnIdData, allocationData);\n+        } catch (IllegalArgumentException iae) {\n+            throw new UnexpectedException(\"Invalid log \" + logName, iae);\n+        } catch (NullPointerException npe) {\n+            throw new UnexpectedException(\"Invalid log \" + logName, npe);\n+        }\n+    }\n+\n+    static Future<ZKLogMetadataForWriter> getLog(final URI uri,\n+                                                 final String logName,\n+                                                 final String logIdentifier,\n+                                                 final ZooKeeperClient zooKeeperClient,\n+                                                 final boolean ownAllocator,\n+                                                 final boolean createIfNotExists) {\n+        final String logRootPath = ZKLogMetadata.getLogRootPath(uri, logName, logIdentifier);\n+        try {\n+            PathUtils.validatePath(logRootPath);\n+        } catch (IllegalArgumentException e) {\n+            LOG.error(\"Illegal path value {} for stream {}\", new Object[]{logRootPath, logName, e});\n+            return Future.exception(new InvalidStreamNameException(logName, \"Log name is invalid\"));\n+        }\n+\n+        try {\n+            final ZooKeeper zk = zooKeeperClient.get();\n+            return checkLogMetadataPaths(zk, logRootPath, ownAllocator)\n+                    .flatMap(new AbstractFunction1<List<Versioned<byte[]>>, Future<List<Versioned<byte[]>>>>() {\n+                        @Override\n+                        public Future<List<Versioned<byte[]>>> apply(List<Versioned<byte[]>> metadatas) {\n+                            Promise<List<Versioned<byte[]>>> promise =\n+                                    new Promise<List<Versioned<byte[]>>>();\n+                            createMissingMetadata(zk, logRootPath, metadatas, zooKeeperClient.getDefaultACL(),\n+                                    ownAllocator, createIfNotExists, promise);\n+                            return promise;\n+                        }\n+                    }).map(new ExceptionalFunction<List<Versioned<byte[]>>, ZKLogMetadataForWriter>() {\n+                        @Override\n+                        public ZKLogMetadataForWriter applyE(List<Versioned<byte[]>> metadatas) throws DLException {\n+                            return processLogMetadatas(\n+                                    uri,\n+                                    logName,\n+                                    logIdentifier,\n+                                    metadatas,\n+                                    ownAllocator);\n+                        }\n+                    });\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            return Future.exception(new ZKException(\"Encountered zookeeper connection issue on creating log \" + logName,\n+                    KeeperException.Code.CONNECTIONLOSS));\n+        } catch (InterruptedException e) {\n+            return Future.exception(new DLInterruptedException(\"Interrupted on creating log \" + logName, e));\n+        }\n+    }\n+\n+    @Override\n+    public Future<ZKLogMetadataForWriter> getLog(final URI uri,\n+                                                 final String logName,\n+                                                 final boolean ownAllocator,\n+                                                 final boolean createIfNotExists) {\n+        return getLog(\n+                uri,\n+                logName,\n+                conf.getUnpartitionedStreamName(),\n+                zooKeeperClient,\n+                ownAllocator,\n+                createIfNotExists);\n+    }\n+\n+    //\n+    // Delete Log\n+    //\n+\n+    @Override\n+    public Future<Void> deleteLog(URI uri, final String logName) {\n+        final Promise<Void> promise = new Promise<Void>();\n+        try {\n+            String streamPath = ZKLogMetadata.getLogStreamPath(uri, logName);\n+            ZKUtil.deleteRecursive(zooKeeperClient.get(), streamPath, new AsyncCallback.VoidCallback() {\n+                @Override\n+                public void processResult(int rc, String path, Object ctx) {\n+                    if (KeeperException.Code.OK.intValue() != rc) {\n+                        FutureUtils.setException(promise,\n+                                new ZKException(\"Encountered zookeeper issue on deleting log stream \"\n+                                        + logName, KeeperException.Code.get(rc)));\n+                        return;\n+                    }\n+                    FutureUtils.setValue(promise, null);\n+                }\n+            }, null);\n+        } catch (ZooKeeperClient.ZooKeeperConnectionException e) {\n+            FutureUtils.setException(promise, new ZKException(\"Encountered zookeeper issue on deleting log stream \"\n+                    + logName, KeeperException.Code.CONNECTIONLOSS));\n+        } catch (InterruptedException e) {\n+            FutureUtils.setException(promise, new DLInterruptedException(\"Interrupted while deleting log stream \"\n+                    + logName));\n+        } catch (KeeperException e) {\n+            FutureUtils.setException(promise, new ZKException(\"Encountered zookeeper issue on deleting log stream \"\n+                    + logName, e));\n+        }\n+        return promise;\n+    }\n+}"},{"sha":"5144634dce551ccce5f0efddca5fd0380ac97729","filename":"src/main/java/com/twitter/distributedlog/logsegment/LogSegmentMetadataStore.java","status":"modified","additions":16,"deletions":8,"changes":24,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Flogsegment%2FLogSegmentMetadataStore.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -20,6 +20,8 @@\n import com.google.common.annotations.Beta;\n import com.twitter.distributedlog.LogSegmentMetadata;\n import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadata;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n import com.twitter.distributedlog.util.Transaction;\n import com.twitter.distributedlog.util.Transaction.OpListener;\n import com.twitter.util.Future;\n@@ -52,15 +54,15 @@ public interface LogSegmentMetadataStore extends Closeable {\n      *\n      * @param txn\n      *          transaction to execute for storing log segment sequence number.\n-     * @param path\n-     *          path to store sequence number\n+     * @param logMetadata\n+     *          metadata of the log stream\n      * @param sequenceNumber\n      *          log segment sequence number to store\n      * @param listener\n      *          listener on the result to this operation\n      */\n     void storeMaxLogSegmentSequenceNumber(Transaction<Object> txn,\n-                                          String path,\n+                                          ZKLogMetadata logMetadata,\n                                           Versioned<Long> sequenceNumber,\n                                           OpListener<Version> listener);\n \n@@ -69,15 +71,15 @@ void storeMaxLogSegmentSequenceNumber(Transaction<Object> txn,\n      *\n      * @param txn\n      *          transaction to execute for storing transaction id\n-     * @param path\n-     *          path to store sequence number\n+     * @param logMetadata\n+     *          metadata of the log stream\n      * @param transactionId\n      *          transaction id to store\n      * @param listener\n      *          listener on the result to this operation\n      */\n     void storeMaxTxnId(Transaction<Object> txn,\n-                       String path,\n+                       ZKLogMetadataForWriter logMetadata,\n                        Versioned<Long> transactionId,\n                        OpListener<Version> listener);\n \n@@ -91,8 +93,12 @@ void storeMaxTxnId(Transaction<Object> txn,\n      *          transaction to execute for this operation\n      * @param segment\n      *          segment to create\n+     * @param opListener\n+     *          the listener on the operation result\n      */\n-    void createLogSegment(Transaction<Object> txn, LogSegmentMetadata segment);\n+    void createLogSegment(Transaction<Object> txn,\n+                          LogSegmentMetadata segment,\n+                          OpListener<Void> opListener);\n \n     /**\n      * Delete a log segment <code>segment</code> under transaction <code>txn</code>.\n@@ -105,7 +111,9 @@ void storeMaxTxnId(Transaction<Object> txn,\n      * @param segment\n      *          segment to delete\n      */\n-    void deleteLogSegment(Transaction<Object> txn, LogSegmentMetadata segment);\n+    void deleteLogSegment(Transaction<Object> txn,\n+                          LogSegmentMetadata segment,\n+                          OpListener<Void> opListener);\n \n     /**\n      * Update a log segment <code>segment</code> under transaction <code>txn</code>."},{"sha":"ac36ef2f2cceb07f21aefd803da9d61175dba5c8","filename":"src/main/java/com/twitter/distributedlog/metadata/BKDLConfig.java","status":"modified","additions":2,"deletions":3,"changes":5,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FBKDLConfig.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FBKDLConfig.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FBKDLConfig.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -51,16 +51,15 @@ public class BKDLConfig implements DLConfig {\n             new ConcurrentHashMap<URI, DLConfig>();\n \n     public static void propagateConfiguration(BKDLConfig bkdlConfig, DistributedLogConfiguration dlConf) {\n-        dlConf.setSanityCheckTxnID(bkdlConfig.getSanityCheckTxnID());\n         dlConf.setEncodeRegionIDInLogSegmentMetadata(bkdlConfig.getEncodeRegionID());\n         dlConf.setFirstLogSegmentSequenceNumber(bkdlConfig.getFirstLogSegmentSeqNo());\n         if (bkdlConfig.isFederatedNamespace()) {\n             dlConf.setCreateStreamIfNotExists(false);\n             LOG.info(\"Disabled createIfNotExists for federated namespace.\");\n         }\n-        LOG.info(\"Propagate BKDLConfig to DLConfig : sanityCheckTxnID = {}, encodeRegionID = {},\" +\n+        LOG.info(\"Propagate BKDLConfig to DLConfig : encodeRegionID = {},\" +\n                         \" firstLogSegmentSequenceNumber = {}, createStreamIfNotExists = {}, isFederated = {}.\",\n-                new Object[] { dlConf.getSanityCheckTxnID(), dlConf.getEncodeRegionIDInLogSegmentMetadata(),\n+                new Object[] { dlConf.getEncodeRegionIDInLogSegmentMetadata(),\n                         dlConf.getFirstLogSegmentSequenceNumber(), dlConf.getCreateStreamIfNotExists(),\n                         bkdlConfig.isFederatedNamespace() });\n     }"},{"sha":"0e5e6d40c80399e76575b1dcad9bc636a82504de","filename":"src/main/java/com/twitter/distributedlog/metadata/LogSegmentMetadataStoreUpdater.java","status":"modified","additions":2,"deletions":2,"changes":4,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogSegmentMetadataStoreUpdater.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogSegmentMetadataStoreUpdater.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogSegmentMetadataStoreUpdater.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -177,8 +177,8 @@ public LogSegmentMetadata apply(Void value) {\n     protected void addNewSegmentAndDeleteOldSegment(Transaction<Object> txn,\n                                                     LogSegmentMetadata newSegment,\n                                                     LogSegmentMetadata oldSegment) {\n-        metadataStore.deleteLogSegment(txn, oldSegment);\n-        metadataStore.createLogSegment(txn, newSegment);\n+        metadataStore.deleteLogSegment(txn, oldSegment, null);\n+        metadataStore.createLogSegment(txn, newSegment, null);\n     }\n \n }"},{"sha":"db7812e375ffc047bc56d14e0e6dac83b631bc18","filename":"src/main/java/com/twitter/distributedlog/metadata/LogStreamMetadataStore.java","status":"added","additions":116,"deletions":0,"changes":116,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogStreamMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogStreamMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fmetadata%2FLogStreamMetadataStore.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.twitter.distributedlog.metadata;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Optional;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForReader;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n+import com.twitter.distributedlog.lock.DistributedLock;\n+import com.twitter.distributedlog.logsegment.LogSegmentMetadataStore;\n+import com.twitter.distributedlog.util.PermitManager;\n+import com.twitter.distributedlog.util.Transaction;\n+import com.twitter.util.Future;\n+\n+import java.io.Closeable;\n+import java.net.URI;\n+\n+/**\n+ * The interface to manage the log stream metadata. The implementation is responsible\n+ * for creating the metadata layout.\n+ */\n+@Beta\n+public interface LogStreamMetadataStore extends Closeable {\n+\n+    /**\n+     * Create a transaction for the metadata operations happening in the metadata store.\n+     *\n+     * @return transaction for the metadata operations\n+     */\n+    Transaction<Object> newTransaction();\n+\n+    /**\n+     * Ensure the existence of a log stream\n+     *\n+     * @param uri the location of the log stream\n+     * @param logName the name of the log stream\n+     * @return future represents the existence of a log stream. {@link com.twitter.distributedlog.LogNotFoundException}\n+     *         is thrown if the log doesn't exist\n+     */\n+    Future<Void> logExists(URI uri, String logName);\n+\n+    /**\n+     * Create the read lock for the log stream.\n+     *\n+     * @param metadata the metadata for a log stream\n+     * @param readerId the reader id used for lock\n+     * @return the read lock\n+     */\n+    Future<DistributedLock> createReadLock(ZKLogMetadataForReader metadata,\n+                                           Optional<String> readerId);\n+\n+    /**\n+     * Create the write lock for the log stream.\n+     *\n+     * @param metadata the metadata for a log stream\n+     * @return the write lock\n+     */\n+    DistributedLock createWriteLock(ZKLogMetadataForWriter metadata);\n+\n+    /**\n+     * Create the metadata of a log.\n+     *\n+     * @param uri the location to store the metadata of the log\n+     * @param streamName the name of the log stream\n+     * @param ownAllocator whether to use its own allocator or external allocator\n+     * @param createIfNotExists flag to create the stream if it doesn't exist\n+     * @return the metadata of the log\n+     */\n+    Future<ZKLogMetadataForWriter> getLog(URI uri,\n+                                          String streamName,\n+                                          boolean ownAllocator,\n+                                          boolean createIfNotExists);\n+\n+    /**\n+     * Delete the metadata of a log.\n+     *\n+     * @param uri the location to store the metadata of the log\n+     * @param streamName the name of the log stream\n+     * @return future represents the result of the deletion.\n+     */\n+    Future<Void> deleteLog(URI uri, String streamName);\n+\n+    /**\n+     * Get the log segment metadata store.\n+     *\n+     * @return the log segment metadata store.\n+     */\n+    LogSegmentMetadataStore getLogSegmentMetadataStore();\n+\n+    /**\n+     * Get the permit manager for this metadata store. It can be used for limiting the concurrent\n+     * metadata operations. The implementation can disable handing over the permits when the metadata\n+     * store is unavailable (for example zookeeper session expired).\n+     *\n+     * @return the permit manager\n+     */\n+    PermitManager getPermitManager();\n+\n+\n+\n+}"},{"sha":"23d8e405b197b0364087ec72dcb13af25c5aed58","filename":"src/main/java/com/twitter/distributedlog/tools/DistributedLogTool.java","status":"modified","additions":2,"deletions":1,"changes":3,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FDistributedLogTool.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FDistributedLogTool.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Ftools%2FDistributedLogTool.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -267,7 +267,8 @@ protected DistributedLogNamespace getNamespace() throws IOException {\n         protected LogSegmentMetadataStore getLogSegmentMetadataStore() throws IOException {\n             DistributedLogNamespace namespace = getFactory().getNamespace();\n             assert(namespace instanceof BKDistributedLogNamespace);\n-            return ((BKDistributedLogNamespace) namespace).getWriterSegmentMetadataStore();\n+            return ((BKDistributedLogNamespace) namespace).getWriterStreamMetadataStore()\n+                    .getLogSegmentMetadataStore();\n         }\n \n         protected ZooKeeperClient getZooKeeperClient() throws IOException {"},{"sha":"78292e903047c47b4370692f64dd003c72dea46a","filename":"src/main/java/com/twitter/distributedlog/zk/DefaultZKOp.java","status":"modified","additions":15,"deletions":5,"changes":20,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FDefaultZKOp.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FDefaultZKOp.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FDefaultZKOp.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -17,29 +17,39 @@\n  */\n package com.twitter.distributedlog.zk;\n \n+import com.twitter.distributedlog.util.Transaction.OpListener;\n import org.apache.zookeeper.Op;\n import org.apache.zookeeper.OpResult;\n \n+import javax.annotation.Nullable;\n+\n /**\n  * Default zookeeper operation. No action on commiting or aborting.\n  */\n public class DefaultZKOp extends ZKOp {\n \n-    public static DefaultZKOp of(Op op) {\n-        return new DefaultZKOp(op);\n+    public static DefaultZKOp of(Op op, OpListener<Void> listener) {\n+        return new DefaultZKOp(op, listener);\n     }\n \n-    private DefaultZKOp(Op op) {\n+    private final OpListener<Void> listener;\n+\n+    private DefaultZKOp(Op op, @Nullable OpListener<Void> opListener) {\n         super(op);\n+        this.listener = opListener;\n     }\n \n     @Override\n     protected void commitOpResult(OpResult opResult) {\n-        // no-op\n+        if (null != listener) {\n+            listener.onCommit(null);\n+        }\n     }\n \n     @Override\n     protected void abortOpResult(Throwable t, OpResult opResult) {\n-        // no-op\n+        if (null != listener) {\n+            listener.onAbort(t);\n+        }\n     }\n }"},{"sha":"78ff0a2eb58827ec7e8b8730f15f401ca837b574","filename":"src/main/java/com/twitter/distributedlog/zk/LimitedPermitManager.java","status":"renamed","additions":2,"deletions":1,"changes":3,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FLimitedPermitManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FLimitedPermitManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FLimitedPermitManager.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -15,8 +15,9 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.twitter.distributedlog.util;\n+package com.twitter.distributedlog.zk;\n \n+import com.twitter.distributedlog.util.PermitManager;\n import org.apache.bookkeeper.stats.Gauge;\n import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.bookkeeper.stats.StatsLogger;","previous_filename":"src/main/java/com/twitter/distributedlog/util/LimitedPermitManager.java"},{"sha":"5b788e2064ab62547b6c440a18b6624901736c28","filename":"src/main/java/com/twitter/distributedlog/zk/ZKVersionedSetOp.java","status":"modified","additions":8,"deletions":3,"changes":11,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKVersionedSetOp.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKVersionedSetOp.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Fmain%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fzk%2FZKVersionedSetOp.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -33,7 +33,8 @@ public class ZKVersionedSetOp extends ZKOp {\n \n     private final OpListener<Version> listener;\n \n-    public ZKVersionedSetOp(Op op, OpListener<Version> opListener) {\n+    public ZKVersionedSetOp(Op op,\n+                            @Nullable OpListener<Version> opListener) {\n         super(op);\n         this.listener = opListener;\n     }\n@@ -42,7 +43,9 @@ public ZKVersionedSetOp(Op op, OpListener<Version> opListener) {\n     protected void commitOpResult(OpResult opResult) {\n         assert(opResult instanceof OpResult.SetDataResult);\n         OpResult.SetDataResult setDataResult = (OpResult.SetDataResult) opResult;\n-        listener.onCommit(new ZkVersion(setDataResult.getStat().getVersion()));\n+        if (null != listener) {\n+            listener.onCommit(new ZkVersion(setDataResult.getStat().getVersion()));\n+        }\n     }\n \n     @Override\n@@ -60,7 +63,9 @@ protected void abortOpResult(Throwable t,\n                 cause = KeeperException.create(KeeperException.Code.get(errorResult.getErr()));\n             }\n         }\n-        listener.onAbort(cause);\n+        if (null != listener) {\n+            listener.onAbort(cause);\n+        }\n     }\n \n }"},{"sha":"1485ae615ca9a0f287318d2df6f795bf4ea615f2","filename":"src/test/java/com/twitter/distributedlog/DLMTestUtil.java","status":"modified","additions":3,"deletions":2,"changes":5,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FDLMTestUtil.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -36,6 +36,7 @@\n import org.apache.bookkeeper.conf.ServerConfiguration;\n import org.apache.bookkeeper.feature.SettableFeatureProvider;\n import org.apache.bookkeeper.stats.NullStatsLogger;\n+import org.apache.bookkeeper.versioning.Version;\n import org.apache.zookeeper.CreateMode;\n import org.apache.zookeeper.KeeperException;\n import org.apache.zookeeper.ZooDefs;\n@@ -429,7 +430,7 @@ public static void injectLogSegmentWithGivenLogSegmentSeqNo(DistributedLogManage\n                 .setEnvelopeEntries(LogSegmentMetadata.supportsEnvelopedEntries(logSegmentMetadataVersion))\n                 .build();\n         l.write(dlm.writerZKC);\n-        writeHandler.maxTxId.store(startTxID);\n+        writeHandler.maxTxId.update(Version.ANY, startTxID);\n         writeHandler.addLogSegmentToCache(inprogressZnodeName, l);\n         BKLogSegmentWriter writer = new BKLogSegmentWriter(\n                 writeHandler.getFullyQualifiedName(),\n@@ -479,7 +480,7 @@ public static void injectLogSegmentWithLastDLSN(DistributedLogManager manager, D\n             .setInprogress(false)\n             .build();\n         l.write(dlm.writerZKC);\n-        writeHandler.maxTxId.store(startTxID);\n+        writeHandler.maxTxId.update(Version.ANY, startTxID);\n         writeHandler.addLogSegmentToCache(inprogressZnodeName, l);\n         BKLogSegmentWriter writer = new BKLogSegmentWriter(\n                 writeHandler.getFullyQualifiedName(),"},{"sha":"6aa38c30eeeb87a81678133ee7edbe04693c0604","filename":"src/test/java/com/twitter/distributedlog/TestAppendOnlyStreamWriter.java","status":"modified","additions":3,"deletions":2,"changes":5,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamWriter.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamWriter.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestAppendOnlyStreamWriter.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -21,6 +21,7 @@\n import java.net.URI;\n \n import com.twitter.distributedlog.exceptions.BKTransmitException;\n+import com.twitter.distributedlog.util.FutureUtils;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.rules.TestName;\n@@ -203,7 +204,7 @@ public void testWriterStartsAtTxidZeroForEmptyStream() throws Exception {\n         BKDistributedLogManager dlm = (BKDistributedLogManager) createNewDLM(conf, name);\n \n         URI uri = createDLMURI(\"/\" + name);\n-        BKDistributedLogManager.createLog(conf, dlm.getReaderZKC(), uri, name);\n+        FutureUtils.result(dlm.getWriterMetadataStore().getLog(uri, name, true, true));\n \n         // Log exists but is empty, better not throw.\n         AppendOnlyStreamWriter writer = dlm.getAppendOnlyStreamWriter();\n@@ -264,7 +265,7 @@ long writeRecordsAndReadThemBackAfterInjectingAFailedTransmit(\n         BKDistributedLogManager dlm = (BKDistributedLogManager) createNewDLM(conf, name);\n \n         URI uri = createDLMURI(\"/\" + name);\n-        BKDistributedLogManager.createLog(conf, dlm.getReaderZKC(), uri, name);\n+        FutureUtils.result(dlm.getWriterMetadataStore().getLog(uri, name, true, true));\n \n         // Log exists but is empty, better not throw.\n         AppendOnlyStreamWriter writer = dlm.getAppendOnlyStreamWriter();"},{"sha":"c8a1c74000eb46b8e8d02360db3602a3f049695d","filename":"src/test/java/com/twitter/distributedlog/TestBKDistributedLogManager.java","status":"modified","additions":4,"deletions":61,"changes":65,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogManager.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -147,61 +147,6 @@ public void testNumberOfTransactions() throws Exception {\n         dlm.close();\n     }\n \n-    @Test(timeout = 60000)\n-    public void testSanityCheckTxnID() throws Exception {\n-        String name = \"distrlog-sanity-check-txnid\";\n-        BKDistributedLogManager dlm = createNewDLM(conf, name);\n-        BKSyncLogWriter out = dlm.startLogSegmentNonPartitioned();\n-        long txid = 1;\n-        for (long j = 1; j <= DEFAULT_SEGMENT_SIZE; j++) {\n-            LogRecord op = DLMTestUtil.getLogRecordInstance(txid++);\n-            out.write(op);\n-        }\n-        out.closeAndComplete();\n-\n-        BKSyncLogWriter out1 = dlm.startLogSegmentNonPartitioned();\n-        LogRecord op1 = DLMTestUtil.getLogRecordInstance(1);\n-        try {\n-            out1.write(op1);\n-            fail(\"Should fail writing lower txn id if sanityCheckTxnID is enabled.\");\n-        } catch (TransactionIdOutOfOrderException tioooe) {\n-            // expected\n-        }\n-        out1.closeAndComplete();\n-        dlm.close();\n-\n-        DLMTestUtil.updateBKDLConfig(bkutil.getUri(), bkutil.getZkServers(), bkutil.getBkLedgerPath(), false);\n-        LOG.info(\"Disable sanity check txn id.\");\n-        BKDLConfig.clearCachedDLConfigs();\n-\n-        DistributedLogConfiguration newConf = new DistributedLogConfiguration();\n-        newConf.addConfiguration(conf);\n-        BKDistributedLogManager newDLM = createNewDLM(newConf, name);\n-        BKSyncLogWriter out2 = newDLM.startLogSegmentNonPartitioned();\n-        LogRecord op2 = DLMTestUtil.getLogRecordInstance(1);\n-        out2.write(op2);\n-        out2.closeAndComplete();\n-        newDLM.close();\n-\n-        DLMTestUtil.updateBKDLConfig(bkutil.getUri(), bkutil.getZkServers(), bkutil.getBkLedgerPath(), true);\n-        LOG.info(\"Enable sanity check txn id.\");\n-        BKDLConfig.clearCachedDLConfigs();\n-\n-        DistributedLogConfiguration conf3 = new DistributedLogConfiguration();\n-        conf3.addConfiguration(conf);\n-        BKDistributedLogManager dlm3 = createNewDLM(newConf, name);\n-        BKSyncLogWriter out3 = dlm3.startLogSegmentNonPartitioned();\n-        LogRecord op3 = DLMTestUtil.getLogRecordInstance(1);\n-        try {\n-            out3.write(op3);\n-            fail(\"Should fail writing lower txn id if sanityCheckTxnID is enabled.\");\n-        } catch (TransactionIdOutOfOrderException tioooe) {\n-            // expected\n-        }\n-        out3.closeAndComplete();\n-        dlm3.close();\n-    }\n-\n     @Test(timeout = 60000)\n     public void testContinuousReaders() throws Exception {\n         String name = \"distrlog-continuous\";\n@@ -958,12 +903,9 @@ public void testLogSegmentListener() throws Exception {\n         final AtomicReference<Collection<LogSegmentMetadata>> receivedStreams =\n                 new AtomicReference<Collection<LogSegmentMetadata>>();\n \n-        DistributedLogManager dlm = createNewDLM(conf, name);\n-        ZooKeeperClient zkClient = TestZooKeeperClientBuilder.newBuilder()\n-                .uri(createDLMURI(\"/\"))\n-                .build();\n+        BKDistributedLogManager dlm = (BKDistributedLogManager) createNewDLM(conf, name);\n \n-        BKDistributedLogManager.createLog(conf, zkClient, ((BKDistributedLogManager) dlm).uri, name);\n+        FutureUtils.result(dlm.getWriterMetadataStore().getLog(dlm.getUri(), name, true, true));\n         dlm.registerListener(new LogSegmentListener() {\n             @Override\n             public void onSegmentsUpdated(List<LogSegmentMetadata> segments) {\n@@ -992,7 +934,6 @@ public void onLogStreamDeleted() {\n                 // no-op\n             }\n         });\n-        LOG.info(\"Registered listener for stream {}.\", name);\n         long txid = 1;\n         for (int i = 0; i < numSegments; i++) {\n             LOG.info(\"Waiting for creating log segment {}.\", i);\n@@ -1018,6 +959,8 @@ public void onLogStreamDeleted() {\n             assertEquals(seqno * DEFAULT_SEGMENT_SIZE, m.getLastTxId());\n             ++seqno;\n         }\n+\n+        dlm.close();\n     }\n \n     @Test(timeout = 60000)"},{"sha":"ecc20e0a8dacd72e3ee7f559dfe7b4ce9a7070d7","filename":"src/test/java/com/twitter/distributedlog/TestBKDistributedLogNamespace.java","status":"modified","additions":3,"deletions":3,"changes":6,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogNamespace.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogNamespace.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestBKDistributedLogNamespace.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -102,7 +102,7 @@ public void testCreateIfNotExists() throws Exception {\n         dlm.close();\n \n         // create the stream\n-        BKDistributedLogManager.createLog(conf, zooKeeperClient, uri, streamName);\n+        namespace.createLog(streamName);\n \n         DistributedLogManager newDLM = namespace.openLog(streamName);\n         LogWriter newWriter = newDLM.startLogSegmentNonPartitioned();\n@@ -273,9 +273,9 @@ public void onStreamsChanged(Iterator<String> streams) {\n             }\n         });\n         latches[0].await();\n-        BKDistributedLogManager.createLog(conf, zooKeeperClient, uri, \"test1\");\n+        namespace.createLog(\"test1\");\n         latches[1].await();\n-        BKDistributedLogManager.createLog(conf, zooKeeperClient, uri, \"test2\");\n+        namespace.createLog(\"test2\");\n         latches[2].await();\n         assertEquals(0, numFailures.get());\n         assertNotNull(receivedStreams.get());"},{"sha":"8a734b5994b75249abb6c0283c934b11c37063bc","filename":"src/test/java/com/twitter/distributedlog/TestDistributedLogBase.java","status":"modified","additions":2,"deletions":1,"changes":3,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestDistributedLogBase.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -191,7 +191,8 @@ public DLMTestUtil.BKLogPartitionWriteHandlerAndClients createNewBKDLM(\n     protected LogSegmentMetadataStore getLogSegmentMetadataStore(DistributedLogManagerFactory factory) {\n         DistributedLogNamespace namespace = factory.getNamespace();\n         assertTrue(namespace instanceof BKDistributedLogNamespace);\n-        return ((BKDistributedLogNamespace) namespace).getWriterSegmentMetadataStore();\n+        return ((BKDistributedLogNamespace) namespace).getWriterStreamMetadataStore()\n+                .getLogSegmentMetadataStore();\n     }\n \n     @SuppressWarnings(\"deprecation\")"},{"sha":"027b0123283abf1e1df9fdc7c65fa327e69c5af0","filename":"src/test/java/com/twitter/distributedlog/TestRollLogSegments.java","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestRollLogSegments.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestRollLogSegments.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2FTestRollLogSegments.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -253,6 +253,7 @@ public void testRollingLogSegments() throws Exception {\n         confLocal.setOutputBufferSize(0);\n         confLocal.setLogSegmentRollingIntervalMinutes(0);\n         confLocal.setMaxLogSegmentBytes(1);\n+        confLocal.setLogSegmentRollingConcurrency(Integer.MAX_VALUE);\n \n         int numLogSegments = 10;\n "},{"sha":"66b97bef1ff626e5041bc269f3079be6ee6e9876","filename":"src/test/java/com/twitter/distributedlog/bk/TestLedgerAllocator.java","status":"modified","additions":2,"deletions":2,"changes":4,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocator.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocator.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fbk%2FTestLedgerAllocator.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -140,7 +140,7 @@ public void testAllocation() throws Exception {\n         logger.info(\"Try obtaining ledger handle {}\", lh.getId());\n         byte[] data = zkc.get().getData(allocationPath, false, null);\n         assertEquals((Long) lh.getId(), Long.valueOf(new String(data, UTF_8)));\n-        txn.addOp(DefaultZKOp.of(Op.setData(\"/unexistedpath\", \"data\".getBytes(UTF_8), -1)));\n+        txn.addOp(DefaultZKOp.of(Op.setData(\"/unexistedpath\", \"data\".getBytes(UTF_8), -1), null));\n         try {\n             FutureUtils.result(txn.execute());\n             fail(\"Should fail the transaction when setting unexisted path\");\n@@ -337,7 +337,7 @@ public void testCloseAllocatorAfterAbort() throws Exception {\n         ZKTransaction txn = newTxn();\n         // close during obtaining ledger.\n         LedgerHandle lh = FutureUtils.result(allocator.tryObtain(txn, NULL_LISTENER));\n-        txn.addOp(DefaultZKOp.of(Op.setData(\"/unexistedpath\", \"data\".getBytes(UTF_8), -1)));\n+        txn.addOp(DefaultZKOp.of(Op.setData(\"/unexistedpath\", \"data\".getBytes(UTF_8), -1), null));\n         try {\n             FutureUtils.result(txn.execute());\n             fail(\"Should fail the transaction when setting unexisted path\");"},{"sha":"2a8c83b155c5efb7c7a8f9f509c4533f61e7e8b8","filename":"src/test/java/com/twitter/distributedlog/impl/TestZKLogSegmentMetadataStore.java","status":"modified","additions":44,"deletions":29,"changes":73,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2FTestZKLogSegmentMetadataStore.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -27,6 +27,8 @@\n import com.twitter.distributedlog.ZooKeeperClientUtils;\n import com.twitter.distributedlog.callback.LogSegmentNamesListener;\n import com.twitter.distributedlog.exceptions.ZKException;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadata;\n+import com.twitter.distributedlog.impl.metadata.ZKLogMetadataForWriter;\n import com.twitter.distributedlog.util.DLUtils;\n import com.twitter.distributedlog.util.FutureUtils;\n import com.twitter.distributedlog.util.OrderedScheduler;\n@@ -57,6 +59,7 @@\n import java.util.concurrent.atomic.AtomicInteger;\n \n import static org.junit.Assert.*;\n+import static org.mockito.Mockito.*;\n \n /**\n  * Test ZK based log segment metadata store.\n@@ -133,14 +136,14 @@ public void teardown() throws Exception {\n     public void testCreateLogSegment() throws Exception {\n         LogSegmentMetadata segment = createLogSegment(1L);\n         Transaction<Object> createTxn = lsmStore.transaction();\n-        lsmStore.createLogSegment(createTxn, segment);\n+        lsmStore.createLogSegment(createTxn, segment, null);\n         FutureUtils.result(createTxn.execute());\n         // the log segment should be created\n         assertNotNull(\"LogSegment \" + segment + \" should be created\",\n                 zkc.get().exists(segment.getZkPath(), false));\n         LogSegmentMetadata segment2 = createLogSegment(1L);\n         Transaction<Object> createTxn2 = lsmStore.transaction();\n-        lsmStore.createLogSegment(createTxn2, segment2);\n+        lsmStore.createLogSegment(createTxn2, segment2, null);\n         try {\n             FutureUtils.result(createTxn2.execute());\n             fail(\"Should fail if log segment exists\");\n@@ -158,13 +161,13 @@ public void testCreateLogSegment() throws Exception {\n     public void testDeleteLogSegment() throws Exception {\n         LogSegmentMetadata segment = createLogSegment(1L);\n         Transaction<Object> createTxn = lsmStore.transaction();\n-        lsmStore.createLogSegment(createTxn, segment);\n+        lsmStore.createLogSegment(createTxn, segment, null);\n         FutureUtils.result(createTxn.execute());\n         // the log segment should be created\n         assertNotNull(\"LogSegment \" + segment + \" should be created\",\n                 zkc.get().exists(segment.getZkPath(), false));\n         Transaction<Object> deleteTxn = lsmStore.transaction();\n-        lsmStore.deleteLogSegment(deleteTxn, segment);\n+        lsmStore.deleteLogSegment(deleteTxn, segment, null);\n         FutureUtils.result(deleteTxn.execute());\n         assertNull(\"LogSegment \" + segment + \" should be deleted\",\n                 zkc.get().exists(segment.getZkPath(), false));\n@@ -174,7 +177,7 @@ public void testDeleteLogSegment() throws Exception {\n     public void testDeleteNonExistentLogSegment() throws Exception {\n         LogSegmentMetadata segment = createLogSegment(1L);\n         Transaction<Object> deleteTxn = lsmStore.transaction();\n-        lsmStore.deleteLogSegment(deleteTxn, segment);\n+        lsmStore.deleteLogSegment(deleteTxn, segment, null);\n         try {\n             FutureUtils.result(deleteTxn.execute());\n             fail(\"Should fail deletion if log segment doesn't exist\");\n@@ -208,7 +211,7 @@ public void testUpdateNonExistentLogSegment() throws Exception {\n     public void testUpdateLogSegment() throws Exception {\n         LogSegmentMetadata segment = createLogSegment(1L, 99L);\n         Transaction<Object> createTxn = lsmStore.transaction();\n-        lsmStore.createLogSegment(createTxn, segment);\n+        lsmStore.createLogSegment(createTxn, segment, null);\n         FutureUtils.result(createTxn.execute());\n         // the log segment should be created\n         assertNotNull(\"LogSegment \" + segment + \" should be created\",\n@@ -230,15 +233,15 @@ public void testCreateDeleteLogSegmentSuccess() throws Exception {\n         LogSegmentMetadata segment2 = createLogSegment(2L);\n         // create log segment 1\n         Transaction<Object> createTxn = lsmStore.transaction();\n-        lsmStore.createLogSegment(createTxn, segment1);\n+        lsmStore.createLogSegment(createTxn, segment1, null);\n         FutureUtils.result(createTxn.execute());\n         // the log segment should be created\n         assertNotNull(\"LogSegment \" + segment1 + \" should be created\",\n                 zkc.get().exists(segment1.getZkPath(), false));\n         // delete log segment 1 and create log segment 2\n         Transaction<Object> createDeleteTxn = lsmStore.transaction();\n-        lsmStore.createLogSegment(createDeleteTxn, segment2);\n-        lsmStore.deleteLogSegment(createDeleteTxn, segment1);\n+        lsmStore.createLogSegment(createDeleteTxn, segment2, null);\n+        lsmStore.deleteLogSegment(createDeleteTxn, segment1, null);\n         FutureUtils.result(createDeleteTxn.execute());\n         // segment 1 should be deleted, segment 2 should be created\n         assertNull(\"LogSegment \" + segment1 + \" should be deleted\",\n@@ -254,16 +257,16 @@ public void testCreateDeleteLogSegmentFailure() throws Exception {\n         LogSegmentMetadata segment3 = createLogSegment(3L);\n         // create log segment 1\n         Transaction<Object> createTxn = lsmStore.transaction();\n-        lsmStore.createLogSegment(createTxn, segment1);\n+        lsmStore.createLogSegment(createTxn, segment1, null);\n         FutureUtils.result(createTxn.execute());\n         // the log segment should be created\n         assertNotNull(\"LogSegment \" + segment1 + \" should be created\",\n                 zkc.get().exists(segment1.getZkPath(), false));\n         // delete log segment 1 and delete log segment 2\n         Transaction<Object> createDeleteTxn = lsmStore.transaction();\n-        lsmStore.deleteLogSegment(createDeleteTxn, segment1);\n-        lsmStore.deleteLogSegment(createDeleteTxn, segment2);\n-        lsmStore.createLogSegment(createDeleteTxn, segment3);\n+        lsmStore.deleteLogSegment(createDeleteTxn, segment1, null);\n+        lsmStore.deleteLogSegment(createDeleteTxn, segment2, null);\n+        lsmStore.createLogSegment(createDeleteTxn, segment3, null);\n         try {\n             FutureUtils.result(createDeleteTxn.execute());\n             fail(\"Should fail transaction if one operation failed\");\n@@ -286,7 +289,7 @@ public void testCreateDeleteLogSegmentFailure() throws Exception {\n     public void testGetLogSegment() throws Exception {\n         LogSegmentMetadata segment = createLogSegment(1L, 99L);\n         Transaction<Object> createTxn = lsmStore.transaction();\n-        lsmStore.createLogSegment(createTxn, segment);\n+        lsmStore.createLogSegment(createTxn, segment, null);\n         FutureUtils.result(createTxn.execute());\n         // the log segment should be created\n         assertNotNull(\"LogSegment \" + segment + \" should be created\",\n@@ -304,7 +307,7 @@ public void testGetLogSegmentNames() throws Exception {\n         for (int i = 0; i < 10; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n             createdSegments.add(segment);\n-            lsmStore.createLogSegment(createTxn, segment);\n+            lsmStore.createLogSegment(createTxn, segment, null);\n         }\n         FutureUtils.result(createTxn.execute());\n         String rootPath = \"/\" + runtime.getMethodName();\n@@ -353,7 +356,7 @@ public void testLogSegmentNamesListener() throws Exception {\n         Transaction<Object> createTxn = lsmStore.transaction();\n         for (int i = 0; i < numSegments; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n-            lsmStore.createLogSegment(createTxn, segment);\n+            lsmStore.createLogSegment(createTxn, segment, null);\n         }\n         FutureUtils.result(createTxn.execute());\n         String rootPath = \"/\" + runtime.getMethodName();\n@@ -394,7 +397,7 @@ public void onLogStreamDeleted() {\n         Transaction<Object> anotherCreateTxn = lsmStore.transaction();\n         for (int i = numSegments; i < 2 * numSegments; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n-            lsmStore.createLogSegment(anotherCreateTxn, segment);\n+            lsmStore.createLogSegment(anotherCreateTxn, segment, null);\n         }\n         FutureUtils.result(anotherCreateTxn.execute());\n         List<String> newChildren = zkc.get().getChildren(rootPath, false);\n@@ -419,7 +422,7 @@ public void testLogSegmentNamesListenerOnDeletion() throws Exception {\n         Transaction<Object> createTxn = lsmStore.transaction();\n         for (int i = 0; i < numSegments; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n-            lsmStore.createLogSegment(createTxn, segment);\n+            lsmStore.createLogSegment(createTxn, segment, null);\n         }\n         FutureUtils.result(createTxn.execute());\n         String rootPath = \"/\" + runtime.getMethodName();\n@@ -459,7 +462,7 @@ public void onLogStreamDeleted() {\n         Transaction<Object> deleteTxn = lsmStore.transaction();\n         for (int i = 0; i < numSegments; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n-            lsmStore.deleteLogSegment(deleteTxn, segment);\n+            lsmStore.deleteLogSegment(deleteTxn, segment, null);\n         }\n         FutureUtils.result(deleteTxn.execute());\n         List<String> newChildren = zkc.get().getChildren(rootPath, false);\n@@ -491,7 +494,7 @@ public void testLogSegmentNamesListenerOnSessionExpired() throws Exception {\n         Transaction<Object> createTxn = lsmStore.transaction();\n         for (int i = 0; i < numSegments; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n-            lsmStore.createLogSegment(createTxn, segment);\n+            lsmStore.createLogSegment(createTxn, segment, null);\n         }\n         FutureUtils.result(createTxn.execute());\n         String rootPath = \"/\" + runtime.getMethodName();\n@@ -536,7 +539,7 @@ public void onLogStreamDeleted() {\n         Transaction<Object> anotherCreateTxn = lsmStore.transaction();\n         for (int i = numSegments; i < 2 * numSegments; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n-            lsmStore.createLogSegment(anotherCreateTxn, segment);\n+            lsmStore.createLogSegment(anotherCreateTxn, segment, null);\n         }\n         FutureUtils.result(anotherCreateTxn.execute());\n         List<String> newChildren = zkc.get().getChildren(rootPath, false);\n@@ -561,7 +564,7 @@ public void testLogSegmentNamesListenerOnDeletingLogStream() throws Exception {\n         Transaction<Object> createTxn = lsmStore.transaction();\n         for (int i = 0; i < numSegments; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n-            lsmStore.createLogSegment(createTxn, segment);\n+            lsmStore.createLogSegment(createTxn, segment, null);\n         }\n         FutureUtils.result(createTxn.execute());\n         String rootPath = \"/\" + runtime.getMethodName();\n@@ -602,7 +605,7 @@ public void onLogStreamDeleted() {\n         Transaction<Object> deleteTxn = lsmStore.transaction();\n         for (int i = 0; i < numSegments; i++) {\n             LogSegmentMetadata segment = createLogSegment(i);\n-            lsmStore.deleteLogSegment(deleteTxn, segment);\n+            lsmStore.deleteLogSegment(deleteTxn, segment, null);\n         }\n         FutureUtils.result(deleteTxn.execute());\n         List<String> newChildren = zkc.get().getChildren(rootPath, false);\n@@ -634,7 +637,9 @@ public void testStoreMaxLogSegmentSequenceNumber() throws Exception {\n         Transaction<Object> updateTxn = lsmStore.transaction();\n         Versioned<Long> value = new Versioned<Long>(999L, new ZkVersion(0));\n         final Promise<Version> result = new Promise<Version>();\n-        lsmStore.storeMaxLogSegmentSequenceNumber(updateTxn, rootZkPath, value,\n+        ZKLogMetadata metadata = mock(ZKLogMetadata.class);\n+        when(metadata.getLogSegmentsPath()).thenReturn(rootZkPath);\n+        lsmStore.storeMaxLogSegmentSequenceNumber(updateTxn, metadata, value,\n                 new Transaction.OpListener<Version>() {\n             @Override\n             public void onCommit(Version r) {\n@@ -659,7 +664,9 @@ public void testStoreMaxLogSegmentSequenceNumberBadVersion() throws Exception {\n         Transaction<Object> updateTxn = lsmStore.transaction();\n         Versioned<Long> value = new Versioned<Long>(999L, new ZkVersion(10));\n         final Promise<Version> result = new Promise<Version>();\n-        lsmStore.storeMaxLogSegmentSequenceNumber(updateTxn, rootZkPath, value,\n+        ZKLogMetadata metadata = mock(ZKLogMetadata.class);\n+        when(metadata.getLogSegmentsPath()).thenReturn(rootZkPath);\n+        lsmStore.storeMaxLogSegmentSequenceNumber(updateTxn, metadata, value,\n                 new Transaction.OpListener<Version>() {\n                     @Override\n                     public void onCommit(Version r) {\n@@ -695,7 +702,9 @@ public void testStoreMaxLogSegmentSequenceNumberOnNonExistentPath() throws Excep\n         Versioned<Long> value = new Versioned<Long>(999L, new ZkVersion(10));\n         final Promise<Version> result = new Promise<Version>();\n         String nonExistentPath = rootZkPath + \"/non-existent\";\n-        lsmStore.storeMaxLogSegmentSequenceNumber(updateTxn, nonExistentPath, value,\n+        ZKLogMetadata metadata = mock(ZKLogMetadata.class);\n+        when(metadata.getLogSegmentsPath()).thenReturn(nonExistentPath);\n+        lsmStore.storeMaxLogSegmentSequenceNumber(updateTxn, metadata, value,\n                 new Transaction.OpListener<Version>() {\n                     @Override\n                     public void onCommit(Version r) {\n@@ -726,7 +735,9 @@ public void testStoreMaxTxnId() throws Exception {\n         Transaction<Object> updateTxn = lsmStore.transaction();\n         Versioned<Long> value = new Versioned<Long>(999L, new ZkVersion(0));\n         final Promise<Version> result = new Promise<Version>();\n-        lsmStore.storeMaxTxnId(updateTxn, rootZkPath, value,\n+        ZKLogMetadataForWriter metadata = mock(ZKLogMetadataForWriter.class);\n+        when(metadata.getMaxTxIdPath()).thenReturn(rootZkPath);\n+        lsmStore.storeMaxTxnId(updateTxn, metadata, value,\n                 new Transaction.OpListener<Version>() {\n             @Override\n             public void onCommit(Version r) {\n@@ -751,7 +762,9 @@ public void testStoreMaxTxnIdBadVersion() throws Exception {\n         Transaction<Object> updateTxn = lsmStore.transaction();\n         Versioned<Long> value = new Versioned<Long>(999L, new ZkVersion(10));\n         final Promise<Version> result = new Promise<Version>();\n-        lsmStore.storeMaxTxnId(updateTxn, rootZkPath, value,\n+        ZKLogMetadataForWriter metadata = mock(ZKLogMetadataForWriter.class);\n+        when(metadata.getMaxTxIdPath()).thenReturn(rootZkPath);\n+        lsmStore.storeMaxTxnId(updateTxn, metadata, value,\n                 new Transaction.OpListener<Version>() {\n                     @Override\n                     public void onCommit(Version r) {\n@@ -787,7 +800,9 @@ public void testStoreMaxTxnIdOnNonExistentPath() throws Exception {\n         Versioned<Long> value = new Versioned<Long>(999L, new ZkVersion(10));\n         final Promise<Version> result = new Promise<Version>();\n         String nonExistentPath = rootZkPath + \"/non-existent\";\n-        lsmStore.storeMaxLogSegmentSequenceNumber(updateTxn, nonExistentPath, value,\n+        ZKLogMetadataForWriter metadata = mock(ZKLogMetadataForWriter.class);\n+        when(metadata.getMaxTxIdPath()).thenReturn(nonExistentPath);\n+        lsmStore.storeMaxTxnId(updateTxn, metadata, value,\n                 new Transaction.OpListener<Version>() {\n                     @Override\n                     public void onCommit(Version r) {"},{"sha":"9a08aa0393c0a8132c7cc4ca0e9a042aaec7d2e2","filename":"src/test/java/com/twitter/distributedlog/impl/metadata/TestZKLogStreamMetadataStore.java","status":"renamed","additions":11,"deletions":12,"changes":23,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogStreamMetadataStore.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogStreamMetadataStore.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogStreamMetadataStore.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -52,14 +52,15 @@\n import java.util.List;\n \n import static com.twitter.distributedlog.impl.metadata.ZKLogMetadata.*;\n+import static com.twitter.distributedlog.impl.metadata.ZKLogStreamMetadataStore.*;\n import static org.junit.Assert.*;\n \n /**\n- * Test {@link ZKLogMetadataForWriter}\n+ * Test {@link ZKLogStreamMetadataStore}\n  */\n-public class TestZKLogMetadataForWriter extends ZooKeeperClusterTestCase {\n+public class TestZKLogStreamMetadataStore extends ZooKeeperClusterTestCase {\n \n-    private static final Logger logger = LoggerFactory.getLogger(TestZKLogMetadataForWriter.class);\n+    private static final Logger logger = LoggerFactory.getLogger(TestZKLogStreamMetadataStore.class);\n \n     private final static int sessionTimeoutMs = 30000;\n \n@@ -91,7 +92,7 @@ private static void createLog(ZooKeeperClient zk, URI uri, String logName, Strin\n                 zk.getDefaultACL(), CreateMode.PERSISTENT);\n         txn.create(readLockPath, DistributedLogConstants.EMPTY_BYTES,\n                 zk.getDefaultACL(), CreateMode.PERSISTENT);\n-        txn.create(versionPath, ZKLogMetadataForWriter.intToBytes(LAYOUT_VERSION),\n+        txn.create(versionPath, intToBytes(LAYOUT_VERSION),\n                 zk.getDefaultACL(), CreateMode.PERSISTENT);\n         txn.create(allocationPath, DistributedLogConstants.EMPTY_BYTES,\n                 zk.getDefaultACL(), CreateMode.PERSISTENT);\n@@ -127,7 +128,7 @@ public void teardown() throws Exception {\n     public void testCheckLogMetadataPathsWithAllocator() throws Exception {\n         String logRootPath = \"/\" + testName.getMethodName();\n         List<Versioned<byte[]>> metadatas =\n-                FutureUtils.result(ZKLogMetadataForWriter.checkLogMetadataPaths(\n+                FutureUtils.result(checkLogMetadataPaths(\n                         zkc.get(), logRootPath, true));\n         assertEquals(\"Should have 8 paths\",\n                 8, metadatas.size());\n@@ -141,7 +142,7 @@ public void testCheckLogMetadataPathsWithAllocator() throws Exception {\n     public void testCheckLogMetadataPathsWithoutAllocator() throws Exception {\n         String logRootPath = \"/\" + testName.getMethodName();\n         List<Versioned<byte[]>> metadatas =\n-                FutureUtils.result(ZKLogMetadataForWriter.checkLogMetadataPaths(\n+                FutureUtils.result(checkLogMetadataPaths(\n                         zkc.get(), logRootPath, false));\n         assertEquals(\"Should have 7 paths\",\n                 7, metadatas.size());\n@@ -167,13 +168,12 @@ private void testCreateLogMetadataWithMissingPaths(URI uri,\n         }\n \n         ZKLogMetadataForWriter logMetadata =\n-                FutureUtils.result(ZKLogMetadataForWriter.of(uri, logName, logIdentifier,\n-                        zkc.get(), zkc.getDefaultACL(), ownAllocator, true));\n+                FutureUtils.result(getLog(uri, logName, logIdentifier, zkc, ownAllocator, true));\n \n         final String logRootPath = getLogRootPath(uri, logName, logIdentifier);\n \n         List<Versioned<byte[]>> metadatas =\n-                FutureUtils.result(ZKLogMetadataForWriter.checkLogMetadataPaths(zkc.get(), logRootPath, ownAllocator));\n+                FutureUtils.result(checkLogMetadataPaths(zkc.get(), logRootPath, ownAllocator));\n \n         if (ownAllocator) {\n             assertEquals(\"Should have 8 paths : ownAllocator = \" + ownAllocator,\n@@ -184,7 +184,7 @@ private void testCreateLogMetadataWithMissingPaths(URI uri,\n         }\n \n         for (Versioned<byte[]> metadata : metadatas) {\n-            assertTrue(ZKLogMetadataForWriter.pathExists(metadata));\n+            assertTrue(pathExists(metadata));\n             assertTrue(((ZkVersion) metadata.getVersion()).getZnodeVersion() >= 0);\n         }\n \n@@ -300,8 +300,7 @@ public void testCreateLogMetadata() throws Exception {\n     public void testCreateLogMetadataWithCreateIfNotExistsSetToFalse() throws Exception {\n         String logName = testName.getMethodName();\n         String logIdentifier = \"<default>\";\n-        FutureUtils.result(ZKLogMetadataForWriter.of(uri, logName, logIdentifier,\n-                        zkc.get(), zkc.getDefaultACL(), true, false));\n+        FutureUtils.result(getLog(uri, logName, logIdentifier, zkc, true, false));\n     }\n \n     @Test(timeout = 60000)","previous_filename":"src/test/java/com/twitter/distributedlog/impl/metadata/TestZKLogMetadataForWriter.java"},{"sha":"f14a2177a859a03a6d72a2fc26f47a147cabbaa8","filename":"src/test/java/com/twitter/distributedlog/impl/metadata/TestZKLogStreamMetadataStoreUtils.java","status":"renamed","additions":19,"deletions":17,"changes":36,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogStreamMetadataStoreUtils.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogStreamMetadataStoreUtils.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Fimpl%2Fmetadata%2FTestZKLogStreamMetadataStoreUtils.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -28,9 +28,10 @@\n import java.net.URI;\n import java.util.List;\n \n+import static com.twitter.distributedlog.impl.metadata.ZKLogStreamMetadataStore.*;\n import static org.junit.Assert.*;\n \n-public class TestZKLogMetadataForWriterUtilFunctions {\n+public class TestZKLogStreamMetadataStoreUtils {\n \n     @SuppressWarnings(\"unchecked\")\n     @Test(timeout = 60000, expected = UnexpectedException.class)\n@@ -43,7 +44,7 @@ public void testProcessLogMetadatasMissingMaxTxnId() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null));\n-        ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n+        processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n     }\n \n     @SuppressWarnings(\"unchecked\")\n@@ -58,7 +59,7 @@ public void testProcessLogMetadatasMissingVersion() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(DLUtils.serializeTransactionId(1L), new ZkVersion(1)),\n                 new Versioned<byte[]>(null, null));\n-        ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n+        processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n     }\n \n     @SuppressWarnings(\"unchecked\")\n@@ -72,8 +73,8 @@ public void testProcessLogMetadatasWrongVersion() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(DLUtils.serializeTransactionId(1L), new ZkVersion(1)),\n-                new Versioned<byte[]>(ZKLogMetadataForWriter.intToBytes(9999), null));\n-        ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n+                new Versioned<byte[]>(intToBytes(9999), null));\n+        processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n     }\n \n     @SuppressWarnings(\"unchecked\")\n@@ -87,9 +88,9 @@ public void testProcessLogMetadatasMissingLockPath() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(DLUtils.serializeTransactionId(1L), new ZkVersion(1)),\n-                new Versioned<byte[]>(ZKLogMetadataForWriter.intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n+                new Versioned<byte[]>(intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n                 new Versioned<byte[]>(null, null));\n-        ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n+        processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n     }\n \n     @SuppressWarnings(\"unchecked\")\n@@ -103,10 +104,10 @@ public void testProcessLogMetadatasMissingReadLockPath() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(DLUtils.serializeTransactionId(1L), new ZkVersion(1)),\n-                new Versioned<byte[]>(ZKLogMetadataForWriter.intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n+                new Versioned<byte[]>(intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 new Versioned<byte[]>(null, null));\n-        ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n+        processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n     }\n \n     @SuppressWarnings(\"unchecked\")\n@@ -120,11 +121,11 @@ public void testProcessLogMetadatasMissingLogSegmentsPath() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(DLUtils.serializeTransactionId(1L), new ZkVersion(1)),\n-                new Versioned<byte[]>(ZKLogMetadataForWriter.intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n+                new Versioned<byte[]>(intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 new Versioned<byte[]>(null, null));\n-        ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n+        processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n     }\n \n     @SuppressWarnings(\"unchecked\")\n@@ -138,12 +139,12 @@ public void testProcessLogMetadatasMissingAllocatorPath() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(DLUtils.serializeTransactionId(1L), new ZkVersion(1)),\n-                new Versioned<byte[]>(ZKLogMetadataForWriter.intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n+                new Versioned<byte[]>(intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 new Versioned<byte[]>(DLUtils.serializeLogSegmentSequenceNumber(1L), new ZkVersion(1)),\n                 new Versioned<byte[]>(null, null));\n-        ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, true);\n+        processLogMetadatas(uri, logName, logIdentifier, metadatas, true);\n     }\n \n     @SuppressWarnings(\"unchecked\")\n@@ -161,12 +162,12 @@ public void testProcessLogMetadatasNoAllocatorPath() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null),\n                 maxTxnIdData,\n-                new Versioned<byte[]>(ZKLogMetadataForWriter.intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n+                new Versioned<byte[]>(intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 logSegmentsData);\n         ZKLogMetadataForWriter metadata =\n-                ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n+                processLogMetadatas(uri, logName, logIdentifier, metadatas, false);\n         assertTrue(maxTxnIdData == metadata.getMaxTxIdData());\n         assertTrue(logSegmentsData == metadata.getMaxLSSNData());\n         assertNull(metadata.getAllocationData().getValue());\n@@ -190,15 +191,16 @@ public void testProcessLogMetadatasAllocatorPath() throws Exception {\n                 new Versioned<byte[]>(null, null),\n                 new Versioned<byte[]>(null, null),\n                 maxTxnIdData,\n-                new Versioned<byte[]>(ZKLogMetadataForWriter.intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n+                new Versioned<byte[]>(intToBytes(ZKLogMetadata.LAYOUT_VERSION), null),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 new Versioned<byte[]>(new byte[0], new ZkVersion(1)),\n                 logSegmentsData,\n                 allocationData);\n         ZKLogMetadataForWriter metadata =\n-                ZKLogMetadataForWriter.processLogMetadatas(uri, logName, logIdentifier, metadatas, true);\n+                processLogMetadatas(uri, logName, logIdentifier, metadatas, true);\n         assertTrue(maxTxnIdData == metadata.getMaxTxIdData());\n         assertTrue(logSegmentsData == metadata.getMaxLSSNData());\n         assertTrue(allocationData == metadata.getAllocationData());\n     }\n+\n }","previous_filename":"src/test/java/com/twitter/distributedlog/impl/metadata/TestZKLogMetadataForWriterUtilFunctions.java"},{"sha":"db87a655cac25436f548201ef29bebc92d54ced5","filename":"src/test/java/com/twitter/distributedlog/util/TestPermitManager.java","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/blob/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestPermitManager.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/bookkeeper/raw/de4711ddf87571c4de5686385663aef3f19fcaf7/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestPermitManager.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/bookkeeper/contents/src%2Ftest%2Fjava%2Fcom%2Ftwitter%2Fdistributedlog%2Futil%2FTestPermitManager.java?ref=de4711ddf87571c4de5686385663aef3f19fcaf7","patch":"@@ -17,6 +17,7 @@\n  */\n package com.twitter.distributedlog.util;\n \n+import com.twitter.distributedlog.zk.LimitedPermitManager;\n import org.junit.Test;\n \n import java.util.ArrayList;"}]}