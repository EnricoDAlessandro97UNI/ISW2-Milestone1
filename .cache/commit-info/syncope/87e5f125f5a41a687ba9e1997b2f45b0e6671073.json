{"sha":"87e5f125f5a41a687ba9e1997b2f45b0e6671073","node_id":"MDY6Q29tbWl0NjM2ODc5MDYyOjg3ZTVmMTI1ZjVhNDFhNjg3YmE5ZTE5OTdiMmY0NWIwZTY2NzEwNzM=","commit":{"author":{"name":"Francesco Chicchiriccò","email":"ilgrosso@users.noreply.github.com","date":"2020-03-29T17:14:41Z"},"committer":{"name":"Francesco Chicchiriccò","email":"ilgrosso@apache.org","date":"2020-03-29T17:21:47Z"},"message":"Upgrading ApacheDS (#170)","tree":{"sha":"4af2a95641e90ae5afbbe96d4b9b48ceed1dffda","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/git/trees/4af2a95641e90ae5afbbe96d4b9b48ceed1dffda"},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/git/commits/87e5f125f5a41a687ba9e1997b2f45b0e6671073","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/commits/87e5f125f5a41a687ba9e1997b2f45b0e6671073","html_url":"https://github.com/EnricoDAlessandro97UNI/syncope/commit/87e5f125f5a41a687ba9e1997b2f45b0e6671073","comments_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/commits/87e5f125f5a41a687ba9e1997b2f45b0e6671073/comments","author":{"login":"ilgrosso","id":1064664,"node_id":"MDQ6VXNlcjEwNjQ2NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1064664?v=4","gravatar_id":"","url":"https://api.github.com/users/ilgrosso","html_url":"https://github.com/ilgrosso","followers_url":"https://api.github.com/users/ilgrosso/followers","following_url":"https://api.github.com/users/ilgrosso/following{/other_user}","gists_url":"https://api.github.com/users/ilgrosso/gists{/gist_id}","starred_url":"https://api.github.com/users/ilgrosso/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ilgrosso/subscriptions","organizations_url":"https://api.github.com/users/ilgrosso/orgs","repos_url":"https://api.github.com/users/ilgrosso/repos","events_url":"https://api.github.com/users/ilgrosso/events{/privacy}","received_events_url":"https://api.github.com/users/ilgrosso/received_events","type":"User","site_admin":false},"committer":{"login":"ilgrosso","id":1064664,"node_id":"MDQ6VXNlcjEwNjQ2NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1064664?v=4","gravatar_id":"","url":"https://api.github.com/users/ilgrosso","html_url":"https://github.com/ilgrosso","followers_url":"https://api.github.com/users/ilgrosso/followers","following_url":"https://api.github.com/users/ilgrosso/following{/other_user}","gists_url":"https://api.github.com/users/ilgrosso/gists{/gist_id}","starred_url":"https://api.github.com/users/ilgrosso/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ilgrosso/subscriptions","organizations_url":"https://api.github.com/users/ilgrosso/orgs","repos_url":"https://api.github.com/users/ilgrosso/repos","events_url":"https://api.github.com/users/ilgrosso/events{/privacy}","received_events_url":"https://api.github.com/users/ilgrosso/received_events","type":"User","site_admin":false},"parents":[{"sha":"894386b966b0484748880136aedfc4524fb2dd09","url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/commits/894386b966b0484748880136aedfc4524fb2dd09","html_url":"https://github.com/EnricoDAlessandro97UNI/syncope/commit/894386b966b0484748880136aedfc4524fb2dd09"}],"stats":{"total":783,"additions":694,"deletions":89},"files":[{"sha":"86a9726880c742dfc3a71cd0c52651a269cead4a","filename":"fit/build-tools/pom.xml","status":"modified","additions":4,"deletions":12,"changes":16,"blob_url":"https://github.com/EnricoDAlessandro97UNI/syncope/blob/87e5f125f5a41a687ba9e1997b2f45b0e6671073/fit%2Fbuild-tools%2Fpom.xml","raw_url":"https://github.com/EnricoDAlessandro97UNI/syncope/raw/87e5f125f5a41a687ba9e1997b2f45b0e6671073/fit%2Fbuild-tools%2Fpom.xml","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/contents/fit%2Fbuild-tools%2Fpom.xml?ref=87e5f125f5a41a687ba9e1997b2f45b0e6671073","patch":"@@ -64,23 +64,15 @@ under the License.\n     </dependency>\n     <dependency>\n       <groupId>org.apache.directory.server</groupId>\n-      <artifactId>apacheds-service-builder</artifactId>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.directory.api</groupId>\n-      <artifactId>api-ldap-codec-standalone</artifactId>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.directory.api</groupId>\n-      <artifactId>api-ldap-model</artifactId>\n+      <artifactId>apacheds-core-annotations</artifactId>\n     </dependency>\n     <dependency>\n-      <groupId>org.apache.directory.api</groupId>\n-      <artifactId>api-ldap-schema-data</artifactId>\n+      <groupId>org.apache.directory.server</groupId>\n+      <artifactId>apacheds-service-builder</artifactId>\n     </dependency>\n     <dependency>\n       <groupId>org.apache.directory.api</groupId>\n-      <artifactId>api-util</artifactId>\n+      <artifactId>api-ldap-codec-standalone</artifactId>\n     </dependency>\n \n     <dependency>"},{"sha":"e5cfb5a721d7234f6b97cb49c7b440617f573216","filename":"fit/build-tools/src/main/java/org/apache/directory/server/core/normalization/NormalizationInterceptor.java","status":"added","additions":628,"deletions":0,"changes":628,"blob_url":"https://github.com/EnricoDAlessandro97UNI/syncope/blob/87e5f125f5a41a687ba9e1997b2f45b0e6671073/fit%2Fbuild-tools%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fdirectory%2Fserver%2Fcore%2Fnormalization%2FNormalizationInterceptor.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/syncope/raw/87e5f125f5a41a687ba9e1997b2f45b0e6671073/fit%2Fbuild-tools%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fdirectory%2Fserver%2Fcore%2Fnormalization%2FNormalizationInterceptor.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/contents/fit%2Fbuild-tools%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fdirectory%2Fserver%2Fcore%2Fnormalization%2FNormalizationInterceptor.java?ref=87e5f125f5a41a687ba9e1997b2f45b0e6671073","patch":"@@ -0,0 +1,628 @@\n+/*\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing,\n+ *  software distributed under the License is distributed on an\n+ *  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ *  KIND, either express or implied.  See the License for the\n+ *  specific language governing permissions and limitations\n+ *  under the License.\n+ *\n+ */\n+package org.apache.directory.server.core.normalization;\n+\n+// Remove this class as soon as upgrade to ApacheDS 2.0.0.AM27 is available\n+\n+// CHECKSTYLE:OFF\n+\n+import org.apache.directory.api.ldap.model.constants.SchemaConstants;\n+import org.apache.directory.api.ldap.model.cursor.EmptyCursor;\n+import org.apache.directory.api.ldap.model.entry.Entry;\n+import org.apache.directory.api.ldap.model.entry.Modification;\n+import org.apache.directory.api.ldap.model.entry.Value;\n+import org.apache.directory.api.ldap.model.exception.LdapException;\n+import org.apache.directory.api.ldap.model.exception.LdapInvalidAttributeTypeException;\n+import org.apache.directory.api.ldap.model.filter.AndNode;\n+import org.apache.directory.api.ldap.model.filter.BranchNode;\n+import org.apache.directory.api.ldap.model.filter.EqualityNode;\n+import org.apache.directory.api.ldap.model.filter.ExprNode;\n+import org.apache.directory.api.ldap.model.filter.LeafNode;\n+import org.apache.directory.api.ldap.model.filter.NotNode;\n+import org.apache.directory.api.ldap.model.filter.ObjectClassNode;\n+import org.apache.directory.api.ldap.model.filter.OrNode;\n+import org.apache.directory.api.ldap.model.filter.PresenceNode;\n+import org.apache.directory.api.ldap.model.filter.UndefinedNode;\n+import org.apache.directory.api.ldap.model.name.Ava;\n+import org.apache.directory.api.ldap.model.name.Dn;\n+import org.apache.directory.api.ldap.model.name.Rdn;\n+import org.apache.directory.api.ldap.model.schema.AttributeType;\n+import org.apache.directory.api.ldap.model.schema.normalizers.ConcreteNameComponentNormalizer;\n+import org.apache.directory.api.ldap.model.schema.normalizers.NameComponentNormalizer;\n+import org.apache.directory.server.core.api.DirectoryService;\n+import org.apache.directory.server.core.api.InterceptorEnum;\n+import org.apache.directory.server.core.api.filtering.EntryFilteringCursorImpl;\n+import org.apache.directory.server.core.api.filtering.EntryFilteringCursor;\n+import org.apache.directory.server.core.api.interceptor.BaseInterceptor;\n+import org.apache.directory.server.core.api.interceptor.context.AddOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.CompareOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.DeleteOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.HasEntryOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.LookupOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.ModifyOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.MoveAndRenameOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.MoveOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.RenameOperationContext;\n+import org.apache.directory.server.core.api.interceptor.context.SearchOperationContext;\n+import org.apache.directory.server.core.api.normalization.FilterNormalizingVisitor;\n+import org.apache.directory.server.i18n.I18n;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A name normalization service.  This service makes sure all relative and distinguished\n+ * names are normalized before calls are made against the respective interface methods\n+ * on DefaultPartitionNexus.\n+ *\n+ * The Filters are also normalized.\n+ *\n+ * If the Rdn AttributeTypes are not present in the entry for an Add request,\n+ * they will be added.\n+ *\n+ * @author <a href=\"mailto:dev@directory.apache.org\">Apache Directory Project</a>\n+ */\n+public class NormalizationInterceptor extends BaseInterceptor\n+{\n+    /** logger used by this class */\n+    private static final Logger LOG = LoggerFactory.getLogger( NormalizationInterceptor.class );\n+\n+    /** a filter node value normalizer and undefined node remover */\n+    private FilterNormalizingVisitor normVisitor;\n+\n+\n+    /**\n+     * Creates a new instance of a NormalizationInterceptor.\n+     */\n+    public NormalizationInterceptor()\n+    {\n+        super( InterceptorEnum.NORMALIZATION_INTERCEPTOR );\n+    }\n+\n+\n+    /**\n+     * Initialize the registries, normalizers.\n+     */\n+    @Override\n+    public void init( DirectoryService directoryService ) throws LdapException\n+    {\n+        LOG.debug( \"Initialiazing the NormalizationInterceptor\" );\n+\n+        super.init( directoryService );\n+\n+        NameComponentNormalizer ncn = new ConcreteNameComponentNormalizer( schemaManager );\n+        normVisitor = new FilterNormalizingVisitor( ncn, schemaManager );\n+    }\n+\n+\n+    /**\n+     * The destroy method does nothing\n+     */\n+    @Override\n+    public void destroy()\n+    {\n+    }\n+\n+\n+    // ------------------------------------------------------------------------\n+    // Normalize all Name based arguments for ContextPartition interface operations\n+    // ------------------------------------------------------------------------\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void add( AddOperationContext addContext ) throws LdapException\n+    {\n+        Dn addDn = addContext.getDn();\n+        \n+        if ( !addDn.isSchemaAware() )\n+        {\n+            addContext.setDn( new Dn( schemaManager, addDn ) );\n+        }\n+        \n+        Dn entryDn = addContext.getEntry().getDn();\n+        \n+        if ( !entryDn.isSchemaAware() )\n+        {\n+            addContext.getEntry().setDn( new Dn( schemaManager, entryDn ) );\n+        }\n+        \n+        addRdnAttributesToEntry( addContext.getDn(), addContext.getEntry() );\n+        \n+        next( addContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public boolean compare( CompareOperationContext compareContext ) throws LdapException\n+    {\n+        Dn dn = compareContext.getDn();\n+        \n+        if ( !dn.isSchemaAware() )\n+        {\n+            compareContext.setDn( new Dn( schemaManager, dn ) );\n+        }\n+\n+        // Get the attributeType from the OID\n+        try\n+        {\n+            AttributeType attributeType = schemaManager.lookupAttributeTypeRegistry( compareContext.getOid() );\n+\n+            // Translate the value from binary to String if the AT is HR\n+            if ( attributeType.getSyntax().isHumanReadable() && ( !compareContext.getValue().isHumanReadable() ) )\n+            {\n+                compareContext.setValue( compareContext.getValue() );\n+            }\n+\n+            compareContext.setAttributeType( attributeType );\n+        }\n+        catch ( LdapException le )\n+        {\n+            throw new LdapInvalidAttributeTypeException( I18n.err( I18n.ERR_266, compareContext.getOid() ) );\n+        }\n+\n+        return next( compareContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void delete( DeleteOperationContext deleteContext ) throws LdapException\n+    {\n+        Dn dn = deleteContext.getDn();\n+        \n+        if ( !dn.isSchemaAware() )\n+        {\n+            deleteContext.setDn( new Dn( schemaManager, dn ) );\n+        }\n+\n+        next( deleteContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public boolean hasEntry( HasEntryOperationContext hasEntryContext ) throws LdapException\n+    {\n+        Dn dn = hasEntryContext.getDn();\n+        \n+        if ( !dn.isSchemaAware() )\n+        {\n+            hasEntryContext.setDn( new Dn( schemaManager, dn ) );\n+        }\n+\n+        return next( hasEntryContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public Entry lookup( LookupOperationContext lookupContext ) throws LdapException\n+    {\n+        Dn dn = lookupContext.getDn();\n+        \n+        if ( !dn.isSchemaAware() )\n+        {\n+            lookupContext.setDn( new Dn( schemaManager, dn ) );\n+        }\n+\n+        return next( lookupContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void modify( ModifyOperationContext modifyContext ) throws LdapException\n+    {\n+        Dn dn = modifyContext.getDn();\n+        \n+        if ( !dn.isSchemaAware() )\n+        {\n+            modifyContext.setDn( new Dn( schemaManager, dn ) );\n+        }\n+\n+        if ( modifyContext.getModItems() != null )\n+        {\n+            for ( Modification modification : modifyContext.getModItems() )\n+            {\n+                AttributeType attributeType = schemaManager.getAttributeType( modification.getAttribute().getId() );\n+                modification.apply( attributeType );\n+            }\n+        }\n+\n+        next( modifyContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void move( MoveOperationContext moveContext ) throws LdapException\n+    {\n+        Dn moveDn = moveContext.getDn();\n+        \n+        if ( !moveDn.isSchemaAware() )\n+        {\n+            moveContext.setDn( new Dn( schemaManager, moveDn ) );\n+        }\n+\n+        Dn oldSuperiorDn = moveContext.getOldSuperior();\n+        \n+        if ( !oldSuperiorDn.isSchemaAware() )\n+        {\n+            moveContext.setOldSuperior( new Dn( schemaManager, oldSuperiorDn ) );\n+        }\n+\n+        Dn newSuperiorDn = moveContext.getNewSuperior();\n+        \n+        if ( !newSuperiorDn.isSchemaAware() )\n+        {\n+            moveContext.setNewSuperior( new Dn( schemaManager, newSuperiorDn ) );\n+        }\n+        \n+        Dn newDn = moveContext.getNewDn();\n+        \n+        if ( !newDn.isSchemaAware() )\n+        {\n+            moveContext.setNewDn( new Dn( schemaManager, newDn ) );\n+        }\n+\n+        Rdn rdn = moveContext.getRdn();\n+        \n+        if ( !rdn.isSchemaAware() )\n+        {\n+            moveContext.setRdn( new Rdn( schemaManager, rdn ) );\n+        }\n+\n+        next( moveContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void moveAndRename( MoveAndRenameOperationContext moveAndRenameContext ) throws LdapException\n+    {\n+        Rdn newRdn = moveAndRenameContext.getNewRdn();\n+        \n+        if ( !newRdn.isSchemaAware() )\n+        {\n+            moveAndRenameContext.setNewRdn( new Rdn( schemaManager, newRdn ) );\n+        }\n+        \n+        Dn dn = moveAndRenameContext.getDn();\n+        \n+        if ( !dn.isSchemaAware() )\n+        {\n+            moveAndRenameContext.setDn( new Dn( schemaManager, dn ) );\n+        }\n+        \n+        Dn newDn = moveAndRenameContext.getNewDn();\n+        \n+        if ( !newDn.isSchemaAware() )\n+        {\n+            moveAndRenameContext.setNewDn( new Dn( schemaManager, newDn ) );\n+        }\n+        \n+        Dn newSuperiorDn = moveAndRenameContext.getNewSuperiorDn();\n+        \n+        if ( !newSuperiorDn.isSchemaAware() )\n+        {\n+            moveAndRenameContext.setNewSuperiorDn( new Dn( schemaManager, newSuperiorDn ) );\n+        }\n+\n+        next( moveAndRenameContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void rename( RenameOperationContext renameContext ) throws LdapException\n+    {\n+        // Normalize the new Rdn and the Dn if needed\n+        Dn dn = renameContext.getDn();\n+        \n+        if ( !dn.isSchemaAware() )\n+        {\n+            renameContext.setDn( new Dn( schemaManager, dn ) );\n+        }\n+        \n+        Rdn newRdn = renameContext.getNewRdn();\n+        \n+        if ( !newRdn.isSchemaAware() )\n+        {\n+            renameContext.setNewRdn( new Rdn( schemaManager, newRdn ) );\n+        }\n+        \n+        Dn newDn = renameContext.getNewDn();\n+        \n+        if ( !newDn.isSchemaAware() )\n+        {\n+            renameContext.setNewDn( new Dn( schemaManager, newDn ) );\n+        }\n+\n+        // Push to the next interceptor\n+        next( renameContext );\n+    }\n+\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public EntryFilteringCursor search( SearchOperationContext searchContext ) throws LdapException\n+    {\n+        Dn dn = searchContext.getDn();\n+        \n+        if ( !dn.isSchemaAware() )\n+        {\n+            searchContext.setDn( new Dn( schemaManager, dn ) );\n+        }\n+\n+        ExprNode filter = searchContext.getFilter();\n+\n+        if ( filter == null )\n+        {\n+            LOG.warn( \"undefined filter based on undefined attributeType not evaluted at all.  Returning empty enumeration.\" );\n+            return new EntryFilteringCursorImpl( new EmptyCursor<Entry>(), searchContext, schemaManager );\n+        }\n+\n+        // Normalize the filter\n+        filter = ( ExprNode ) filter.accept( normVisitor );\n+\n+        if ( filter == null )\n+        {\n+            LOG.warn( \"undefined filter based on undefined attributeType not evaluted at all.  Returning empty enumeration.\" );\n+            return new EntryFilteringCursorImpl( new EmptyCursor<Entry>(), searchContext, schemaManager );\n+        }\n+\n+        // We now have to remove the (ObjectClass=*) filter if it's present, and to add the scope filter\n+        ExprNode modifiedFilter = removeObjectClass( filter );\n+\n+        searchContext.setFilter( modifiedFilter );\n+\n+        // TODO Normalize the returned Attributes, storing the UP attributes to format the returned values.\n+        return next( searchContext );\n+    }\n+\n+\n+    /**\n+     * Remove the (ObjectClass=*) node from an AndNode, if we have one.\n+     */\n+    private ExprNode handleAndNode( ExprNode node )\n+    {\n+        int nbNodes = 0;\n+        AndNode newAndNode = new AndNode();\n+\n+        for ( ExprNode child : ( ( BranchNode ) node ).getChildren() )\n+        {\n+            ExprNode modifiedNode = removeObjectClass( child );\n+\n+            if ( !( modifiedNode instanceof ObjectClassNode ) )\n+            {\n+                newAndNode.addNode( modifiedNode );\n+                nbNodes++;\n+            }\n+\n+            if ( modifiedNode instanceof UndefinedNode )\n+            {\n+                // We can just return an Undefined node as nothing will get selected\n+                return UndefinedNode.UNDEFINED_NODE;\n+            }\n+        }\n+\n+        switch ( nbNodes )\n+        {\n+            case 0:\n+                // Unlikely... But (&(ObjectClass=*)) or (|(ObjectClass=*)) are still an option\n+                return ObjectClassNode.OBJECT_CLASS_NODE;\n+\n+            case 1:\n+                // We can safely remove the AND/OR node and replace it with its first child\n+                return newAndNode.getFirstChild();\n+\n+            default:\n+                return newAndNode;\n+        }\n+    }\n+\n+\n+    /**\n+     * Remove the (ObjectClass=*) node from a NotNode, if we have one.\n+     */\n+    private ExprNode handleNotNode( ExprNode node )\n+    {\n+        NotNode newNotNode = new NotNode();\n+\n+        for ( ExprNode child : ( ( BranchNode ) node ).getChildren() )\n+        {\n+            ExprNode modifiedNode = removeObjectClass( child );\n+\n+            if ( modifiedNode instanceof ObjectClassNode )\n+            {\n+                // We don't want any entry which has an ObjectClass, return an undefined node\n+                return UndefinedNode.UNDEFINED_NODE;\n+            }\n+\n+            if ( modifiedNode instanceof UndefinedNode )\n+            {\n+                // Here, we will select everything\n+                return ObjectClassNode.OBJECT_CLASS_NODE;\n+            }\n+            \n+            newNotNode.addNode( modifiedNode );\n+\n+        }\n+\n+        return newNotNode;\n+    }\n+\n+\n+    /**\n+     * Remove the (ObjectClass=*) node from an OrNode, if we have one.\n+     */\n+    private ExprNode handleOrNode( ExprNode node )\n+    {\n+        OrNode newOrNode = new OrNode();\n+\n+        for ( ExprNode child : ( ( BranchNode ) node ).getChildren() )\n+        {\n+            ExprNode modifiedNode = removeObjectClass( child );\n+\n+            if ( modifiedNode instanceof ObjectClassNode )\n+            {\n+                // We can return immediately with an ObjectClass node\n+                return ObjectClassNode.OBJECT_CLASS_NODE;\n+            }\n+            \n+            newOrNode.addNode( modifiedNode );\n+        }\n+\n+        return newOrNode;\n+    }\n+\n+\n+    /**\n+     * Remove the (ObjectClass=*) and ( ObjectClass=top) nodes from the filter, if we have one.\n+     */\n+    private ExprNode removeObjectClass( ExprNode node )\n+    {\n+        if ( node instanceof LeafNode )\n+        {\n+            LeafNode leafNode = ( LeafNode ) node;\n+\n+            if ( leafNode.getAttributeType() == directoryService.getAtProvider().getObjectClass() )\n+            {\n+                if ( leafNode instanceof PresenceNode )\n+                {\n+                    // We can safely remove the node and return an undefined node\n+                    return ObjectClassNode.OBJECT_CLASS_NODE;\n+                }\n+                else if ( leafNode instanceof EqualityNode )\n+                {\n+                    Value value = ( ( EqualityNode<String> ) leafNode ).getValue();\n+\n+                    if ( value.equals( SchemaConstants.TOP_OC ) )\n+                    {\n+                        // Here too we can safely remove the node and return an undefined node\n+                        return ObjectClassNode.OBJECT_CLASS_NODE;\n+                    }\n+                }\n+            }\n+        }\n+\n+        // --------------------------------------------------------------------\n+        //                 H A N D L E   B R A N C H   N O D E S\n+        // --------------------------------------------------------------------\n+\n+        if ( node instanceof AndNode )\n+        {\n+            return handleAndNode( node );\n+        }\n+        else if ( node instanceof OrNode )\n+        {\n+            return handleOrNode( node );\n+        }\n+        else if ( node instanceof NotNode )\n+        {\n+            return handleNotNode( node );\n+        }\n+        else\n+        {\n+            // Failover : we return the initial node as is\n+            return node;\n+        }\n+    }\n+\n+\n+    // ------------------------------------------------------------------------\n+    // Normalize all Name based arguments for other interface operations\n+    // ------------------------------------------------------------------------\n+    /**\n+     * Adds missing Rdn's attributes and values to the entry.\n+     *\n+     * @param dn the Dn\n+     * @param entry the entry\n+     */\n+    private void addRdnAttributesToEntry( Dn dn, Entry entry ) throws LdapException\n+    {\n+        if ( dn == null || entry == null )\n+        {\n+            return;\n+        }\n+\n+        Rdn rdn = dn.getRdn();\n+\n+        // Loop on all the AVAs\n+        for ( Ava ava : rdn )\n+        {\n+            Value value = ava.getValue();\n+            String upValue = ava.getValue().getString();\n+            String upId = ava.getType();\n+\n+            // Check that the entry contains this Ava\n+            if ( !entry.contains( upId, value ) )\n+            {\n+                String message = \"The Rdn '\" + upId + \"=\" + upValue + \"' is not present in the entry\";\n+                LOG.warn( message );\n+\n+                // We don't have this attribute : add it.\n+                // Two cases :\n+                // 1) The attribute does not exist\n+                if ( !entry.containsAttribute( upId ) )\n+                {\n+                    entry.add( upId, upValue );\n+                }\n+                // 2) The attribute exists\n+                else\n+                {\n+                    AttributeType at = schemaManager.lookupAttributeTypeRegistry( upId );\n+\n+                    // 2.1 if the attribute is single valued, replace the value\n+                    if ( at.isSingleValued() )\n+                    {\n+                        entry.removeAttributes( upId );\n+                        entry.add( upId, upValue );\n+                    }\n+                    // 2.2 the attribute is multi-valued : add the missing value\n+                    else\n+                    {\n+                        entry.add( upId, upValue );\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}"},{"sha":"6a3322fdbe69b3f54f1cff9931d0ee2349c40e1d","filename":"fit/build-tools/src/main/java/org/apache/syncope/fit/buildtools/ApacheDSStartStopListener.java","status":"modified","additions":55,"deletions":60,"changes":115,"blob_url":"https://github.com/EnricoDAlessandro97UNI/syncope/blob/87e5f125f5a41a687ba9e1997b2f45b0e6671073/fit%2Fbuild-tools%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fsyncope%2Ffit%2Fbuildtools%2FApacheDSStartStopListener.java","raw_url":"https://github.com/EnricoDAlessandro97UNI/syncope/raw/87e5f125f5a41a687ba9e1997b2f45b0e6671073/fit%2Fbuild-tools%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fsyncope%2Ffit%2Fbuildtools%2FApacheDSStartStopListener.java","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/contents/fit%2Fbuild-tools%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fsyncope%2Ffit%2Fbuildtools%2FApacheDSStartStopListener.java?ref=87e5f125f5a41a687ba9e1997b2f45b0e6671073","patch":"@@ -19,17 +19,23 @@\n package org.apache.syncope.fit.buildtools;\n \n import java.io.File;\n-import java.util.HashSet;\n+import java.io.IOException;\n import java.util.List;\n import java.util.Objects;\n import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n import javax.servlet.ServletContext;\n import javax.servlet.ServletContextEvent;\n import javax.servlet.ServletContextListener;\n import javax.servlet.annotation.WebListener;\n+import org.apache.directory.api.ldap.model.constants.SchemaConstants;\n import org.apache.directory.api.ldap.model.entry.Entry;\n import org.apache.directory.api.ldap.model.name.Dn;\n+import org.apache.directory.api.ldap.model.schema.LdapComparator;\n import org.apache.directory.api.ldap.model.schema.SchemaManager;\n+import org.apache.directory.api.ldap.model.schema.comparators.NormalizingComparator;\n+import org.apache.directory.api.ldap.model.schema.registries.ComparatorRegistry;\n import org.apache.directory.api.ldap.model.schema.registries.SchemaLoader;\n import org.apache.directory.api.ldap.schema.extractor.SchemaLdifExtractor;\n import org.apache.directory.api.ldap.schema.extractor.impl.DefaultSchemaLdifExtractor;\n@@ -38,12 +44,12 @@\n import org.apache.directory.api.util.exception.Exceptions;\n import org.apache.directory.server.constants.ServerDNConstants;\n import org.apache.directory.server.core.DefaultDirectoryService;\n-import org.apache.directory.server.core.api.CacheService;\n import org.apache.directory.server.core.api.DirectoryService;\n import org.apache.directory.server.core.api.DnFactory;\n import org.apache.directory.server.core.api.InstanceLayout;\n import org.apache.directory.server.core.api.partition.Partition;\n import org.apache.directory.server.core.api.schema.SchemaPartition;\n+import org.apache.directory.server.core.factory.JdbmPartitionFactory;\n import org.apache.directory.server.core.partition.impl.btree.jdbm.JdbmIndex;\n import org.apache.directory.server.core.partition.impl.btree.jdbm.JdbmPartition;\n import org.apache.directory.server.core.partition.ldif.LdifPartition;\n@@ -78,7 +84,7 @@ public class ApacheDSStartStopListener implements ServletContextListener {\n      * @return The newly added partition\n      * @throws Exception If the partition can't be added\n      */\n-    private Partition addPartition(final String partitionId, final String partitionDn, final DnFactory dnFactory)\n+    private void addPartition(final String partitionId, final String partitionDn, final DnFactory dnFactory)\n             throws Exception {\n \n         // Create a new partition with the given partition id\n@@ -88,24 +94,11 @@ private Partition addPartition(final String partitionId, final String partitionD\n         partition.setSuffixDn(new Dn(partitionDn));\n         service.addPartition(partition);\n \n-        return partition;\n-    }\n-\n-    /**\n-     * Add a new set of index on the given attributes.\n-     *\n-     * @param partition The partition on which we want to add index\n-     * @param attrs The list of attributes to index\n-     */\n-    private static void addIndex(final Partition partition, final String... attrs) {\n-        // Index some attributes on the apache partition\n-        Set<Index<?, String>> indexedAttributes = new HashSet<>();\n-\n-        for (String attribute : attrs) {\n-            indexedAttributes.add(new JdbmIndex<String>(attribute, false));\n-        }\n-\n-        ((JdbmPartition) partition).setIndexedAttributes(indexedAttributes);\n+        Set<Index<?, String>> indexedAttributes = Stream.of(\n+                SchemaConstants.OBJECT_CLASS_AT, SchemaConstants.OU_AT,\n+                SchemaConstants.UID_AT, SchemaConstants.CN_AT).\n+                map(attr -> new JdbmIndex<String>(attr, false)).collect(Collectors.toSet());\n+        partition.setIndexedAttributes(indexedAttributes);\n     }\n \n     /**\n@@ -114,41 +107,63 @@ private static void addIndex(final Partition partition, final String... attrs) {\n      * @throws Exception if the schema LDIF files are not found on the classpath\n      */\n     private void initSchemaPartition() throws Exception {\n-        InstanceLayout instanceLayout = service.getInstanceLayout();\n-\n-        File schemaPartitionDirectory = new File(instanceLayout.getPartitionsDirectory(), \"schema\");\n+        File workingDirectory = service.getInstanceLayout().getPartitionsDirectory();\n \n         // Extract the schema on disk (a brand new one) and load the registries\n-        if (schemaPartitionDirectory.exists()) {\n-            LOG.debug(\"schema partition already exists, skipping schema extraction\");\n-        } else {\n-            SchemaLdifExtractor extractor = new DefaultSchemaLdifExtractor(instanceLayout.getPartitionsDirectory());\n+        File schemaRepository = new File(workingDirectory, \"schema\");\n+        SchemaLdifExtractor extractor = new DefaultSchemaLdifExtractor(workingDirectory);\n+        try {\n             extractor.extractOrCopy();\n+        } catch (IOException ioe) {\n+            // The schema has already been extracted, bypass\n         }\n \n-        SchemaLoader loader = new LdifSchemaLoader(schemaPartitionDirectory);\n+        SchemaLoader loader = new LdifSchemaLoader(schemaRepository);\n         SchemaManager schemaManager = new DefaultSchemaManager(loader);\n \n         // We have to load the schema now, otherwise we won't be able\n-        // to initialize the Partitions, as we won't be able to parse\n+        // to initialize the Partitions, as we won't be able to parse \n         // and normalize their suffix Dn\n         schemaManager.loadAllEnabled();\n \n+        // Tell all the normalizer comparators that they should not normalize anything\n+        ComparatorRegistry comparatorRegistry = schemaManager.getComparatorRegistry();\n+        for (LdapComparator<?> comparator : comparatorRegistry) {\n+            if (comparator instanceof NormalizingComparator) {\n+                ((NormalizingComparator) comparator).setOnServer();\n+            }\n+        }\n+\n+        service.setSchemaManager(schemaManager);\n+\n+        // Init the LdifPartition\n+        LdifPartition ldifPartition = new LdifPartition(schemaManager, service.getDnFactory());\n+        ldifPartition.setPartitionPath(new File(workingDirectory, \"schema\").toURI());\n+        SchemaPartition schemaPartition = new SchemaPartition(schemaManager);\n+        schemaPartition.setWrappedPartition(ldifPartition);\n+        service.setSchemaPartition(schemaPartition);\n+\n         List<Throwable> errors = schemaManager.getErrors();\n         if (!errors.isEmpty()) {\n             throw new IllegalStateException(I18n.err(I18n.ERR_317, Exceptions.printErrors(errors)));\n         }\n+    }\n \n-        service.setSchemaManager(schemaManager);\n+    private void initSystemPartition() throws Exception {\n+        JdbmPartitionFactory partitionFactory = new JdbmPartitionFactory();\n \n-        // Init the LdifPartition with schema\n-        LdifPartition schemaLdifPartition = new LdifPartition(schemaManager, service.getDnFactory());\n-        schemaLdifPartition.setPartitionPath(schemaPartitionDirectory.toURI());\n+        Partition systemPartition = partitionFactory.createPartition(\n+                service.getSchemaManager(),\n+                service.getDnFactory(),\n+                \"system\",\n+                ServerDNConstants.SYSTEM_DN,\n+                500,\n+                new File(service.getInstanceLayout().getPartitionsDirectory(), \"system\"));\n+        systemPartition.setSchemaManager(service.getSchemaManager());\n \n-        // The schema partition\n-        SchemaPartition schemaPartition = new SchemaPartition(schemaManager);\n-        schemaPartition.setWrappedPartition(schemaLdifPartition);\n-        service.setSchemaPartition(schemaPartition);\n+        partitionFactory.addIndex(systemPartition, SchemaConstants.OBJECT_CLASS_AT, 100);\n+\n+        service.setSystemPartition(systemPartition);\n     }\n \n     /**\n@@ -166,38 +181,18 @@ private void initDirectoryService(final ServletContext servletContext, final Fil\n         service = new DefaultDirectoryService();\n         service.setInstanceLayout(new InstanceLayout(workDir));\n \n-        CacheService cacheService = new CacheService();\n-        cacheService.initialize(service.getInstanceLayout());\n-\n-        service.setCacheService(cacheService);\n-\n         // first load the schema\n         initSchemaPartition();\n \n         // then the system partition\n-        // this is a MANDATORY partition\n-        // DO NOT add this via addPartition() method, trunk code complains about duplicate partition\n-        // while initializing\n-        JdbmPartition systemPartition = new JdbmPartition(service.getSchemaManager(), service.getDnFactory());\n-        systemPartition.setId(\"system\");\n-        systemPartition.setPartitionPath(\n-                new File(service.getInstanceLayout().getPartitionsDirectory(), systemPartition.getId()).toURI());\n-        systemPartition.setSuffixDn(new Dn(ServerDNConstants.SYSTEM_DN));\n-        systemPartition.setSchemaManager(service.getSchemaManager());\n-\n-        // mandatory to call this method to set the system partition\n-        // Note: this system partition might be removed from trunk\n-        service.setSystemPartition(systemPartition);\n+        initSystemPartition();\n \n         // Disable the ChangeLog system\n         service.getChangeLog().setEnabled(false);\n         service.setDenormalizeOpAttrsEnabled(true);\n \n         // Now we can create as many partitions as we need\n-        Partition ispPartition = addPartition(\"isp\", \"o=isp\", service.getDnFactory());\n-\n-        // Index some attributes on the apache partition\n-        addIndex(ispPartition, \"objectClass\", \"ou\", \"uid\");\n+        addPartition(\"isp\", \"o=isp\", service.getDnFactory());\n \n         // And start the service\n         service.startup();"},{"sha":"900830b6bbe59a035e86fd928a6617221bc51c64","filename":"pom.xml","status":"modified","additions":7,"deletions":17,"changes":24,"blob_url":"https://github.com/EnricoDAlessandro97UNI/syncope/blob/87e5f125f5a41a687ba9e1997b2f45b0e6671073/pom.xml","raw_url":"https://github.com/EnricoDAlessandro97UNI/syncope/raw/87e5f125f5a41a687ba9e1997b2f45b0e6671073/pom.xml","contents_url":"https://api.github.com/repos/EnricoDAlessandro97UNI/syncope/contents/pom.xml?ref=87e5f125f5a41a687ba9e1997b2f45b0e6671073","patch":"@@ -434,8 +434,8 @@ under the License.\n \n     <elasticsearch.version>7.6.1</elasticsearch.version>\n \n-    <apacheds.version>2.0.0.AM25</apacheds.version>\n-    <apachedirapi.version>2.0.0.AM2</apachedirapi.version>\n+    <apacheds.version>2.0.0.AM26</apacheds.version>\n+    <apachedirapi.version>2.0.0</apachedirapi.version>\n \n     <log4j.version>2.13.1</log4j.version>\n     <disruptor.version>3.4.2</disruptor.version>\n@@ -1286,6 +1286,11 @@ under the License.\n         <artifactId>apacheds-core-api</artifactId>\n         <version>${apacheds.version}</version>\n       </dependency>\n+      <dependency>\n+        <groupId>org.apache.directory.server</groupId>\n+        <artifactId>apacheds-core-annotations</artifactId>\n+        <version>${apacheds.version}</version>\n+      </dependency>\n       <dependency>\n         <groupId>org.apache.directory.server</groupId>\n         <artifactId>apacheds-service-builder</artifactId>\n@@ -1302,21 +1307,6 @@ under the License.\n         <artifactId>api-ldap-codec-standalone</artifactId>\n         <version>${apachedirapi.version}</version>\n       </dependency>\n-      <dependency>\n-        <groupId>org.apache.directory.api</groupId>\n-        <artifactId>api-ldap-model</artifactId>\n-        <version>${apachedirapi.version}</version>\n-      </dependency>\n-      <dependency>\n-        <groupId>org.apache.directory.api</groupId>\n-        <artifactId>api-ldap-schema-data</artifactId>\n-        <version>${apachedirapi.version}</version>\n-      </dependency>\n-      <dependency>\n-        <groupId>org.apache.directory.api</groupId>\n-        <artifactId>api-util</artifactId>\n-        <version>${apachedirapi.version}</version>\n-      </dependency>\n \n       <dependency>\n         <groupId>com.icegreen</groupId>"}]}